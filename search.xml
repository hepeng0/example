<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Spring三级缓存解决循环依赖</title>
      <link href="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/"/>
      <url>/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/</url>
      
        <content type="html"><![CDATA[<p>前置阅读<a href="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/" title="初读Spring的Bean生命周期">初读Spring的Bean生命周期</a></p><h3 id="三级缓存具体是什么"><a href="#三级缓存具体是什么" class="headerlink" title="三级缓存具体是什么"></a>三级缓存具体是什么</h3><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img.png"></p><p>可以看到填充属性的时候，spring会提前将已经实例化的bean通过ObjectFactory半成品暴露出去。</p><p>为什么称为半成品是因为这时候的bean对象实例化，但是未进行属性填充，是一个不完整的bean实例对象。</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_1.png"></p><p><strong>spring利用singletonObjects, earlySingletonObjects, singletonFactories三级缓存去解决的，所说的缓存其实也就是三个Map</strong></p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_2.png"></p><p>可以看到三级缓存各自保存的对象，这里重点关注二级缓存earlySingletonObjects和三级缓存singletonFactory，一级缓存可以进行忽略。</p><p>前面我们讲过先实例化的bean会通过ObjectFactory半成品提前暴露在三级缓存中</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_3.png"></p><p>singletonFactory是传入的一个匿名内部类，调用ObjectFactory.getObject()最终会调用getEarlyBeanReference方法。</p><h3 id="循环依赖中是怎么拿其它半成品的实例对象"><a href="#循环依赖中是怎么拿其它半成品的实例对象" class="headerlink" title="循环依赖中是怎么拿其它半成品的实例对象"></a>循环依赖中是怎么拿其它半成品的实例对象</h3><p>我们假设现在有这样的场景AService依赖BService，BService依赖AService</p><ol><li><p>AService首先实例化，实例化通过ObjectFactory半成品暴露在三级缓存中</p></li><li><p>填充属性BService，发现BService还未进行过加载，就会先去加载BService</p></li><li><p>再加载BService的过程中，实例化，也通过ObjectFactory半成品暴露在三级缓存</p></li><li><p>填充属性AService的时候，这时候能够从三级缓存中拿到半成品的ObjectFactory<br> <img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_4.png"><br> 三级缓存拿到ObjectFactory对象后，调用ObjectFactory.getObject()方法最终会调用getEarlyBeanReference()方法。</p><p> <strong>getEarlyBeanReference</strong>这个方法主要逻辑大概描述下如果bean被AOP切面代理则返回的是beanProxy对象，如果未被代理则返回的是原bean实例。</p><p>这时我们会发现能够拿到bean实例(属性未填充)，然后从三级缓存移除，放到二级缓存earlySingletonObjects中，而此时B注入的是一个半成品的实例A对象，不过随着B初始化完成后，A会继续进行后续的初始化操作，最终B会注入的是一个完整的A实例，因为在内存中它们是同一个对象。</p></li></ol><h3 id="为什么必须要三级缓存"><a href="#为什么必须要三级缓存" class="headerlink" title="为什么必须要三级缓存"></a>为什么必须要三级缓存</h3><p>我们发现这个二级缓存好像显得有点多余，好像可以去掉，只需要一级和三级缓存也可以做到解决循环依赖的问题？？？</p><p><strong>只要两个缓存确实可以做到解决循环依赖的问题，但是有一个前提这个bean没被AOP进行切面代理</strong></p><p>如果这个bean被AOP进行了切面代理，那么只使用两个缓存是无法解决问题。</p><p>下面来看一下bean被AOP进行了切面代理的场景：</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_5.png"></p><p>我们发现AService的testAopProxy被AOP代理了，看看传入的匿名内部类的getEarlyBeanReference返回的是什么对象。</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_6.png"></p><p>发现singletonFactory.getObject()返回的是一个AService的代理对象，还是被CGLIB代理的。</p><p>再看一张再执行一遍singletonFactory.getObject()返回的是否是同一个AService的代理对象</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_7.png"></p><p>我们会发现再执行一遍singleFactory.getObject()方法又是一个新的代理对象。</p><p>这就会有问题了，因为AService是单例的，每次执行singleFactory.getObject()方法又会产生新的代理对象。</p><p>假设这里只有一级和三级缓存的话，我每次从三级缓存中拿到singleFactory对象，执行getObject()方法又会产生新的代理对象，这是不行的，因为AService是单例的，所有这里我们要借助二级缓存来解决这个问题，将执行了singleFactory.getObject()产生的对象放到二级缓存中去，后面去二级缓存中拿，没必要再执行一遍singletonFactory.getObject()方法再产生一个新的代理对象，保证始终只有一个代理对象。</p><p>还有一个注意的点</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_8.png"></p><p>既然singleFactory.getObject()返回的是代理对象，那么注入的也应该是代理对象，我们可以看到注入的确实是经过CGLIB代理的AService对象。</p><p>所以<strong>如果没有AOP的话确实可以两级缓存就可以解决循环依赖的问题；如果加上AOP，每次执行singleFactory.getObject()方法会产生一个新的代理对象，所以还要借助另外一个缓存来保存产生的代理对象</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Bean </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初读Spring的Bean生命周期</title>
      <link href="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
      <url>/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="Bean的生命周期"><a href="#Bean的生命周期" class="headerlink" title="Bean的生命周期"></a>Bean的生命周期</h2><p>在spring的BeanFactory工厂列举了很多接口，代表着bean的生命周期。</p><details><summary>public interface BeanFactory</summary><ul><li>@author Rod Johnson</li><li>@author Juergen Hoeller</li><li>@author Chris Beams</li><li>@since 13 April 2001</li><li>@see BeanNameAware#setBeanName</li><li>@see BeanClassLoaderAware#setBeanClassLoader</li><li>@see BeanFactoryAware#setBeanFactory</li><li>@see org.springframework.context.ResourceLoaderAware#setResourceLoader</li><li>@see org.springframework.context.ApplicationEventPublisherAware#setApplicationEventPublisher</li><li>@see org.springframework.context.MessageSourceAware#setMessageSource</li><li>@see org.springframework.context.ApplicationContextAware#setApplicationContext</li><li>@see org.springframework.web.context.ServletContextAware#setServletContext</li><li>@see org.springframework.beans.factory.config.BeanPostProcessor#postProcessBeforeInitialization</li><li>@see InitializingBean#afterPropertiesSet</li><li>@see org.springframework.beans.factory.support.RootBeanDefinition#getInitMethodName</li><li>@see org.springframework.beans.factory.config.BeanPostProcessor#postProcessAfterInitialization</li><li>@see DisposableBean#destroy</li><li>@see org.springframework.beans.factory.support.RootBeanDefinition#getDestroyMethodName</li></ul></details><p>我们结合spring的源码来看这些接口主要是在哪里调用的。</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_1.png"></p><h4 id="第一步：-AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始"><a href="#第一步：-AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始" class="headerlink" title="第一步： AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始"></a>第一步： AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始</h4><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img.png"></p><p>我们可以看到首先需要实例化这个bean，也就是在堆中开辟一块内存空间给这个对象，createBeanInstance方法里面逻辑大概就是采用反射生成实例对象， 进行到这里表示对象还并未进行属性的填充，也就是@Autowired注解的属性还未得到注入</p><h3 id="第二步：-填充bean的成员属性"><a href="#第二步：-填充bean的成员属性" class="headerlink" title="第二步： 填充bean的成员属性"></a>第二步： 填充bean的成员属性</h3><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_2.png"></p><p>populateBean内逻辑大致就是对使用到了注入属性的注解就会进行注入，如果在注入的过程发现注入的对象还没生成，则会跑去生产要注入的对象</p><h3 id="第三步-调用initializeBean方法初始化bean内容"><a href="#第三步-调用initializeBean方法初始化bean内容" class="headerlink" title="第三步: 调用initializeBean方法初始化bean内容"></a>第三步: 调用initializeBean方法初始化bean内容</h3><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_3.png"></p><p>可以看到initializeBean方法中，首先调用的是使用的Aware接口的方法，我们具体看一下invokeAwareMethods方法中会调用Aware接口的那些方法</p><h4 id="invokeAwareMethods调用实现Aware接口的方法"><a href="#invokeAwareMethods调用实现Aware接口的方法" class="headerlink" title="invokeAwareMethods调用实现Aware接口的方法"></a>invokeAwareMethods调用实现Aware接口的方法</h4><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_4.png"></p><p>如果我们实现了BeanNameAware，BeanClassLoaderAware，BeanFactoryAware三个Aware接口的话，会依次调用setBeanName(), setBeanClassLoader(), setBeanFactory()方法</p><h4 id="applyBeanPostProcessorsBeforeInitialization"><a href="#applyBeanPostProcessorsBeforeInitialization" class="headerlink" title="applyBeanPostProcessorsBeforeInitialization"></a>applyBeanPostProcessorsBeforeInitialization</h4><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_5.png"></p><p>如果有类实现了BeanPostProcessor接口，就会执行postProcessBeforeInitialization方法，这里需要注意的是：</p><ul><li><p>如果多个类实现BeanPostProcessor接口，那么多个实现类都会执行postProcessBeforeInitialization方法，可以看到是for循环依次执行的。</p></li><li><p>如果加载A类到spring容器中，A类也重写了BeanPostProcessor接口的postProcessBeforeInitialization方法，这时要注意<strong>A类的postProcessBeforeInitialization方法并不会得到执行</strong>，因为A类还未加载完成，还未完全放到spring的singletonObjects一级缓存中。</p></li><li><p>可以看到ApplicationContextAwareProcessor也实现了BeanPostProcessor接口，重写了postProcessBeforeInitialization方法，方法里面并调用了invokeAwareInterfaces方法，而invokeAwareInterfaces方法也写着如果实现了众多的Aware接口，则会依次执行相应的方法，值得注意的是ApplicationContextAware接口的setApplicationContext方法<br>  <img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_6.png"><br>  <img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_7.png"><br>  <img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_8.png"></p></li></ul><h4 id="invokeInitMethods"><a href="#invokeInitMethods" class="headerlink" title="invokeInitMethods"></a>invokeInitMethods</h4><p>如果实现了InitializingBean接口，重写了afterPropertiesSet方法，则会调用afterPropertiesSet方法。</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_9.png"></p><p>最后还会调用是否指定了init-method，可以通过标签，或者@Bean注解的initMethod指定</p><h4 id="applyBeanPostProcessorsAfterInitialization"><a href="#applyBeanPostProcessorsAfterInitialization" class="headerlink" title="applyBeanPostProcessorsAfterInitialization"></a>applyBeanPostProcessorsAfterInitialization</h4><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_10.png"></p><p>跟之前的postProcessBeforeInitialization方法类似，也是循环遍历实现了BeanPostProcessor的接口实现类，执行postProcessAfterInitialization方法。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Bean </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB原理篇之数据页与索引初探</title>
      <link href="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/"/>
      <url>/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<p>文档说明：转载自<a href="https://mp.weixin.qq.com/s/BVqxg-k8Ro4wAisktLT0Tg">InnoDB原理篇：聊聊数据页变成索引这件事</a><br>文档意义：通过数据页到最后的索引，体会数据库查询优化的过程</p><h2 id="数据页"><a href="#数据页" class="headerlink" title="数据页"></a>数据页</h2><p>数据库执行<code>CRUD</code>的时候，都会从磁盘上加载数据页到<code>Buffer Pool</code>的缓存页里去，更新缓存页后，由异步线程刷回磁盘的数据页。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img.png"></p><p>所以MySQL进行数据操作的最小单位是数据页，接下来就分析分析，数据页到底长什么样。</p><p>每个数据页默认16kb的大小，数据页由多个部分组成，如下图所示</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_1.png"></p><h3 id="空闲空间"><a href="#空闲空间" class="headerlink" title="空闲空间"></a>空闲空间</h3><p>其实数据页还未写入数据时，是没有数据行的，只有空闲空间。</p><p>一旦写入，空闲空间会减少一些，直到空闲空间耗尽，具体过程如下图</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_2.png"></p><p>数据页满了，自然需要开辟新的数据页出来存储数据。</p><p>但是随着数据页多起来，它们怎么知道上一页与下一页在那呢？</p><h3 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h3><p>其实在数据页文件头中存放了特别多的信息，如当前页号、页类型、所属表空间、上一页号、下一页号等等。</p><p>所以数据页是通过上下页号，组成双向链表，如下图所示</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_3.png"></p><p>数据页内部会存储一行一行的数据，每一行数据都会按照主键大小进行排序存储，同时每一行数据都有指针指向下一行数据，组成单向链表。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_4.png"></p><p>但是这个结构并不高效，假设根据主键ID查询数据，只能进入数据页，挨个挨个的对单向链表遍历查询。</p><p>所以要再加点料，把<strong>二分查找</strong>利用起来</p><h3 id="数据页目录"><a href="#数据页目录" class="headerlink" title="数据页目录"></a>数据页目录</h3><p>这个料就是数据页目录部分，数据页目录存储的内容就是主键ID和行位置。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_5.png"></p><p>这样就可以通过数据页目录走二分查找，快速定位到数据页内的数据行。</p><p>如果只有一个数据页，倒没啥问题，哪有成千上万个数据页呢，还是得一个一个进数据页，搜索数据页目录。</p><p>有没有觉得，这似乎是在做全表扫描？</p><p>没错，在没有索引的情况下，数据库就是这样执行的。</p><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>如果没有索引，查询速度可以说是慢到惊人，一般是不能让查询走全表扫描的。</p><p>因此数据库中的查询，必须要运用索引来加速。</p><h3 id="页分裂"><a href="#页分裂" class="headerlink" title="页分裂"></a>页分裂</h3><p>在说索引之前，先说个前置知识，索引的核心基础要求后一个数据页的主键值都大于前面一个数据页的主键值，如果你的主键是自增的，可以保证这一点。</p><p>但有时候主键并不是自增长的，可能会出现后一个数据页的主键值小于前一个数据页的主键值。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_6.png"></p><p>为了保证索引的核心基础，有个交换行数据的过程，这个过程叫页分裂。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_7.png"></p><p>过程如下：</p><ul><li>数据页0的id=6行数据挪到数据页1</li><li>数据页1的页目录更新</li><li>数据页1的id=3行数据挪到数据页0</li><li>数据页0的页目录更新</li></ul><h3 id="主键目录"><a href="#主键目录" class="headerlink" title="主键目录"></a>主键目录</h3><p>好了，现在我们以主键为例，创建一个主键索引，这个主键索引就是主键目录，它会维护所有数据页的最小主键值与对应的页号。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_8.png"></p><p>有了主键目录的加持，那找数据就非常快了，过程如下：</p><ul><li>二分查找主键目录，找到对应的数据页</li><li>进入数据页，二分查找数据页目录，找到对应的行数据</li></ul><p>可是又来一个新问题，表里的数据可能有几百万，几千万，甚至几亿条数据，会有大量的数据页，意味着主键目录要存储大量的数据页号和最小主键值。</p><p>可能主键目录存储不下，就算能存储，海量的数据仅仅靠二分查找也很吃力。</p><p>所以InnoDB实际上是把主键目录数据存储在多个数据页中，我们把这个数据页称为索引页</p><h3 id="索引页"><a href="#索引页" class="headerlink" title="索引页"></a>索引页</h3><p>索引页，顾名思义，就是存储索引信息的数据页，在数据页的文件头部，有页类型来进行区分。</p><p>索引页会存储两类内容，一类是最小主键值与索引页号，另一类是最小主键值与数据页号。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_9.png"></p><p>把大量的索引信息分散在多个索引页中，再将多个索引页组建成B+树结构，方便二分查找，结构如下图</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_10.png"></p><p>一直说InnoDB的索引是用B+树来组成的，其实就是这个意思，当然真实的B+树不长这样，这样画还是为了帮助大家理解。</p><p>现在整个搜索过程就十分简单了：</p><ul><li>根据主键id二分查找索引页</li><li>找到对应索引页，再二分查找数据页</li><li>进入数据页，二分查找数据页目录，找到对应的行数据</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库MySQL系列之主从同步与GTID特性</title>
      <link href="/2022/02/24/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8EGTID%E7%89%B9%E6%80%A7/"/>
      <url>/2022/02/24/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8EGTID%E7%89%B9%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL主从同步原理"><a href="#MySQL主从同步原理" class="headerlink" title="MySQL主从同步原理"></a>MySQL主从同步原理</h2><h3 id="为什么需要主从同步"><a href="#为什么需要主从同步" class="headerlink" title="为什么需要主从同步"></a>为什么需要主从同步</h3><ol><li><p>在业务复杂的系统中，有这么一个情景，有一句sql语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。</p></li><li><p>做数据的热备</p></li><li><p>架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。</p></li></ol><h3 id="MySQL主从复制"><a href="#MySQL主从复制" class="headerlink" title="MySQL主从复制"></a>MySQL主从复制</h3><h4 id="复制过程"><a href="#复制过程" class="headerlink" title="复制过程"></a>复制过程</h4><p><img src="/2022/02/24/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8EGTID%E7%89%B9%E6%80%A7/mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5.png" alt="mysql主从同步"></p><ul><li>主服务器（master）将数据更改的操作记录写到二进制redo日志（binlog）中</li><li>从服务器（slave）将主服务器中的二进制日志复制到自己的中继日志（relay log）中<ul><li>首先slave开始一个工作线程——I/O线程，I/O线程在master上打开一个普通的连接，然后开始Binlog dump process（Binlog转储过程），Binlog dump process从master的二进制日志中读取事件。</li><li>如果已经跟上master，它会睡眠并等待master产生新的事件。</li></ul></li><li>从服务器重做中继日志中的日志，把更改应用到自己的数据库中，保证数据的最终一致性<ul><li>中继日志通常存在系统的缓存中，所以中继日志的开销很小。</li></ul></li></ul><p>复制过程有一个很重要的限制，就是在slave上的复制是串行化的，master上是并行化的。</p><h4 id="同步-异步"><a href="#同步-异步" class="headerlink" title="同步/异步"></a>同步/异步</h4><ul><li>异步复制<ul><li>MySQL主从模式默认的复制，并不关心从库是否已经接收并处理</li><li>可能导致数据不完整</li></ul></li><li>同步复制<ul><li>MySQL Cluster为同步复制，所有客户端确认执行事务后才返回。</li><li>事务时间拉长、性能降低。</li></ul></li><li>半同步复制<ul><li>插件形式支持，至少一个从库接收并写ready log。</li><li>至少延迟一个TCP/IP时间，最好在低延迟网络使用。</li></ul></li></ul><h4 id="Mysql读写分离"><a href="#Mysql读写分离" class="headerlink" title="Mysql读写分离"></a>Mysql读写分离</h4><p>本身未实现读写分离：</p><ul><li>基于项目代码内部实现</li><li>基于中间代理实现<ul><li>MySQL-Proxy</li><li>amoeba(变形虫)</li></ul></li></ul><h2 id="MySQL-GTID特性"><a href="#MySQL-GTID特性" class="headerlink" title="MySQL GTID特性"></a>MySQL GTID特性</h2><p>TODO</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>事务数据库特性及隔离级别</title>
      <link href="/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BA%8B%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%B9%E6%80%A7%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
      <url>/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BA%8B%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%B9%E6%80%A7%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>说明： 文章转账自<a href="https://www.cnblogs.com/z-sm/p/7245981.html">数据库事务的特性、隔离级别、传播策略</a></p><h2 id="事务ACID特性"><a href="#事务ACID特性" class="headerlink" title="事务ACID特性"></a>事务ACID特性</h2><p>数据库管理系统中事务(transaction)的四个特性（分析时根据首字母缩写依次解释）：</p><ul><li>原子性（Atomicity）</li><li>一致性（Consistency）</li><li>隔离性（Isolation）</li><li>持久性（Durability）</li></ul><p>所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。（执行单个逻辑功能的一组指令或操作称为事务）</p><h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>原子性是指事务是一个<strong>不可再分割的工作单元</strong>，事务中的操作要么都发生，要么都不发生。</p><p>可采用“<strong>A向B转账</strong>”这个例子来说明解释。</p><p>在DBMS中，默认情况下<strong>一条SQL就是一个单独事务，事务是自动提交的</strong>。</p><p>只有显式的使用<strong>start transaction</strong>开启一个事务，才能将一个代码块放在事务中执行。</p><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>一致性是指在<strong>事务开始之前和事务结束以后，数据库的完整性约束没有被破坏</strong>。这是说数据库事务不能破坏关系<strong>数据的完整性以及业务逻辑上的一致性</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如A给B转账，不论转账的事务操作是否成功，其两者的存款总额不变（这是业务逻辑的一致性，至于数据库关系约束的完整性就更好理解了）。</span><br></pre></td></tr></table></figure><p>保障机制：</p><ul><li>数据库层面: 在一个事务执行之前和之后，数据符合你设置的约束（唯一约束，外键约束,check约束等)和触发器设置；</li><li>此外: 数据库的内部数据结构（如 B 树索引或双向链表）都必须是正确的。</li></ul><p>业务的一致性一般由开发人员进行保证，亦可转移至数据库层面。</p><h3 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h3><p><strong>多个事务并发访问时，事务之间是隔离的</strong>，一个事务不应该影响其它事务运行效果。</p><p>在并发环境中，当<strong>不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间</strong>。</p><p>由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。</p><p>事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，<strong>事务不会查看到中间状态的数据</strong>。</p><p>事务最复杂问题都是由事务隔离性引起的。完全的隔离性是不现实的，完全的隔离性要求数据库同一时间只执行一条事务，这样会严重影响性能。</p><h3 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h3><p>意味着在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。</p><p>完成的事务是系统永久的部分，对系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Write-Ahead Logging：SQL Server中使用了WAL（Write-Ahead Logging）技术来保证事务日志的ACID特性，在数据写入到数据库之前，先写入到日志，再将日志记录变更到存储器中。</span><br></pre></td></tr></table></figure><h2 id="事务隔离"><a href="#事务隔离" class="headerlink" title="事务隔离"></a>事务隔离</h2><p>当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性。</p><h3 id="不用事务隔离带来的问题"><a href="#不用事务隔离带来的问题" class="headerlink" title="不用事务隔离带来的问题"></a>不用事务隔离带来的问题</h3><h4 id="更新丢失"><a href="#更新丢失" class="headerlink" title="更新丢失"></a>更新丢失</h4><p>此写彼写： 两事务同时更新，一个失败回滚覆盖另一个事务的更新。或事务1执行更新操作，在事务1结束前事务2也更新，则事务1的更新结果被事务2的覆盖了。</p><ul><li>两个事务分别写，然后：都回滚则没问题；</li><li>一回滚一提交 或 都提交 则会出现更新丢失问题<ol><li>更新丢失（Lostupdate）: 两个事务都做更新操作，一个事务回滚会覆盖另一个事务更新的数据，导致更新丢失</li><li>两次更新问题（Secondlost updates problem）: 两个事务都做更新操作，后提交事务者会覆盖先提交者的更新。</li></ol></li></ul><h4 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h4><p>此写彼读： 事务T2读取到事务T1修改了但是事务1还未提交的数据，之后事务T1又回滚其更新操作，导致事务T2读到的是脏数据。</p><h4 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h4><p>此读彼写： 对于数据库中的某个数据，一个事务内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。</p><p>例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。</p><p>在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主；但在另一些情况下就有可能发生问题，例如对于同一个数据被A和B依次查询得到的结果就可能不同，A和B就可能打起来了……</p><h4 id="幻读-虚读"><a href="#幻读-虚读" class="headerlink" title="幻读/虚读"></a>幻读/虚读</h4><p>此读彼写： 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。</p><h4 id="各问题区别"><a href="#各问题区别" class="headerlink" title="各问题区别"></a>各问题区别</h4><ul><li><p>脏读和不可重复读的区别：脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。</p></li><li><p>不可重复读和幻读的异同：都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。</p></li></ul><h3 id="事务隔离的级别"><a href="#事务隔离的级别" class="headerlink" title="事务隔离的级别"></a>事务隔离的级别</h3><p>为此我们需要通过提供不同类型的“锁”机制针对数据库事务进行不同程度的并发访问控制，由此产生了不同的事务隔离级别：隔离级别（低-&gt;高）。</p><p>SQL、SQL2标准定义了四种隔离级别：</p><h4 id="读未提交（Read-Uncommitted）"><a href="#读未提交（Read-Uncommitted）" class="headerlink" title="读未提交（Read Uncommitted）"></a>读未提交（Read Uncommitted）</h4><p>含义解释：只限制同一数据写事务禁止其他写事务。解决”更新丢失”。（一事务写时禁止其他事务写）</p><p>名称解释：可读取未提交数据</p><p>所需的锁：排他写锁</p><h4 id="读提交（Read-Committed）"><a href="#读提交（Read-Committed）" class="headerlink" title="读提交（Read Committed）"></a>读提交（Read Committed）</h4><p>含义解释：只限制同一数据写事务禁止其它读写事务。解决”脏读”，以及”更新丢失”。（一事务写时禁止其他事务读写）</p><p>名称解释：必须提交以后的数据才能被读取</p><p>所需的锁：排他写锁、瞬间共享读锁</p><h4 id="可重复读（Repeatable-Read）"><a href="#可重复读（Repeatable-Read）" class="headerlink" title="可重复读（Repeatable Read）"></a>可重复读（Repeatable Read）</h4><p>含义解释：限制同一数据写事务禁止其他读写事务，读事务禁止其它写事务(允许读)。解决”不可重复读”，以及”更新丢失”和”脏读”。（一事务写时禁止其他事务读写、一事务读时禁止其他事务写）</p><p>注意没有解决幻读，解决幻读的方法是增加范围锁（range lock）或者表锁。</p><p>名称解释：能够重复读取</p><p>所需的锁：排他写锁、共享读锁</p><h4 id="串行化（Serializable）"><a href="#串行化（Serializable）" class="headerlink" title="串行化（Serializable）"></a>串行化（Serializable）</h4><p>含义解释：限制所有读写事务都必须串行化实行。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。（一事务写时禁止其他事务读写、一事务读时禁止其他事务读写）</p><p>所须的锁：范围锁或表锁</p><h3 id="各隔离级别对各种异常的控制能力"><a href="#各隔离级别对各种异常的控制能力" class="headerlink" title="各隔离级别对各种异常的控制能力"></a>各隔离级别对各种异常的控制能力</h3><table><thead><tr><th></th><th>更新丢失</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>RU(读未提交)</td><td>避免</td><td></td><td></td><td></td></tr><tr><td>RC（读提交）</td><td>避免</td><td>避免</td><td></td><td></td></tr><tr><td>RR（可重复读）</td><td>避免</td><td>避免</td><td>避免</td><td></td></tr><tr><td>S（串行化）</td><td>避免</td><td>避免</td><td>避免</td><td>避免</td></tr></tbody></table><p>四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，数据完整性越好，但执行效率就越低。</p><p>像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁)使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。</p><h3 id="常见数据库的默认事务隔离级别"><a href="#常见数据库的默认事务隔离级别" class="headerlink" title="常见数据库的默认事务隔离级别"></a>常见数据库的默认事务隔离级别</h3><table><thead><tr><th>数据库</th><th>默认隔离级别</th><th>备注</th></tr></thead><tbody><tr><td>MySQL</td><td>可重复读（Repeatable Read）</td><td>MySQL的Repeatable Read隔离级别也解决了幻读问题（通过Next-key lock加锁方法即范围锁解决不可重复读和幻读问题，如select * from t where a&gt;10会对key为[10,infinite）范围的行加锁，这样其他事务就不能对此范围内key对应的行更改）达到了SQL、SQL2标准中的Serializable级别。</td></tr><tr><td>Oracle</td><td>读提交（Read Committed）</td><td>只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别</td></tr><tr><td>SQLServer</td><td>读提交（Read Committed）</td><td></td></tr><tr><td>DB2</td><td>读提交（Read Committed）</td><td></td></tr><tr><td>PostgreSQL</td><td>读提交（Read Committed）</td><td></td></tr></tbody></table><p>在MySQL数据库中查看当前事务的隔离级别：</p><pre><code>select @@tx_isolation;</code></pre><p>在MySQL数据库中设置事务的隔离级别：</p><pre><code>set  [glogal | session]  transaction isolation level 隔离级别名称; //设置全部连接或当前连接的事务隔离级别set tx_isolation=’隔离级别名称; //设置当前连接的事务隔离级别</code></pre><p><strong>设置数据库的隔离级别一定要是在开启事务之前！</strong></p><p>如果是使用JDBC对数据库的事务设置隔离级别的话，也应该是在调用Connection对象的setAutoCommit(false)方法之前。调用Connection对象的setTransactionIsolation(level)即可设置当前链接的隔离级别，至于参数level，可以使用Connection对象的字段：</p><p><img src="/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BA%8B%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%B9%E6%80%A7%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/img.png"></p><p>在JDBC中设置隔离级别的部分代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">try (Connection conn = JdbcUtils.getConnection()) &#123;</span><br><span class="line">  conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);</span><br><span class="line">  conn.setAutoCommit(false);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>后记：隔离级别的设置只对当前链接有效。对于使用MySQL命令窗口而言，一个窗口就相当于一个链接，当前窗口设置的隔离级别只对当前窗口中的事务有效；对于JDBC操作数据库来说，一个Connection对象相当于一个链接，而对于Connection对象设置的隔离级别只对该Connection对象有效，与其他链接Connection对象无关。</p><h2 id="事务传播"><a href="#事务传播" class="headerlink" title="事务传播"></a>事务传播</h2><p>事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。</p><p>需要注意的是，传播是指一个线程内的传播，不同线程间是没有传播一说的，即不同线程间无法在一个事务内（不然还要事务隔离干嘛），因为他们通常是不同的数据库连接。因此子异步线程事务回滚与否不会影响父线程的事务回滚与否。</p><p>以Spring Transaction为例，在TransactionDefinition接口定义中包括了如下几个表示传播行为的常量（3+3+1）：</p><ul><li>TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。</li><li>TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。</li><li>TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。</li><li>TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。</li><li>TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。</li><li>TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。</li><li>TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则新建事务。</li></ul><p>示例可参阅：<a href="https://blog.csdn.net/f641385712/article/details/98642777">https://blog.csdn.net/f641385712/article/details/98642777</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库MySQL系列之MVCC浅探</title>
      <link href="/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8BInnoDB%E4%B8%ADMVCC%E6%B5%85%E6%8E%A2/"/>
      <url>/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8BInnoDB%E4%B8%ADMVCC%E6%B5%85%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="MVCC简介"><a href="#MVCC简介" class="headerlink" title="MVCC简介"></a>MVCC简介</h1><h2 id="MVCC名词解释"><a href="#MVCC名词解释" class="headerlink" title="MVCC名词解释"></a>MVCC名词解释</h2><p>MVCC (Multiversion Concurrency Control)，即多版本并发控制技术。</p><h2 id="MVCC解决了什么问题"><a href="#MVCC解决了什么问题" class="headerlink" title="MVCC解决了什么问题"></a>MVCC解决了什么问题</h2><p>它使得大部分支持行锁的事务引擎（InnoDB,Falcon以及PBXT等），不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来。<br>只需要很小的开销，就可以实现非锁定读，从而大大提高数据库系统的并发性能。</p><h2 id="锁分类"><a href="#锁分类" class="headerlink" title="锁分类"></a>锁分类</h2><ul><li><strong>读锁</strong>：也叫共享锁、S锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S 锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。</li><li><strong>写锁</strong>：又称排他锁、X锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。</li><li><strong>表锁</strong>：操作对象是数据表。Mysql大多数锁策略都支持(常见mysql innodb)，是系统开销最低但并发性最低的一个锁策略。事务t对整个表加读锁，则其他事务可读不可写，若加写锁，则其他事务增删改都不行。</li><li><strong>行级锁</strong>：操作对象是数据表中的一行。是MVCC技术用的比较多的，但在MYISAM用不了，行级锁用mysql的储存引擎实现而不是mysql服务器。但行级锁对系统开销较大，处理高并发较好。</li></ul><h1 id="MVCC实现原理"><a href="#MVCC实现原理" class="headerlink" title="MVCC实现原理"></a>MVCC实现原理</h1><p>MVCC是通过保存数据在某个时间点的快照来实现的。不同存储引擎的MVCC实现是不同的，典型的有乐观并发控制和悲观并发控制。</p><h2 id="InnoDB-MVCC具体实现分析"><a href="#InnoDB-MVCC具体实现分析" class="headerlink" title="InnoDB MVCC具体实现分析"></a>InnoDB MVCC具体实现分析</h2><p>innodb MVCC主要是为<strong>Repeatable-Read事务隔离级别</strong>做的。在此隔离级别下，A、B客户端所示的数据相互隔离，互相更新不可见。</p><p>innodb存储的最基本row中包含一些额外的存储信息： DATA_TRX_ID，DATA_ROLL_PTR，DB_ROW_ID，DELETE BIT。</p><ul><li>6字节的DATA_TRX_ID 标记了最新更新这条行记录的transaction id，每处理一个事务，其值自动+1；</li><li>7字节的DATA_ROLL_PTR 指向当前记录项的rollback segment的undo log记录，找之前版本的数据就是通过这个指针；</li><li>6字节的DB_ROW_ID，当由innodb自动产生聚集索引时，聚集索引包括这个DB_ROW_ID的值，否则聚集索引中不包括这个值，这个用于索引当中；</li><li>DELETE BIT位用于标识该记录是否被删除，这里的不是真正的删除数据，而是标志出来的删除，真正意义的删除是在commit的时候。</li></ul><p><img src="/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8BInnoDB%E4%B8%ADMVCC%E6%B5%85%E6%8E%A2/img.png" alt="img.png"></p><p>具体的执行过程</p><p>begin-&gt;用排他锁锁定该行-&gt;记录redo log-&gt;记录undo log-&gt;修改当前行的值，写事务编号，回滚指针指向undo log中的修改前的行</p><p>该过程准确说是UPDATE的事务过程，其实undo log分insert和update undo log，因为insert时，原始的数据并不存在，所以回滚时把insert undo log丢弃即可，而update undo log则必须遵守上述过程。</p><h3 id="SELECT"><a href="#SELECT" class="headerlink" title="SELECT"></a>SELECT</h3><p>Innodb检查每行数据，确保他们符合两个标准：</p><ol><li><p>InnoDB只查找版本早于当前事务版本的数据行(也就是数据行的版本必须小于或等于当前事务的版本)，这确保当前事务读取的行要么是事务之前已经存在的，要么是由当前事务创建或修改的；</p></li><li><p>行的删除版本要么未定义,要么大于当前事务版本号,这可以确保事务读取到的行，在事务开始之前未被删除。</p></li></ol><p>只有a,b同时满足的记录，才能返回作为查询结果。</p><h3 id="INSERT"><a href="#INSERT" class="headerlink" title="INSERT"></a>INSERT</h3><p>InnoDB为新插入的每一行保存当前事务版本号作为版本号。</p><h3 id="DELETE"><a href="#DELETE" class="headerlink" title="DELETE"></a>DELETE</h3><p>InnoDB会为删除的每一行保存当前事务的版本号(事务的ID)作为删除标识。</p><h3 id="UPDATE"><a href="#UPDATE" class="headerlink" title="UPDATE"></a>UPDATE</h3><p>InnoDB执行UPDATE，实际上是新插入了一行记录，并保存其创建时间为当前事务的ID，同时保存当前事务ID到要UPDATE的行的删除时间。</p><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>insert操作时 “创建时间”=DB_ROW_ID，这时，“删除时间 ”是未定义的；</p><p>update时，复制新增行的“创建时间”=DB_ROW_ID，删除时间未定义，旧数据行“创建时间”不变，删除时间=该事务的DB_ROW_ID；</p><p>delete操作，相应数据行的“创建时间”不变，删除时间=该事务的DB_ROW_ID；</p><p>select操作对两者都不修改，只读相应的数据</p><h1 id="对于MVCC的总结"><a href="#对于MVCC的总结" class="headerlink" title="对于MVCC的总结"></a>对于MVCC的总结</h1><p>上述更新前建立undo log，根据各种策略读取时非阻塞就是MVCC，undo log中的行就是MVCC中的多版本。</p><p>这个可能与我们所理解的MVCC有较大的出入，一般我们认为MVCC有下面几个特点：</p><ul><li>每行数据都存在一个版本，每次数据更新时都更新该版本</li><li>修改时Copy出当前版本随意修改，各个事务之间无干扰 </li><li>保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback）</li></ul><p>就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道。</p><p>而Innodb的实现方式是：</p><ul><li>事务以排他锁的形式修改原始数据</li><li>把修改前的数据存放于undo log，通过回滚指针与主数据关联</li><li>修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）</li></ul><p>二者最本质的区别是，当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ </p><p>Innodb的实现真算不上MVCC，因为并没有实现核心的多版本共存，undo log中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。</p><p>但理想的MVCC是难以实现的，当事务仅修改一行记录使用理想的MVCC模式是没有问题的，可以通过比较版本号进行回滚；但当事务影响到多行数据时，理想的MVCC据无能为力了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">比如，如果Transaciton1执行理想的MVCC，修改Row1成功，而修改Row2失败，此时需要回滚Row1，但因为Row1没有被锁定，其数据可能又被Transaction2所修改，如果此时回滚Row1的内容，则会破坏Transaction2的修改结果，导致Transaction2违反ACID。</span><br></pre></td></tr></table></figure><p>理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。</p><p>修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二提交是目前这种场景保证一致性的唯一手段。</p><p>二段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的MVCC难以真正在实际中被应用，Innodb只是借了MVCC这个名字，提供了读的非阻塞而已。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
            <tag> MVCC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA并发编程之这个&quot;破玩意儿&quot;叫锁</title>
      <link href="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/"/>
      <url>/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/</url>
      
        <content type="html"><![CDATA[<p>说明： 转载自<a href="https://mp.weixin.qq.com/s/PL-oTc5J_pe5Oyb8mdltjQ">中间件兴趣圈-你管这“破玩意儿”叫锁</a></p><h2 id="锁的种类"><a href="#锁的种类" class="headerlink" title="锁的种类"></a>锁的种类</h2><p>首先以一个非常常见的生活场景举例，例如一个三口之家居住在一个二房一厅的房子里，只有一个卫生间，早上一起床，大家都有抢卫生间，这里就会发生： 一人在如厕，其他人排队等待的场景。</p><p>这个场景下有如下几个关键的特征：</p><ul><li>独占 “厕所“作为一个资源，在任意时刻只能被一个人占用，为了实现该效果，使用资源之前，需要先获得与该资源关联的锁</li><li>当多个线程都需要访问该资源时，必须先获得锁，而且在同一时刻有且只会有一个线程获得锁，那没有获得锁的线程就需要排队等待。是一直等，还是等得不耐烦时就放弃？</li><li>当有多人排队时，一个线程将锁释放后，交给谁？什么样的策略？</li></ul><p>上面是最常见的锁应用场景，有一个非常响亮的名称：<strong>互斥锁、排它锁</strong>。</p><h3 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h3><p>在java领域中，实现互斥锁通常有两种方式：</p><ul><li>synchronized</li><li>ReentrantLock</li></ul><p>互斥锁的基本语义：</p><table><thead><tr><th>语义</th><th>说明</th><th>ReentrantLock</th><th>synchronized</th></tr></thead><tbody><tr><td>可重入性</td><td>一个线程获取锁后，没有释放之前，继续申请</td><td>支持</td><td>支持</td></tr><tr><td>锁只能被锁的拥有者释放</td><td><strong>基于redis实现分布式锁时，要特别注意这个特质</strong></td><td>——</td><td>——</td></tr><tr><td>中断</td><td>申请锁时是否支持被中断</td><td>调用lockInterruptibly方法，可以支持线程中断，即停止继续申请锁</td><td>不支持</td></tr><tr><td>公平锁或非公平锁</td><td>当拥有锁的线程释放锁后，锁的下一个获取者就是锁等待队列中的第一个元素</td><td>支持</td><td>不支持</td></tr></tbody></table><h3 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h3><p>与互斥锁相对应的是共享锁，所谓的共享锁是<strong>同一时间可以被多个线程共同申请</strong>，一个非常经典的使用场景就是<strong>读写锁</strong>。</p><p>例如在一个缓存场景，在一个商品系统中，为了提供对商品的访问性能，通常会引入一个缓存区(Map)来缓存商品的数据，缓存数据对查询请求(读请求)是可以并行执行的，即多个线程同时查询缓存区的数据，这个是一个非常安全的操作，但不允许多个线程对缓存区进行修改。这里共享锁的意义就发挥出来了。</p><p>既然多个线程对缓存区可以同时进行读操作，那为什么还要加共享锁呢？主要的目的是<strong>避免写操作与读操作同时进行</strong>。</p><p>只要当前有读操作在进行，写操作就需要排队，请看如下示例图：<br><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img.png"><br>如上图所示：例如 线程T1,T2,T3连续申请共享锁，然后T4申请写锁，再T5申请读锁，那各个线程的并发执行情况如下所示：</p><ul><li>线程 T1、T2、T3 将并发执行</li><li>T4由于是申请的写锁，必须等 T1、T2、T3释放锁后，才能执行。</li><li>T5虽然申请是共享锁，但由于T4持有写锁，故T5也需要阻塞，直至T4释放锁。</li></ul><p>在Java等世界中按<strong>锁的排斥性</strong>来分基本就包含<strong>排它锁与共享锁</strong>，其他读写锁、间隙锁等是以锁的粒度这个纬度进行细分。</p><h2 id="锁的实现原理"><a href="#锁的实现原理" class="headerlink" title="锁的实现原理"></a>锁的实现原理</h2><p>从某种意义上来说，锁的实现原理就是两个队列：<strong>同步阻塞队列、条件等待队列</strong>。</p><h3 id="同步阻塞队列"><a href="#同步阻塞队列" class="headerlink" title="同步阻塞队列"></a>同步阻塞队列</h3><p>阻塞队列的作用说明如下图所示：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_1.png"></p><p>上面使用synchronized，其传入的是一个锁对象，如果此时有5个线程同时去执行这段代码，由于锁的互斥性，同一时间只有一个线程能获得锁，<strong>其他线程需要排队等待</strong>，故需要引入一个队列来存储在这些排队的线程，所以<strong>synchronized的实现机制中，会在锁对象中开辟一个队列，用来存储等待获取当前锁的线程</strong>。</p><h3 id="条件等待队列"><a href="#条件等待队列" class="headerlink" title="条件等待队列"></a>条件等待队列</h3><p>Object对象中有一对特殊的方法：wait()/notify()/notifyAll()，消费者/生产者中示例中，使用过wait,notify方法，示例代码如下：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_2.png"></p><p>wait方法必须在synchronized中调用，并且通常是<strong>线程调用锁对象的wait方法</strong>，表示当前继续往下执行的条件不足，当前线程需要等待，故需要为锁对象再维护一个个队列，用来存储等待的线程，俗称条件等待队列。</p><p>当其他线程调用锁对象的notify方法或notifyAll方法，会唤醒等待队列中的线程。</p><pre><code>温馨提示： Object.wait方法，会使当前线程进入等待状态，并且释放锁。通常条件等待会使用while语句，避免条件不满足时被误唤醒，故使用while对条件进行再一次的判断。当被唤醒后，并不立即去执行while条件判断，而是需要重新去申请锁，即可能会进入到阻塞队列。</code></pre><h2 id="锁的优化思路"><a href="#锁的优化思路" class="headerlink" title="锁的优化思路"></a>锁的优化思路</h2><p>大家都对锁很敏感，因为性能低下，但锁肯定有其存在的原因，主要解决<strong>数据访问的安全性</strong></p><p>大家可能会感到惊讶，作为一款高性能的消息中间件(RocketMQ)，在消息写入时也使用了锁，其代码如下:</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_3.png"></p><p>这是因为RocketMQ是顺序写文件，多个请求同时申请写一个文件，必须排队执行，否则会带来逻辑异常，此时锁是不用不行了。</p><p>对锁的优化策略，通常基于如下原则：</p><ul><li>能不用锁就不使用锁，</li><li>必须使用锁则尽量保证被锁包裹代码的快速执行</li><li>降低锁的粒度。</li></ul><h3 id="优化锁执行时间"><a href="#优化锁执行时间" class="headerlink" title="优化锁执行时间"></a>优化锁执行时间</h3><p>当然能不用锁就不用锁，但有些场景是必须使用锁来保证多线程环境下结果的正确性。</p><p>就以RocketMQ顺序写commitlog文件为例，对同一个文件写入，需要记录当前的写入位置，然后另外一个线程就进行追加，故这个为写入位置是多线程不安全的，故必须引入锁。</p><p>那RocketMQ作为一款高性能的消息中间件，是如何做到消息发送的高并发，低延迟能力低呢？</p><p>核心法宝：<strong>控制锁的范围，确保被锁包含的代码执行性能高效</strong>，接下来我们看一下RocketMQ消息写入的几个重要步骤：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_4.png"></p><p>并不是需要将上述三个步骤都加锁，而是只对写内存这段加锁即可，这段代码非常高效。</p><h3 id="优化锁的粒度"><a href="#优化锁的粒度" class="headerlink" title="优化锁的粒度"></a>优化锁的粒度</h3><p>锁的性能优化是一个永恒的主旨，另外一个核心思路是：<strong>降低锁的粒度，提高并发度</strong>。</p><p>接下来我们以JDK中的HashTable与ConcurrentHashMap的实现原理为例，让大家体会一下如何降低锁的粒度从而提高并发度。</p><p>Hashtable的性能低下是众所周知，因为整个容器就一把锁，因为它的get、put都是被synchronized修饰，synchronized用来修饰非static方法，其锁对象为Hashtable是对象锁。</p><ul><li>并发度：同一时间只有一个线程能向该容器添加数据、获取数据。</li></ul><p>而jkd1.7及其版本，ConcurrentHashMap的内部数据结构如下图所示：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_5.png"></p><p>可以看出ConcurrentHashMap的设计思路是将整个HashMap分割成多个小的HashMap，然后为每一个HashMap加锁，从而降低锁的粒度，从而提高并发度。</p><p>在JDK1.8及版本后，ConcurrentHashMap的存储结构又发了很大改变，摒弃分段思想，使用来数组 + Node ，进一步释放读写的并发度，其数据结构如下图所示：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_6.png"></p><p>其中，对每一个链表的Node节点，写操作时会加锁，但在查询时候，并不会对各个Node加锁，提高读操作的并发度；并且会基于CAS机制实现无锁化处理，使用volatile保证可见性。</p><h3 id="无锁化设计"><a href="#无锁化设计" class="headerlink" title="无锁化设计"></a>无锁化设计</h3><p>锁的存在必然有其使用场景，特别是需要<strong>被锁保护的资源众多</strong>，即临界区中的逻辑复杂，对其进行拆分会使代码变的臃肿，直接使用锁保护会清晰明了，但评估是否需要引入锁时需要慎重，特别是一些对吞吐量有极高要求的场景，能不用锁就不要用锁.</p><p><strong>无锁化设计的基础：CAS，比较和交换。</strong></p><p>在Java领域也提供了对应的原子操作工具：CAS</p><p>CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。</p><ul><li>如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。</li><li>否则，处理器不做任何操作。</li><li>*CAS是CPU指令级命令**。</li></ul><p>CAS简单使用示例如下：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_7.png"></p>]]></content>
      
      
      <categories>
          
          <category> 并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> 锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA并发编程之线程安全及解决方案大纲</title>
      <link href="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%A4%A7%E7%BA%B2/"/>
      <url>/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%A4%A7%E7%BA%B2/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么需要多线程"><a href="#为什么需要多线程" class="headerlink" title="为什么需要多线程"></a>为什么需要多线程</h2><p>线程是Java语言中不可或缺的重要部分，它们能使复杂的异步代码变得简单，简化复杂系统的开发；能充分发挥多处理器系统的强大计算能力。</p><h3 id="多线程优点"><a href="#多线程优点" class="headerlink" title="多线程优点"></a>多线程优点</h3><ol><li><p><strong>充分利用硬件资源</strong>。由于线程是cpu的基本调度单位，所以如果是单线程，那么最多只能同时在一个处理器上运行，意味着其他的CPU资源都将被浪费。而多线程可以同时在多个处理器上运行，只要各个线程间的通信设计正确，那么多线程将能充分利用处理器的资源。</p></li><li><p><strong>结构优雅</strong>。多线程程序能将代码量巨大，复杂的程序分成一个个简单的功能模块，每块实现复杂程序的一部分单一功能，这将会使得程序的建模，测试更加方便，结构更加清晰，更加优雅。</p></li><li><p><strong>简化异步处理</strong>。为了避免阻塞，单线程应用程序必须使用非阻塞I/O,这样的I/O复杂性远远高于同步I/O，并且容易出错。</p></li></ol><h3 id="多线程缺点"><a href="#多线程缺点" class="headerlink" title="多线程缺点"></a>多线程缺点</h3><ol><li><p><strong>线程安全</strong>：由于统一进程下的多个线程是共享同样的地址空间和数据的，又由于线程执行顺序的不可预知性，一个线程可能会修改其他线程正在使用的变量，这一方面是给数据共享带来了便利；另一方面，如果处理不当，会产生脏读，幻读等问题，好在Java提供了一系列的同步机制来帮助解决这一问题，例如内置锁。</p></li><li><p><strong>活跃性问题</strong>。可能会发生长时间的等待锁，甚至是死锁。</p></li><li><p><strong>性能问题</strong>。 线程的频繁调度切换会浪费资源，同步机制会导致内存缓冲区的数据无效，以及增加同步流量。</p></li></ol><h2 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替运行，并且在主调试代码中不需要任何额外的同步或者协同，这个类都能表现出正确的行为，则称这个类时线程安全的。</p><p>线程安全类中封装了必要的同步机制，因此客户端无须进一步采取同步措施。</p><h3 id="线程安全问题产生的原因"><a href="#线程安全问题产生的原因" class="headerlink" title="线程安全问题产生的原因"></a>线程安全问题产生的原因</h3><p>正确性取决于多个线程的交替执行时序，产生了竞态条件。</p><h3 id="原子类"><a href="#原子类" class="headerlink" title="原子类"></a>原子类</h3><p>应尽量使用原子类，这样会让你分析线程安全时更加方便，但需要注意的是用线程安全类构建的类并不能保证线程安全。</p><p>例如，一个AtomicInteger get() 和 AtomicInteger set() 是线程安全的，在一个类的一个方法 f()中同时用到了这两个方法，此时的f()就是线程不安全的，因为你不能保证这个复合操作中的get 和 set同时更新。</p><h2 id="线程安全的解决方案"><a href="#线程安全的解决方案" class="headerlink" title="线程安全的解决方案"></a>线程安全的解决方案</h2><h3 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h3><ol><li><p>锁能使其保护的代码以串行的形式来访问，当给一个复合操作加锁后，能使其成为原子操作。一种错误的思想是只要对写数据的方法加锁，其实这是错的，对数据进行操作的所有方法都需加锁，不管是读还是写。</p></li><li><p>加锁时需要考虑性能问题，不能总是一味地给整个方法加锁synchronized就了事了，应该将方法中不影响共享状态且执行时间比较长的代码分离出去。</p></li><li><p>加锁的含义不仅仅局限于互斥，还包括可见性。为了确保所有线程都能看见最新值，读操作和写操作必须使用同样的锁对象。</p></li></ol><h3 id="不共享状态"><a href="#不共享状态" class="headerlink" title="不共享状态"></a>不共享状态</h3><ol><li><p>无状态对象： 无状态对象一定是线程安全的，因为不会影响到其他线程。</p></li><li><p>线程关闭： 仅在单线程环境下使用。</p></li></ol><h3 id="不可变对象"><a href="#不可变对象" class="headerlink" title="不可变对象"></a>不可变对象</h3><p>可以使用final修饰的对象保证线程安全，由于final修饰的引用型变量(除String外)不可变是指引用不可变，但其指向的对象是可变的，所以此类必须安全发布，也即不能对外提供可以修改final对象的接口。</p>]]></content>
      
      
      <categories>
          
          <category> 并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> 锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA并发编程之通用多线程基础</title>
      <link href="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="Java多线程"><a href="#Java多线程" class="headerlink" title="Java多线程"></a>Java多线程</h2><h3 id="线程-amp-程序-amp-进程"><a href="#线程-amp-程序-amp-进程" class="headerlink" title="线程&amp;程序&amp;进程"></a>线程&amp;程序&amp;进程</h3><ul><li>进程: 程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。<ul><li>各进程相互独立</li></ul></li><li>线程：比进程更小的执行单位。<ul><li>同类的多个线程共享进程的堆和方法区资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多。</li><li>每个线程有自己的程序计数器、虚拟机栈和本地方法栈。</li><li>同一进程中的线程极有可能会相互影响。</li></ul></li></ul><h3 id="线程基本状态"><a href="#线程基本状态" class="headerlink" title="线程基本状态"></a>线程基本状态</h3><p>Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。<br><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png" alt="Java线程状态"></p><p>线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）：<br><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/Java%20%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E8%BF%81.png" alt="Java线程状态变迁"></p><ul><li>线程创建之后它将处于 NEW（新建） 状态</li><li>调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。</li><li>可运行状态的线程获得了 cpu 时间片（timeslice）后就处于 RUNNING（运行） 状态。</li><li>当线程执行 wait()方法之后，线程进入 WAITING（等待）状态， 进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态</li><li>而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。</li><li>当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。</li><li>当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。</li><li>线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">操作系统隐藏 Java 虚拟机（JVM）中的 READY 和 RUNNING 状态，它只能看到 RUNNABLE 状态，所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。</span><br></pre></td></tr></table></figure><h3 id="sleep-amp-wait"><a href="#sleep-amp-wait" class="headerlink" title="sleep&amp;wait"></a>sleep&amp;wait</h3><p>两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。<br>两者都可以暂停线程的执行。</p><ul><li>Wait 通常被用于线程间交互/通信，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法, 可以使用 wait(long timeout)超时后线程会自动苏醒。</li><li>sleep 通常被用于暂停执行, 线程会自动苏醒。</li></ul><h3 id="start-amp-run"><a href="#start-amp-run" class="headerlink" title="start() &amp; run()"></a>start() &amp; run()</h3><ul><li>new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。</li><li>start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。</li><li>而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。</li></ul><h2 id="Java锁"><a href="#Java锁" class="headerlink" title="Java锁"></a>Java锁</h2><h3 id="从对象头看锁实现原理"><a href="#从对象头看锁实现原理" class="headerlink" title="从对象头看锁实现原理"></a>从对象头看锁实现原理</h3><h4 id="对象头转换过程"><a href="#对象头转换过程" class="headerlink" title="对象头转换过程"></a>对象头转换过程</h4><p><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/markword.png" alt="markword"></p><ul><li><p>对象未加锁的时候，lock标志位为01，包含哈希值、年龄分代和偏向锁标志位等，此时偏向锁标志位为0；</p></li><li><p>当对象被施加偏向锁时，哈希值和一部分无用内存会转化为锁主人的线程信息，以及加锁的时间戳epoch，此时lock标志位没变，偏向锁为1，也就是说，偏向锁和lock标志位共同决定是否偏向锁状态。</p><p>偏向锁的加锁步骤：</p><ul><li>Load-and-test，也就是简单判断一下当前线程id是否与Markword当中的线程id是否一致.</li><li>如果一致，则说明此线程已经成功获得了锁，继续执行下面的代码.</li><li>如果不一致，则要检查一下对象是否还是可偏向，即“是否偏向锁”标志位的值。</li><li>如果还未偏向，则利用CAS操作来竞争锁，也即是第一次获取锁时的操作。</li></ul></li><li><p>当发生锁竞争时，偏向锁会变为轻量级锁，这时需要先将偏向锁进行锁撤销，这一步骤也会消耗不少的性能，轻量级锁的Mark Word中，lock标志位为00，其余内容被替换为一个指针，指向了栈里面的锁记录。</p><p>锁撤销的过程如下：</p><ul><li>在一个安全点停止拥有锁的线程。</li><li>遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。</li><li>唤醒当前线程，将当前锁升级成轻量级锁。</li></ul><p>所以，如果某些同步代码块大多数情况下都是有两个及以上的线程竞争的话，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭</p><p>轻量级锁的加锁步骤：</p><ul><li>线程在自己的栈桢中创建锁记录LockRecord。</li><li>将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。</li><li>将锁记录中的Owner指针指向锁对象。</li><li>将锁对象的对象头的MarkWord替换为指向锁记录的指针。</li></ul><p>轻量级锁主要有两种：自旋锁和自适应自旋锁。自旋锁会导致空耗CPU且很可能锁不公平；自适应是指根据上一次该线程是否成功或者多久获取过该锁设置旋转次数，若上次失败很可能直接进入重量级锁</p></li><li><p>如果竞争线程增多，锁继续膨胀，变为重量级锁，也是互斥锁，即synchronized，其lock标志位为10，Mark Word其余内容被替换为一个指向对象监视器Monitor的指针。</p></li><li><p>特殊的是，如果此对象已经被GC标记过，lock会变为11，不含其余内容。</p></li></ul><h4 id="Monitor对象"><a href="#Monitor对象" class="headerlink" title="Monitor对象"></a>Monitor对象</h4><p>每个对象都有一个Monitor对象相关联，Monitor对象中记录了持有锁的线程信息、等待队列等。Monitor对象包含以下三个字段：</p><ul><li>_owner 记录当前持有锁的线程</li><li>_EntryList 是一个队列，记录所有阻塞等待锁的线程</li><li>_WaitSet 也是一个队列，记录调用 wait() 方法并还未被通知的线程</li></ul><p>当线程持有锁的时候，线程id等信息会拷贝进owner字段，其余线程会进入阻塞队列entrylist，当持有锁的线程执行wait方法，会立即释放锁进入waitset，当线程释放锁的时候，owner会被置空，公平锁条件下，entrylist中的线程会竞争锁，竞争成功的线程id会写入owner，其余线程继续在entrylist中等待。</p><h4 id="Monitor与Synchronized"><a href="#Monitor与Synchronized" class="headerlink" title="Monitor与Synchronized"></a>Monitor与Synchronized</h4><ul><li>对于Synchronized的同步代码块，JVM会在进入代码块之前加上monitorenter ，如果进入monitor成功，线程便获取了锁，一个对象的monitor同一时刻只能被一个线程锁占有；</li><li>对于同步方法，JVM会讲方法设置 ACC_SYNCHRONIZED 标志，调用的时候 JVM 根据这个标志判断是否是同步方法。</li><li>采用Synchronized给对象加锁会使线程阻塞，因而会造成线程状态的切换，而线程状态的切换必须要操作系统来执行，因此需要将用户态切换为内核态，这个切换的过程是十分耗时的都需要操作系统来帮忙，有可能比用户执行代码的时间还要长。</li></ul><h4 id="Synchronized"><a href="#Synchronized" class="headerlink" title="Synchronized"></a>Synchronized</h4><p>JVM级别的锁，它在不断被优化着，从目前来看Synchronized已经远没有以前那么“重”了，也大概就是JUC包源码（如ConcurrentHashMap）中大量使用Synchronized的原因吧。</p><p><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/Java%20Synchronized.png" alt="java syschronized"></p><h3 id="偏向锁、轻量级锁、重量级锁"><a href="#偏向锁、轻量级锁、重量级锁" class="headerlink" title="偏向锁、轻量级锁、重量级锁"></a>偏向锁、轻量级锁、重量级锁</h3><p><a href="https://www.cnblogs.com/cxuanBlog/p/11684390.html">看完你就明白的锁系列之锁的状态</a></p><p><a href="https://www.jianshu.com/p/36eedeb3f912">浅谈偏向锁、轻量级锁、重量级锁</a></p><h4 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h4><p>内置锁在Java中被抽象为监视器锁（monitor），在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。<br>这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。<br>因此，后来称这种锁为“重量级锁”。</p><h4 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h4><p>内核态与用户态的切换上不容易优化。但通过自旋锁，可以<em><strong>减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）</strong></em>。</p><ul><li>当前线程竞争锁失败时，打算阻塞自己</li><li>不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会</li><li>在自旋的同时重新竞争锁</li><li>如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己</li></ul><p>如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。</p><ul><li><p>单核处理器上，不存在实际的并行，当前线程不阻塞自己的话，旧owner就不能执行，锁永远不会释放，此时不管自旋多久都是浪费；进而，如果线程多而处理器少，自旋也会造成不少无谓的浪费。</p></li><li><p>自旋锁要占用CPU，如果是计算密集型任务，这一优化通常得不偿失，减少锁的使用是更好的选择。</p></li><li><p>如果锁竞争的时间比较长，那么自旋通常不能获得锁，白白浪费了自旋占用的CPU时间。这通常发生在锁持有时间长，且竞争激烈的场景中，此时应主动禁用自旋锁。</p><pre><code>使用-XX:-UseSpinning参数关闭自旋锁优化；-XX:PreBlockSpin参数修改默认的自旋次数。</code></pre></li></ul><h4 id="自适应自旋锁"><a href="#自适应自旋锁" class="headerlink" title="自适应自旋锁"></a>自适应自旋锁</h4><p>自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定.</p><ul><li>如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。</li><li>相反的，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能减少自旋时间甚至省略自旋过程，以避免浪费处理器资源。</li></ul><p>自适应自旋解决的是“锁竞争时间不确定”的问题。<em>自适应自旋假定不同线程持有同一个锁对象的时间基本相当，竞争程度趋于稳定，因此，可以根据上一次自旋的时间与结果调整下一次自旋的时间。</em></p><ul><li>如果默认的自旋次数设置不合理（过高或过低），那么自适应的过程将很难收敛到合适的值。</li></ul><h4 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h4><p>轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。</p><ul><li>使用轻量级锁时，不需要申请互斥量，仅仅将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record</li><li>如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁</li><li>否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。</li></ul><p>由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。</p><ul><li>如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁，那么维持轻量级锁的过程就成了浪费。</li></ul><h4 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h4><p>偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。</p><ul><li>“偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁）</li><li>因此，只需要在Mark Word中CAS记录owner（本质上也是更新，但初始值为空）</li><li>如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁</li><li>否则，说明有其他线程竞争，膨胀为轻量级锁。</li></ul><p>偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定</p><ul><li>如果明显存在其他线程申请锁，那么偏向锁将很快膨胀为轻量级锁。</li></ul><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。</li><li>轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。</li><li>重量级锁：有实际竞争，且锁竞争时间长。</li></ul><h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><p>ReentrantLock 类实现了 Lock ，它拥有与 synchronized 相同的并发性和内存语义，但是添加了类似锁投票、定时锁等候和可中断锁等候的一些特性。</p><details><summary>使用</summary><pre><code>public class Printer  &#123;     private Lock lock = new ReentrantLock();// 锁对象       public void printLetters(char c) &#123;         lock.lock();// 得到锁           try &#123;             for(int i = 0; i<5; i++) &#123; system.out.print(c); &#125; system.out.println(); &#125;finally lock.unlock(); 释放锁 < code></5;></code></pre></details><h3 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。</p><p>创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（） 和 set（） 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。</p><ul><li>Thread 类中有一个 threadLocals 和 一个  inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量,我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap;</li><li>最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。</li><li>同一个线程中声明了两个 ThreadLocal 对象的话，会使用 Thread内部都是使用仅有那个ThreadLocalMap 存放数据的，ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值。</li><li>ThreadLocalMap是ThreadLocal的静态内部类。</li></ul><h4 id="ThreadLocal-内存泄露问题"><a href="#ThreadLocal-内存泄露问题" class="headerlink" title="ThreadLocal 内存泄露问题"></a>ThreadLocal 内存泄露问题</h4><p>ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。</p><p>所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。</p><p>这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后最好手动调用remove()方法。</p><h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><h4 id="为什么使用线程池"><a href="#为什么使用线程池" class="headerlink" title="为什么使用线程池"></a>为什么使用线程池</h4><p>线程池提供了一种限制和管理资源（包括执行一个任务）。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。</p><ul><li>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</li><li>提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。</li><li>提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。</li></ul><h4 id="Runnable-amp-Callable"><a href="#Runnable-amp-Callable" class="headerlink" title="Runnable&amp;Callable"></a>Runnable&amp;Callable</h4><p>Runnable 接口不会返回结果或抛出检查异常，但是Callable 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口，这样代码看起来会更加简洁。</p><h4 id="execute-amp-submit"><a href="#execute-amp-submit" class="headerlink" title="execute() &amp; submit()"></a>execute() &amp; submit()</h4><ul><li>execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；</li><li>submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</li></ul><h3 id="Atomic原子类"><a href="#Atomic原子类" class="headerlink" title="Atomic原子类"></a>Atomic原子类</h3><h4 id="AtomicInteger使用示例"><a href="#AtomicInteger使用示例" class="headerlink" title="AtomicInteger使用示例"></a>AtomicInteger使用示例</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AtomicIntegerTest</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> AtomicInteger count = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line">      <span class="comment">//使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increment</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                  count.incrementAndGet();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> count.get();</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="AtomicInteger线程安全原理"><a href="#AtomicInteger线程安全原理" class="headerlink" title="AtomicInteger线程安全原理"></a>AtomicInteger线程安全原理</h4><p>AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。</p><p>CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。</p><h3 id="AbstractQueuedSynchronizer"><a href="#AbstractQueuedSynchronizer" class="headerlink" title="AbstractQueuedSynchronizer"></a>AbstractQueuedSynchronizer</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。</p><pre><code>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。</code></pre><p>AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state;<span class="comment">//共享变量，使用volatile修饰保证线程可见性</span></span><br></pre></td></tr></table></figure><p>状态信息通过protected类型的getState，setState，compareAndSetState进行操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//返回同步状态的当前值</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getState</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> state;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 设置同步状态的值</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(<span class="keyword">int</span> newState)</span> </span>&#123; </span><br><span class="line">    state = newState;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">compareAndSetState</span><span class="params">(<span class="keyword">int</span> expect, <span class="keyword">int</span> update)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> unsafe.compareAndSwapInt(<span class="keyword">this</span>, stateOffset, expect, update);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="AQS-对资源的共享方式"><a href="#AQS-对资源的共享方式" class="headerlink" title="AQS 对资源的共享方式"></a>AQS 对资源的共享方式</h4><ul><li>Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：<ul><li>公平锁：按照线程在队列中的排队顺序，先到者先拿到锁</li><li>非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的</li></ul></li><li>Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock</li></ul><p>ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。</p><p>不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。</p><h4 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h4><ul><li>使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）</li><li>将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。</li></ul><p>AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。</span><br><span class="line">tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。</span><br><span class="line">tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。</span><br><span class="line">tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。</span><br><span class="line">tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。</span><br></pre></td></tr></table></figure><p>这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。</p><h4 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h4><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247484832&amp;idx=1&amp;sn=f902febd050eac59d67fc0804d7e1ad5&source=41#wechat_redirect">并发编程面试必备：AQS 原理以及 AQS 同步组件总结</a></p><h3 id="同步辅助类"><a href="#同步辅助类" class="headerlink" title="同步辅助类"></a>同步辅助类</h3><p><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/%E5%B9%B6%E5%8F%91%E8%BE%85%E5%8A%A9%E7%B1%BB.png" alt="并发辅助类"></p><h4 id="CountDownLatch-–-减计数器"><a href="#CountDownLatch-–-减计数器" class="headerlink" title="CountDownLatch – 减计数器"></a>CountDownLatch – 减计数器</h4><p>允许一个或多个线程等待直到在其他线程中执行的一组操作完成的同步辅助。</p><details>    <summary>使用示例</summary>    <pre><code>public class CountDownLatchDemo &#123;    public static void main(String[] args) throws InterruptedException &#123;        //定义：允许一个或多个线程等待直到在其他线程中执行的一组操作完成的同步辅助。        //用途：1.一个CountDownLatch为一个计数的CountDownLatch用作一个简单的开/关锁存器，或者门：        //      所有线程调用await在门口等待，直到被调用countDown()的线程打开。        //     2.一个CountDownLatch初始化N可以用来做一个线程等待，直到N个线程完成某项操作，或某些动作已经完成N次        CountDownLatch countDownLatch = new CountDownLatch(20);        for (int i=1 ;i<=20;i++)&#123; new thread(()->&#123;                countDownLatch.countDown();                System.out.println(Thread.currentThread().getName()+">="+countDownLatch.getCount());            //&#125;,String.valueOf(i)).start();        &#125;        // 特性：它不要求调用countDown线程等待计数到达零之前继续，        // 它只是阻止任何线程通过await ，直到所有线程可以通过。        System.out.println("我可以在Await方法之前执行");        countDownLatch.await();        System.out.println("我为什么在最后执行呢");    &#125;&#125;</=20;i++)&#123;></code></pre></details><p>CountDownLatch的构造函数接收一个int类型的参数作为计数器，如果你想等待N个点完成，这里就传入N。<br>当我们调用CountDownLatch的countDown方法时，N就会减1，CountDownLatch的await方法会阻塞当前线程，直到N变成零。由于countDown方法可以用在任何地方，所以这里说的N个点，可以是N个线程，也可以是1个线程里的N个执行步骤。用在多个线程时，只需要把这个CountDownLatch的引用传递到线程里即可。<br>如果有某个解析sheet的线程处理得比较慢，我们不可能让主线程一直等待，所以可以使用另外一个带指定时间的await方法——await（long time，TimeUnit unit），这个方法等待特定时间后，就会不再阻塞当前线程。join也有类似的方法。</p><ul><li>计数器必须大于等于0，只是等于0时候，计数器就是零，调用await方法时不会阻塞当前线程</li><li>CountDownLatch不可能重新初始化或者修改CountDownLatch对象的内部计数器的值</li><li>一个线程调用countDown方法happen-before，另外一个线程调用await方法</li></ul><details><summary>源码</summary><pre><code>public class CountDownLatch &#123;    /**Synchronization control For CountDownLatch. Uses AQS state to represent count.*/    private static final class Sync extends AbstractQueuedSynchronizer &#123;        private static final long serialVersionUID = 4982264981922014374L;        Sync(int count) &#123;            setState(count);//初始化同步状态        &#125;        int getCount() &#123;            return getState();        &#125;        protected int tryAcquireShared(int acquires) &#123;            return (getState() == 0) ? 1 : -1;        &#125;        protected boolean tryReleaseShared(int releases) &#123;            // Decrement count; signal when transition to zero            for (;;) &#123;                int c = getState();                if (c == 0)                    return false;                int nextc = c-1;                if (compareAndSetState(c, nextc))                    return nextc == 0;            &#125;        &#125;    &#125;    private final Sync sync;//组合一个同步器（AQS）    public CountDownLatch(int count) &#123;        if (count < 0) throw new IllegalArgumentException("count < 0");        this.sync = new Sync(count);//初始化同步状态    &#125;    /*Causes the current thread to wait until the latch has counted down to     * zero, unless the thread is &#123;@linkplain Thread#interrupt interrupted&#125;.*/    public void await() throws InterruptedException &#123;        sync.acquireSharedInterruptibly(1);//    &#125;    public boolean await(long timeout, TimeUnit unit)        throws InterruptedException &#123;        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));    &#125;    public void countDown() &#123;        sync.releaseShared(1);//释放同步状态    &#125;    public long getCount() &#123;        return sync.getCount();    &#125;    public String toString() &#123;        return super.toString() + "[Count = " + sync.getCount() + "]";    &#125;&#125;</code></pre></details><h4 id="CyclicBarrier-–-加计数器"><a href="#CyclicBarrier-–-加计数器" class="headerlink" title="CyclicBarrier – 加计数器"></a>CyclicBarrier – 加计数器</h4><p>等待多个操作完成，再执行下一步</p><details>    <summary>使用示例</summary>    <pre><code>public class CyclicBarrierDemo &#123;    public static void main(String[] args) throws BrokenBarrierException, InterruptedException &#123;        //适用需等待多个操作完成，再执行下一步        CyclicBarrier cyclicBarrier = new CyclicBarrier(7,()->&#123;            System.out.println("舍利子集齐成功，如来重生");        &#125;);        for (int i=1;i<=7;i++)&#123; int finali="i;" new thread(()->&#123;                System.out.println(Thread.currentThread().getName()+"：收集了"+ finalI +"颗");                try &#123;                    //等待，舍利子集齐，一起向下执行                    cyclicBarrier.await();                    System.out.println("无天必须在如来重生之后，再死");                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125; catch (BrokenBarrierException e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;    &#125;&#125;    </=7;i++)&#123;></code></pre></details><h4 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h4><p>可循环使用（Cyclic）的屏障（Barrier）。<br>它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。</p><p>CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。</p><details><summary>使用示例</summary><pre><code>import java.util.Random; import java.util.concurrent.CyclicBarrier;import java.util.concurrent.atomic.AtomicInteger;public class CyclicBarrierTest &#123;    private static Random sr=new Random(47);     private static AtomicInteger result=new AtomicInteger(0);    private static int threadCount=10;    //屏障后面执行汇总    private static CyclicBarrier barrier=new CyclicBarrier(threadCount,new Accumulate());    private static class Parser implements Runnable&#123;         String name;        public Parser(String name)&#123;            this.name=name;        &#125;        @Override        public void run() &#123;            int sum=0;            int seed=Math.abs(sr.nextInt()) ;            Random r=new Random(47);             for(int i=0;i<(seed%100*100000);i++)&#123; sum+="r.nextInt(seed);" &#125; result.addandget(sum); system.out.println(system.currenttimemillis()+"-"+name+"线程的解析结果："+sum); try &#123; barrier.await(); system.out.println(system.currenttimemillis()+"-"+name+"线程越过屏障！"); catch (exception e) e.printstacktrace(); static class accumulate implements runnable&#123; @override public void run() system.out.println("所有线程解析结束！"); system.out.println("所有线程的解析结果："+result); main(string[] args) throws interruptedexception thread[] threads="new" thread[threadcount]; for(int i="0;i<threadCount;i++)&#123;" threads[i]="new" thread(new parser("parser-"+i)); threads[i].start(); < code></(seed%100*100000);i++)&#123;></code></pre></details><ul><li>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。</li><li>CyclicBarrier还提供其他有用的方法，比如getNumberWaiting方法可以获得Cyclic-Barrier阻塞的线程数量。isBroken()方法用来了解阻塞的线程是否被中断。</li></ul><h4 id="Semaphore并发数控制"><a href="#Semaphore并发数控制" class="headerlink" title="Semaphore并发数控制"></a>Semaphore并发数控制</h4><p>限流、多个资源的互斥使用</p><details><summary>使用示例</summary><pre><code>public class SemaphoreDemo &#123;    public static void main(String[] args) &#123;        // 限流：停车位为3，车位满之后，等待车走，再进一个。        // 多个资源的互斥使用        Semaphore semaphore = new Semaphore(3);        for (int i = 1; i <= 6; i++) &#123; new thread(() -> &#123;                try &#123;                    //先占一个位                    semaphore.acquire();                    System.out.println(Thread.currentThread().getName() + "抢到了车位");                    TimeUnit.SECONDS.sleep(2);                    System.out.println(Thread.currentThread().getName() + "离开了车位");                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125; finally &#123;                    // 释放一个位置                    semaphore.release();                &#125;            &#125;, String.valueOf(i)).start();        &#125;    &#125;&#125;</=></code></pre></details><p>Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore（10）表示允许10个线程获取许可证，也就是最大并发数是10。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证，使用完之后调用release()方法归还许可证。<br>还可以用tryAcquire()方法尝试获取许可证。</p><ul><li>int availablePermits()：返回此信号量中当前可用的许可证数。</li><li>int getQueueLength()：返回正在等待获取许可证的线程数。</li><li>boolean hasQueuedThreads()：是否有线程正在等待获取许可证。</li><li>void reducePermits（int reduction）：减少reduction个许可证，是个protected方法。</li><li>Collection getQueuedThreads()：返回所有等待获取许可证的线程集合，是个protected方法。</li></ul><h4 id="Exchanger-–-线程数据交换"><a href="#Exchanger-–-线程数据交换" class="headerlink" title="Exchanger – 线程数据交换"></a>Exchanger – 线程数据交换</h4><p>Exchanger用于进行线程间的数据交换。</p><p>它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。<br>这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。</p><ul><li>Exchanger可以用于遗传算法，遗传算法里需要选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。</li><li>Exchanger也可以用于校对工作，比如我们需要将纸制银行流水通过人工的方式录入成电子银行流水，为了避免错误，采用AB岗两人进行录入，录入到Excel之后，系统需要加载这两个Excel，并对两个Excel数据进行校对，看看是否录入一致.</li></ul><details><summary>使用示例</summary><pre><code>public class ExchangerTest &#123;    private static final Exchanger<String> exgr = new Exchanger<String>();    private static ExecutorService threadPool = Executors.newFixedThreadPool(2);    public static void main(String[] args) &#123;        threadPool.execute(new Runnable() &#123;            @Override            public void run() &#123;                try &#123;                    String A = "银行流水100";// A录入银行流水数据                    String B=exgr.exchange(A);                    System.out.println("A的视角：A和B数据是否一致：" + A.equals(B) + "，A录入的是：" + A + "，B录入是：" + B);                &#125; catch (InterruptedException e) &#123;                &#125;            &#125;        &#125;);        threadPool.execute(new Runnable() &#123;            @Override            public void run() &#123;                try &#123;                    String B = "银行流水200";// B录入银行流水数据                    String A = exgr.exchange(B);                    System.out.println("B的视角：A和B数据是否一致：" + A.equals(B) + "，A录入的是：" + A + "，B录入是：" + B);                &#125; catch (InterruptedException e) &#123;                &#125;            &#125;        &#125;);        threadPool.shutdown();    &#125;&#125;结果：B的视角：A和B数据是否一致：false，A录入的是：银行流水100，B录入是：银行流水200A的视角：A和B数据是否一致：false，A录入的是：银行流水100，B录入是：银行流水200</String></String></code></pre></details><p>如果两个线程有一个没有执行exchange()方法，则会一直等待，如果担心有特殊情况发生，避免一直等待，可以使用exchange（V x，longtimeout，TimeUnit unit）设置最大等待时长。</p>]]></content>
      
      
      <categories>
          
          <category> 并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> 锁 </tag>
            
            <tag> 线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>增量数据同步之Debezium技术研究</title>
      <link href="/2021/12/08/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%8A%80%E6%9C%AF/%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%B9%8BDebezium%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/"/>
      <url>/2021/12/08/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%8A%80%E6%9C%AF/%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%B9%8BDebezium%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="常见关系型数据库数据同步思路"><a href="#常见关系型数据库数据同步思路" class="headerlink" title="常见关系型数据库数据同步思路"></a>常见关系型数据库数据同步思路</h2><h3 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h3><h4 id="JDBC-Batch"><a href="#JDBC-Batch" class="headerlink" title="JDBC-Batch"></a>JDBC-Batch</h4><p>分页查询源端的表，然后通过 jdbc的batch 方式插入到目标表</p><p>需要注意的是，分页查询时，一定要按照主键id来排序分页，避免重复插入。</p><h4 id="数据文件导出导入"><a href="#数据文件导出导入" class="headerlink" title="数据文件导出导入"></a>数据文件导出导入</h4><p>一般只适用于同种数据库之间的同步，如果是不同的数据库，这种方式可能会存在问题。</p><h3 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h3>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据同步 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ初探之整体设计简介</title>
      <link href="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/"/>
      <url>/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<p>说明： 文章转账自<a href="https://www.cnblogs.com/weifeng1463/p/12889300.html">RocketMQ之一：RocketMQ整体介绍</a></p><h2 id="什么是RocketMQ"><a href="#什么是RocketMQ" class="headerlink" title="什么是RocketMQ"></a>什么是RocketMQ</h2><p>RocketMQ 是阿里巴巴开源的分布式消息中间件。</p><p>支持:</p><ul><li>事务消息<ul><li>对于分布式事务来说提供了又一种解决思路。</li></ul></li><li>顺序消息：<ul><li>保证消息消费者按照消息发送的顺序对消息进行消费。</li><li>分为全局有序和局部有序</li><li>一般推荐使用局部有序，即生产者通过将某一类消息按顺序发送至同一个队列来实现</li></ul></li><li>批量消息</li><li>定时消息</li><li>消息回溯<ul><li>指消费者已经消费成功的消息，由于业务上需求需要重新消费</li><li>RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。</li></ul></li></ul><p>它里面有几个区别于标准消息中件间的概念，如</p><ul><li>Group</li><li>Topic</li><li>Queue</li></ul><p>系统组成由</p><ul><li>Producer</li><li>Consumer</li><li>Broker</li><li>NameServer</li></ul><h3 id="RocketMQ特点"><a href="#RocketMQ特点" class="headerlink" title="RocketMQ特点"></a>RocketMQ特点</h3><ul><li>一个队列模型的消息中间件，具有高性能、高可靠、高实时、分布式等特点</li><li>Producer、Consumer、队列都可以分布式</li><li>Producer 向一些队列轮流发送消息，队列集合称为 Topic<ul><li>Consumer 如果做广播消费，则一个 Consumer 实例消费这个 Topic 对应的所有队列</li><li><font color="#FF0000">如果做集群消费，则多个 Consumer 实例平均消费这个 Topic 对应的队列集合</font><ul><li>如何实现平均消费？</li></ul></li></ul></li><li>能够保证严格的消息顺序</li><li>支持 <font color="#FF0000">拉（pull）和推（push）两种消息模式</font></li><li>高效的订阅者水平扩展能力</li><li>实时的消息订阅机制</li><li>亿级消息堆积能力，堆积了这么多消息后依然保持写入低延迟</li><li>支持多种消息协议，如 JMS、OpenMessaging 等</li><li>较少的依赖</li></ul><h2 id="RocketMQ概念解读"><a href="#RocketMQ概念解读" class="headerlink" title="RocketMQ概念解读"></a>RocketMQ概念解读</h2><h3 id="RocketMQ核心概念"><a href="#RocketMQ核心概念" class="headerlink" title="RocketMQ核心概念"></a>RocketMQ核心概念</h3><p>消息队列 RocketMQ 在任何一个环境都是可扩展的，生产者必须是一个集群，消息服务器必须是一个集群，消费者也同样。</p><p>集群级别的高可用，是消息队列 RocketMQ 跟其他的消息服务器的主要区别，消息生产者发送一条消息到消息服务器，消息服务器会<font color="#FF0000">随机的选择一个消费者</font><br>，只要这个消费者消费成功就认为是成功了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：文中所提及的消息队列 RocketMQ 的服务端或者服务器包含 Name Server、Broker 等。服务端不等同于 Broker。</span><br></pre></td></tr></table></figure><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011406.png"></p><p>RocketMQ主要由 Producer、Broker、Consumer 三部分组成。</p><p>其中：</p><ul><li>Producer 负责生产消息，<ul><li>同步<ul><li>指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包</li><li>一般用于重要通知消息，例如重要通知邮件、营销短信。</li></ul></li><li>异步<ul><li>发送方发出数据后，不等接收方发回响应，接着发送下个数据包</li><li>一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。</li></ul></li><li>单向</li></ul></li><li>Consumer 负责消费消息，<ul><li>ConsumerGroup 由多个 Consumer 实例构成。</li></ul></li><li>Broker 负责存储消息。<ul><li>Broker 在实际部署过程中对应一台服务器，每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。</li><li>Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。</li></ul></li></ul><p>图中所涉及到的概念如下所述：</p><h4 id="Name-Server-名称服务充当路由消息的提供者。"><a href="#Name-Server-名称服务充当路由消息的提供者。" class="headerlink" title="Name Server: 名称服务充当路由消息的提供者。"></a>Name Server: 名称服务充当路由消息的提供者。</h4><p>一个几乎无状态节点，可集群部署，节点之间无任何信息同步。在消息队列 RocketMQ 中提供命名服务，更新和发现 Broker 服务。</p><p><strong>两个功能</strong></p><ul><li>接收broker的请求，注册broker的路由信息</li><li>接收client（producer/consumer）的请求，根据某个topic获取其到broker的路由信息</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NameServer没有状态，可以横向扩展。</span><br><span class="line"></span><br><span class="line">每个broker在启动的时候会到NameServer注册； Producer在发送消息前会根据topic到NameServer获取路由(到broker)信息； </span><br><span class="line">Consumer也会定时获取topic路由信息。</span><br><span class="line"></span><br><span class="line">无信息同步如何实现数据持久化</span><br></pre></td></tr></table></figure><h4 id="Broker：消息中转角色，负责存储消息，转发消息。"><a href="#Broker：消息中转角色，负责存储消息，转发消息。" class="headerlink" title="Broker：消息中转角色，负责存储消息，转发消息。"></a>Broker：消息中转角色，负责存储消息，转发消息。</h4><p>Broker可以理解为消息队列服务器，提供了消息的接收、存储、拉取和转发服务。 它是RocketMQ的核心，<font color="#FF0000">需要保证broker的高可用</font>。</p><ul><li>broker分为 Master Broker 和 Slave Broker，一个 Master Broker 可以对应多个 Slave Broker，但是一个 Slave Broker<br>只能对应一个 Master Broker。</li><li>Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。</li><li>每个Broker与Name Server集群中的所有节点建立长连接，定时注册Topic信息到所有Name Server。Broker 启动后需要完成一次将自己注册至 Name Server<br>的操作；随后每隔 30s 定期向 Name Server 上报 Topic 路由信息。<ul><li>如果Master挂了，需要30s才能被Name Server感知</li></ul></li></ul><h4 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h4><p>与 Name Server 集群中的其中一个节点（随机）建立长链接（Keep-alive），定期从 Name Server 读取 Topic 路由信息，并向提供 Topic 服务的 Master<br>Broker 建立长链接，且定时向 Master Broker 发送心跳。</p><h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><p>与 Name Server 集群中的其中一个节点（随机）建立长连接，定期从 Name Server 拉取 Topic 路由信息，并向提供 Topic 服务的 Master Broker、Slave<br>Broker 建立长连接，且定时向 Master Broker、Slave Broker 发送心跳。</p><p>Consumer 既可以从 Master Broker 订阅消息，也可以从 Slave Broker 订阅消息，订阅规则由 Broker 配置决定。</p><h3 id="Topic、Queue、tags"><a href="#Topic、Queue、tags" class="headerlink" title="Topic、Queue、tags"></a>Topic、Queue、tags</h3><p>RocketMQ的Topic/Queue和JMS中的Topic/Queue概念有一定的差异:</p><ul><li>JMS中所有消费者都会消费一个Topic消息的副本，而Queue中消息只会被一个消费者消费；</li><li><strong>RocketMQ中Topic只代表普通的消息队列，而Queue是组成Topic的更小单元</strong>。</li></ul><h4 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h4><p>表示消息的第一级类型，比如一个电商系统的消息可以分为：交易消息、物流消息…… 一条消息必须有一个Topic。</p><h4 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h4><p>主题被划分为一个或多个子主题，称为“message queues”。一个topic下，我们可以设置多个queue(消息队列)。</p><p>当我们发送消息时，需要要指定该消息的topic。RocketMQ会轮询该topic下的所有队列，将消息发送出去。</p><p><strong>定义： Queue是Topic在一个Broker上的分片，在分片基础上再等分为若干份（可指定份数）后的其中一份，是负载均衡过程中资源分配的基本单元。</strong></p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011721.png"></p><p>集群消费模式下一个消费者只消费该Topic中部分Queue中的消息，当一个消费者开启广播模式时则会消费该Topic下所有Queue中的消息。</p><h4 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h4><p>Tags是Topic下的次级消息类型/二级类型（注：Tags也支持TagA || TagB这样的表达式），可以在同一个Topic下基于Tags进行消息过滤。</p><p>Tags的过滤需要经过两次比对，首先会在Broker端通过Tag hashcode进行一次比对过滤，匹配成功传到consumer端后再对具体Tags进行比对，以防止Tag hashcode重复的情况。</p><p>比如交易消息又可以分为：交易创建消息，交易完成消息….. 一条消息可以没有Tag。</p><p>RocketMQ提供2级消息分类，方便大家灵活控制。标签，换句话说，为用户提供了额外的灵活性。有了标签，来自同一个业务模块的不同目的的消息可能具有相同的主题和不同的标签。标签将有助于保持您的代码干净和连贯，并且标签还可以为RocketMQ提供的查询系统提供帮助。</p><p>Queue中具体的存储单元结构如下图，最后面的8个Byte存储Tag信息。</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011726.png"></p><p>具体参考<a href="https://www.cnblogs.com/duanxz/p/5020398.html">RocketMQ消息存储</a></p><h3 id="Group"><a href="#Group" class="headerlink" title="Group"></a>Group</h3><h4 id="Producer-amp-amp-Producer-Group"><a href="#Producer-amp-amp-Producer-Group" class="headerlink" title="Producer &amp;&amp; Producer Group"></a>Producer &amp;&amp; Producer Group</h4><p>Producer表示消息队列的生产者。消息队列的本质就是实现了pub/sub模式，生产者生产消息，消费者消费消息。</p><ul><li>所以这里的Producer就是用来生产和发送消息的，一般指业务系统。</li><li>RocketMQ提供了发送：普通消息（同步、异步和单向（one-way）消息）、定时消息、延时消息、事务消息。</li></ul><p>Producer Group是一类Producer的集合名称，这类Producer通常发送一类消息，且发送逻辑一致。相同角色的生产者被分组在一起。</p><ul><li>同一生产者组的另一个生产者实例可能被broker联系，以提交或回滚事务，以防原始生产者在交易后崩溃。</li></ul><p><font color="#FF0000">警告： 考虑提供的生产者在发送消息时足够强大，每个生产者组只允许一个实例，以避免对生产者实例进行不必要的初始化。</font></p><h4 id="Consumer-amp-amp-Consumer-Group"><a href="#Consumer-amp-amp-Consumer-Group" class="headerlink" title="Consumer &amp;&amp; Consumer Group"></a>Consumer &amp;&amp; Consumer Group</h4><p>Consumer: 消息消费者，一般由业务后台系统异步的消费消息。</p><ul><li>Push Consumer： Consumer 的一种，应用通常向 Consumer 对象注册一个 Listener 接口，一旦收到消息，Consumer 对象立刻回调 Listener<br>接口方法。</li><li>Pull Consumer： Consumer 的一种，应用通常主动调用 Consumer 的拉消息方法从 Broker 拉消息，主动权由应用控制。</li></ul><p>Consumer Group： Consumer Group是一类Consumer的集合名称，这类Consumer通常消费一类消息，且消费逻辑一致(使用相同 Group ID<br>的订阅者属于同一个集群。同一个集群下的订阅者消费逻辑必须完全一致（包括 Tag 的使用），这些订阅者在逻辑上可以认为是一个消费节点)。</p><ul><li>消费者群体是一个伟大的概念，它实现了负载平衡和容错的目标，在信息消费方面，是非常容易的。</li></ul><p><font color="#FF0000">警告： 消费者群体的消费者实例<strong>必须</strong>订阅完全相同的主题。</font></p><h2 id="RocketMQ组件关系"><a href="#RocketMQ组件关系" class="headerlink" title="RocketMQ组件关系"></a>RocketMQ组件关系</h2><h3 id="Broker-amp-amp-Producer-amp-amp-Consumer"><a href="#Broker-amp-amp-Producer-amp-amp-Consumer" class="headerlink" title="Broker &amp;&amp; Producer &amp;&amp; Consumer"></a>Broker &amp;&amp; Producer &amp;&amp; Consumer</h3><p>如果不考虑负载均衡和高可用，最简单的Broker，Producer和Consumer之间的关系如下图所示：</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011748.png"></p><h3 id="Topic-amp-amp-Topic分片-amp-amp-Queue"><a href="#Topic-amp-amp-Topic分片-amp-amp-Queue" class="headerlink" title="Topic &amp;&amp; Topic分片 &amp;&amp; Queue"></a>Topic &amp;&amp; Topic分片 &amp;&amp; Queue</h3><p>从本质上来说，RocketMQ中的Queue是数据分片的产物。 为了更好地理解Queue的定义，我们还需要引入一个新的概念：Topic分片。</p><p>在分布式数据库和分布式缓存领域，分片概念已经有了清晰的定义。</p><p>同理，对于RocketMQ，一个Topic可以分布在各个Broker上，我们可以把一个Topic分布在一个Broker上的子集定义为一个Topic分片。</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011757.png"></p><p>对应上图，TopicA有3个Topic分片，分布在Broker1,Broker2和Broker3上，TopicB有2个Topic分片，分布在Broker1和Broker2上，TopicC有2个Topic分片，分布在Broker2和Broker3上。</p><p><strong>将Topic分片再切分为若干等分，其中的一份就是一个Queue</strong></p><p>每个Topic分片等分的Queue的数量可以不同，由用户在创建Topic时指定。</p><p>数据分片的主要目的是突破单点的资源（网络带宽，CPU，内存或文件存储）限制从而实现水平扩展。 RocketMQ<br>在进行Topic分片以后，已经达到水平扩展的目的了，为什么还需要进一步切分为Queue呢？</p><p>解答这个问题还需要从<strong>负载均衡</strong>说起。以消息消费为例，借用Rocket MQ官方文档中的Consumer负载均衡示意图来说明：</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021307.png"></p><p>如图所示，TOPIC_A在一个Broker上的Topic分片有5个Queue，一个Consumer<br>Group内有2个Consumer按照集群消费的方式消费消息，按照平均分配策略进行负载均衡得到的结果是：第一个 Consumer 消费3个Queue，第二个Consumer<br>消费2个Queue。如果增加Consumer，每个Consumer分配到的Queue会相应减少。</p><p>Rocket MQ的负载均衡策略规定：Consumer数量应该小于等于Queue数量，如果Consumer超过Queue数量，那么多余的Consumer 将不能消费消息。</p><p>在一个Consumer<br>Group内，Queue和Consumer之间的对应关系是一对多的关系：一个Queue最多只能分配给一个Consumer，一个Cosumer可以分配得到多个Queue。这样的分配规则，每个Queue只有一个消费者，可以避免消费过程中的多线程处理和资源锁定，有效提高各Consumer消费的并行度和处理效率。</p><p>由此，我们可以给出Queue的定义：</p><p>Queue是Topic在一个Broker上的分片等分为指定份数后的其中一份，是负载均衡过程中资源分配的基本单元。</p><h4 id="Queue数量指定方式"><a href="#Queue数量指定方式" class="headerlink" title="Queue数量指定方式"></a>Queue数量指定方式</h4><ul><li><p>代码指定</p><ul><li>producer.setDefaultTopicQueueNums(8);</li></ul></li><li><p>配置文件指定</p><ul><li>同时设置broker服务器的配置文件broker.properties：defaultTopicQueueNums=16</li></ul></li><li><p>rocket-console控制台指定</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011801.png"></p></li></ul><h2 id="RocketMQ发布订阅大体流程"><a href="#RocketMQ发布订阅大体流程" class="headerlink" title="RocketMQ发布订阅大体流程"></a>RocketMQ发布订阅大体流程</h2><ol><li><p>producer生产者连接nameserver，产生数据放入不同的topic；</p></li><li><p>对于RocketMQ，一个Topic可以分布在各个Broker上，我们可以把一个Topic分布在一个Broker上的子集定义为一个Topic分片；</p></li><li><p>将Topic分片再切分为若干等分，其中的一份就是一个Queue。每个Topic分片等分的Queue的数量可以不同，由用户在创建Topic时指定。</p></li><li><p>consumer消费者连接nameserver，根据broker分配的Queue来消费数据。</p></li></ol><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021312.png"></p><h2 id="消息分类"><a href="#消息分类" class="headerlink" title="消息分类"></a>消息分类</h2><h3 id="发送类型分类"><a href="#发送类型分类" class="headerlink" title="发送类型分类"></a>发送类型分类</h3><h4 id="同步消息"><a href="#同步消息" class="headerlink" title="同步消息"></a>同步消息</h4><p>指消息发送方发出数据后，<strong>会阻塞直到MQ服务方发回响应消息</strong>。</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021324.png"></p><p>应用场景：此种方式应用场景非常广泛，例如重要通知邮件、报名短信通知、营销短信系统等。</p><p>关键代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SendResult sendResult = producer.send(msg);</span><br></pre></td></tr></table></figure><h4 id="异步消息"><a href="#异步消息" class="headerlink" title="异步消息"></a>异步消息</h4><p>发送方发出数据后，不等接收方发回响应，接着发送下个数据包的通讯方式。</p><p><strong>MQ<br>的异步发送，需要用户实现异步发送回调接口（SendCallback），在执行消息的异步发送时，应用不需要等待服务器响应即可直接返回，通过回调接口接收服务器响应，并对服务器的响应结果进行处理。</strong></p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021327.png" class><p>应用场景：异步发送一般用于链路耗时较长，对 RT 响应时间较为敏感的业务场景，例如用户视频上传后通知启动转码服务，转码完成后通知推送转码结果等。</p><p>关键代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">producer.sendAsync(msg, new SendCallback() &#123;//...&#125;);</span><br></pre></td></tr></table></figure><h4 id="单向消息"><a href="#单向消息" class="headerlink" title="单向消息"></a>单向消息</h4><p>只负责发送消息，不等待服务器回应且没有回调函数触发，即只发送请求不等待应答。</p><p><strong>此方式发送消息的过程耗时非常短，一般在微秒级别。但是可能存在数据丢失</strong></p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021330.png"></p><p>应用场景：适用于某些耗时非常短，但对可靠性要求并不高的场景，例如日志收集。</p><p>关键代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">producer.sendOneway(msg);</span><br></pre></td></tr></table></figure><h3 id="按照功能使用划分"><a href="#按照功能使用划分" class="headerlink" title="按照功能使用划分"></a>按照功能使用划分</h3><h4 id="普通消息-amp-amp-顺序消息"><a href="#普通消息-amp-amp-顺序消息" class="headerlink" title="普通消息 &amp;&amp; 顺序消息"></a>普通消息 &amp;&amp; 顺序消息</h4><h4 id="广播消息"><a href="#广播消息" class="headerlink" title="广播消息"></a>广播消息</h4><h4 id="延时消息"><a href="#延时消息" class="headerlink" title="延时消息"></a>延时消息</h4><h5 id="定时消息"><a href="#定时消息" class="headerlink" title="定时消息"></a>定时消息</h5><p>定时消息，单位毫秒（ms），在指定时间戳（当前时间之后）进行投递</p><p>核心代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 例如 2016-03-07 16:21:00 投递。</span><br><span class="line">// 如果被设置成当前时间戳之前的某个时刻，消息将立刻投递给消费者。    </span><br><span class="line">long timeStamp = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).parse(&quot;2016-03-07 16:21:00&quot;).getTime();    </span><br><span class="line">msg.setStartDeliverTime(timeStamp);​    </span><br><span class="line">// 发送消息，只要不抛异常就是成功    </span><br><span class="line">SendResult sendResult = producer.send(msg);   </span><br></pre></td></tr></table></figure><h5 id="延时消息-1"><a href="#延时消息-1" class="headerlink" title="延时消息"></a>延时消息</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Message sendMsg = new Message(topic, tags, message.getBytes());</span><br><span class="line">sendMsg.setDelayTimeLevel(delayLevel);</span><br><span class="line">// 默认3秒超时</span><br><span class="line">SendResult sendResult = rocketMQProducer.send(sendMsg);</span><br></pre></td></tr></table></figure><h4 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h4><p>RocketMQ提供类似X/Open XA的分布式事务功能来确保业务发送方和MQ消息的最终一致性。</p><p><strong>其本质是通过半消息(prepare消息和commit消息)的方式把分布式事务放在MQ端来处理</strong>。</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031329.png"></p><p>其中：</p><ol><li>发送方向消息队列 RocketMQ 服务端发送消息。</li><li>服务端将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功，此时消息为半消息。</li><li>发送方开始执行本地事务逻辑。</li><li>发送方根据本地事务执行结果向服务端提交二次确认（Commit 或是 Rollback），服务端收到 Commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；服务端收到 Rollback<br>状态则删除半消息，订阅方将不会接受该消息。</li></ol><p>补偿流程：</p><ol start="5"><li>在断网或者是应用重启的特殊情况下，上述步骤 4 提交的二次确认最终未到达服务端，经过固定时间后服务端将对该消息发起消息回查。</li><li>发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li><li>发送方根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤 4 对半消息进行操作。</li></ol><p><strong><font color="#FF0000">RocketMQ的半消息机制的注意事项是</font></strong></p><ol><li>根据第六步可以看出他要求发送方提供业务回查接口。</li><li>不能保证发送方的消息幂等，在ack没有返回的情况下，可能存在重复消息</li><li>消费方要做幂等处理。</li></ol><h2 id="发布订阅模型"><a href="#发布订阅模型" class="headerlink" title="发布订阅模型"></a>发布订阅模型</h2><p>在RocketMQ中，producer发布消息，consumer订阅消息。消息的收发模型如下图：</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031342.png"></p><h3 id="producer端消息发布原理"><a href="#producer端消息发布原理" class="headerlink" title="producer端消息发布原理"></a>producer端消息发布原理</h3><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031345.png"></p><p>producer完全无状态，可以集群部署。</p><h3 id="consumer端消息获取模式（push-pull）"><a href="#consumer端消息获取模式（push-pull）" class="headerlink" title="consumer端消息获取模式（push/pull）"></a>consumer端消息获取模式（push/pull）</h3><p>consumer有两种消息的获取模式</p><ul><li>Push模式，即MQServer主动向消费端推送；</li><li>Pull模式，即消费端在需要时，主动到MQServer拉取。</li></ul><p>实际实现中： <strong>Push和Pull模式都是采用消费端主动拉取的方式</strong>。</p><p>消费端的Push模式是通过长轮询的模式来实现的：</p><ul><li>Consumer端每隔一段时间主动向broker发送拉消息请求，broker在收到Pull请求后<ul><li>如果有消息就立即返回数据，Consumer端收到返回的消息后，再回调消费者设置的Listener方法。</li><li>消息队列里没有数据，broker端会阻塞请求直到有数据传递或超时才返回。</li></ul></li><li>当然，Consumer端是通过一个线程将阻塞队列LinkedBlockingQueue<PullRequest>中的PullRequest发送到broker拉取消息，以防止Consumer一致被阻塞。</PullRequest></li><li>而Broker端，在接收到Consumer的PullRequest时，如果发现没有消息，就会把PullRequest扔到ConcurrentHashMap中缓存起来。</li><li>broker在启动时，会启动一个线程不停的从ConcurrentHashMap取出PullRequest检查，直到有数据返回。</li></ul><h3 id="consumer端消息消费模式-集群-广播"><a href="#consumer端消息消费模式-集群-广播" class="headerlink" title="consumer端消息消费模式(集群/广播)"></a>consumer端消息消费模式(集群/广播)</h3><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>消息队列 RocketMQ 是基于发布/订阅模型的消息系统。消息的订阅方订阅关注的 Topic，以获取并消费消息。</p><p>由于订阅方应用一般是分布式系统，以集群方式部署有多台机器。</p><h4 id="集群消费"><a href="#集群消费" class="headerlink" title="集群消费"></a>集群消费</h4><p>使用相同 Group ID 的订阅者属于同一个集群。同一个集群下的订阅者消费逻辑必须完全一致（包括 Tag 的使用），这些订阅者在逻辑上可以认为是一个消费节点。</p><p>当使用集群消费模式时，消息队列 RocketMQ 认为任意一条消息只需要被集群内的任意一个消费者处理即可。</p><p>一个Consumer Group中的Consumer实例平均分摊消费消息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">例如某个Topic有 9 条消息，其中一个Consumer Group有 3 个实例(可能是 3 个进程,或者 3 台机器)，那么每个实例只消费其中的 3 条消息。</span><br></pre></td></tr></table></figure><h5 id="使用场景-amp-amp-注意事项"><a href="#使用场景-amp-amp-注意事项" class="headerlink" title="使用场景 &amp;&amp; 注意事项"></a>使用场景 &amp;&amp; 注意事项</h5><ul><li>消费端集群化部署，每条消息只需要被处理一次。</li><li>由于消费进度在服务端维护，可靠性更高。</li><li>集群消费模式下，<strong>每一条消息都只会被分发到一台机器上处理</strong>。如果需要被集群下的每一台机器都处理，请使用广播模式。</li><li>集群消费模式下，<strong>不保证每一次失败重投的消息路由到同一台机器上</strong>，因此处理消息时不应该做任何确定性假设。</li></ul><h4 id="广播消费"><a href="#广播消费" class="headerlink" title="广播消费"></a>广播消费</h4><p>当使用广播消费模式时，消息队列 RocketMQ 会将每条消息推送给集群内所有注册过的客户端，保证消息至少被每台机器消费一次。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一条消息被多个Consumer消费，即使这些Consumer属于同一个Consumer Group，消息也会被Consumer Group中的每个Consumer都消费一次。</span><br></pre></td></tr></table></figure><p><strong>在广播消费中的Consumer Group概念可以认为在消息划分方面无意义</strong>。</p><h5 id="使用场景-amp-amp-注意事项-1"><a href="#使用场景-amp-amp-注意事项-1" class="headerlink" title="使用场景 &amp;&amp; 注意事项"></a>使用场景 &amp;&amp; 注意事项</h5><ul><li>广播消费模式下<strong>不支持顺序消息</strong>。</li><li>广播消费模式下<strong>不支持重置消费位点</strong>。</li><li>每条消息都需要被相同逻辑的多台机器处理。</li><li>消费进度在客户端维护，出现重复的概率稍大于集群模式。</li><li>广播模式下，消息队列 RocketMQ 保证每条消息至少被每台客户端消费一次，但是并<strong>不会对消费失败的消息进行失败重投</strong>，因此业务方需要关注消费失败的情况。</li><li>广播模式下，客户端每一次重启都会从最新消息消费。<strong>客户端在被停止期间发送至服务端的消息将会被自动跳过</strong>，请谨慎选择。</li><li>广播模式下，每条消息都会被大量的客户端重复处理，因此推荐尽可能使用集群模式。</li><li>目前仅 Java 客户端支持广播模式。</li><li>广播模式下服务端不维护消费进度，所以消息队列 RocketMQ 控制台<strong>不支持消息堆积查询、消息堆积报警和订阅关系查询功能</strong>。</li></ul><h4 id="使用集群模式模拟广播"><a href="#使用集群模式模拟广播" class="headerlink" title="使用集群模式模拟广播"></a>使用集群模式模拟广播</h4><p>如果业务需要使用广播模式，也可以创建多个 Group ID，用于订阅同一个 Topic。</p><h5 id="适用场景-amp-amp-注意事项"><a href="#适用场景-amp-amp-注意事项" class="headerlink" title="适用场景 &amp;&amp; 注意事项"></a>适用场景 &amp;&amp; 注意事项</h5><ul><li>每条消息都需要被多台机器处理，每台机器的逻辑可以相同也可以不一样。</li><li>消费进度在服务端维护，可靠性高于广播模式。</li><li>对于一个 Group ID 来说，可以部署一个消费端实例，也可以部署多个消费端实例。 <ul><li>当部署多个消费端实例时，实例之间又组成了集群模式（共同分担消费消息）。</li><li>假设 Group ID 1 部署了三个消费者实例 C1、C2、C3，那么这三个实例将共同分担服务器发送给 Group ID 1 的消息。 </li><li>实例之间订阅关系必须保持一致。</li></ul></li></ul><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><h3 id="生产端负载均衡"><a href="#生产端负载均衡" class="headerlink" title="生产端负载均衡"></a>生产端负载均衡</h3><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031427.png"></p><p>首先分析一下RocketMQ的客户端发送消息的源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DefaultMQProducer defaultMQProducer = new DefaultMQProducer(&quot;ProducerGroupName&quot;);</span><br><span class="line">// 初始化Producer， 整个生命周期只需要一次</span><br><span class="line">producer.start();</span><br><span class="line">// 构造Message</span><br><span class="line">Message msg = new Message(&quot;Topic&quot;, &quot;TagA&quot;, &quot;key&quot;, &quot;aaaaaaaa&quot;.getBytes());</span><br><span class="line">// 发送消息并返回结果</span><br><span class="line">SendResult sendResult = producer.send(msg);</span><br><span class="line">// 清理资源、关闭网络、注销自己</span><br><span class="line">producer.shutdown();</span><br></pre></td></tr></table></figure><p>在整个应用生命周期内，生产者需要调用一次start方法来初始化，初始化主要完成的任务有：</p><ul><li>如果没有指定namesrv地址，将会自动寻址</li><li>启动定时任务<ul><li>更新namesrv地址</li><li>从namsrv更新topic路由信息</li><li>清理已经挂掉的broker</li><li>向所有broker发送心跳…</li></ul></li><li>启动负载均衡的服务</li></ul><p>初始化完成后，开始发送消息，发送消息的主要代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">privete SendResult sendDefaultImpl(Message msg, .....) &#123;</span><br><span class="line">  // 检查Producer状态是否Running</span><br><span class="line">  this.makesureStateOK();</span><br><span class="line">  // 检查msg是否合法，是否为null, topic、body是否为空，body是否超长</span><br><span class="line">  Validators.checkMessage(msg, this.defaultMQProducer);</span><br><span class="line">  // 获取路由信息</span><br><span class="line">  TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic());</span><br><span class="line">  // 从路由中悬着一个消息队列</span><br><span class="line">  MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, info);</span><br><span class="line">  // </span><br><span class="line">  sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码中需要关注的两个方法tryToFindTopicPublishInfo和selectOneMessageQueue。</p><ul><li>前面说过在producer初始化时，会启动定时任务获取路由信息并更新到本地缓存，所以tryToFindTopicPublishInfo会首先从缓存中获取topic路由信息，如果没有获取到，则会自己去namesrv获取路由信息。</li><li>selectOneMessageQueue方法通过轮询的方式，返回一个队列，以达到负载均衡的目的。</li></ul><p>如果Producer发送消息失败，会自动重试，重试的策略：</p><ul><li>重试次数 &lt; retryTimesWhenSendFailed（可配置）</li><li>总的耗时（包含重试n次的耗时） &lt; sendMsgTimeout（发送消息时传入的参数）</li><li>同时满足上面两个条件后，Producer会选择另外一个队列发送消息</li></ul><h3 id="消费端负载均衡"><a href="#消费端负载均衡" class="headerlink" title="消费端负载均衡"></a>消费端负载均衡</h3><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031500.png"></p><p>producer向一些队列轮流发送消息，队列集合称为Topic：</p><ul><li>Consumer如果做广播消费，则一个consumer实例消费这个Topic对应的所有队列；</li><li>如果做集群消费，则多个Consumer实例平均消费这个Topic对应的队列集合</li></ul><p>集群模式里，每个consumer消费部分消息，这里的负载均衡是怎样的呢:</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031503.png"></p><p>消费端会通过RebalanceService线程，20秒钟做一次基于topic下的所有队列负载：</p><ul><li>遍历Consumer下的所有topic，然后根据topic订阅所有的消息</li><li>获取同一topic和Consumer Group下的所有Consumer</li><li>然后根据具体的分配策略来分配消费队列，分配的策略包含：平均分配、消费端配置等</li></ul><p>如同上图所示：如果有 3 个队列，2 个 consumer，那么第一个 Consumer 消费 2 个队列，第二 consumer 消费 1 个队列。这里采用的就是平均分配策略，它类似于我们的分页，TOPIC下面的所有queue就是记录，Consumer的个数就相当于总的页数，那么每页有多少条记录，就类似于某个Consumer会消费哪些队列。</p><p>通过这样的策略来达到大体上的平均消费，这样的设计也可以很方面的水平扩展Consumer来提高消费能力。</p><h2 id="部署架构"><a href="#部署架构" class="headerlink" title="部署架构"></a>部署架构</h2><ul><li>单Master模式：无需多言，一旦单个broker重启或宕机，一切都结束了！。</li><li>多Master模式：全是Master，没有Slave。<ul><li>当然，一个broker宕机了，应用是无影响的</li><li>缺点在于宕机的Master上未被消费的消息在Master没有恢复之前不可以订阅。</li></ul></li><li>多Master多Slave模式（异步复制）：多对Master-Slave，高可用！<ul><li>采用异步复制的方式，主备之间短暂延迟，MS级别。</li><li>Master宕机，消费者可以从Slave上进行消费，不受影响。</li><li>但是Master的宕机，会导致丢失掉极少量的消息。</li></ul></li><li>多Master多Slave模式（同步双写）：在Master/Slave都写成功的前提下，向应用返回成功<ul><li>不论是数据，还是服务都没有单点，都非常可靠！</li><li>缺点在于同步的性能比异步稍低。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
            <tag> RocketMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MQ详解及四大常用MQ对比</title>
      <link href="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/"/>
      <url>/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/</url>
      
        <content type="html"><![CDATA[<h2 id="消息队列概述"><a href="#消息队列概述" class="headerlink" title="消息队列概述"></a>消息队列概述</h2><h3 id="消息队列使用场景及其优缺点"><a href="#消息队列使用场景及其优缺点" class="headerlink" title="消息队列使用场景及其优缺点"></a>消息队列使用场景及其优缺点</h3><ul><li><p>消息队列使用场景</p><ul><li>异步通信<ul><li>紧急重要（需要立刻响应）的业务放到该调用方法中，响应要求不高的使用消息队列，放到MQ队列中，供消费者处理。</li><li>提高系统响应时长</li></ul></li><li>削峰<ul><li>过载保护和缓冲</li></ul></li><li>解耦<ul><li>降低工程间的强依赖程度，针对异构系统进行适配。</li></ul></li><li>冗余<ul><li>消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。</li><li>许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</li></ul></li><li>保证执行顺序</li><li>数据流处理<ul><li>ELK</li></ul></li></ul></li><li><p>消息队列优点</p><ul><li>低耦合</li><li>可靠投递</li><li>广播</li><li>流量控制</li><li>最终一致性</li><li>实时处理框架支撑等</li></ul></li><li><p>消息队列的问题</p><ul><li>系统可用性降低<ul><li>如何保证消息队列可用性？</li></ul></li><li>系统复杂度提高<ul><li>消息队列语义</li><li>如何保证没有重复消费</li><li>如何保证没有消息丢失</li><li>如何保证消息顺序</li></ul></li><li>一致性问题<ul><li>部分消费成功部分消费失败？</li></ul></li></ul></li></ul><h3 id="消息中间件组成"><a href="#消息中间件组成" class="headerlink" title="消息中间件组成"></a>消息中间件组成</h3><h4 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h4><p>消息服务器，作为server提供消息核心服务</p><h4 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h4><p>消息生产者，业务的发起方，负责生产消息传输给broker，</p><h4 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h4><p>主题，发布订阅模式下的消息统一汇集地，不同生产者向topic发送消息，由MQ服务器分发到不同的订阅者，实现消息的<strong>广播</strong></p><h4 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h4><p>队列，PTP模式下，特定生产者向特定queue发送消息，消费者订阅特定的queue完成指定消息的接收</p><h4 id="Topic-VS-Queue"><a href="#Topic-VS-Queue" class="headerlink" title="Topic VS Queue"></a>Topic VS Queue</h4><ul><li><p><strong>Queue</strong>: 实现了负载均衡，将producer生产的消息发送到消息队列中，由多个消费者消费。但一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有一个可用的消费者。</p></li><li><p><strong>Topic</strong>: 实现了发布和订阅，当你发布一个消息，所有订阅这个topic的服务都能得到这个消息，所以从1到N个订阅者都能得到一个消息的拷贝。</p></li></ul><h4 id="Message"><a href="#Message" class="headerlink" title="Message"></a>Message</h4><p>消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传输</p><h3 id="消息中间件模式"><a href="#消息中间件模式" class="headerlink" title="消息中间件模式"></a>消息中间件模式</h3><h4 id="点对点（PTP）"><a href="#点对点（PTP）" class="headerlink" title="点对点（PTP）"></a>点对点（PTP）</h4><p>PTP点对点： <strong>使用Queue作为通信载体</strong></p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/202112011037.png"></p><p>说明：</p><ul><li>消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。</li><li>消息被消费以后，queue中不再存储，所以消息消费者不可能消费到已经被消费的消息。 Queue支持存在多个消费者，<strong>但是对一个消息而言，只会有一个消费者可以消费</strong>。</li></ul><h4 id="发布-订阅-PUB-SUB"><a href="#发布-订阅-PUB-SUB" class="headerlink" title="发布/订阅(PUB/SUB)"></a>发布/订阅(PUB/SUB)</h4><p>Pub/Sub发布订阅（广播）：<strong>使用topic作为通信载体</strong></p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/202112011041.png"></p><p>说明：</p><ul><li>消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，<strong>发布到topic的消息会被所有订阅者消费</strong>。</li></ul><h3 id="消息中间件常用协议"><a href="#消息中间件常用协议" class="headerlink" title="消息中间件常用协议"></a>消息中间件常用协议</h3><h4 id="AMQP-Advanced-Message-Queuing-Protocol-协议"><a href="#AMQP-Advanced-Message-Queuing-Protocol-协议" class="headerlink" title="AMQP(Advanced Message Queuing Protocol)协议"></a>AMQP(Advanced Message Queuing Protocol)协议</h4><p>一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。</p><p>基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。</p><p>优点：可靠、通用</p><h4 id="MQTT（Message-Queuing-Telemetry-Transport，消息队列遥测传输）协议"><a href="#MQTT（Message-Queuing-Telemetry-Transport，消息队列遥测传输）协议" class="headerlink" title="MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）协议"></a>MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）协议</h4><p>IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。</p><p>该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和致动器（比如通过Twitter让房屋联网）的通信协议。 </p><p>优点：格式简洁、占用带宽小、移动端通信、PUSH、嵌入式系统</p><h4 id="STOMP（Streaming-Text-Orientated-Message-Protocol，流文本定向消息协议）协议"><a href="#STOMP（Streaming-Text-Orientated-Message-Protocol，流文本定向消息协议）协议" class="headerlink" title="STOMP（Streaming Text Orientated Message Protocol，流文本定向消息协议）协议"></a>STOMP（Streaming Text Orientated Message Protocol，流文本定向消息协议）协议</h4><p>是一种为MOM(Message Oriented Middleware，面向消息的中间件)设计的简单文本协议。</p><p>STOMP提供一个可互操作的连接格式，允许客户端与任意STOMP消息代理（Broker）进行交互。</p><p>优点：命令模式（非topic\queue模式）</p><h4 id="XMPP（Extensible-Messaging-and-Presence-Protocol，可扩展消息处理现场协议）协议"><a href="#XMPP（Extensible-Messaging-and-Presence-Protocol，可扩展消息处理现场协议）协议" class="headerlink" title="XMPP（Extensible Messaging and Presence Protocol，可扩展消息处理现场协议）协议"></a>XMPP（Extensible Messaging and Presence Protocol，可扩展消息处理现场协议）协议</h4><p>基于可扩展标记语言（XML）的协议，多用于即时消息（IM）以及在线现场探测。</p><p>适用于服务器之间的准即时操作。</p><p>核心是基于XML流传输，这个协议可能最终允许因特网用户向因特网上的其他任何人发送即时消息，即使其操作系统和浏览器不同。</p><p>优点：通用公开、兼容性强、可扩展、安全性高，但XML编码格式占用带宽大</p><h4 id="其他基于TCP-IP自定义的协议"><a href="#其他基于TCP-IP自定义的协议" class="headerlink" title="其他基于TCP/IP自定义的协议"></a>其他基于TCP/IP自定义的协议</h4><p>有些特殊框架（如：redis、kafka、zeroMq等）根据自身需要未严格遵循MQ规范，而是基于TCP\IP自行封装了一套协议，通过网络socket接口进行传输，实现了MQ的功能。</p><h3 id="常用消息中间件MQ总结"><a href="#常用消息中间件MQ总结" class="headerlink" title="常用消息中间件MQ总结"></a>常用消息中间件MQ总结</h3><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><p>Apache下的一个子项目，使用scala实现的一个高性能分布式Pub/Sub消息队列系统，具有以下特性：</p><ul><li>快速持久化：通过磁盘顺序读写与零拷贝机制，可以在O(1)的系统开销下进行消息持久化；</li><li>高吞吐：在一台普通的服务器上既可以达到10W/s的吞吐速率；</li><li>高堆积：支持topic下消费者较长时间离线，消息堆积量大；</li><li>完全的分布式系统：Broker、Producer、Consumer都原生自动支持分布式，依赖zookeeper（已移除）自动实现复杂均衡；</li><li>支持Hadoop数据并行加载：对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。</li></ul><h4 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h4><p>阿里参照kafka设计思想使用java实现的一套mq。同时将阿里系内部多款mq产品（Notify、metaq）进行整合，只维护核心功能，去除了所有其他运行时依赖，保证核心功能最简化，在此基础上配合阿里上述其他开源产品实现不同场景下mq的架构，目前主要多用于订单交易系统。</p><p>具有以下特点：</p><ul><li>能够保证严格的消息顺序</li><li>提供针对消息的过滤功能</li><li>提供丰富的消息拉取模式</li><li>高效的订阅者水平扩展能力</li><li>实时的消息订阅机制</li><li>亿级消息堆积能力</li></ul><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP,STOMP，也正是如此，使的它变的非常重量级，更适合于企业级的开发。</p><p>同时实现了Broker架构，核心思想是生产者不会将消息直接发送给队列，消息在发送给客户端时先在中心队列排队。</p><p>对路由(Routing)，负载均衡(Load balance)、数据持久化都有很好的支持。</p><p>多用于进行企业级的ESB整合。</p><h4 id="ZeroMQ"><a href="#ZeroMQ" class="headerlink" title="ZeroMQ"></a>ZeroMQ</h4><p>号称最快的消息队列系统，专门为高吞吐量/低延迟的场景开发，在金融界的应用中经常使用，偏重于实时数据通信场景。</p><p>ZMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，开发成本高。</p><p>因此ZeroMQ具有一个独特的非中间件的模式，更像一个socket library，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序本身就是使用ZeroMQ API完成逻辑服务的角色。</p><p>但是ZeroMQ仅提供<strong>非持久性的队列</strong>，如果down机，数据将会丢失。如：Twitter的Storm中使用ZeroMQ作为数据流的传输。</p><p>ZeroMQ套接字是与传输层无关的：ZeroMQ套接字对所有传输层协议定义了统一的API接口。默认支持 进程内(inproc) ，进程间(IPC) ，多播，TCP协议，在不同的协议之间切换只要简单的改变连接字符串的前缀。可以在任何时候以最小的代价从进程间的本地通信切换到分布式下的TCP通信。ZeroMQ在背后处理连接建立，断开和重连逻辑。</p><p>特性：</p><ul><li>无锁的队列模型：对于跨线程间的交互（用户端和session）之间的数据交换通道pipe，采用无锁的队列算法CAS；在pipe的两端注册有异步事件，在读或者写消息到pipe的时，会自动触发读写事件。</li><li>批量处理的算法：对于批量的消息，进行了适应性的优化，可以批量的接收和发送消息。</li><li>多核下的线程绑定，无须CPU切换：区别于传统的多线程并发模式，信号量或者临界区，zeroMQ充分利用多核的优势，每个核绑定运行一个工作者线程，避免多线程之间的CPU切换开销。</li></ul><h4 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h4><p>本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。</p><p>实验表明：</p><ul><li>入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；</li><li>出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</li></ul><h3 id="主要消息中间件的比较"><a href="#主要消息中间件的比较" class="headerlink" title="主要消息中间件的比较"></a>主要消息中间件的比较</h3><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/202112011141.png"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>详解HTTP2.0及HTTPS协议</title>
      <link href="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/"/>
      <url>/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<p>说明： 转自<a href="https://juejin.cn/post/7034668672262242318">详解 HTTP2.0 及 HTTPS 协议</a></p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>本文基于运维视角在阐述解析HTTP2.0协议相比较HTTP1.1的优点的同时讲述HTTPS协议的原理，并结合实际业务场景作为案例，目的是可以通过本文掌握HTTP2.0及HTTPS协议，了解原理，具备定位排查问题，调优的能力。</p><h2 id="HTTP1-1-VS-HTTP2"><a href="#HTTP1-1-VS-HTTP2" class="headerlink" title="HTTP1.1 VS HTTP2"></a>HTTP1.1 VS HTTP2</h2><p>严格意义上HTTP2.0和HTTPS并没有什么必然的联系，只是搭配使用更香一些，HTTP2 是1999年HTTP1.1之后的第一次更新。</p><p>HTTP2具有更好的效率和资源利用率，尤其适用于页面比较重，有大量资源加载的场景（公司的业务属于典型的场景），根据网络上的测试数据，在大量图片、资源需要加载的场景下，HTTP2解决HTTP1.1的线头阻塞（一次请求交互必须等待前一次请求交互的完成）问题相比HTTP1.1可以达到5倍以上的速度提升，目前，淘宝，天猫，京东等平台都已启用HTTP2，如果是<strong>页面存在大量惊天资源需要加载</strong>的情况，启用HTTP2.0，绝对物超所值。</p><h3 id="HTTP2-0特性"><a href="#HTTP2-0特性" class="headerlink" title="HTTP2.0特性"></a>HTTP2.0特性</h3><h4 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a>二进制分帧</h4><ul><li>HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。</li><li>HTTP/1 的请求和响应报文，都是由起始行，首部和实体正文（可选）组成，各部分之间以文本换行符分隔。 HTTP/2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。</li><li>HTTP1.1 的纯文本形式看起来一目了然，非常直观，但这只是对人的体验而言，事实上这种方式存在多义性，例如大小写、空白字符、回车换行、多字少字等，程序在处理的时候需要复杂的处理。</li><li>而二进制的方式，只是0和1，可以严格规定字段大小，顺序，标志位等，不存在歧义，提交小，同时也提升了数据在网络中传输的效率。</li></ul><h4 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h4><ul><li>HTTP1.1中一次请求与响应的交互必须要等待前面的请求交互完成，否则后面的只能等待。</li><li>而在HTTP2.0中，一次链接成功后，只要链接还没断开，那么 client 端就可以在一个链接中并发的发起多个请求，且每个请求的响应不需要等待其他请求。<ul><li>多路复用，代替原来的序列和阻塞机制。所有就是请求的都是通过一个 TCP连接并发完成。 HTTP 1.x 中，如果想并发多个请求，必须使用多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8个的TCP链接请求限制。常见的一个情况是，如果一个页面需要加载的静态资源过多，因为只有6-8个并发，所以客户端浏览器的等待时间就会比较久。</li></ul></li></ul><h4 id="服务器推送"><a href="#服务器推送" class="headerlink" title="服务器推送"></a>服务器推送</h4><ul><li><p>HTTP2中服务端可以在发送页面HTML时主动推送其它资源，而不用等到浏览器解析到相应位置，发起请求再响应。例如服务端可以主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML时再发送这些请求。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当然，如果一次性推送了太多的资源，因为浏览器需要处理所有推送过来的资源。反而会拖累性能。所以需要根据业务场景做权衡。</span><br></pre></td></tr></table></figure></li></ul><h4 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a>头部压缩</h4><ul><li><p>HTTP 1.1请求的大小变得越来越大，有时甚至会大于TCP窗口的初始大小，因为它们需要等待带着ACK的响应回来以后才能继续被发送。HTTP/2对消息头采用HPACK（专为http/2头部设计的压缩格式）进行压缩传输，能够节省消息头占用的网络的流量。而HTTP/1.x每次请求，都会携带大量冗余头信息，浪费了很多带宽资源。像cookie这些信息，每个请求都会附带，产生了很多不必要的资源消耗。为了减少这块的资源消耗并提升性能， HTTP/2对这些首部采取了压缩策略：</p><ul><li>HTTP/2在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键－值对，对于相同的数据，不再通过每次请求和响应发送；</li><li>首部表在HTTP/2的连接存续期内始终存在，由客户端和服务器共同渐进地更新;</li><li>每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值。</li></ul></li></ul><h3 id="ALPN-应用协议协商"><a href="#ALPN-应用协议协商" class="headerlink" title="ALPN 应用协议协商"></a>ALPN 应用协议协商</h3><p>HTTPS 握手的时候，客户端会首先告诉服务端自己支持的协议，由服务端选择客户端服务端都支持的协议。如果服务端Nginx开启了HTTP2支持，服务端会选择HTTP2协议，否则，服务端就会选择HTTP1.1协议来通讯。</p><h2 id="SSL-TLS模型"><a href="#SSL-TLS模型" class="headerlink" title="SSL/TLS模型"></a>SSL/TLS模型</h2><h3 id="TLS版本"><a href="#TLS版本" class="headerlink" title="TLS版本"></a>TLS版本</h3><p><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img.png"></p><p>历史版本的TLS/SSL因为安全漏洞和性能问题已经慢慢成为历史的尘埃，目前应用最为广泛的是TLS1.2版本，而TLS 1.3 是对于TLS1.2的升级，提供更强大的安全性和更高的性能。</p><h3 id="加密套件"><a href="#加密套件" class="headerlink" title="加密套件"></a>加密套件</h3><p><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img1.png"></p><p>加密套件：TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA</p><p>解释:</p><ul><li>基于TLS协议，使用ECDHE和RSA作为秘钥交换算法，加密算法是AES GCM，秘钥长度128位，哈希算法使用sha256</li><li>AES-GCM 是目前常用的分组加密算法，但是其有一个缺点就是计算量大，导致性能和电量开销比较大。为了解决这个问题，Intel 推出了名为 AES NI（Advanced Encryption Standard new instructions）的 x86 指令拓展集，从硬件上提供对 AES 的支持。对于支持 AES NI 指令的主机来说，使用 AES-GCM 是最佳选择。AES-GCM的优点在于可以利用多核提高加解密性能。</li></ul><h3 id="HTTPS握手过程"><a href="#HTTPS握手过程" class="headerlink" title="HTTPS握手过程"></a>HTTPS握手过程</h3><p><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img2.png"></p><ul><li><p><strong>Client-hello 阶段</strong></p><p>Client-hello 是TCP链接建立后客户端发送的第一条消息，主要目的是把客户端支持的功能和选项告诉服务端。</p><ul><li>浏览器中完成地址输入后, 解析域名获得 IP Host 地址, 浏览器会与此 Host 的443(默认, 如果指定其他端口则会连接此端口) 三次握手建立TCP连接，然后进入TLS 握手协议的 Client-hello。这一步骤中浏览器会将客户端支持的加密套件，目标Host等信息发送给服务器, 并会附上一份随机生成的 session ticket1.</li><li>ALPN协商: 应用层可以协商在安全连接层之上使用什么协议, 避免了额外的往返通讯。<br><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img_1.png"></li></ul></li><li><p><strong>Server-hello阶段</strong></p><ul><li>服务器收到浏览器发送来的 TLS 握手请求后, 存储浏览器发送的session ticket1, 然后根据发送来的 host 寻找对应的服务器证书, 然后会将服务器证书, 服务器从Client Hello提供的客户端支持的加密套件清单中按照优先级选择一个双方都支持的套件（如果服务端支持的套件和client支持的套件交集为空则握手失败）, 和一份随机生成的 session ticket2 返回给浏览器.</li></ul><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img_2.png" class></li></ul><p><strong>Client-hello和server-hello的步骤很像是买东西： 客户端： 我有多少钱，能支付宝也能微信付款， 服务端：需要xxx RMB，我们使用支付宝吧。</strong></p><ul><li><p>Cipher-spec 阶段</p><p>经过Client Hello和Server Hello 客户端和服务端完成了加密套件的协商。进入Cipher-spec 阶段会核验证书的有效性。</p><p>验证步骤如下:</p><ul><li>验证证书有效期</li><li>验证证书域名与实际的host是否匹配。</li><li>验证证书吊销状态(CRL+OCSP)确认证书是否被吊销。</li><li>验证证书颁发机构, 如果颁发机构是中间证书（基本都是）, 再验证中间证书的有效期/颁发机构/吊销状态. 一直验证到最后一层证书, 中途任何一个环节不通过都会提示不信任。</li><li>若检查通过, 随机生成一份 session ticket 3 (这是浏览器生成的第二份 ticket), 通过返回证书中的公钥, 用协商的加密算法加密, 返回给服务器.同时浏览器用 session ticket 1(浏览器) &amp; session ticket 2(服务器) &amp; session ticket 3(浏浏览器) 组合成 session key。</li></ul></li><li><p>内容传输阶段</p><ul><li>TLS 连接建立完成, 在连接销毁前, 浏览器与服务器的交互数据均通过 session key 来进行对称加密.</li></ul></li></ul><h4 id="HTTPS握手过程抓包："><a href="#HTTPS握手过程抓包：" class="headerlink" title="HTTPS握手过程抓包："></a>HTTPS握手过程抓包：</h4><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img_3.png" class><ul><li>前三行为TCP三次握手，</li><li>第四行客户端发起Client hello，</li><li>第五行服务端ack回复， </li><li>第六行Server Hello，</li><li>第9行Cipher-spec阶段进行证书校验，</li><li>完成握手之后第13行进入数据交互阶段。</li></ul><h3 id="HSTS"><a href="#HSTS" class="headerlink" title="HSTS"></a>HSTS</h3><p>通常访问网址的时候我们大多不会刻意的在前面写上https，也很少会关注我们是通过HTTP协议还是HTTPS协议在浏览。而要求https访问的站点，在用户通过http访问的时候大多以重定向的方式重定向到HTTPS地址，而如果我劫持了用户流量，拦截向https的重定向请求，然后担当一个代理的角色，如实转发客户端请求并返回，但是客户端跟中间人的交互采用的是明文的HTTP协议，由于没有建立SSL连接，所以客户端提交的信息都会暴露。基于此问题，是国际互联网工程组织 IETF 发布了HSTS的安全策略机制，强制让浏览器使用HTTPS与站点进行通信。</p><p>HSTS（HTTP Strict Transport Security）的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。HSTS主要是通过服务器发送响应头的方式来控制浏览器操作：</p><ul><li><p>当客户端通过 HTTPS 发出请求时，服务器会在返回的 HTTP 响应头中包含 Strict-Transport-Security 字段（HSTS的开关由服务端控制）。</p></li><li><p>浏览器接收到这样的信息之后，在一定期限内对该网站的任何请求都会以 HTTPS 发起（浏览器内部307跳转），而不会以 HTTP发起再由服务器重定向到 HTTPS。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM基础系列之对象的创建与访问</title>
      <link href="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/"/>
      <url>/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h3><h4 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h4><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/f301a9680197b8c1538bc25cf3823c32.jpg" alt="对象创建过程"></p><h5 id="类加载检查"><a href="#类加载检查" class="headerlink" title="类加载检查"></a>类加载检查</h5><p>虚拟机遇到一条 new 指令时: </p><ol><li>检查这个指令的参数是否能在常量池中定位到这个类的符号引用<ul><li>若常量池中没有这个类的符号引用，说明这个类还没有被定义，抛出ClassNotFoundException</li></ul></li><li>这个符号引用代表的类是否已被加载过、解析和初始化过。<ul><li>如果有，为新生对象分配内存</li><li>如果没有，必须先执行相应的类加载过程。</li></ul></li></ol><h5 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h5><p>对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。</p><p><code>一个对象所需的内存大小是在这个对象所属类被定义完就能确定的, 因此一个类所生产的所有对象的内存大小是一样的</code></p><p>分配方式无非有两种方法：</p><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/da8bf89a0c0434b587b2b37bb1bc3547.png" alt="java类内存分配"></p><ul><li>“指针碰撞”： 通过一个类似于指针的东西为对象分配内存，前提是堆空间是相对规整的。</li><li>“空闲列表”： 堆空间不规整，使用一个列表记录了哪些空间是空闲的，分配内存的时候会更新列表。 </li></ul><p><code>这是两种不同的方法，具体选择那种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。值得注意的是，复制算法内存也是规整的。</code></p><p><strong>java类内存分配如何保证并发线程安全</strong></p><p>多线程并发时会出现正在给对象 A 分配内存，还没来得及修改指针，对象 B 又用这个指针分配内存，这样就出现问题了。解决这种问题有两种方案：</p><ul><li>CAS+失败重试<ul><li>采用同步方法，使用 CAS 配上失败重试的方式保证更新操作的原子性。</li></ul></li><li>本地线程分配缓冲(Thread Local Allocation Buffer, TLAB)<ul><li>为每一个线程预先在 Eden 区分配一块儿内存(线程私有)，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配</li><li>扩展阅读： <a href="https://juejin.cn/post/6925217498723778568">TLAB</a></li></ul></li></ul><h5 id="初始化零值"><a href="#初始化零值" class="headerlink" title="初始化零值"></a>初始化零值</h5><p>虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头)</p><p><code>注意零值不是初始化方法指定的值，数字设置为0，布尔设置为false</code></p><p>保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。</p><h5 id="设置对象头"><a href="#设置对象头" class="headerlink" title="设置对象头"></a>设置对象头</h5><p>虚拟机要对对象进行必要的设置，例如</p><ul><li>这个对象是那个类的实例</li><li>如何才能找到类的元数据信息</li><li>对象的哈希码</li><li>对象的 GC 分代年龄等信息。</li></ul><p>这些信息存放在对象头中。</p><ul><li>另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。</li></ul><h5 id="执行-init-方法"><a href="#执行-init-方法" class="headerlink" title="执行 init 方法"></a>执行 init 方法</h5><p>在上⾯⼯作都完成之后，从虚拟机的视⻆来看，⼀个新的对象已经产⽣了，但从Java 程序的视⻆来看，对象创建才刚开始，⽅法还没有执⾏，所有的字段都还为零</p><p>把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</p><p><strong>初始化顺序</strong></p><p>在new B一个实例时首先要进行类的装载。（<strong>类只有在使用New调用创建的时候才会被java类装载器装入</strong>）</p><ul><li>先装载父类A，完成静态动作（包括静态代码和变量，它们的级别是相同的，按照代码中出现的顺序初始化）</li><li>再装载子类B，完成静态动作</li></ul><p>类装载完成，开始进行实例化</p><ul><li>父类A的成员实例化（非静态代码）</li><li>父类A的构造方法</li><li>子类B的成员实例化（非静态代码）</li><li>子类B的构造方法</li></ul><h4 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h4><p>在HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。</p><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/img.png"></p><h5 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h5><p>对象头主要划分为三个部分</p><ul><li><p>存储对象自身的运行时数据(markword)</p><ul><li>哈希码[jvm计算得到，对象重写的hashcode未写入对象头]、</li><li>GC 分代年龄: 扩展阅读: <a href="file:///G:\code\example\doc\java\Java多线程.md">从对象头状态变迁看内置锁实现</a></li><li>锁状态标志</li></ul></li><li><p>类型指针（class pointer）</p><ul><li>即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Klass Word  这里其实是虚拟机设计的一个oop-klass model模型，这里的OOP是指Ordinary Object Pointer（普通对象指针），看起来像个指针实际上是藏在指针里的对象。而 klass 则包含 元数据和方法信息，用来描述 Java 类。它在64位虚拟机开启压缩指针的环境下占用 32bits 空间。</span><br></pre></td></tr></table></figure></li><li><p>数组长度（对象数组）</p></li></ul><h5 id="实例数据-instance-data"><a href="#实例数据-instance-data" class="headerlink" title="实例数据(instance data)"></a>实例数据(instance data)</h5><p>对象真正存储的有效信息，在程序中所定义的各种类型的字段内容</p><p>存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在 Java 源码中定义顺序的影响</p><p>分配策略:相同宽度的字段总是放在一起，比如double和long</p><h5 id="对齐填充-padding"><a href="#对齐填充-padding" class="headerlink" title="对齐填充(padding)"></a>对齐填充(padding)</h5><p>对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">由于HotSpot规定对象的大小必须是8的整数倍，对象头刚好是整数倍，如果实例数据不是的话，就需要占位符对齐填充。</span><br></pre></td></tr></table></figure><h4 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h4><p>对象的访问方式由虚拟机决定，java虚拟机提供两种主流的方式：句柄访问对象和直接指针访问对象</p><h5 id="句柄访问对象"><a href="#句柄访问对象" class="headerlink" title="句柄访问对象"></a>句柄访问对象</h5><p>Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；</p><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/img_1.png"></p><p>优点:引用中存储的是稳定的句柄地址,在对象被移动【垃圾收集时移动对象是常态】只需改变句柄中实例数据的指针，不需要改动引用【ref】本身。</p><h5 id="直接指针访问对象"><a href="#直接指针访问对象" class="headerlink" title="直接指针访问对象"></a>直接指针访问对象</h5><p>Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference 中存储的直接就是对象的地址。</p><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/img_2.png"></p><p>优点:优势很明显，就是速度快，相比于句柄访问少了一次指针定位的开销时间。【可能是出于Java中对象的访问时十分频繁的,平时我们常用的JVM HotSpot采用此种方式】</p><h4 id="创建一个新对象的内存分配全流程"><a href="#创建一个新对象的内存分配全流程" class="headerlink" title="创建一个新对象的内存分配全流程"></a>创建一个新对象的内存分配全流程</h4>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM基础系列之Java类加载机制</title>
      <link href="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"/>
      <url>/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h3><h4 id="什么叫类加载"><a href="#什么叫类加载" class="headerlink" title="什么叫类加载"></a>什么叫类加载</h4><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/9f1e696004981c0f9249ad145474feea.jpg" alt="类装载器"></p><p>类的加载指的是将类的.class文件中的二进制数据读入到内存中，并为之创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。</p><p>类的加载过程是由类加载器来完成，类加载器由JVM提供。我们开发人员也可以通过继承ClassLoader来实现自己的类加载器。</p><h4 id="什么时候启动类加载"><a href="#什么时候启动类加载" class="headerlink" title="什么时候启动类加载"></a>什么时候启动类加载</h4><p>类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它。</p><p>如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误），如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。</p><h4 id="从什么地方加载-class文件"><a href="#从什么地方加载-class文件" class="headerlink" title="从什么地方加载.class文件"></a>从什么地方加载.class文件</h4><ul><li>本地磁盘</li><li>网上加载.class文件</li><li>数据库中</li><li>压缩文件（ZAR，JAR等）</li><li>从其他文件生成（JSP应用）</li><li>把一个java源文件动态编译，并执行加载。</li></ul><h4 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h4><p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：<strong>加载、验证、准备、解析、初始化、使用和卸载</strong>七个阶段。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/f2f2e86a8bedea038839b34d67e7dc90.jpg" alt="类生命周期"></p><p>类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">加载、验证、准备和初始化这四个阶段发生的顺序是确定的，</span><br><span class="line"></span><br><span class="line">而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始。</span><br><span class="line"></span><br><span class="line">另外,注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。</span><br></pre></td></tr></table></figure><h5 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h5><ul><li>通过类的全限定名称获取其定义的二进制字节流</li><li>将字节流代表的今天存储结构转化为方法区的运行时数据结构</li><li>在<strong>堆</strong>中生成一个代表这个类的 java.lang.Class 对象，作为方法区这些数据的访问入口。（注意不是方法区的数据结构）</li></ul><h5 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h5><blockquote><p>通过类的加载，内存中已经创建了一个Class对象。链接负责将二进制数据合并到 JRE中。链接需要通过验证、准备、解析三个阶段。</p></blockquote><h6 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h6><blockquote><p>验证阶段用于检查被加载的类是否有正确的内部结构，并和其他类协调一致，即是否满足java虚拟机的约束。</p></blockquote><ol><li>文件格式的验证：验证.class文件字节流是否符合class文件的格式的规范，并且能够被当前版本的虚拟机处理。这里面主要对魔数、主版本号、常量池等等的校验。</li><li>元数据验证：主要是对字节码描述的信息进行语义分析，以保证其描述的信息符合java语言规范的要求，比如说验证这个类是不是有父类，类中的字段方法是不是和父类冲突等等。</li><li>字节码验证：这是整个验证过程最复杂的阶段，主要是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。在元数据验证阶段对数据类型做出验证后，这个阶段主要对类的方法做出分析，保证类的方法在运行时不会做出危害虚拟机安全的事。</li><li>符号引用验证：它是验证的最后一个阶段，发生在虚拟机将符号引用转化为直接引用的时候。主要是对类自身以外的信息进行校验。目的是确保解析动作能够完成。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">符号引用:</span><br><span class="line">以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义的定位到目标即可。</span><br><span class="line">例如，在Class文件中它以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现。</span><br><span class="line">符号引用与虚拟机的内存布局无关，引用的目标并不一定加载到内存中。</span><br><span class="line">在Java中，一个java类将会编译成一个class文件。</span><br><span class="line">在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。</span><br><span class="line">比如org.simple.People类引用了org.simple.Language类，在编译时People类并不知道Language类的实际内存地址，因此只能使用符号org.simple.Language（假设是这个，当然实际中是由类似于CONSTANT_Class_info的常量来表示的）来表示Language类的地址。</span><br><span class="line">各种虚拟机实现的内存布局可能有所不同，但是它们能接受的符号引用都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。</span><br><span class="line">  </span><br><span class="line">直接引用:</span><br><span class="line">直接指向目标的指针（比如，指向“类型”【Class对象】、类变量、类方法的直接引用可能是指向方法区的指针）</span><br><span class="line">相对偏移量（比如，指向实例变量、实例方法的直接引用都是偏移量）</span><br><span class="line">一个能间接定位到目标的句柄</span><br><span class="line">直接引用是和虚拟机的布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经被加载入内存中了。</span><br></pre></td></tr></table></figure><blockquote><p>对整个类加载机制而言，验证阶段是一个很重要但是非必需的阶段，如果我们的代码能够确保没有问题，那么我们就没有必要去验证，毕竟验证需要花费一定的的时间。当然我们可以使用-Xverfity:none来关闭大部分的验证。</p></blockquote></li></ol><h6 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h6><blockquote><p>准备阶段主要为类变量分配内存并设置初始值。</p></blockquote><ul><li>类变量（static）会分配内存（方法区），但是实例变量不会，实例变量主要随着对象的实例化一块分配到java堆中;</li><li>这里的初始值指的是数据类型默认值(例如int为0， boolean为false)，而不是代码中被显示赋予的值。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public static int value = 1; //在这里准备阶段过后的value值为0，而不是1。赋值为1的动作在初始化阶段。</span><br></pre></td></tr></table></figure><h6 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h6>在类还未加载到虚拟机时，无法获取实际方法的引用地址。对于一个方法的调用，编译器会生成一个包含目标方法所在的类、目标方法名、接收参数类型以及返回值类型的符号引用，来指代要调用的方法。</li></ul><blockquote><p>解析阶段主要是虚拟机将常量池中的符号引用转化为直接引用的过程。</p></blockquote><p>主要针对<strong>类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符</strong>7类符号引用进行。</p><p>如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必会触发解析与初始化）</p><h5 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h5><blockquote><p>在初始化阶段，主要为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。</p></blockquote><h6 id="类变量初始化方式"><a href="#类变量初始化方式" class="headerlink" title="类变量初始化方式"></a>类变量初始化方式</h6><ol><li>申明类变量时指定初始值</li><li>使用静态代码块为类变量指定初始值</li></ol><h6 id="JVM初始化步骤"><a href="#JVM初始化步骤" class="headerlink" title="JVM初始化步骤"></a>JVM初始化步骤</h6><ul><li>假如这个类还没有被加载和连接，则程序先加载并连接该类</li><li>假如该类的直接父类还没有被初始化，则先初始化其直接父类</li><li>假如类中有初始化语句，则系统依次执行这些初始化语句</li></ul><h6 id="类初始化时机"><a href="#类初始化时机" class="headerlink" title="类初始化时机"></a>类初始化时机</h6><blockquote><p>只有对类的主动使用才会导致类的初始化</p></blockquote><ol><li>当虚拟机启动时(用户需要指定一个主类（包含main()方法的类）)，初始化用户指定的主类。</li><li>当遇到用以新建目标类实例的new指令时，初始化new指令的目标类</li><li>当遇到调用静态方法或者使用静态变量或者对该静态变量赋值(放入常量池中的常量除外)，初始化静态变量或方法所在的类； </li><li>初始化某个类的子类，则其父类也会被初始化</li><li>如果一个接口定义了default方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口初始化；</li><li>使用反射API对某个类进行反射调用时（如 Class.forName(“com.hepeng.Test”)），初始化这个类</li><li>使用jdk1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、RE_invokeStatic的方法句柄，并且这个方法句柄对应的类没有进行初始化，则需要先触发其初始化。</li></ol><h6 id="lt-clinit-gt-方法"><a href="#lt-clinit-gt-方法" class="headerlink" title="&lt; clinit&gt;方法"></a>&lt; clinit&gt;方法</h6><blockquote><p>虚拟机会收集类及父类中的类变量及类方法组合为&lt; clinit&gt;方法，根据定义的顺序进行初始化。</p></blockquote><ol><li><p>虚拟机会保证子类的&lt; clinit&gt;执行之前，父类的&lt; clinit&gt;方法先执行完毕。</p> <details><summary>一个简单的小Demo</summary>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;    </span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> A = <span class="number">10</span>;    </span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        A = <span class="number">20</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test1</span> <span class="keyword">extends</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> B = A;    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;        </span><br><span class="line">        System.out.println(Test1.B);    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 输出结果</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">20</span><br></pre></td></tr></table></figure><p> 从输出中看出，父类的静态初始化块在子类静态变量初始化之前初始化完毕，所以输出结果是20，不是10。</p> </details> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">因此，虚拟机中第一个被执行完毕的&lt; clinit&gt;方法肯定是java.lang.Object方法</span><br></pre></td></tr></table></figure></li><li><p>如果类或者父类中都没有静态变量及方法，虚拟机不会为其生成&lt; clinit&gt;方法。</p></li><li><p>接口与类不同的是，执行接口的＜clinit＞方法不需要先执行父接口的＜clinit＞方法。 </p><ul><li>只有当父接口中定义的变量使用时，父接口才会初始化。</li><li>另外，接口的实现类在初始化时也一样不会执行接口的＜clinit＞方法。</li></ul> <details><summary>这与普通类加载不一致</summary> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">InterfaceInitTest</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> A = CurrentTime.getTime();</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">InterfaceInitTest1</span> <span class="keyword">extends</span> <span class="title">InterfaceInitTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> B = <span class="number">100</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InterfaceInitTestImpl</span> <span class="keyword">implements</span> <span class="title">InterfaceInitTest1</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(InterfaceInitTestImpl.B);</span><br><span class="line">        System.out.println(<span class="string">&quot;---------------------------&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;当前时间：&quot;</span>+InterfaceInitTestImpl.A);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CurrentTime</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;加载了InterfaceInitTest接口&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 输出结果</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">100</span><br><span class="line">---------------------------</span><br><span class="line">加载了InterfaceInitTest接口</span><br><span class="line">当前时间：1560158880660</span><br></pre></td></tr></table></figure> </details></li><li><p>虚拟机会保证一个类的&lt; clinit&gt;方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只有一个线程去执行这个类的&lt; clinit&gt;方法，其他线程都需要阻塞等待，直到活动线程执行&lt; clinit&gt;方法完毕。</p> <details><summary>Demo</summary> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiThreadInitTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> A = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(Thread.currentThread()+<span class="string">&quot;init MultiThreadInitTest&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123; </span><br><span class="line">            TimeUnit.SECONDS.sleep(<span class="number">10</span>); </span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123; </span><br><span class="line">            e.printStackTrace(); </span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Runnable runnable = () -&gt; &#123; </span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot;start&quot;</span>);</span><br><span class="line">            System.out.println(MultiThreadInitTest.A);</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot;run over&quot;</span>); </span><br><span class="line">        &#125;;</span><br><span class="line">        Thread thread1 = <span class="keyword">new</span> Thread(runnable);</span><br><span class="line">        Thread thread2 = <span class="keyword">new</span> Thread(runnable);</span><br><span class="line">        thread1.start();</span><br><span class="line">        thread2.start();</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure><p> 输出结果</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Thread[main,5,main]init MultiThreadInitTest</span><br><span class="line">Thread[Thread-0,5,main]start</span><br><span class="line">10</span><br><span class="line">Thread[Thread-0,5,main]run over</span><br><span class="line">Thread[Thread-1,5,main]start</span><br><span class="line">10</span><br><span class="line">Thread[Thread-1,5,main]run over</span><br></pre></td></tr></table></figure><p> 只有第一个线程对MultiThreadInitTest进行了一次初始化，第二个线程一直阻塞等待等第一个线程初始化完毕</p> </details></li></ol><h6 id="final定义的初始化"><a href="#final定义的初始化" class="headerlink" title="final定义的初始化"></a>final定义的初始化</h6><p>对于一个使用final定义的常量，如果在编译时就已经确定了值，在引用时不会触发初始化，因为在编译的时候就已经确定下来，就是“宏变量”。如果在编译时无法确定，在初次使用才会导致初始化。</p><details><summary>单例模式静态内部类实现方式</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StaticInnerSingleton</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 使用静态内部类实现单例：</span></span><br><span class="line"><span class="comment">   * 1：线程安全</span></span><br><span class="line"><span class="comment">   * 2：懒加载</span></span><br><span class="line"><span class="comment">   * 3：非反序列化安全，即反序列化得到的对象与序列化时的单例对象不是同一个，违反单例原则</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">LazyHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> StaticInnerSingleton INNER_SINGLETON = <span class="keyword">new</span> StaticInnerSingleton();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">StaticInnerSingleton</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> StaticInnerSingleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> LazyHolder.INNER_SINGLETON;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看到单例实例使用final定义，但在编译时无法确定下来，所以在第一次使用StaticInnerSingleton.getInstance()方法时，才会触发静态内部类的加载，也就是延迟加载。</p><p>这里想指出，<strong>如果final定义的变量在编译时无法确定，则在使用时还是会进行类的初始化</strong>。</p></details><h6 id="ClassLoader只会对类进行加载，不会进行初始化"><a href="#ClassLoader只会对类进行加载，不会进行初始化" class="headerlink" title="ClassLoader只会对类进行加载，不会进行初始化"></a>ClassLoader只会对类进行加载，不会进行初始化</h6><h4 id="类加载方式"><a href="#类加载方式" class="headerlink" title="类加载方式"></a>类加载方式</h4><ul><li><p>通过命令行启动应用时由JVM初始化加载含有main()方法的主类。</p></li><li><p>通过Class.forName()方法动态加载，会默认执行初始化块（static{}），但是Class.forName(name,initialize,loader)中的initialze可指定是否要执行初始化块。</p></li><li><p>通过ClassLoader.loadClass()方法动态加载，不会执行初始化块。</p></li></ul><h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h3><p>Java虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便<strong>让应用程序自己决定如何去获取所需的类</strong>。实现这个动作的代码被称为“类加载器”（Class Loader）。</p><h4 id="类与类加载器"><a href="#类与类加载器" class="headerlink" title="类与类加载器"></a>类与类加载器</h4><p>类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远超类加载阶段。</p><p>对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。</p><p>这句话可以表达得更通俗一些：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">每个类在JVM中使用全限定类名（包名+类名）与类加载器联合为唯一的ID，所以如果同一个类使用不同的类加载器，可以被加载到虚拟机，但彼此不兼容。</span><br></pre></td></tr></table></figure><h4 id="类加载机制-1"><a href="#类加载机制-1" class="headerlink" title="类加载机制"></a>类加载机制</h4><ol><li><strong>全盘负责</strong>：   当一个类加载器负责加载某个Class时，该Class所依赖和引用的其他Class也由该类加载器负责载入，除非显示使用另一个类加载器来载入。</li><li><strong>父类委托（双亲委派）</strong>：先让父加载器试图加载该Class，只有在父加载器无法加载时该类加载器才会尝试从自己的类路径中加载该类。</li><li><strong>缓存机制</strong>：缓存机制会将已经加载的class缓存起来，当程序中需要使用某个Class时，类加载器先从缓存区中搜寻该Class，只有当缓存中不存在该Class时，系统才会读取该类的二进制数据，并将其转换为Class对象，存入缓存中。这就是为什么更改了class后，需要重启JVM才生效的原因。</li></ol><h4 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h4><p>Java语言系统自带有三个类加载器:</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/c2a7c4bf19cfc90945643d8d94ac0f3d.png" alt="双亲委派机制"></p><ul><li><p>Bootstrap ClassLoader：启动类加载器, 最顶层的加载类</p><blockquote><p>这个类加载器使用C++语言实现，是虚拟机自身的一部分<br>其他所有的类加载器都由Java语言实现，独立存在于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。</p></blockquote><ul><li>主要加载核心类库，也就是我们环境变量下面%JRE_HOME%\lib下的rt.jar、resources.jar、charsets.jar和class等(按照文件名识别，名字不符合的类库即使放在lib目录中也不会被加载)。</li><li>另外需要注意的是可以通过启动jvm时指定-Xbootclasspath和路径来改变Bootstrap ClassLoader的加载目录。比如java -Xbootclasspath/a:path被指定的文件追加到默认的bootstrap路径中。</li><li>我们可以打开我的电脑，在上面的目录下查看，看看这些jar包是不是存在于这个目录。</li></ul></li><li><p>Extention ClassLoader ：扩展的类加载器</p><blockquote><p>类sun.misc.Launcher$ExtClassLoader中以Java方式实现</p></blockquote><ul><li>加载目录%JRE_HOME%\lib\ext目录下的jar包和class文件。</li><li>还可以加载-D java.ext.dirs选项指定的目录。</li></ul></li><li><p>Appclass Loader：也称为SystemAppClass。</p><blockquote><p>sun.misc.Launcher$AppClassLoader来实现。是ClassLoader类中的getSystem-ClassLoader()方法的返回值，所以有些场合中也称它为“系统类加载器”</p></blockquote><ul><li>它负责加载用户类路径（ClassPath）上所有的类库，开发者同样可以直接在代码中使用这个类加载器。 </li></ul></li></ul><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B%E5%9B%BE.png"></p><p>加载器加载顺序： Bootstrap ClassLoader &gt; Extention ClassLoader &gt; Appclass Loader</p><h5 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h5><p>当一个类加载器收到类加载任务，会先交给其父类加载器去完成，因此最终加载任务都会传递到顶层的启动类加载器，只有当父类加载器无法完成加载任务时，才会尝试执行加载任务。</p><ul><li>可以避免重复加载，父类已经加载了，子类就不需要再次加载</li><li>更加安全，很好的解决了各个类加载器的基础类的统一问题，如果不使用该种方式，那么用户可以随意定义类加载器来加载核心api，会带来相关隐患。</li></ul><blockquote><p>类加载可以理解为通过类加载器（ClassLoader）定制化的类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”的动作，一个复杂的JAVA程序可能会包含大量的依赖，而JAVA&amp;框架本身也有自己依赖，两个不同程序的依赖可能会产生冲突，存在同一个全限定名加载出来的接口也可能有不兼容的情况。<br>通过双亲委派模型（自下而上扫描，扫描结束后不直接加载，交给父加载器，父加载器反馈不能加载后再通过当前加载器加载），有效解决重复加载和加载安全问题。</p></blockquote><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F.png"></p><h4 id="自定义加载器"><a href="#自定义加载器" class="headerlink" title="自定义加载器"></a>自定义加载器</h4><p>实现方案:</p><ul><li>遵守双亲委派模型：继承ClassLoader，重写findClass()方法。</li><li>破坏双亲委派模型：继承ClassLoader,重写loadClass()方法。</li></ul><p>通常我们推荐采用第一种方法自定义类加载器，最大程度上的遵守双亲委派模型。</p><p>实现步骤: </p><ul><li>创建一个类继承ClassLoader抽象类</li><li>重写findClass()方法</li><li>在findClass()方法中调用defineClass()</li></ul><h4 id="OSGI动态模型系统"><a href="#OSGI动态模型系统" class="headerlink" title="OSGI动态模型系统"></a>OSGI动态模型系统</h4><p>OSGi(Open Service Gateway Initiative)，是面向 Java 的动态模型系统，是 Java 动态化模块化系统的一系列规范。</p><p>OSGi 服务平台提供在多种网络设备上无需重启的动态改变构造的功能。为了最小化耦合度和促使这些耦合度可管理，OSGi 技术提供一种面向服务的架构，它能使这些组件动态地发现对方。</p><p>OSGi 旨在为实现 Java 程序的模块化编程提供基础条件，基于OSGi的程序很可能可以实现<strong>模块级的热插拔功能</strong>，当程序升级更新时，可以只停用、重新安装然后启动程序的其中一部分，这对企 业级程序开发来说是非常具有诱惑力的特性。</p><p>OSGi 描绘了一个很美好的模块化开发目标，而且定义了实现这个目标的所需要服务与架构，同时也有成熟的框架进行实现支持。但并非所有的应用都适合采用 OSGi 作为基础架构，它在提供强大功能同时，也引入了额外的复杂度，因为它不遵守了类加载的双亲委托模型。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM基础系列之运行时内存分配模型</title>
      <link href="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/"/>
      <url>/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="JVM是什么"><a href="#JVM是什么" class="headerlink" title="JVM是什么"></a>JVM是什么</h3><p>而对于不同的操作系统，系统操作指令集（CPU原语）往往是不同的。JVM即Java虚拟机，是基于C/C++开发的一种抽象计算机，它对不同平台的系统指令集进行封装，对外提供了一套固定的指令集，在运行时操作各种内存区域，使JAVA成为可以跨平台的语言。</p><p><code>一般来说，使用特定编译器编译的程序只能在对应的平台运行，这里也可以说编译器是与平台相关的，编译后的文件也是与平台相关的。我们说的语言跨平台是编译后的文件跨平台，而不是源程序跨平台。</code></p><p>虚拟机有很多种，不同厂商提供了不同实现，只要遵循虚拟机规范即可，目前我们所说的虚拟机一般指的是Hot Spot。</p><p>JVM对Java语言一无所知，只知道一种特定的二进制格式，即类文件格式，我们写好的程序最终交给JVM执行的时候会被编译成二进制格式，JVM只认识二进制格式，所以任何语言只要编译后的格式符合要求，都可以在JVM上运行。</p><p><strong>JVM 组成部分</strong></p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img.png"></p><ul><li>类加载器，在 JVM 启动时或者类运行时将需要的 class 加载到 JVM 中。</li><li>内存区，将内存划分成若干个区以模拟实际机器上的存储、记录和调度功能模块，如实际机器上的各种功能的寄存器或者 PC 指针的记录器等。</li><li>执行引擎，执行引擎的任务是负责执行 class 文件中包含的字节码指令，相当于实际机器上的 CPU 。</li><li>本地方法调用，调用 C 或 C++ 实现的本地方法的代码返回结果。</li></ul><p>一个Java类在经过编译好类加载之后，会将加载后的数据放入运行时数据区域，这样我们在运行程序时就可以直接从运行时数据区域中读取信息。</p><h3 id="JVM运行时数据区域详解"><a href="#JVM运行时数据区域详解" class="headerlink" title="JVM运行时数据区域详解"></a>JVM运行时数据区域详解</h3><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_1.png"></p><p>JVM 内存布局规定了 Java 在运行过程中内存申请、分配、管理的策略 ，保证了 JVM 的高效稳定运行。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_8.png"></p><h4 id="从jdk版本差异解读各内存区域"><a href="#从jdk版本差异解读各内存区域" class="headerlink" title="从jdk版本差异解读各内存区域"></a>从jdk版本差异解读各内存区域</h4><p>实际上，为了更好的适应 CPU 性能提升，最大限度提升JVM 运行效率，JDK中各个版本对JVM进行了一些迭代，示意图如下</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/JVM%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB.png"></p><p>JDK1.6、JDK1.7、JDK1.8 JVM 内存模型主要有以下差异：</p><ul><li>JDK 1.6：有永久代，静态变量存放在永久代上。</li><li>JDK 1.7：有永久代，但已经把字符串常量池、静态变量，存放在堆上。逐渐的减少永久代的使用。</li><li>JDK 1.8：无永久代，运行时常量池、类常量池，都保存在元数据区，也就是常说的元空间。但字符串常量池仍然存放在堆上。</li></ul><h4 id="从线程是否共享解读各内存区域"><a href="#从线程是否共享解读各内存区域" class="headerlink" title="从线程是否共享解读各内存区域"></a>从线程是否共享解读各内存区域</h4><p>如果按照线程是否共享来分类的话，如下图所示：</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_9.png"></p><h5 id="线程私有"><a href="#线程私有" class="headerlink" title="线程私有"></a>线程私有</h5><h6 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h6><ul><li>字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。</li><li>在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储。<code>由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，CPU 只有把数据装载到寄存器才能够运行。寄存器存储指令相关的现场信息，由于CPU 时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。</code><ul><li>每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器用来存放执行指令的偏移量和行号指示器等，线程执行或恢复都要依赖程序计数器。</li></ul></li><li>如果该方法不是Native方法，即PC寄存器会记录当前正在执行的java虚拟机指令的地址; 如果线程当前执行的方法是本地的，那么java虚拟机的PC寄存器的值就是Undefined。</li><li><strong>唯一不会发生OOM的区</strong>，随线程创建而创建、随线程死亡而死亡，因此不需要进行 GC。</li></ul><h6 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h6><ul><li><p>Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：<strong>局部变量表、操作数栈、动态链接、方法出口信息</strong>。</p></li><li><p>局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用</p><ul><li><p>存放方法参数和方法内部定义的局部变量</p><p><code>所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</code> </p><ul><li><p>如果局部变量是Java的8种基本基本数据类型，则存在局部变量表中，如果是引用类型。如new出来的String，局部变量表中存的是引用，而实例在堆中。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_10.png"></p></li></ul></li></ul></li><li><p>操作数栈</p><ul><li>操作数栈（Operand Stack）看名字可以知道是一个栈结构。</li><li>Java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。</li><li>当JVM为方法创建栈帧的时候，在栈帧中为方法创建一个操作数栈，保证方法内指令可以完成工作。</li></ul><details><summary>用实操理解一下</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* <span class="doctag">@author</span> Richard_yyf</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OperandStackTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> a + b;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译生成.class文件之后，再反汇编查看汇编指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">javac OperandStackTest.java</span><br><span class="line">javap -v OperandStackTest.class &gt; 1.txt</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public int sum(int, int);</span><br><span class="line">  descriptor: (II)I</span><br><span class="line">  flags: ACC_PUBLIC</span><br><span class="line">  Code:</span><br><span class="line">    stack=2, locals=3, args_size=3 // 最大栈深度为2 局部变量个数为3</span><br><span class="line">       0: iload_1 // 局部变量1 压栈</span><br><span class="line">       1: iload_2 // 局部变量2 压栈</span><br><span class="line">       2: iadd    // 栈顶两个元素相加，计算结果压栈</span><br><span class="line">       3: ireturn</span><br><span class="line">    LineNumberTable:</span><br><span class="line">      line 10: 0</span><br></pre></td></tr></table></figure></details></li><li><p>动态链接</p><ul><li>每个栈帧中包含一个在常量池中<strong>对当前方法的引用</strong>， 目的是<strong>支持方法调用过程的动态连接</strong>。</li></ul></li><li><p>方法返回地址</p><p>方法执行时有两种退出情况：</p><ul><li>正常退出，即正常执行到任何方法的返回字节码指令，如 RETURN、IRETURN、ARETURN等</li><li>异常退出</li></ul><p>无论何种退出情况，都将返回至方法当前被调用的位置。方法退出的过程相当于弹出当前栈帧，退出可能有三种方式：</p><ul><li>返回值压入上层调用栈帧</li><li>异常信息抛给能够处理的栈帧</li><li>PC 计数器指向方法调用后的下一条指令</li></ul><p>扩展阅读： <a href="https://link.juejin.cn/?target=https://louluan.blog.csdn.net/article/details/50412126">JVM机器指令集图解</a></p></li><li><p>为执行字节码服务</p></li><li><p>StackOverFlowError（不允许动态扩展，栈深度大于虚拟机允许的栈深度） 和 OutOfMemoryError （允许动态扩展，内存不足）</p></li><li><p>方法执行时入栈，方法执行完出栈，入栈出栈的时机很明确，所以这块区域不需要进行 GC。<br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img4.png"></p></li><li><p>扩展阅读： <a href="https://www.cnblogs.com/noKing/p/8167700.html">栈帧</a></p></li><li><p>扩展阅读： <a href="https://www.pianshen.com/article/9519386034/">逃逸分析-栈上分配-TLAB</a>, 对于开启逃逸分析的程序而言，不会逃逸的对象也会分配在栈上。</p></li></ul><h6 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h6><ul><li>与虚拟机栈相似，为执行Native服务。</li><li>本地方法栈和虚拟机栈在有的虚拟机是合在一起的，例如Hot Spot虚拟机。</li></ul><h5 id="线程共享"><a href="#线程共享" class="headerlink" title="线程共享"></a>线程共享</h5><h6 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h6><ul><li><p>所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放<strong>对象实例和数组</strong>，<em>几乎</em> 所有的对象实例以及数组都在这里分配内存(随着JIT编译器的发展和逃逸分析技术的成熟，这个说法也不是那么绝对)。</p><p>  <img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/cb25f0d4c52a9ffca1925e9694c6954d.jpg" alt="java堆空间"></p></li><li><p>java8后永久代已移除。</p></li><li><p>堆中的对象永远不会被显式释放，必须由GC回收。GC主要区域，也叫GC堆，采用分代垃圾收集算法（年轻代&amp;老年代）。</p></li><li><p>Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。</p><p><code>值得注意的是，在通常情况下，服务器在运行过程中，堆空间不断地扩容与回缩，会形成不必要的系统压力 所以在线上生产环境中 JVM的Xms和 Xmx会设置成同样大小，避免在GC 后调整堆大小时带来的额外压力。</code></p></li></ul><h6 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h6><ul><li>方法区也是所有线程共享。主要用于存储<strong>类的信息、常量池、方法数据、方法代码</strong>等。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。</li><li>JDK 1.8中移除整个永久代，取而代之的是一个叫元空间（Metaspace）的区域, 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。  空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。</li><li>如果方法区的内存无法满足分配请求时也会抛出OutOfMemoryError</li><li>扩展阅读：<a href="https://www.cnblogs.com/paddix/p/5309550.html">Java8内存模型—永久代(PermGen)和元空间(Metaspace)</a></li></ul><p><em>运行时常量池</em></p><p>方法区的一部分，用于存储编译生成的字面量（基本数据类型或被final修饰的常量或字符串）和符号引用，类或接口的运行时常量池是在java虚拟机创建类或接口时创建的。</p><ul><li>jdk1.6及之前: Java中的字符串是放在方法区中的运行时常量池内，</li><li>jdk1.7以后: 将字符串常量池拿出来放在了堆中。</li></ul><details><summary>一个有趣的例子</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GcDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String [] args)</span> </span>&#123;</span><br><span class="line">        String str = <span class="keyword">new</span> String(<span class="string">&quot;lonely&quot;</span>)+<span class="keyword">new</span> String(<span class="string">&quot;wolf&quot;</span>);</span><br><span class="line">        System.out.println(str == str.intern());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码在jdk1.6中打印false，在jdk1.7和jdk1.8中打印true。 关于intern()方法：</p><ul><li>JDK1.6：调用String.intern()方法，会先去检查常量池中是否存在该字符串，如果不存在，则会在方法区中创建一个字符串，而new String()创建的字符串在堆中，两个字符串的地址当然不相等。</li><li>JDK1.8：字符串常量池从方法区的运行时常量池移到了堆中，调用String.intern()方法，首先会检查常量池是否存在，如果不存在，那么就会创建一个常量，并将引用指向堆，也就是说不会再重新创建一个字符串对象了，两者都会指向堆中的对象，所以返回true。</li></ul><p>只有一个new String()，产生两个对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GcDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String [] args)</span> </span>&#123;</span><br><span class="line">        String str = <span class="keyword">new</span> String(<span class="string">&quot;lonely&quot;</span>);</span><br><span class="line">        System.out.println(str == str.intern());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只有一个new String()，在jdk1.7和jdk1.8也会返回false，我们假设一开始字符串常量池没有任何字符串，执行一个new String(“lonely”)会产生两个对象，一个在堆，一个在字符串常量池。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_5.png"></p><p>String.intern()先检查字符串常量池，发现存在”lonely”的字符串，所以直接返回，这时候两个地址不一样，所以返回false。</p><ul><li><p>new String(“lonely”)+new String(“wolf”)会产生5个对象，2个在字符串常量池，3个在堆。<br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_6.png" alt="img.png"></p><ul><li>如果在1.7和1.8中会检查字符串常量池，发现没有lonelywolf的字符串，所以会在字符串常量池创建一个，指向堆中的字符串。</li><li>JDK1.6中不会指向堆，会重新创建一个lonelywolf的字符串放到字符串常量池，所以才会产生不同的结果。</li></ul></li></ul></details><h6 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h6><ul><li>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。</li><li>使用Native函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。  这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。</li><li>Java8后<strong>方法区的实现-元空间就在使用了直接内存实现</strong>（不进行GC进而提高了性能）</li><li>Code Cache<ul><li><strong>JVM代码缓存是JVM将其字节码存储为本机代码的区域</strong>。我们将可执行本机代码的每个块称为 nmethod 。该 nmethod可能是一个完整的或内联Java方法。</li><li>实时（JIT）编译器是代码缓存区域的最大消费者。这就是为什么一些开发人员将此内存称为JIT代码缓存的原因。 </li><li>一般情况下我们是不会关心这部分区域的且大部分开发人员对这块区域也不熟悉。如果这块区域OOM了，在日志里面就会看到 java.lang.OutOfMemoryError code cache。</li><li>扩展阅读: <a href="https://link.juejin.cn/?target=https://www.baeldung.com/jvm-code-cache">Introduction to JVM Code Cache</a></li></ul></li><li>也可能导致 OutOfMemoryError 异常出现。</li><li>扩展阅读：<a href="https://link.juejin.cn/?target=https://www.jianshu.com/p/35cf0f348275">堆外内存回收</a></li></ul><h3 id="从进程与线程的角度理解JVM运行时数据区设计原理"><a href="#从进程与线程的角度理解JVM运行时数据区设计原理" class="headerlink" title="从进程与线程的角度理解JVM运行时数据区设计原理"></a>从进程与线程的角度理解JVM运行时数据区设计原理</h3><p>首先，我们回顾一下进程与线程的区别与联系:</p><p><strong>进程 = 线程+内存+文件/网络句柄</strong></p><ul><li>这里的内存是逻辑内存，指的是内存的寻址空间。每个进程的内存是相互独立的。</li><li>文件/网络句柄是所有的进程所共有的，例如打开同一个文件，去抢同一个网络的端口这样的操作是被允许的</li></ul><p><strong>线程 = 栈+PC+TLS</strong></p><ul><li>通常都是说调用堆栈，调用堆栈就是调用栈的意思(这里的堆是没有含义的)。每次调用的时候，会把所有的参数和返回地址压入到栈中。</li><li>Program Counter: 程序计数器，我们的进程只是一个容器。PC就是指向当前的指令，而这个指令是放在内存中。每个线程都有一串自己的指针，去指向自己当前所在内存的指针。</li><li>thread local storage: 线程独立的内存就是TLS，可以用来存储我们线程所独有的数据。</li></ul><p><strong>总结如下</strong></p><ol><li>线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；</li><li>一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线；</li><li>进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见；</li><li>调度和切换：线程上下文切换比进程上下文切换要快得多。</li></ol><p>线程与进程关系的示意图：<br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_2.png"><br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_3.png"></p><p><strong>对于一个JAVA进程而言</strong>：</p><ul><li>JAVA进程间的内存分配保持独立</li><li>JAVA同进程的多线程间共享代码段（方法区）、数据集（堆）</li><li>JAVA各线程分别维护自己的寄存器（程序计数器）和方法栈（分为本地方法栈和虚拟机栈）</li></ul><h3 id="从操作系统层面理解JVM与系统物理内存分配"><a href="#从操作系统层面理解JVM与系统物理内存分配" class="headerlink" title="从操作系统层面理解JVM与系统物理内存分配"></a>从操作系统层面理解JVM与系统物理内存分配</h3><h4 id="系统进程占用的物理内存高于-Xmx"><a href="#系统进程占用的物理内存高于-Xmx" class="headerlink" title="系统进程占用的物理内存高于-Xmx"></a>系统进程占用的物理内存高于-Xmx</h4><p>在实际运行过程中，我们通常会发现: 系统进程占用的物理内存(Res/Rss)会大于设置的Xmx值</p><p>实际上，-Xmx和-Xms参数实际上只是Java堆对象将会占用的内存，而堆只是影响Java程序占用内存数量的一个因素。</p><p>除了堆，影响Java程序所占用内存的因素还包括: 栈、永生代、JVM本身、NIO中的DirectBuffer等。</p><p>因此，一般使用Xmx分配给JVM的，肯定不能太多。</p><p>而且，在操作系统上，运行的不仅仅是JVM应用，还会有其他一些守护进程，比如各种日志收集工具、监控工具、安全工具等。它们虽然占用的内存不是很多，但累加起来还是比较可观的。JVM内存和操作系统的剩余内存是一个此消彼长的关系，这些小内存挤占了JVM的发挥空间，就容易出问题。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_7.png"></p><p>JVM是我们的主体，所以要把它放在主人公的位置。这种划分方式，就可以把整个内存搞成JVM内存、操作系统物理内存、SWAP三个部分。</p><p>当JVM和其他程序占满了物理内存，接着占满了SWAP内存（交换分区一般不开，此处不展开），当在需要申请内存空间的时候，操作系统发现没有可用的内存空间了。</p><p>这个时候，Linux会启动oom-killer，杀死占用内存最大的进程，这个时候大概率我们的JVM进程。</p><p>由于这个OOM为操作系统本身的OOM，这个时候会出现的现象为: <strong>java进程死了，但是没有留下任何日志</strong></p><p><code>此日志可以通过dmesg命令找到，属于操作系统范畴</code></p><h4 id="对内存做一些更细致的划分"><a href="#对内存做一些更细致的划分" class="headerlink" title="对内存做一些更细致的划分"></a>对内存做一些更细致的划分</h4><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/%E5%86%85%E5%AD%98.png"></p><ul><li>堆内内存: 是我们平常打交道最多的地方，因为我们大部分Java对象，都是在堆上分配的。<ul><li>一旦有溢出问题，使用jmap + mat等一系列猛如虎的操作，就可以方便快捷的发现问题。</li></ul></li><li>堆外内存<ul><li>元空间<ul><li>jdk8以后才加入的，用来替换原来的永久代，用于存储那些变动很少的数据，稳定为主。</li><li>比如我们在jvm启动时，加载的那些class文件；以及在运行时，动态生成的代理类。</li><li>默认是没有上限的，极端情况下，会一直挤占操作系统的剩余内存。</li></ul></li><li>CodeCache<ul><li>JIT是JVM一个非常重要的特性，CodeCahe存放的，就是即时编译器所生成的二进制代码。</li><li>当然，JNI的代码也是放在这里的。</li><li>在不同的平台，大小都是不一样的，但一般够用了。<code>调的非常小的情况下，JVM不会溢出，这个区域也不会溢出，但是会退化成解释型执行模式，速度和JIT不可同日而语，慢个数量级也是可能的</code></li></ul></li><li>本地内存<ul><li>网络内存<ul><li>可以认为它是操作系统内核所占用的内存，也可以认为是JVM进程占用的内存</li><li>如果你的系统并发非常高，这部分内存的占用也是比较多的。因为连接一般对应着网卡的数据缓冲区，还有文件句柄的耗费。</li></ul></li><li>线程内存<ul><li>如果你造的线程非常多，JVM除了占用Thread对象本身很小的一部分堆内存，大部分是以轻量级进程的方式存在于操作系统。</li><li>这同样是一个积少成多的内存区域，但一般不会发生问题</li></ul></li><li>JNI内存<ul><li>上面谈到CodeCache存放的JNI代码，JNI内存就是指的这部分代码所malloc的具体内存。 </li><li>比如Java的zip库，就不是在JVM的堆里完成的，而是开辟了一个堆外的缓冲池进行运算。</li></ul></li><li>直接内存<ul><li>指的是使用了Java的直接内存API，进行操作的内存。</li><li>这部分内存可以受到JVM的管控，比如ByteBuffer类所做的事情。</li><li>ByteBuffer底层是用的unsafe, 但unsafe是不受直接内存的管控的，因此并不会造成JVM直接内存溢出，反而会造成操作系统内存溢出。。</li></ul></li></ul></li></ul></li></ul><h4 id="如何排查操作系统内存"><a href="#如何排查操作系统内存" class="headerlink" title="如何排查操作系统内存"></a>如何排查操作系统内存</h4><p>linux下有一个命令lsof，可以看到JVM进程所关联的所有句柄信息，一般可作为参考。</p><p>近一步，使用pmap函数，即可观测到具体的内存分布。但是不要怕，有很多是共享内存。</p><p>具体排查思路可以参考 <a href="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/" title="JAVA线上故障排查全套路">JAVA线上故障排查全套路</a> 中的堆外内存溢出。</p><h4 id="内存区域控制参数"><a href="#内存区域控制参数" class="headerlink" title="内存区域控制参数"></a>内存区域控制参数</h4><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%8F%82%E6%95%B0.png"></p><ul><li>堆  <code>-Xmx  -Xms</code></li><li>元空间 <code>-XX:MaxMetaspaceSize  -XX:MetaspaceSize</code></li><li>栈 <code>-Xss</code></li><li>直接内存  <code>-XX:MaxDirectMemorySize</code></li><li>JIT编译后代码存放 <code>-XX:ReservedCodeCacheSize</code></li><li>其他堆外内存 <code>无法控制！随缘吧</code></li></ul><p>可以看到，堆外内存的占用，其实还是比较多的。如果你太贪婪，整个内存很容易就玩玩。</p><p>一般的，我们使用操作系统的2/3作为堆空间，是比较合理的。这是一个经验值。比如6GB的内存，你分配给JVM的，最好不要超过4GB。</p><p>还有，我们上面谈到的swap交换分区，在高并发应用中，一般是关掉的。因为它会造成频繁的页交换，在GC的时候，会引起严重的卡顿。</p><p>但要辩证的思维看待问题。对于低频的，对内存大小有非常大的依赖的情况下，SWAP不仅要开，还要开的大一些。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码实用小套路之Java 性能优化的一些细节</title>
      <link href="/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BJava-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82/"/>
      <url>/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BJava-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<p>在JAVA程序中，性能问题的大部分原因并不在于JAVA语言，而是程序本身。养成良好的编码习惯非常重要，能够显著地提升程序性能。</p><ol><li><p>尽量在合适的场合使用单例</p><p> 使用单例可以减轻加载的负担，缩短加载的时间，提高加载的效率，但并不是所有地方都适用于单例</p><p> 简单来说，单例主要适用于以下三个方面：</p><ul><li>控制资源的使用，通过线程同步来控制资源的并发访问；</li><li>控制实例的产生，以达到节约资源的目的；</li><li>控制数据共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信。</li></ul></li><li><p>尽量避免随意使用静态变量</p><p> 当某个对象被定义为static变量所引用，那么GC通常是不会回收这个对象所占有的内存，如:</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> B b = <span class="keyword">new</span> B();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时静态变量 b 的生命周期与A类同步，如果A类不会卸载，那么b对象会常驻内存，直到程序终止。</p></li><li><p>尽量避免过多过常地创建Java对象</p><p>尽量避免在经常调用的方法，循环中new对象，由于系统不仅要花费时间来创建对象，而且还要花时间对这些对象进行垃圾回收和处理。</p><p>在我们可以控制的范围内，最大限度地重用对象，最好能用基本的数据类型或数组来替代对象。</p></li><li><p>尽量使用final修饰符</p><p>带有final修饰符的类是不可派生的。在JAVA核心API中，有许多应用final的例子，例如java、lang、String，为String类指定final防止了使用者覆盖length()方法。</p><p>另外，如果一个类是final的，则该类所有方法都是final的。java编译器会寻找机会内联（inline）所有的final方法（这和具体的编译器实现有关），此举能够使性能平均提高50%。</p><p>如：让访问实例内变量的getter/setter方法变成”final：简单的getter/setter方法应该被置成final，这会告诉编译器，这个方法不会被重载，所以，可以变成”inlined”,例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MAF</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSize</span> <span class="params">(<span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">     _size = size;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> _size;</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"><span class="comment">// 更正</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DAF_fixed</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">final</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSize</span> <span class="params">(<span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">     _size = size;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> _size;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>尽量使用局部变量</p><p>调用方法时传递的参数以及在调用中创建的临时变量都保存在栈（Stack）中，速度较快；其他变量，如静态变量、实例变量等，都在堆（Heap）中创建，速度较慢。</p></li><li><p>尽量处理好包装类型和基本类型两者的使用场所</p><p>虽然包装类型和基本类型在使用过程中是可以相互转换，但它们两者所产生的内存区域是完全不同的</p><ul><li><p>基本类型数据产生和处理都在栈中处理，包装类型作为对象是在堆中产生实例（开启逃逸分析小对象也在栈上分配?）。</p></li><li><p>在集合类对象，有对象方面需要的处理适用包装类型，其他的处理提倡使用基本类型。</p></li></ul></li><li><p>慎用synchronized，尽量减小synchronize的方法</p><p>都知道，实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。</p><p>synchronize方法被调用时，直接会把当前对象锁了，在方法执行完之前其他线程无法调用当前对象的其他方法。</p><p>所以，synchronize的方法尽量减小，并且应<strong>尽量使用方法同步代替代码块同步</strong>。</p></li><li><p>尽量不要使用finalize方法</p><p>实际上，将资源清理放在finalize方法中完成是非常不好的选择</p><p>由于GC的工作量很大，尤其是回收Young代内存时，大都会引起应用程序暂停，所以再选择使用finalize方法进行资源清理，会导致GC负担更大，程序运行效率更差。</p></li><li><p>尽量使用基本数据类型代替对象</p><p>String str = “hello”;</p><p>上面这种方式会创建一个“hello”字符串，而且JVM的字符缓存池还会缓存这个字符串；</p><p>String str = new String(“hello”);</p><p>此时程序除创建字符串外，str所引用的String对象底层还包含一个char[]数组，这个char[]数组依次存放了h,e,l,l,o</p></li><li><p>多线程在未发生线程安全前提下应尽量使用HashMap、ArrayList</p></li></ol><p>   HashTable、Vector等使用了同步机制，降低了性能。</p><ol start="11"><li>尽量合理的创建HashMap</li></ol><p>   当你要创建一个比较大的hashMap时，充分利用这个构造函数</p><p>   public HashMap(int initialCapacity, float loadFactor);</p><p>   避免HashMap多次进行了hash重构,扩容是一件很耗费性能的事</p><p>   在默认中initialCapacity只有16，而loadFactor是 0.75，需要多大的容量，你最好能准确的估计你所需要的最佳大小，同样的Hashtable，Vectors也是一样的道理。</p><ol start="12"><li>尽量减少对变量的重复计算</li></ol><p>   如：</p><p>   <code>for(int i=0;i&lt;list.size();i++)</code></p><p>   应该改为：<br>   <code>for(int i=0,len=list.size();i&lt;len;i++)</code></p><p>   并且在循环中应该避免使用复杂的表达式，在循环中，循环条件会被反复计算，如果不使用复杂表达式，而使循环条件值不变的话，程序将会运行的更快。</p><ol start="13"><li>尽量避免不必要的创建</li></ol><p>   如：</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A a = new A();</span><br><span class="line">if(i==1)&#123;</span><br><span class="line">   list.add(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   应该改为：</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if(i==1)&#123;</span><br><span class="line">   A a = new A();</span><br><span class="line">   list.add(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="14"><li>尽量在finally块中释放资源</li></ol><p>   程序中使用到的资源应当被释放，以避免资源泄漏，这最好在finally块中去做。不管程序执行的结果如何，finally块总是会执行的，以确保资源的正确关闭。</p><ol start="15"><li>尽量使用移位来代替’a/b’或者’a*b’的操作</li></ol><p>   “/“和”*”是一个代价很高的操作，使用移位的操作将会更快和更有效</p><p>   如：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int num = a / 4;</span><br><span class="line">int num = a / 8;</span><br><span class="line">int num = a * 4;</span><br><span class="line">int num = a * 8;</span><br></pre></td></tr></table></figure></p><p>   应该改为：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int num = a &gt;&gt; 2;</span><br><span class="line">int num = a &gt;&gt; 3;</span><br><span class="line">int num = a &lt;&lt; 2;</span><br><span class="line">int num = a &lt;&lt; 3;</span><br></pre></td></tr></table></figure></p><p>   但注意的是<strong>使用移位应添加注释</strong>，因为移位操作不直观，比较难理解。</p><ol start="16"><li>尽量确定StringBuffer的容量</li></ol><p>   StringBuffer 的构造器会创建一个默认大小（通常是16）的字符数组。</p><p>   在使用中，如果超出这个大小，就会重新分配内存，创建一个更大的数组，并将原先的数组复制过来，再丢弃旧的数组。</p><p>   在大多数情况下，你可以在创建 StringBuffer的时候指定大小，这样就避免了在容量不够的时候自动增长，以提高性能。如：</p><p>   StringBuffer buffer = new StringBuffer(1000);</p><ol start="17"><li>尽量早释放无用对象的引用</li></ol><p>   大部分时，方法局部引用变量所引用的对象会随着方法结束而变成垃圾，因此，大部分时候程序无需将局部，引用变量显式设为null。例如：</p><p>   Java代码<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Public void test()&#123;</span><br><span class="line">   Object obj = new Object();</span><br><span class="line">   ……</span><br><span class="line">   Obj = null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>   上面这个就没必要了，随着方法test()的执行完成，程序中obj引用变量的作用域就结束了。</p><p>   但是如果是改成下面：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Public void test()&#123;</span><br><span class="line">   Object obj = new Object();</span><br><span class="line">   ……</span><br><span class="line">   Obj = null;</span><br><span class="line">   //执行耗时，耗内存操作；或调用耗时，耗内存的方法</span><br><span class="line">   ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>   这时候就有必要将obj赋值为null，可以尽早的释放对Object对象的引用。</p><ol start="18"><li>尽量避免使用二维数组</li></ol><p>   二维数据占用的内存空间比一维数组多得多，大概10倍以上。</p><ol start="19"><li>尽量避免使用split</li></ol><p>   除非是必须的，否则应该避免使用split，split由于支持正则表达式，所以效率比较低</p><p>   如果是频繁的几十，几百万的调用将会耗费大量资源，如果确实需要频繁的调用split，可以考虑使用apache的StringUtils.split(string,char)，频繁split的可以缓存结果</p><ol start="20"><li>ArrayList &amp; LinkedList</li></ol><p>   一个是线性表，一个是链表，一句话，随机查询尽量使用ArrayList，ArrayList优于LinkedList，LinkedList还要移动指针，添加删除的操作LinkedList优于ArrayList，ArrayList还要移动数据</p><p>   不过这是理论性分析，事实未必如此，重要的是理解好2者得数据结构，对症下药。</p><ol start="21"><li>尽量使用System.arraycopy ()代替通过来循环复制数组</li></ol><p>   System.arraycopy() 要比通过循环来复制数组快的多。</p><ol start="22"><li>尽量缓存经常使用的对象</li></ol><p>   尽可能将经常使用的对象进行缓存，可以使用数组，或HashMap的容器来进行缓存，但这种方式可能导致系统占用过多的缓存，性能下降</p><p>   推荐可以使用一些第三方的开源工具，如EhCache，Oscache进行缓存，他们基本都实现了FIFO/FLU等缓存算法。</p><ol start="23"><li>尽量避免非常大的内存分配</li></ol><p>   有时候问题不是由当时的堆状态造成的，而是因为分配失败造成的。分配的内存块都必须是连续的，而随着堆越来越满，找到较大的连续块越来越困难。</p><ol start="24"><li>慎用异常</li></ol><p>   当创建一个异常时，需要收集一个栈跟踪(stack track)，这个栈跟踪用于描述异常是在何处创建的。</p><p>   构建这些栈跟踪时需要为运行时栈做一份快照，正是这一部分开销很大。</p><p>   当需要创建一个 Exception 时，JVM 不得不说：先别动，我想就您现在的样子存一份快照，所以暂时停止入栈和出栈操作。栈跟踪不只包含运行时栈中的一两个元素，而是包含这个栈中的每一个元素。</p><p>   如果您创建一个 Exception ，就得付出代价，好在捕获异常开销不大，因此可以使用 try-catch 将核心内容包起来。</p><p>   从技术上讲，你甚至可以随意地抛出异常，而不用花费很大的代价。招致性能损失的并不是 throw 操作——尽管在没有预先创建异常的情况下就抛出异常是有点不寻常。</p><p>   真正要花代价的是创建异常，幸运的是，好的编程习惯已教会我们，不应该不管三七二十一就抛出异常。异常是为异常的情况而设计的，使用时也应该牢记这一原则。</p><ol start="25"><li>尽量重用对象</li></ol><p>   特别是String对象的使用中，出现字符串连接情况时应使用StringBuffer代替，由于系统不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理。因此生成过多的对象将会给程序的性能带来很大的影响。</p><ol start="26"><li>不要重复初始化变量</li></ol><p>   默认情况下，调用类的构造函数时，java会把变量初始化成确定的值，所有的对象被设置成null，整数变量设置成0，float和double变量设置成0.0，逻辑值设置成false。</p><p>   当一个类从另一个类派生时，这一点尤其应该注意，因为用new关键字创建一个对象时，构造函数链中的所有构造函数都会被自动调用。</p><p>   这里有个注意，给成员变量设置初始值但需要调用其他方法的时候，最好放在一个方法。比如initXXX()中，因为直接调用某方法赋值可能会因为类尚未初始化而抛空指针异常，如：public int state = this.getState()。</p><ol start="27"><li><p>在java+Oracle的应用系统开发中，java中内嵌的SQL语言应尽量使用大写形式，以减少Oracle解析器的解析负担。</p></li><li><p>在java编程过程中，进行数据库连接，I/O流操作，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销。</p></li><li><p>过分的创建对象会消耗系统的大量内存，严重时，会导致内存泄漏</p></li></ol><p>   因此，保证过期的对象的及时回收具有重要意义。JVM的GC并非十分智能，因此建议在对象使用完毕后，手动设置成null。</p><ol start="30"><li>不要在循环中使用Try/Catch语句，应把Try/Catch放在循环最外层</li></ol><p>   Error是获取系统错误的类，或者说是虚拟机错误的类。不是所有的错误Exception都能获取到的，虚拟机报错Exception就获取不到，必须用Error获取。</p><ol start="31"><li>array(数组)和ArrayList的使用</li></ol><p>   array 数组效率最高，但容量固定，无法动态改变，ArrayList容量可以动态增长，但牺牲了效率。</p><ol start="32"><li><p>单线程应尽量使用 HashMap, ArrayList,除非必要，否则不推荐使用HashTable,Vector，它们使用了同步机制，而降低了性能。</p></li><li><p>考虑使用静态方法，如果你没有必要去访问对象的外部，那么就使你的方法成为静态方法。它会被更快地调用，因为它不需要一个虚拟函数导向表。</p></li></ol><p>   这同时也是一个很好的实践，因为它告诉你如何区分方法的性质，调用这个方法不会改变对象的状态。</p><ol start="34"><li><p>避免枚举，浮点数的使用。</p></li><li><p>使用32位的无符号整数（UNSIGNED INT）来存储IP地址，而不是使用字符串 </p><p>  相对字符串存储，使用无符号整数来存储有如下的好处：</p><ul><li>节省空间，不管是数据存储空间，还是索引存储空间<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">通常，在保存IPv4地址时，一个IPv4最小需要7个字符，最大需要15个字符，所以，使用VARCHAR(15)即可。MySQL在保存变长的字符串时，还需要额外的一个字节来保存此字符串的长度。而如果使用无符号整数来存储，只需要4个字节即可。</span><br></pre></td></tr></table></figure></li><li>便于使用范围查询（BETWEEN…AND），且效率更高</li></ul><p>  另外还可以使用4个字段分别存储IPv4中的各部分，但是通常这不管是存储空间和查询效率应该都不是很高（可能有的场景适合使用这种方式存储）。</p><p>  使用无符号整数来存储也有缺点：</p><ul><li>不便于阅读</li><li>需要手动转换</li></ul></li></ol>   <details><summary>对于转换来说，MySQL提供了相应的函数</summary>      <p>   把字符串格式的IP转换成整数<code>INET_ATON</code>，以及把整数格式的IP转换成字符串的<code>INET_NTOA</code>。如下所示：<br>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> select inet_aton(<span class="string">&#x27;192.168.0.1&#x27;</span>);</span></span><br><span class="line">+--------------------------+</span><br><span class="line">| inet_aton(&#x27;192.168.0.1&#x27;) |</span><br><span class="line">+--------------------------+</span><br><span class="line">|               3232235521 |</span><br><span class="line">+--------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> select inet_ntoa(3232235521);</span></span><br><span class="line">+-----------------------+</span><br><span class="line">| inet_ntoa(3232235521) |</span><br><span class="line">+-----------------------+</span><br><span class="line">| 192.168.0.1           |</span><br><span class="line">+-----------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><br>   对于IPv6来说，使用VARBINARY同样可获得相同的好处，同时MySQL也提供了相应的转换函数，即<code>INET6_ATON</code>和<code>INET6_NTOA</code></p><p>   对于转换字符串IPv4和数值类型，可以放在应用层，下面是使用java代码来对二者转换：<br>   <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IpLongUtils</span> </span>&#123;</span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 把字符串IP转换成long</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> ipStr 字符串IP</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> IP对应的long值</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">ip2Long</span><span class="params">(String ipStr)</span> </span>&#123;</span><br><span class="line">      String[] ip = ipStr.split(<span class="string">&quot;\\.&quot;</span>);</span><br><span class="line">      <span class="keyword">return</span> (Long.valueOf(ip[<span class="number">0</span>]) &lt;&lt; <span class="number">24</span>) + (Long.valueOf(ip[<span class="number">1</span>]) &lt;&lt; <span class="number">16</span>)</span><br><span class="line">              + (Long.valueOf(ip[<span class="number">2</span>]) &lt;&lt; <span class="number">8</span>) + Long.valueOf(ip[<span class="number">3</span>]);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 把IP的long值转换成字符串</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> ipLong IP的long值</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> long值对应的字符串</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">long2Ip</span><span class="params">(<span class="keyword">long</span> ipLong)</span> </span>&#123;</span><br><span class="line">      StringBuilder ip = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">      ip.append(ipLong &gt;&gt;&gt; <span class="number">24</span>).append(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">      ip.append((ipLong &gt;&gt;&gt; <span class="number">16</span>) &amp; <span class="number">0xFF</span>).append(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">      ip.append((ipLong &gt;&gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xFF</span>).append(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">      ip.append(ipLong &amp; <span class="number">0xFF</span>);</span><br><span class="line">      <span class="keyword">return</span> ip.toString();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      System.out.println(ip2Long(<span class="string">&quot;192.168.0.1&quot;</span>));</span><br><span class="line">      System.out.println(long2Ip(<span class="number">3232235521L</span>));</span><br><span class="line">      System.out.println(ip2Long(<span class="string">&quot;10.0.0.1&quot;</span>));</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>   输出结果如下：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">3232235521</span><br><span class="line">192.168.0.1</span><br><span class="line">167772161</span><br></pre></td></tr></table></figure><br>   </p></details><p></p>]]></content>
      
      
      <categories>
          
          <category> 代码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码实用小套路之Effective Java阅读笔记</title>
      <link href="/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BEffective-Java%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
      <url>/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BEffective-Java%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p><a href="https://jiapengcai.gitbooks.io/effective-java/content/">《Effective Java》第三版中文版</a></p>]]></content>
      
      
      <categories>
          
          <category> 代码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库版本管理之Flyway使用指南</title>
      <link href="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
      <url>/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>对于数据库版本管理，我们已经介绍过一款类似工具<a href="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" title="数据库版本管理之Liquibase使用指南">数据库版本管理之Liquibase使用指南</a></p><p>本文将介绍另一种数据库版本管理工具flyway.</p><p>老规矩，首先上<a href="https://flywaydb.org/documentation">官网</a></p><h3 id="Flyway是如何工作的"><a href="#Flyway是如何工作的" class="headerlink" title="Flyway是如何工作的"></a>Flyway是如何工作的</h3><p>flyway 工作原理与 Liquibase 基本一致，其工作流程如下:</p><ol><li>项目启动，应用程序完成数据库连接池的建立后，Flyway自动运行。</li><li>初次使用时，Flyway会创建一个flyway_schema_history表，用于记录sql执行记录。</li><li>Flyway会扫描项目指定路径下(默认是classpath:db/migration)的所有sql脚本，与flyway_schema_history表脚本记录进行比对。如果数据库记录执行过的脚本记录，与项目中的sql脚本不一致，Flyway会报错并停止项目执行。</li><li>如果校验通过，则根据表中的sql记录最大版本号，忽略所有版本号不大于该版本的脚本。再按照版本号从小到大，逐个执行其余脚本。</li></ol><h3 id="在SpringBoot项目使用Flyway"><a href="#在SpringBoot项目使用Flyway" class="headerlink" title="在SpringBoot项目使用Flyway"></a>在SpringBoot项目使用Flyway</h3><ol><li>初始化一个SpringBoot项目，引入MySQL数据库驱动依赖等，并且需要引入Flyway依赖：</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--引入flyway--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.flywaydb<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flyway-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>6.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li><p>添加Flyway配置</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring</span>:<span class="string"></span></span><br><span class="line"><span class="comment">  # 数据库连接配置</span></span><br><span class="line">  <span class="attr">datasource</span>:<span class="string"></span></span><br><span class="line">    <span class="meta">driver-class-name</span>: <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">url</span>: <span class="string">jdbc:mysql://localhost:3306/ssm-demo?characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8</span></span><br><span class="line">    <span class="attr">username</span>: <span class="string">xxx</span></span><br><span class="line">    <span class="attr">password</span>: <span class="string">xxx</span></span><br><span class="line">  <span class="attr">flyway</span>:<span class="string"></span></span><br><span class="line"><span class="comment">    # 是否启用flyway</span></span><br><span class="line">    <span class="attr">enabled</span>: <span class="string">true</span></span><br><span class="line"><span class="comment">    # 编码格式，默认UTF-8</span></span><br><span class="line">    <span class="attr">encoding</span>: <span class="string">UTF-8</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件存放路径，默认db/migration</span></span><br><span class="line">    <span class="attr">locations</span>: <span class="string">classpath:db/migration</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的前缀，默认V</span></span><br><span class="line">    <span class="meta">sql-migration-prefix</span>: <span class="string">V</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的分隔符，默认2个下划线__</span></span><br><span class="line">    <span class="meta">sql-migration-separator</span>: <span class="string">__</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的后缀</span></span><br><span class="line">    <span class="meta">sql-migration-suffixes</span>: <span class="string">.sql</span></span><br><span class="line"><span class="comment">    # 迁移时是否进行校验，默认true</span></span><br><span class="line">    <span class="meta">validate-on-migrate</span>: <span class="string">true</span></span><br><span class="line"><span class="comment">    # 当迁移发现数据库非空且存在没有元数据的表时，自动执行基准迁移，新建schema_version表</span></span><br><span class="line">    <span class="meta">baseline-on-migrate</span>: <span class="string">true</span></span><br></pre></td></tr></table></figure></li><li><p>根据在配置文件的脚本存放路径的配置，在resource目录下建立文件夹db/migration</p></li><li><p>添加需要运行的sql脚本。sql脚本的命名规范为：V+版本号(版本号的数字间以”.“或”_“分隔开)+双下划线(用来分隔版本号和描述)+文件描述+后缀名，例如：V20201100__create_user.sql。如图所示：<br> <img src="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/img.png"></p></li><li><p>启动项目。启动成功后，在数据库中可以看到已按照定义好的脚本，完成数据库变更，并在flyway_schema_history表插入了sql执行记录。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库版本管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库版本管理之Liquibase使用指南</title>
      <link href="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
      <url>/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h3 id="为什么需要数据库版本管理"><a href="#为什么需要数据库版本管理" class="headerlink" title="为什么需要数据库版本管理"></a>为什么需要数据库版本管理</h3><p>研发过程中经常涉及到数据库变更，对表结构的修复及对数据的修改，为了保证各环境都能正确的进行变更我们可能需要维护一个数据库升级文档来保存这些记录，有需要升级的环境按文档进行升级。</p><p>这样手工维护有几个缺点：</p><ul><li>无法保证每个环境都按要求执行</li><li>遇到问题不一定有相对的回滚语句</li><li>无法自动化</li></ul><p>为了解决这些问题，我们进行了一些调研，主要调研对象是Liquibase和Flyway，我们希望通过数据库版本管理工具实现以下几个目标：</p><ul><li>数据库升级</li><li>数据库回滚</li><li>版本标记</li></ul><h3 id="数据库版本管理工具Liquibase简介"><a href="#数据库版本管理工具Liquibase简介" class="headerlink" title="数据库版本管理工具Liquibase简介"></a>数据库版本管理工具Liquibase简介</h3><p>首先，上<a href="https://docs.liquibase.com/home.html">官方文档</a></p><h4 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h4><p>首先，Liquibase是用于管理数据库版本的，所以就会有这些概念：</p><ul><li>版本号<ul><li>它的版本号由开发人员来维护，使用 author + id(由ChangeSet定义)</li></ul></li><li>管理的数据</li><li>差异比较</li><li>版本回滚</li></ul><p>提交数据，比较差异，版本回滚 可以使用命令行 或者 maven ，ant 等构建工具来完成</p><h5 id="Changelog-文件"><a href="#Changelog-文件" class="headerlink" title="Changelog 文件"></a>Changelog 文件</h5><p>开发人员将数据库更改存储在其本地开发计算机上基于文本的文件中，并将其应用于其本地数据库。Changelog文件可以任意嵌套，以便更好地管理。</p><p>所有Liquibase更改的根源是更改日志文件, Liquibase使用更改日志按顺序列出对数据库所做的所有更改。</p><p>它是一个包含所有数据库更改记录的文件（变更集s）, Liquibase使用此更改日志记录审核您的数据库并执行尚未应用于您的数据库的任何更改。</p><p><strong>可用属性</strong></p><ul><li>logicalFilePath: 用于在创建changeSet的唯一标识符时覆盖文件名和路径。移动或重命名change logs时是必需的。</li></ul><p><strong>可用的子标签</strong></p><ul><li><p>preConditions: 执行更改日志所需的先决条件。<a href="http://www.liquibase.org/documentation/preconditions.html">read more</a></p><ul><li>记录更改日志的编写者在创建changelog时的假设。</li><li>强制使运行change log的用户不会违反这些假设</li><li>在执行不可恢复的更改（如 drop_Table）之前执行数据检查</li><li>根据数据库的状态控制哪些changeSet运行<details><summary>demo</summary><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">databaseChangeLog</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog/1.8&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog/1.8</span></span></span><br><span class="line"><span class="string"><span class="tag">http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-1.8.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">preConditions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dbms</span> <span class="attr">type</span>=<span class="string">&quot;oracle&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">runningAs</span> <span class="attr">username</span>=<span class="string">&quot;SYSTEM&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">preConditions</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">changeSet</span> <span class="attr">id</span>=<span class="string">&quot;1&quot;</span> <span class="attr">author</span>=<span class="string">&quot;bob&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">preConditions</span> <span class="attr">onFail</span>=<span class="string">&quot;WARN&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">sqlCheck</span> <span class="attr">expectedResult</span>=<span class="string">&quot;0&quot;</span>&gt;</span>select count(*) from oldtable<span class="tag">&lt;/<span class="name">sqlCheck</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">preConditions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">comment</span>&gt;</span>Comments should go after preCondition. If they are before then liquibase usually gives error.<span class="tag">&lt;/<span class="name">comment</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dropTable</span> <span class="attr">tableName</span>=<span class="string">&quot;oldtable&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">changeSet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">databaseChangeLog</span>&gt;</span></span><br></pre></td></tr></table></figure>仅当针对 Oracle执行的数据库和执行脚本的数据库用户为SYSTEM时，才会运行上述databasechangelog。<br>仅当”oldtable”中没有值时，它才会运行 drop_Table命令。</details></li></ul></li><li><p>property: 将属性设置为的值（如果不是通过其他方法设置）。<a href="http://www.liquibase.org/documentation/changelog_parameters.html">read more</a></p></li><li><p>changeSet: 要执行的changeSet。<a href="http://www.liquibase.org/documentation/changeset.html">read more</a></p></li><li><p>include: 包含要执行的changeSet的其他文件。<a href="http://www.liquibase.org/documentation/include.html">read more</a></p></li></ul><p>当 Liquibase 迁移器运行时，它将分析数据库 ChangeLog 标记。它首先检查指定的先决条件。如果先决条件失败，Liquibase将退出，并显示一条错误消息，解释失败的原因。先决条件对于记录和强制执行更改日志编写器的预期和假设（如要针对的 DBMS 或以用户身份运行更改）非常有用。</p><p>如果满足所有的先决条件，Liquibase将会开始运行在databaseChangeLog文件中按照顺序出现changeSet和include标签。</p><p><strong>changelog文件格式说明</strong></p><p>具体格式参考<a href="https://docs.liquibase.com/concepts/basic/changelog.html">官方文档</a></p><p>本文列举两种常见格式:</p><ul><li><p>SQL 文件格式</p><p>其实各种文件格式使用生成数据库脚本就可以看到格式了，照着写就行：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--liquibase formatted sql</span><br><span class="line"></span><br><span class="line">--changeset &lt;author&gt;:&lt;version&gt; </span><br><span class="line">sqls</span><br><span class="line"></span><br><span class="line">--rollback rollback sqls </span><br><span class="line"></span><br><span class="line">--comment: 注释都有特殊含义了，所以注释要这样加</span><br></pre></td></tr></table></figure></li><li><p>XML 文件格式</p><p>xml 比 sql 更加可控，它可以加一个预判断条件，来判断这个后面的 changeSet 要不要执行，但相应的就必须照它的语法来写语句了，没 sql 方便了，还好提供了 xsd</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;preConditions&gt;</span><br><span class="line">    &lt;runningAs username=&quot;liquibase&quot;/&gt;</span><br><span class="line">&lt;/preConditions&gt;</span><br><span class="line">&lt;!-- 版本 1 的修改--&gt;</span><br><span class="line">&lt;changeSet id=&quot;1&quot; author=&quot;sanri&quot;&gt;</span><br><span class="line">    &lt;addColumn tableName=&quot;person&quot;&gt;</span><br><span class="line">        &lt;column name=&quot;username&quot; type=&quot;varchar(8)&quot;/&gt;</span><br><span class="line">    &lt;/addColumn&gt;</span><br><span class="line">&lt;/changeSet&gt;</span><br></pre></td></tr></table></figure></li></ul><h5 id="ChangeSet"><a href="#ChangeSet" class="headerlink" title="ChangeSet"></a>ChangeSet</h5><p>changeSet由author和id属性以及changelog文件的位置唯一标识，是 Liquibase 跟踪执行的单位（管理的数据最小单元）。</p><p>changeSet 可以用 xml,yaml,json,sql 来编写</p><p>运行 Liquibase 时，它会查询标记为已执行的changSet的DATABASECHANGELOG 表，然后执行更改日志文件中尚未执行的所有changeSet。</p><h5 id="Changes"><a href="#Changes" class="headerlink" title="Changes"></a>Changes</h5><p>每个changeSet通常包含一个更改，该更改描述要应用于数据库的更改/重构。</p><p>Liquibase 支持为支持的数据库和原始 SQL 生成 SQL 的描述性更改。</p><p>通常，<strong>每个changeSet应只有一个更改</strong>，以避免可能使数据库处于意外状态的自动提交语句失败。</p><h5 id="Preconditions"><a href="#Preconditions" class="headerlink" title="Preconditions"></a>Preconditions</h5><p>先决条件可以应用于整个changelog或单个changeSet。如果先决条件失败，liquibase将停止执行。</p><h5 id="Contexts"><a href="#Contexts" class="headerlink" title="Contexts"></a>Contexts</h5><p>可以将上下文应用于changeSet，以控制在不同环境中运行的changeSet。例如，某些changeSet可以标记为production，另一些可以标记为test。如果未指定上下文，则无论执行上下文如何，changset都将运行。</p><h4 id="Liquibase是如何工作的"><a href="#Liquibase是如何工作的" class="headerlink" title="Liquibase是如何工作的"></a>Liquibase是如何工作的</h4><p>Liquibase的核心是依靠一种简单的机制来跟踪、版本和部署更改：</p><ul><li>Liquibase 使用更改日志（是更改的分类）按特定顺序显式列出数据库更改。更改日志中的每个更改都是一个change set。更改日志可以任意嵌套，以帮助组织和管理数据库迁移。<ul><li>最佳做法是确保每个change set都尽可能原子性更改，以避免失败的结果使数据库中剩下的未处理的语句处于unknown 状态;</li><li>不过，可以将大型 SQL 脚本视为单个更改集。</li></ul></li><li>Liquibase 使用跟踪表（具体称为DATABASECHANGELOG），该表位于每个数据库上，并跟踪已部署更改日志中的change set。<ul><li>如果 Liquibase所在的数据库没有跟踪表，Liquibase 将创建一个跟踪表。</li><li>为了协助处理您未从空白数据库开始的项目，Liquibase具有生成一条更改日志以表示数据库模式当前状态的功能。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">它会在你的目标数据库生成一张表 DATABASECHANGELOG 来管理版本 ，另一个 lock 的是防止多人同时操作数据库加的锁。</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>使用分类和跟踪表，Liquibase 能够：</p><ul><li>跟踪和以版本控制数据库更改 – 用户确切知道已部署到数据库的更改以及尚未部署的更改。</li><li>部署更改 — 具体来说，通过将分类(ledger)中的内容与跟踪表中的内容进行比较，Liquibase 只能将以前尚未部署到数据库的更改部署到数据库中。<ul><li>Liquibase 具有上下文、标签和先决条件等高级功能，可精确控制changeSet的部署时间以及位置。</li></ul></li></ul><h4 id="liquibase使用"><a href="#liquibase使用" class="headerlink" title="liquibase使用"></a>liquibase使用</h4><h5 id="命令行方式"><a href="#命令行方式" class="headerlink" title="命令行方式"></a>命令行方式</h5><p>虽然使用可以集成自 springboot ，但这种数据库脚本一般公司都是运维在维护，使用命令行是最方便的方式，所以我先说下使用命令行, <a href="http://www.liquibase.org/documentation/command_line.html">官网示例</a> </p><p>为先为了不每次都要写一大堆参数，可以在 liquibase 根目录加一个 liquibase.properties，用于配置数据库 jar、url、用户名、密码等参数, <a href="http://www.liquibase.org/documentation/config_properties.html">配置详情</a> </p><p>命令格式： liquibase [options] [command] [command parameters]</p><h6 id="比较开发库和测试库的差异，并生成升级包"><a href="#比较开发库和测试库的差异，并生成升级包" class="headerlink" title="比较开发库和测试库的差异，并生成升级包"></a>比较开发库和测试库的差异，并生成升级包</h6><p>如果要升级哪个，则哪个要做为源，则配置中的 url 不是 referenceUrl，使用如下命令创建升级包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase --changeLogFile=&quot;changeLogFiledevtest.postgresql.sql&quot; diffChangeLog</span><br></pre></td></tr></table></figure><p>changeLogFile 是有命名规则的，命名必须为 *.dbType.format ，如上所示</p><h6 id="为测试库打一个标签"><a href="#为测试库打一个标签" class="headerlink" title="为测试库打一个标签"></a>为测试库打一个标签</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase tag v1.0</span><br></pre></td></tr></table></figure><h6 id="使用差异升级源库"><a href="#使用差异升级源库" class="headerlink" title="使用差异升级源库"></a>使用差异升级源库</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; update</span><br></pre></td></tr></table></figure><h6 id="升级有问题需要回滚"><a href="#升级有问题需要回滚" class="headerlink" title="升级有问题需要回滚"></a>升级有问题需要回滚</h6><p>liquibase 有几种回滚策略，一种是根据标签回滚，回滚次数，和根据日期回滚；有 9 个与之对应的命令</p><p>回滚要求对应的 changeLogFile 有回滚标签 ，这个在后面文件格式说</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 按照 changeSet 次数回滚</span></span><br><span class="line">liquibase  --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; rollbackCount 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按照标签回滚</span></span><br><span class="line">liquibase  --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; rollback v1.0</span><br></pre></td></tr></table></figure><h6 id="生成数据库脚本-新环境"><a href="#生成数据库脚本-新环境" class="headerlink" title="生成数据库脚本(新环境)"></a>生成数据库脚本(新环境)</h6><p>liquibase –changeLogFile=”sqls/create_table.mysql.sql”  generateChangeLog</p><h5 id="使用构建工具"><a href="#使用构建工具" class="headerlink" title="使用构建工具"></a>使用构建工具</h5><p>我们也可以使用 maven 来执行这些操作，引入 maven 的一个插件就行</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.liquibase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>liquibase-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--指定执行主文件 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;changeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/master_changelog.xml&lt;/changeLogFile&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;diffChangeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/changelog/$&#123;maven.build.timestamp&#125;_changelog.xml&lt;/diffChangeLogFile&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;outputChangeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/changelog/changelog_original.xml&lt;/outputChangeLogFile&gt;--&gt;</span></span><br><span class="line"></span><br><span class="line">                   <span class="tag">&lt;<span class="name">propertyFile</span>&gt;</span>src/main/resources/liquibase/liquibase.properties<span class="tag">&lt;/<span class="name">propertyFile</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                    <span class="tag">&lt;<span class="name">dropFirst</span>&gt;</span>false<span class="tag">&lt;/<span class="name">dropFirst</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">verbose</span>&gt;</span>true<span class="tag">&lt;/<span class="name">verbose</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">logging</span>&gt;</span>debug<span class="tag">&lt;/<span class="name">logging</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!-- 是否需要弹出确认框 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">promptOnNonLocalDatabase</span>&gt;</span>false<span class="tag">&lt;/<span class="name">promptOnNonLocalDatabase</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--输出文件的编码 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">outputFileEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">outputFileEncoding</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--执行的时候是否显示详细的参数信息 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">verbose</span>&gt;</span>true<span class="tag">&lt;/<span class="name">verbose</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--是否每次都重新加载properties --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">propertyFileWillOverride</span>&gt;</span>true<span class="tag">&lt;/<span class="name">propertyFileWillOverride</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">rollbackTag</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">rollbackTag</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">tag</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p>相应的命令做成了目标(goal)，使用 -Dkey=value 来指定参数，如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行更新 sql</span> </span><br><span class="line">mvn liquibase:update -DchangeLogFile=&quot;file&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 打标签，这个版本号在插件中配置成项目版本了</span></span><br><span class="line">mvn liquibase:tag </span><br><span class="line"><span class="meta">#</span><span class="bash"> 将当前库导出表结构</span></span><br><span class="line">mvn liquibase:generateChangeLog </span><br></pre></td></tr></table></figure><h5 id="集成进-springboot-在项目启动的时候执行版本管理"><a href="#集成进-springboot-在项目启动的时候执行版本管理" class="headerlink" title="集成进 springboot, 在项目启动的时候执行版本管理"></a>集成进 springboot, 在项目启动的时候执行版本管理</h5><p>具体实现方案参考文章<a href="https://blog.csdn.net/qq_39508627/article/details/89883549?utm_medium=distribute.pc_feed_404.none-task-blog-2~default~BlogCommendFromBaidu~default-3.nonecase&depth_1-utm_source=distribute.pc_feed_404.none-task-blog-2~default~BlogCommendFromBaidu~default-3.nonecas">springboot引入liquibase</a></p><h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="项目开发中存在的问题"><a href="#项目开发中存在的问题" class="headerlink" title="项目开发中存在的问题"></a>项目开发中存在的问题</h4><p>随着项目的发展，一个项目中的代码量会非常庞大，同时数据库表也会错综复杂。如果一个项目使用了Liquibase对数据库结构进行管理，越来越多的问题会浮现出来。</p><ul><li>ChangeSet文件同时多人在修改，自己的ChangeSet被改掉，甚至被删除掉。</li><li>开发人员将ChangeSet添加到已经执行过的文件中，导致执行顺序出问题。</li><li>开发人员擅自添加对业务数据的修改，其它环境无法执行并报错。</li><li>ChangeSet中SQL包含schema名称，导致其它环境schema名称变化时，ChangeSet报错。</li><li>开发人员不小心改动了已经执行过的ChangeSet，在启动时会报错。</li></ul><h4 id="Liquibase基本规范"><a href="#Liquibase基本规范" class="headerlink" title="Liquibase基本规范"></a>Liquibase基本规范</h4><ul><li>ChangeSet id使用[任务ID]-[日期]-[序号]，如 T100-20181009-001</li><li>ChangeSet必须填写author</li><li>Liquibase禁止对业务数据进行sql操作</li><li>使用<sql>时，禁止包含schema名称</sql></li><li>Liquibase禁止使用存储过程</li><li>所有表，列要加remarks进行注释</li><li>已经执行过的ChangeSet严禁修改。</li><li>不要随便升级项目liquibase版本，特别是大版本升级。不同版本ChangeSet MD5SUM的算法不一样。</li></ul><p>其它数据库规范不再赘述。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">databaseChangeLog</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">changeSet</span> <span class="attr">id</span>=<span class="string">&quot;T100-20181009-001&quot;</span> <span class="attr">author</span>=<span class="string">&quot;markfredchen&quot;</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">createTable</span> <span class="attr">tableName</span>=<span class="string">&quot;demo_user&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户表&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">column</span> <span class="attr">name</span>=<span class="string">&quot;id&quot;</span> <span class="attr">type</span>=<span class="string">&quot;bigint&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户ID,主键&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">constraints</span> <span class="attr">nullable</span>=<span class="string">&quot;false&quot;</span> <span class="attr">primaryKey</span>=<span class="string">&quot;true&quot;</span> <span class="attr">primaryKeyName</span>=<span class="string">&quot;pk_demo_user_id&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">column</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">column</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> <span class="attr">type</span>=<span class="string">&quot;varchar(100)&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户名&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">constraints</span> <span class="attr">nullable</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">column</span>&gt;</span></span><br><span class="line">            ...</span><br><span class="line">        <span class="tag">&lt;/<span class="name">createTable</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">changeSet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">databaseChangeLog</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="有效文件管理"><a href="#有效文件管理" class="headerlink" title="有效文件管理"></a>有效文件管理</h4><p>使用Liquibase中提供<include file="xxx">tag，可以将ChangeSet分布在不同文件中。同时<include>支持多级引用。</include></include></p><p>基于此功能可以对项目中的ChangeSet进行有效管理。推荐使用以下规范进行管理。</p><h5 id="根据发布进行管理"><a href="#根据发布进行管理" class="headerlink" title="根据发布进行管理"></a>根据发布进行管理</h5><ul><li>每个发布新建一个文件夹，所有发布相关的ChangeSet文件以及数据初始化文件，均放在些文件夹中。</li><li>每个发布新建一个master.xml。此master.xml中，include本次发布需要执行的ChangeSet文件</li><li>根据开发小组独立ChangeSet文件(可选)</li><li>根据功能独立ChangeSet文件。例如user.xml, company.xml  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">resources</span><br><span class="line">|-liquibase</span><br><span class="line">|-user</span><br><span class="line">| |- master.xml</span><br><span class="line">| |- release.1.0.0</span><br><span class="line">| | |- release.xml</span><br><span class="line">| | |- user.xml -- 用户相关表ChangeSet</span><br><span class="line">| | |- user.csv -- 用户初始化数据</span><br><span class="line">| | |- company.xml -- 公司相关表ChangeSet</span><br><span class="line">| |- release.1.1.0</span><br><span class="line">| | |- release.xml</span><br><span class="line">| | |- ...</span><br></pre></td></tr></table></figure></li></ul><h5 id="模块化管理"><a href="#模块化管理" class="headerlink" title="模块化管理"></a>模块化管理</h5><p>当项目变得庞大之后，一个服务可能包含的功能模块会越来越多。此时大家会想尽办法进行模块拆分，逐步进行微服务化。然而在面对错综复杂的Liquibase ChangeSet就会无从下手。</p><p>针对这种将来可能会面对的问题，项目初期就对Liquibase进行模块化管理，将在未来带来很大收益。</p><p>首先说明一下Spring Boot中Liquibase默认是如何执行以及执行结果。</p><ul><li>在启动时，LiquibaseAutoConfiguration会根据默认配置初始化SpringLiquibase</li><li>SpringLiquibase.afterPropertiesSet()中执行ChangeSet文件</li><li>第一次跑ChangeSets的时候，会在数据库中自动创建两个表databasechangelog和databasechangeloglock</li></ul><p>因此我们可以认为一个SpringLiquibase执行为一个模块。</p><p>引入多模块管理时，基于上节文件管理规范，我们基于模块管理再做下调整。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">resources</span><br><span class="line">  |-liquibase</span><br><span class="line">    |-user</span><br><span class="line">    | |- master.xml</span><br><span class="line">    | |- release.1.0.0</span><br><span class="line">    | | |- release.xml</span><br><span class="line">    | | |- user.xml -- 用户相关表ChangeSet</span><br><span class="line">    | | |- user.csv -- 用户初始化数据</span><br><span class="line">    | | |- company.xml -- 公司相关表ChangeSet</span><br><span class="line">    | |- release.1.1.0</span><br><span class="line">    | | |- release.xml</span><br><span class="line">    | | |- ...</span><br><span class="line">    |- order</span><br><span class="line">    | |- master.xml</span><br><span class="line">    | |- release.1.0.0</span><br><span class="line">    | | |- ...</span><br></pre></td></tr></table></figure><p>当有一天我们需要把订单模块拆分成独立服务时，我们只需要将模块相关的ChangeSet文件迁出来。即可完成数据结构的拆分。</p><p>那如何在一个Spring Boot运行多个SpringLiquibase呢？需要对代码进行以下调整。</p><ol><li><p>禁用Spring Boot自动运行Liquibase。</p><p> 当以下配置被启用时，Spring Boot AutoConfigure会使用默认配置初始化名为springLiquibase的Bean。然后我们不对其进行配置，Spring Boot启动时会报错。</p> <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># application.properties</span></span><br><span class="line"><span class="comment"># spring boot 2以上</span></span><br><span class="line"><span class="meta">spring.liquibase.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># spring boot 2以下</span></span><br><span class="line"><span class="meta">liquibase.enabled</span>=<span class="string">false</span></span><br></pre></td></tr></table></figure></li><li><p>Spring Boot配置Liquibase Bean</p><p> 配置两个SpringLiquibase Bean，Bean名称分别为userLiquibase和orderLiqubase。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> class <span class="title">LiquibaseConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  用户模块Liquibase   </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SpringLiquibase <span class="title">userLiquibase</span><span class="params">(DataSource dataSource)</span> </span>&#123;</span><br><span class="line">        SpringLiquibase liquibase = <span class="keyword">new</span> SpringLiquibase();</span><br><span class="line">        <span class="comment">// 用户模块Liquibase文件路径</span></span><br><span class="line">        liquibase.setChangeLog(<span class="string">&quot;classpath:liquibase/user/master.xml&quot;</span>);</span><br><span class="line">        liquibase.setDataSource(dataSource);</span><br><span class="line">        liquibase.setShouldRun(<span class="keyword">true</span>);</span><br><span class="line">        liquibase.setResourceLoader(<span class="keyword">new</span> DefaultResourceLoader());</span><br><span class="line">        <span class="comment">// 覆盖Liquibase changelog表名</span></span><br><span class="line">        liquibase.setDatabaseChangeLogTable(<span class="string">&quot;user_changelog_table&quot;</span>);</span><br><span class="line">        liquibase.setDatabaseChangeLogLockTable(<span class="string">&quot;user_changelog_lock_table&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> liquibase;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  订单模块Liquibase   </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SpringLiquibase <span class="title">orderLiquibase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      SpringLiquibase liquibase = <span class="keyword">new</span> SpringLiquibase();</span><br><span class="line">      liquibase.setChangeLog(<span class="string">&quot;classpath:liquibase/order/master.xml&quot;</span>);</span><br><span class="line">      liquibase.setDataSource(dataSource);</span><br><span class="line">      liquibase.setShouldRun(<span class="keyword">true</span>);</span><br><span class="line">      liquibase.setResourceLoader(<span class="keyword">new</span> DefaultResourceLoader());</span><br><span class="line">      liquibase.setDatabaseChangeLogTable(<span class="string">&quot;order_changelog_table&quot;</span>);</span><br><span class="line">      liquibase.setDatabaseChangeLogLockTable(<span class="string">&quot;order_changelog_lock_table&quot;</span>);</span><br><span class="line">      <span class="keyword">return</span> liquibase;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://blog.csdn.net/u012934325/article/details/100652805">LiquiBase中文学习指南</a></p>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库版本管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务解决方案SpringCloud Alibaba系列之Sentinel初探</title>
      <link href="/2021/08/09/SpringCloudAlibaba/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88SpringCloud%20Alibaba%E7%B3%BB%E5%88%97%E4%B9%8BSentinel%E5%88%9D%E6%8E%A2/"/>
      <url>/2021/08/09/SpringCloudAlibaba/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88SpringCloud%20Alibaba%E7%B3%BB%E5%88%97%E4%B9%8BSentinel%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<h3 id="Sentinel-是什么"><a href="#Sentinel-是什么" class="headerlink" title="Sentinel 是什么"></a>Sentinel 是什么</h3><p>新技术学习第一步，<a href="https://sentinelguard.io/zh-cn/docs/introduction.html">官方文档</a></p><p>随着微服务的流行，服务和服务之间的稳定性变得越来越重要。</p><p>Sentinel 是面向分布式服务架构的流量控制组件，作为分布式系统的流量防卫兵， 以<strong>流量</strong>为切入点，从<strong>流量控制、熔断降级、系统负载保护</strong>等多个维度保护服务的稳定性。</p><h3 id="Sentinel-要做什么"><a href="#Sentinel-要做什么" class="headerlink" title="Sentinel 要做什么"></a>Sentinel 要做什么</h3><p>服务的动态注册、服务发现是 SOA、微服务架构体系中首先需要解决的基本问题，服务治理是 SOA 领域又一重要课题，而 dubbo 框架只提供了一些基本的服务治理能力，例如限制服务并发调用数、配置合适的业务线程数量等，但熔断相关的功能就涉及的较少。</p><p>Sentinel 将作为 Dubbo 生态的重要一员，将集中解决服务治理相关的课题，服务限流与熔断又是服务治理首先要解决的课题。</p><p>那什么是限流与熔断呢？</p><ul><li>限流：我们通常使用TPS对流量来进行描述，限流就是现在服务被调用的并发TPS，从而对系统进行自我保护。</li><li>熔断：就是当系统中某一个服务出现性能瓶颈是，对这个服务的调用进行快速失败，避免造成连锁反应，从而影响整个链路的调用。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 限流 </tag>
            
            <tag> Sentinel </tag>
            
            <tag> SpringCloud Alibaba </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之与Zookeeper的爱恨缠绵</title>
      <link href="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/"/>
      <url>/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/</url>
      
        <content type="html"><![CDATA[<p>在 <a href="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/" title="分布式协调组件之Zookeeper基础概念入门">分布式协调组件之Zookeeper基础概念入门</a> 一文中，我们简单介绍了Zookeeper的基础概念。</p><p>而Kafka作为Zookeeper分布式协调的重要案例，本文将通过Kafka与Zookeeper的合与分展示Kafka与Zookeeper的前世今生。</p><h3 id="Kafka为什么需要Zookeeper"><a href="#Kafka为什么需要Zookeeper" class="headerlink" title="Kafka为什么需要Zookeeper"></a>Kafka为什么需要Zookeeper</h3><p>Kafka中存在众多的Leader选举，熟悉Kafka的朋友应该知道，一个主题可以拥有多个分区(数据分片)，每一个数据分片可以配置多个副本，如何保证一个分区的数据在多个副本之间的一致性成为一个迫切的需求。</p><p>Kafka的实现套路就是一个分区的多个副本，从中选举出一个Leader用来承担客户端的读写请求，从节点从主节点处拷贝内容，Leader节点根据数据在副本中成功写入情况，进行抉择来确定是否写入成功。</p><p>Kafka中topic的分区分布示意图：</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_1.png"></p><p>故此处需要进行Leader选举,而基于Zookeeper能轻松实现，从此一拍即合，开启了一段“蜜月之旅”。</p><h3 id="Zookeeper为Kafka提供了什么"><a href="#Zookeeper为Kafka提供了什么" class="headerlink" title="Zookeeper为Kafka提供了什么"></a>Zookeeper为Kafka提供了什么</h3><p>ZooKeeper 作为给分布式系统提供协调服务的工具被 kafka 所依赖。</p><p>在分布式系统中，消费者需要知道有哪些生产者是可用的，而如果每次消费者都需要和生产者建立连接并测试是否成功连接，那效率也太低了，显然是不可取的。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_5.png"></p><p>通过使用 ZooKeeper 协调服务，Kafka 就能将 Producer，Consumer，Broker 等结合在一起，同时借助 ZooKeeper，Kafka 就能够将所有组件在无状态的条件下建立起生产者和消费者的订阅关系，实现负载均衡。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img.png"></p><ol><li><p>注册中心</p><ul><li><p>Broker 信息注册</p><ul><li>在 ZooKeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点，节点路径为 /brokers/ids。  </li><li>Kafka 的每个 Broker 启动时，都会在 ZooKeeper 中注册，创建 /brokers/ids/[0-N] 节点，写入 IP，端口等信息，每个 Broker 都有一个 BrokerId。  </li><li>Broker 创建的是临时节点，在连接断开时节点就会自动删除，所以在 ZooKeeper 上就可以通过 Broker 中节点的变化来得到 Broker 的可用性。</li></ul></li><li><p>Topic 信息注册</p><ul><li><p>在 Kafka 中可以定义很多个 Topic，每个 Topic 又被分为很多个 Partition。一般情况下，每个 Partition 独立在存在一个 Broker 上，所有的这些 Topic 和 Broker 的对应关系都由 ZooKeeper 进行维护。</p></li><li><p>Zookeeper会为topic分配一个单独节点，每个topic都会以/brokers/topics/[topic_name]的形式记录在Zookeeper。</p></li><li><p>一个topic的消息会被保存到多个partition，这些partition跟broker的对应关系也需要保存到Zookeeper。</p></li><li><p>partition是多副本保存的，上图中红色partition是leader副本。当leader副本所在的broker发生故障时，partition需要重新选举leader，这个需要由Zookeeper主导完成。</p></li><li><p>broker启动后，会把自己的Broker ID注册到到对应topic节点的分区列表中。</p><p>我们查看一个topic是xxx，分区编号是1的信息，命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master] get /brokers/topics/xxx/partitions/1/state</span><br><span class="line">&#123;&quot;controller_epoch&quot;:15,&quot;leader&quot;:11,&quot;version&quot;:1,&quot;leader_epoch&quot;:2,&quot;isr&quot;:[11,12,13]&#125;</span><br></pre></td></tr></table></figure><p><code>当broker退出后，Zookeeper会更新其对应topic的分区列表。</code></p></li></ul></li><li><p>consumer 信息注册</p><p>   消费者组也会向Zookeeper进行注册，Zookeeper会为其分配节点来保存相关数据，节点路径为/consumers/{group_id}，有3个子节点，如下图:</p><p>   <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_6.png"></p><p>   这样Zookeeper可以记录分区跟消费者的关系，以及分区的offset。</p></li></ul></li><li><p>负载均衡</p><p> 生产者需要将消息发送给 Broker，消费者需要从 Broker 上获取消息，通过使用 ZooKeeper，就都能监听 Broker 上节点的状态信息，从而实现动态负载均衡。</p><ul><li>broker向Zookeeper进行注册后，生产者根据broker节点来感知broker服务列表变化，这样可以实现动态负载均衡。</li><li>consumer group中的消费者，可以根据topic节点信息来拉取特定分区的消息,实现负载均衡。</li></ul></li><li><p>Controller</p><p> 在 Kafka 中会有多个 Broker，其中一个 Broker 会被选举成为 Controller（控制器），在任意时刻，Kafka 集群中有且仅有一个控制器。</p><p> Controller 负责管理集群中所有分区和副本的状态，当某个分区的 leader 副本出现故障时，由 Controller 为该分区选举出一个新的 leader。</p><p> Controller具体职责如下：</p><ul><li>监听分区变化<ul><li>当某个分区的leader出现故障时，Controller会为该分区选举新的leader。</li><li>当检测到分区的ISR集合发生变化时，Controller会通知所有broker更新元数据。</li><li>当某个topic增加分区时，Controller会负责重新分配分区。</li></ul></li><li>监听topic相关的变化</li><li>监听broker相关的变化</li><li>集群元数据管理</li></ul><p> 下面这张图展示了Controller、Zookeeper和broker的交互细节：<br> <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_7.png"></p><p> Controller选举成功后，会从Zookeeper集群中拉取一份完整的元数据初始化ControllerContext，这些元数据缓存在Controller节点。当集群发生变化时，比如增加topic分区，Controller不仅需要变更本地的缓存数据，还需要将这些变更信息同步到其他Broker。</p><p> Controller监听到Zookeeper事件、定时任务事件和其他事件后，将这些事件按照先后顺序暂存到LinkedBlockingQueue中，由事件处理线程按顺序处理，这些处理多数需要跟Zookeeper交互，Controller则需要更新自己的元数据。</p><p> Kafka 的 Controller 选举就依靠 ZooKeeper 来完成，成功竞选为 Controller 的 Broker 会在 ZooKeeper 中创建 /controller 这个临时节点，在 ZooKeeper 中使用 get 命令查看节点内容：</p><p> <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_2.png"></p><ul><li>“version”在目前版本中固定为1</li><li>“brokerid”表示 Broker 的编号</li><li>“timestamp”表示竞选称为 Controller 时的时间戳。</li></ul><p> Kafka Controller选举流程: 当 Broker 启动时，会尝试读取 /controller 中的“brokerid”: </p><ul><li>如果读取到的值不是-1，则表示已经有节点竞选成为 Controller 了，当前节点就会放弃竞选；</li><li>而如果读取到的值为-1，ZooKeeper 就会尝试创建 /controller 节点，当该 Broker 去创建的时候，可能还有其他 Broker 一起同时创建节点，但只有一个 Broker 能够创建成功，即成为唯一的 Controller。</li></ul></li></ol><h3 id="为什么Kafka要抛弃Zookeeper"><a href="#为什么Kafka要抛弃Zookeeper" class="headerlink" title="为什么Kafka要抛弃Zookeeper"></a>为什么Kafka要抛弃Zookeeper</h3><h4 id="外部依赖带来的复杂度及系统效率影响"><a href="#外部依赖带来的复杂度及系统效率影响" class="headerlink" title="外部依赖带来的复杂度及系统效率影响"></a>外部依赖带来的复杂度及系统效率影响</h4><p>对于 Kafka 来讲，ZooKeeper 是一套外部系统，要想部署一套 Kafka 集群，就要同时部署、管理、监控 ZooKeeper，Kafka的运维人员必须要具备Zookeeper的运维能力。</p><p>ZooKeeper 有自己的配置方式、管理工具，和 Kafka 完全不一样，所以，一起搞两套分布式系统，自然就提升了<strong>复杂度</strong>，也更容易出现问题。有时工作量还会加倍，例如要开启一些安全特性，Kafka 和 ZooKeeper 中都需要配置。</p><p>除了复杂度，外部存储也会<strong>降低系统效率</strong>。</p><p>例如 Kafka 集群每次启动的时候，Controller 必须从 ZooKeeper 加载集群的状态信息。</p><p>再比如选举出一个新的 Controller 之后也会比较麻烦，Kafaka依赖一个单一Controller节点跟Zookeeper进行交互，如果这个Controller节点发生了故障，就需要从broker中选择新的Controller。如下图,新的Controller变成了broker3。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_4.png"></p><p>新的Controller选举成功后，会重新从Zookeeper拉取元数据进行初始化，并且需要通知其他所有的broker更新ActiveControllerId。老的Controller需要关闭监听、事件处理线程和定时任务。分区数非常多时，这个过程非常耗时，而且这个过程中Kafka集群是不能工作的。</p><p>当分区数增加时，Zookeeper保存的元数据变多，Zookeeper集群压力变大，达到一定级别后，监听延迟增加，给Kafaka的工作带来了影响。</p><p>所以，Kafka单集群承载的<strong>分区数量是一个瓶颈</strong>。而这又恰恰是一些业务场景需要的。</p><h4 id="Zookeeper的致命缺陷"><a href="#Zookeeper的致命缺陷" class="headerlink" title="Zookeeper的致命缺陷"></a>Zookeeper的致命缺陷</h4><p>Zookeeper是集群部署，只要集群中超过半数节点存活，即可提供服务，例如一个由3个节点的Zookeeper，允许1个Zookeeper节点宕机，集群仍然能提供服务；一个由５个节点的Zookeeper，允许2个节点宕机。</p><p>但Zookeeper的设计是CP模型，即要保证数据的强一致性，必然在可用性方面做出牺牲。</p><p>Zookeeper集群中也存在所谓的Leader节点和从节点，Leader节点负责写，Leader与从节点可用接受读请求，但在Zookeeper内部节点在选举时整个Zookeeper无法对外提供服务。当然正常情况下选举会非常快，但在异常情况下就不好说了，例如Zookeeper节点发生full Gc，此时造成的影响将是毁灭性的。</p><p>Zookeeper节点如果频繁发生Full Gc，此时与客户端的会话将超时，由于此时无法响应客户端的心跳请求(Stop World)，从而与会话相关联的临时节点将被删除，注意，此时是所有的临时节点会被删除，Zookeeper依赖的事件通知机制将失效，整个集群的选举服务将失效。</p><h4 id="设计优雅性"><a href="#设计优雅性" class="headerlink" title="设计优雅性"></a>设计优雅性</h4><p>站在高可用性的角度，Kafka集群的可用性不仅取决于自身，还受到了外部组件的制约，从长久来看，显然都不是一个优雅的方案。</p><h4 id="分布式领域技术完善"><a href="#分布式领域技术完善" class="headerlink" title="分布式领域技术完善"></a>分布式领域技术完善</h4><p>随着分布式领域相关技术的不断完善，<strong>去中心化</strong>的思想逐步兴起，去Zookeeper的呼声也越来越高，在这个进程中涌现了一个非常优秀的算法：<strong>Raft协议</strong>。</p><p>Raft协议的两个重要组成部分：Leader选举、日志复制，而日志复制为多个副本提供数据强一致性提供了强一致性，并且一个显著的特点是Raft节点是去中心化的架构，不依赖外部的组件，而是作为一个协议簇嵌入到应用中的，即与应用本身是融合为一体的。</p><h3 id="Kafka去掉Zookeeper后怎么实现其功能"><a href="#Kafka去掉Zookeeper后怎么实现其功能" class="headerlink" title="Kafka去掉Zookeeper后怎么实现其功能"></a>Kafka去掉Zookeeper后怎么实现其功能</h3><p>KIP-500用Quorum Controller代替之前的Controller，Quorum中每个Controller节点都会保存所有元数据，通过KRaft协议保证副本的一致性。这样即使Quorum Controller节点出故障了，新的Controller迁移也会非常快。</p><p>以Kafka Topic的分布图举例，引用Raft协议的示例图如下：</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_3.png"></p><p>官方介绍，升级之后，Kafka可以轻松支持百万级别的分区。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafak团队把通过Raft协议同步数据的方式Kafka Raft Metadata mode,简称KRaft</span><br></pre></td></tr></table></figure><p>关于Raft协议，本文并不打算深入进行探讨，具体参考文章<a href="https://zhuanlan.zhihu.com/p/91288179">Raft协议原理详解</a></p><p>Raft协议为选主提供了另外一种可行方案，而且还无需依赖第三方组件，何乐而不为呢？故最终Kafka在2.8版本中正式废弃了Zookeeper，拥抱Raft。</p><p>Kafaka计划在3.0版本会兼容Zookeeper Controller和Quorum Controller，这样用户可以进行灰度测试。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在大规模集群和云原生的背景下，使用Zookeeper给Kafka的运维和集群性能造成了很大的压力。去除Zookeeper是必然趋势，这也符合大道至简的架构思想。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
            <tag> ZOOKEEPER </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件系列之死信、延迟、重试队列</title>
      <link href="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/"/>
      <url>/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<h3 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a>延迟队列</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在发送延时消息的时候并不是先投递到要发送的真实主题（real_topic）中，而是先投递到一些 Kafka 内部的主题（delay_topic）中，这些内部主题对用户不可见，</span><br><span class="line"></span><br><span class="line">然后通过一个自定义的服务拉取这些内部主题中的消息，并将满足条件的消息再投递到要发送的真实的主题中，消费者所订阅的还是真实的主题。</span><br></pre></td></tr></table></figure><p>如果采用这种方案，那么一般是按照不同的延时等级来划分的，比如设定5s、10s、30s、1min、2min、5min、10min、20min、30min、45min、1hour、2hour这些按延时时间递增的延时等级，延时的消息按照延时时间投递到不同等级的主题中，投递到同一主题中的消息的延时时间会被强转为与此主题延时等级一致的延时时间，这样延时误差控制在两个延时等级的时间差范围之内（比如延时时间为17s的消息投递到30s的延时主题中，之后按照延时时间为30s进行计算，延时误差为13s）。虽然有一定的延时误差，但是误差可控，并且这样只需增加少许的主题就能实现延时队列的功能。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_2.png"></p><p>发送到内部主题（delaytopic*）中的消息会被一个独立的 DelayService 进程消费，这个 DelayService 进程和 Kafka broker 进程以一对一的配比进行同机部署（参考下图），以保证服务的可用性。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_3.png"></p><p><strong>针对不同延时级别的主题，在 DelayService 的内部都会有单独的线程来进行消息的拉取，以及单独的 DelayQueue（这里用的是 JUC 中 DelayQueue）进行消息的暂存。</strong></p><p>与此同时，在 DelayService 内部还会有专门的消息发送线程来获取 DelayQueue 的消息并转发到真实的主题中。从消费、暂存再到转发，线程之间都是一一对应的关系。如下图所示，DelayService 的设计应当尽量保持简单，避免锁机制产生的隐患。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_4.png"></p><p>为了保障内部 DelayQueue 不会因为未处理的消息过多而导致内存的占用过大，DelayService 会对主题中的每个分区进行计数，当达到一定的阈值之后，就会暂停拉取该分区中的消息。</p><p>因为一个主题中一般不止一个分区，分区之间的消息并不会按照投递时间进行排序，DelayQueue的作用是将消息按照再次投递时间进行有序排序，这样下游的消息发送线程就能够按照先后顺序获取最先满足投递条件的消息。</p><h3 id="重试队列"><a href="#重试队列" class="headerlink" title="重试队列"></a>重试队列</h3><p>重试队列其实可以看作一种回退队列，具体指消费端消费消息失败时，为了防止消息无故丢失而重新将消息回滚到 broker 中。</p><p>与回退队列不同的是，重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大。</p><p>理解了他们的概念之后我们就可以为每个主题设置重试队列，消息第一次消费失败入重试队列 Q1，Q1 的重新投递延时为5s，5s过后重新投递该消息；如果消息再次消费失败则入重试队列 Q2，Q2 的重新投递延时为10s，10s过后再次投递该消息。</p><p>然后再设置一个主题作为死信队列，重试越多次重新投递的时间就越久，并且需要设置一个上限，超过投递次数就进入死信队列。重试队列与延时队列有相同的地方，都需要设置延时级别。</p><h3 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a>死信队列</h3><p>当一条消息初次消费失败，消息队列 MQ 会自动进行消息重试；</p><p>达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息; </p><p>此时，消息队列 MQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中，这种正常情况下无法被消费的消息称为<strong>死信消息</strong>（Dead-Letter Message），存储死信消息的特殊队列称为<strong>死信队列</strong>（Dead-Letter Queue）。</p><p>当一条消息在队列中出现以下三种情况的时候，该消息就会变成一条死信。</p><ul><li>消费者拒绝消费消息，并且不把消息重新放回原目标队列(消费者不想处理的数据)</li><li>消息TTL(time to live)过期(不符合处理要求的数据)</li><li>队列达到最大长度(消费者不能处理的数据)</li></ul><p>当消息在一个队列中变成一个死信之后，如果配置了死信队列，它将被重新publish到死信交换机，死信交换机将死信投递到一个队列上，这个队列就是死信队列。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img.png"></p><h4 id="死信队列处理的方式"><a href="#死信队列处理的方式" class="headerlink" title="死信队列处理的方式"></a>死信队列处理的方式</h4><ul><li>丢弃，如果不是很重要，可以选择丢弃</li><li>记录死信入库，然后做后续的业务分析或处理</li><li>通过死信队列，由负责监听死信的应用程序进行处理</li></ul><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_1.png"></p><h3 id="各中间件支持"><a href="#各中间件支持" class="headerlink" title="各中间件支持"></a>各中间件支持</h3><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><p>Kafka 没有重试机制不支持消息重试，也没有死信队列，因此使用 Kafka 做消息队列时，如果遇到了消息在业务处理时出现异常，就会很难进行下一步处理。</p><p><strong>使用KafkaConnector扩展实现死信队列</strong></p><p>Kafka连接器是Kafka的一部分，是在Kafka和其它技术之间构建流式管道的一个强有力的框架。它可用于将数据从多个地方（包括数据库、消息队列和文本文件）流式注入到Kafka，以及从Kafka将数据流式传输到目标端（如文档存储、NoSQL、数据库、对象存储等）中。</p><p>Kafka连接器可以配置为将无法处理的消息（例如上面提到的反序列化错误）发送到一个单独的Kafka主题，即死信队列。有效消息会正常处理，管道也会继续运行。然后可以从死信队列中检查无效消息，并根据需要忽略或修复并重新处理。</p><p>进行如下的配置可以启用死信队列：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">errors.tolerance</span> = <span class="string">all</span></span><br><span class="line"><span class="meta">errors.deadletterqueue.topic.name</span> =<span class="string"></span></span><br></pre></td></tr></table></figure><p>如果运行于单节点Kafka集群，还需要配置<code>errors.deadletterqueue.topic.replication.factor = 1</code>，其默认值为3。</p><p>但是只有看到消息才能知道它是无效的JSON，即便如此，也只能假设消息被拒绝的原因，要确定Kafka连接器将消息视为无效的实际原因，有两个方法：</p><ul><li>死信队列的消息头；</li><li>Kafka连接器的工作节点日志。</li></ul><p><strong>记录消息的失败原因：消息头</strong></p><p>消息头是使用Kafka消息的键、值和时间戳存储的附加元数据，是在Kafka 0.11版本中引入的。Kafka连接器可以将有关消息拒绝原因的信息写入消息本身的消息头中。这个做法比写入日志文件更好，因为它将原因直接与消息联系起来。</p><p>配置如下的参数，可以在死信队列的消息头中包含拒绝原因：</p><pre><code>errors.deadletterqueue.context.headers.enable = true</code></pre><p><strong>记录消息的失败原因：日志</strong></p><p>记录消息的拒绝原因的第二个选项是将其写入日志。根据安装方式不同，Kafka连接器会将其写入标准输出或日志文件。无论哪种方式都会为每个失败的消息生成一堆详细输出。进行如下配置可启用此功能：</p><pre><code>errors.log.enable = true</code></pre><p>通过配置<code>errors.log.include.messages = true</code>，还可以在输出中包含有关消息本身的元数据。此元数据中包括一些和上面提到的消息头中一样的项目，包括源消息的主题和偏移量。注意它不包括消息键或值本身</p><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>默认的处理机制中，如果我们只对消息做重复消费，达到最大重试次数之后消息就进入死信队列了。RocketMQ 的处理方式为将达到最大重试次数（16 次）的消息标记为死信消息，将该死信消息投递到 DLQ 死信队列中，业务需要进行人工干预。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码规范之JAVA代码安全指南</title>
      <link href="/2021/07/13/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/"/>
      <url>/2021/07/13/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h2 id="后台类"><a href="#后台类" class="headerlink" title="后台类"></a>后台类</h2><h3 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h3><h4 id="【必须】SQL语句默认使用预编译并绑定变量"><a href="#【必须】SQL语句默认使用预编译并绑定变量" class="headerlink" title="【必须】SQL语句默认使用预编译并绑定变量"></a>【必须】SQL语句默认使用预编译并绑定变量</h4><p>Web后台系统应默认使用预编译绑定变量的形式创建sql语句，保持查询语句和数据相分离。以从本质上避免SQL注入风险。</p><p>如使用Mybatis作为持久层框架，应通过#{}语法进行参数绑定，MyBatis 会创建 <code>PreparedStatement</code> 参数占位符，并通过占位符安全地设置参数。</p><p>示例：JDBC</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String custname=request.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        String query=<span class="string">&quot;SELECT * FROM user_data WHERE user_name = ? &quot;</span>;</span><br><span class="line">        PreparedStatement pstmt=connection.prepareStatement(query);</span><br><span class="line">        pstmt.setString(<span class="number">1</span>,custname);</span><br><span class="line">        ResultSet results=pstmt.executeQuery();</span><br></pre></td></tr></table></figure><p>Mybatis</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id=<span class="string">&quot;queryRuleIdByApplicationId&quot;</span>parameterType=<span class="string">&quot;java.lang.String&quot;</span>resultType=<span class="string">&quot;java.lang.String&quot;</span>&gt;</span><br><span class="line">        select rule_id from scan_rule_sqlmap_tab where application_id=#&#123;applicationId&#125;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure><p>应避免外部输入未经过滤直接拼接到SQL语句中，或者通过Mybatis中的${}传入SQL语句（即使使用PreparedStatement，SQL语句直接拼接外部输入也同样有风险。例如Mybatis中部分参数通过${}传入SQL语句后实际执行时调用的是PreparedStatement.execute()<br>，同样存在注入风险）。</p><h4 id="【必须】白名单过滤"><a href="#【必须】白名单过滤" class="headerlink" title="【必须】白名单过滤"></a>【必须】白名单过滤</h4><p>对于表名、列名等无法进行预编译的场景，比如外部数据拼接到order by, group<br>by语句中，需通过白名单的形式对数据进行校验，例如判断传入列名是否存在、升降序仅允许输入“ASC”和“DESC”、表名列名仅允许输入字符、数字、下划线等。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">someMethod</span><span class="params">(<span class="keyword">boolean</span> sortOrder)</span></span>&#123;</span><br><span class="line">        String SQLquery=<span class="string">&quot;some SQL ... order by Salary &quot;</span>+(sortOrder?<span class="string">&quot;ASC&quot;</span>:<span class="string">&quot;DESC&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><h4 id="【必须】文件类型限制"><a href="#【必须】文件类型限制" class="headerlink" title="【必须】文件类型限制"></a>【必须】文件类型限制</h4><p>须在服务器端采用白名单方式对上传或下载的文件类型、大小进行严格的限制。仅允许业务所需文件类型上传，避免上传.jsp、.jspx、.class、.java等可执行文件。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">String file_name=file.getOriginalFilename();</span><br><span class="line">String[]parts=file_name.split(<span class="string">&quot;\\.&quot;</span>);</span><br><span class="line">String suffix=parts[parts.length-<span class="number">1</span>];</span><br><span class="line"><span class="keyword">switch</span>(suffix)&#123;</span><br><span class="line">    <span class="keyword">case</span><span class="string">&quot;jpeg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpeg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;jpg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;bmp&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.bmp&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;png&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.png&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">//handle error</span></span><br><span class="line">        <span class="keyword">return</span><span class="string">&quot;error&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】禁止外部文件存储于可执行目录"><a href="#【必须】禁止外部文件存储于可执行目录" class="headerlink" title="【必须】禁止外部文件存储于可执行目录"></a>【必须】禁止外部文件存储于可执行目录</h4><p>禁止外部文件存储于WEB容器的可执行目录（appBase）。建议保存在专门的文件服务器中。</p><h4 id="【建议】避免路径拼接"><a href="#【建议】避免路径拼接" class="headerlink" title="【建议】避免路径拼接"></a>【建议】避免路径拼接</h4><p>文件目录避免外部参数拼接。保存文件目录建议后台写死并对文件名进行校验（字符类型、长度）。建议文件保存时，将文件名替换为随机字符串。</p><h4 id="【必须】避免路径穿越"><a href="#【必须】避免路径穿越" class="headerlink" title="【必须】避免路径穿越"></a>【必须】避免路径穿越</h4><p>如因业务需要不能满足避免路径拼接，文件路径、文件命中拼接了不可行数据，需判断请求文件名和文件路径参数中是否存在../或..\(仅windows)， 如存在应判定路径非法并拒绝请求。</p><h3 id="网络访问"><a href="#网络访问" class="headerlink" title="网络访问"></a>网络访问</h3><h4 id="【必须】避免直接访问不可信地址"><a href="#【必须】避免直接访问不可信地址" class="headerlink" title="【必须】避免直接访问不可信地址"></a>【必须】避免直接访问不可信地址</h4><p>服务器访问不可信地址时，禁止访问私有地址段及内网域名。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 以RFC定义的专有网络为例，如有自定义私有网段亦应加入禁止访问列表。</span><br><span class="line">10.0.0.0/8</span><br><span class="line">172.16.0.0/12</span><br><span class="line">192.168.0.0/16</span><br><span class="line">127.0.0.0/8</span><br></pre></td></tr></table></figure><p>建议通过URL解析函数进行解析，获取host或者domain后通过DNS获取其IP，然后和内网地址进行比较。</p><p>对已校验通过地址进行访问时，应关闭跟进跳转功能。</p><p>参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">httpConnection=(HttpURLConnection)Url.openConnection();</span><br><span class="line">httpConnection.setFollowRedirects(<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="XML读写"><a href="#XML读写" class="headerlink" title="XML读写"></a>XML读写</h3><h4 id="【必须】XML解析器关闭DTD解析"><a href="#【必须】XML解析器关闭DTD解析" class="headerlink" title="【必须】XML解析器关闭DTD解析"></a>【必须】XML解析器关闭DTD解析</h4><p>读取外部传入XML文件时，XML解析器初始化过程中设置关闭DTD解析。</p><p>参考示例：</p><p>javax.xml.parsers.DocumentBuilderFactory</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setXIncludeAware(<span class="keyword">false</span>);</span><br><span class="line">        dbf.setExpandEntityReferences(<span class="keyword">false</span>);</span><br><span class="line">        ……</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>org.dom4j.io.SAXReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">saxReader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><p>org.jdom2.input.SAXBuilder</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SAXBuilder builder=<span class="keyword">new</span> SAXBuilder();</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">Document doc=builder.build(<span class="keyword">new</span> File(fileName));</span><br></pre></td></tr></table></figure><p>org.xml.sax.XMLReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">XMLReader reader=XMLReaderFactory.createXMLReader();</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="响应输出"><a href="#响应输出" class="headerlink" title="响应输出"></a>响应输出</h3><h4 id="【必须】设置正确的HTTP响应包类型"><a href="#【必须】设置正确的HTTP响应包类型" class="headerlink" title="【必须】设置正确的HTTP响应包类型"></a>【必须】设置正确的HTTP响应包类型</h4><p>响应包的HTTP头“Content-Type”必须正确配置响应包的类型，禁止非HTML类型的响应包设置为“text/html”。此举会使浏览器在直接访问链接时，将非HTML格式的返回报文当做HTML解析，增加反射型XSS的触发几率。</p><h4 id="【建议】设置安全的HTTP响应头"><a href="#【建议】设置安全的HTTP响应头" class="headerlink" title="【建议】设置安全的HTTP响应头"></a>【建议】设置安全的HTTP响应头</h4><ul><li><p>X-Content-Type-Options：</p><p>建议添加“X-Content-Type-Options”响应头并将其值设置为“nosniff”，可避免部分浏览器根据其“Content-Sniff”特性，将一些非“text/html”类型的响应作为HTML解析，增加反射型XSS的触发几率。</p></li><li><p>HttpOnly：</p><p>控制用户登录鉴权的Cookie字段 应当设置HttpOnly属性以防止被XSS漏洞/JavaScript操纵泄漏。</p></li><li><p>X-Frame-Options：</p><p>设置X-Frame-Options响应头，并根据需求合理设置其允许范围。该头用于指示浏览器禁止当前页面在frame、iframe、embed等标签中展现。从而避免点击劫持问题。它有三个可选的值：<br>DENY： 浏览器会拒绝当前页面加载任何frame页面；<br>SAMEORIGIN：则frame页面的地址只能为同源域名下的页面<br>ALLOW-FROM origin：可以定义允许frame加载的页面地址。</p></li><li><p>Access-Control-Allow-Origin</p><p>当需要配置CORS跨域时，应对请求头的Origin值做严格过滤。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String currentOrigin = request.getHeader(<span class="string">&quot;Origin&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (currentOrigin.equals(<span class="string">&quot;https://domain.qq.com&quot;</span>)) &#123;</span><br><span class="line">       response.setHeader(<span class="string">&quot;Access-Control-Allow-Origin&quot;</span>, currentOrigin);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="【必须】外部输入拼接到response页面前进行编码处理"><a href="#【必须】外部输入拼接到response页面前进行编码处理" class="headerlink" title="【必须】外部输入拼接到response页面前进行编码处理"></a>【必须】外部输入拼接到response页面前进行编码处理</h4><p>当响应“content-type”为“html”类型时，外部输入拼接到响应包中，需根据输出位置进行编码处理。编码规则：</p><table><thead><tr><th>场景</th><th>编码规则</th></tr></thead><tbody><tr><td>输出点在HTML标签之间</td><td>需要对以下6个特殊字符进行HTML实体编码(&amp;, &lt;, &gt;, “, ‘,/)。<br>示例：<br>&amp; –&gt; &amp;amp;<br>&lt; –&gt; &amp;lt;<br>&gt;–&gt; &amp;gt;<br>“ –&gt; &amp;quot;<br>‘ –&gt; &amp;#x27;  <br>/ –&gt; &amp;#x2F;</td></tr><tr><td>输出点在HTML标签普通属性内（如href、src、style等，on事件除外）</td><td>要对数据进行HTML属性编码。<br>编码规则：除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为&#xHH;(以&amp;#x开头，HH则是指该字符对应的十六进制数字，分号作为结束符)</td></tr><tr><td>输出点在JS内的数据中</td><td>需要进行js编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \xHH （以 \x 开头，HH则是指该字符对应的十六进制数字）<br>Tips：这种场景仅限于外部数据拼接在js里被引号括起来的变量值中。除此之外禁止直接将代码拼接在js代码中。</td></tr><tr><td>输出点在CSS中（Style属性）</td><td>需要进行CSS编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \HH （以 \ 开头，HH则是指该字符对应的十六进制数字）</td></tr><tr><td>输出点在URL属性中</td><td>对这些数据进行URL编码<br>Tips：除此之外，所有链接类属性应该校验其协议。禁止JavaScript、data和Vb伪协议。</td></tr></tbody></table><p>以上编码规则相对较为繁琐，可参考或直接使用业界已有成熟第三方库如ESAPI.其提供以下函数对象上表中的编码规则:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ESAPI.encoder().encodeForHTML();</span><br><span class="line">        ESAPI.encoder().encodeForHTMLAttribute();</span><br><span class="line">        ESAPI.encoder().encodeForJavaScript();</span><br><span class="line">        ESAPI.encoder().encodeForCSS();</span><br><span class="line">        ESAPI.encoder().encodeForURL();</span><br></pre></td></tr></table></figure><h4 id="【必须】外部输入拼接到HTTP响应头中需进行过滤"><a href="#【必须】外部输入拼接到HTTP响应头中需进行过滤" class="headerlink" title="【必须】外部输入拼接到HTTP响应头中需进行过滤"></a>【必须】外部输入拼接到HTTP响应头中需进行过滤</h4><p>应尽量避免外部可控参数拼接到HTTP响应头中，如业务需要则需要过滤掉“\r”、”\n”等换行符，或者拒绝携带换行符号的外部输入。</p><h4 id="【必须】避免不可信域名的302跳转"><a href="#【必须】避免不可信域名的302跳转" class="headerlink" title="【必须】避免不可信域名的302跳转"></a>【必须】避免不可信域名的302跳转</h4><p>如果对外部传入域名进行302跳转，必须设置可信域名列表并对传入域名进行校验。</p><p>为避免校验被绕过，应避免直接对URL进行字符串匹配。应通过通过URL解析函数进行解析，获取host或者domain后和白名单进行比较。</p><p>需要注意的是，由于浏览器的容错机制，域名<code>https://www.qq.com\www.bbb.com</code>中的<code>\</code>会被替换成<code>/</code>，最终跳转到<code>www.qq.com</code><br>。而Java的域名解析函数则无此特性。为避免解析不一致导致绕过，建议对host中的<code>/</code>和<code>#</code>进行替换。</p><p>参考代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">String host=<span class="string">&quot;&quot;</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  url=url.replaceAll(<span class="string">&quot;[\\\\#]&quot;</span>,<span class="string">&quot;/&quot;</span>); <span class="comment">//替换掉反斜线和井号</span></span><br><span class="line">  host=<span class="keyword">new</span> URL(url).getHost();</span><br><span class="line">&#125; <span class="keyword">catch</span>(MalformedURLException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(host.endsWith(<span class="string">&quot;.qq.com&quot;</span>))&#123;</span><br><span class="line">    <span class="comment">//跳转操作</span></span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】避免通过Jsonp传输非公开敏感信息"><a href="#【必须】避免通过Jsonp传输非公开敏感信息" class="headerlink" title="【必须】避免通过Jsonp传输非公开敏感信息"></a>【必须】避免通过Jsonp传输非公开敏感信息</h4><p>jsonp请求再被CSRF攻击时，其响应包可被攻击方劫持导致信息泄露。应避免通过jsonp传输非公开的敏感信息，例如用户隐私信息、身份凭证等。</p><h4 id="【必须】限定JSONP接口的callback字符集范围"><a href="#【必须】限定JSONP接口的callback字符集范围" class="headerlink" title="【必须】限定JSONP接口的callback字符集范围"></a>【必须】限定JSONP接口的callback字符集范围</h4><p>JSONP接口的callback函数名为固定白名单。如callback函数名可用户自定义，应限制函数名仅包含 字母、数字和下划线。如：<code>[a-zA-Z0-9_-]+</code></p><h4 id="【必须】屏蔽异常栈"><a href="#【必须】屏蔽异常栈" class="headerlink" title="【必须】屏蔽异常栈"></a>【必须】屏蔽异常栈</h4><p>应用程序出现异常时，禁止将数据库版本、数据库结构、操作系统版本、堆栈跟踪、文件名和路径信息、SQL 查询字符串等对攻击者有用的信息返回给客户端。建议重定向到一个统一、默认的错误提示页面，进行信息过滤。</p><h4 id="【必须】模板-amp-表达式"><a href="#【必须】模板-amp-表达式" class="headerlink" title="【必须】模板&amp;表达式"></a>【必须】模板&amp;表达式</h4><p>web view层通常通过模板技术或者表达式引擎来实现界面与业务数据分离，比如jsp中的EL表达式。这些引擎通常可执行敏感操作，如果外部不可信数据未经过滤拼接到表达式中进行解析。则可能造成严重漏洞。</p><p>下列是基于EL表达式注入漏洞的演示demo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    <span class="meta">@RequestMapping(&quot;/ELdemo&quot;)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">ELdemo</span><span class="params">(RepeatDTO repeat)</span></span>&#123;</span><br><span class="line">    ExpressionFactory expressionFactory=<span class="keyword">new</span> ExpressionFactoryImpl();</span><br><span class="line">    SimpleContext simpleContext=<span class="keyword">new</span> SimpleContext();</span><br><span class="line">    String exp=<span class="string">&quot;$&#123;&quot;</span>+repeat.getel()+<span class="string">&quot;&#125;&quot;</span>;</span><br><span class="line">    ValueExpression valueExpression=expressionFactory.createValueExpression(simpleContext,exp,String.class);</span><br><span class="line">    <span class="keyword">return</span> valueExpression.getValue(simpleContext).toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>外部可通过el参数，将不可信输入拼接到EL表达式中并解析。</p><p>此时外部访问：x.x.x.x/ELdemo?el=”’’.getClass().forName(‘java.lang.Runtime’).getMethod(‘exec’,’’.getClass()).invoke(‘’<br>.getClass().forName(‘java.lang.Runtime’).getMethod(‘getRuntime’).invoke(null),’open /Applications/Calculator.app’)“<br>可执行操作系统命令调出计算器。</p><p>基于以上风险：</p><ul><li>应避免外部输入的内容拼接到EL表达式或其他表达式引起、模板引擎进行解析。</li><li>白名单过滤外部输入，仅允许字符、数字、下划线等。</li></ul><h3 id="OS命令执行"><a href="#OS命令执行" class="headerlink" title="OS命令执行"></a>OS命令执行</h3><h4 id="【建议】避免不可信数据拼接操作系统命令"><a href="#【建议】避免不可信数据拼接操作系统命令" class="headerlink" title="【建议】避免不可信数据拼接操作系统命令"></a>【建议】避免不可信数据拼接操作系统命令</h4><p>当不可信数据存在时，应尽量避免外部数据拼接到操作系统命令使用 <code>Runtime</code> 和 <code>ProcessBuilder</code> 来执行。优先使用其他同类操作进行代替，比如通过文件系统API进行文件操作而非直接调用操作系统命令。</p><h4 id="【必须】避免创建SHELL操作"><a href="#【必须】避免创建SHELL操作" class="headerlink" title="【必须】避免创建SHELL操作"></a>【必须】避免创建SHELL操作</h4><p>如无法避免直接访问操作系统命令，需要严格管理外部传入参数，使不可信数据仅作为执行命令的参数而非命令。</p><ul><li><p>禁止外部数据直接直接作为操作系统命令执行。</p></li><li><p>避免通过”cmd”、“bash”、“sh”等命令创建shell后拼接外部数据来执行操作系统命令。</p></li><li><p>对外部传入数据进行过滤。可通过白名单限制字符类型，仅允许字符、数字、下划线；或过滤转义以下符号：|;&amp;$&gt;&lt;`（反引号）!</p><p>白名单示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern FILTER_PATTERN = Pattern.compile(<span class="string">&quot;[0-9A-Za-z_]+&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (!FILTER_PATTERN.matcher(input).matches()) &#123;</span><br><span class="line">  <span class="comment">// 终止当前请求的处理</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="会话管理"><a href="#会话管理" class="headerlink" title="会话管理"></a>会话管理</h3><h4 id="【必须】非一次有效身份凭证禁止在URL中传输"><a href="#【必须】非一次有效身份凭证禁止在URL中传输" class="headerlink" title="【必须】非一次有效身份凭证禁止在URL中传输"></a>【必须】非一次有效身份凭证禁止在URL中传输</h4><p>身份凭证禁止在URL中传输，一次有效的身份凭证除外（如CAS中的st）。</p><h4 id="【必须】避免未经校验的数据直接给会话赋值"><a href="#【必须】避免未经校验的数据直接给会话赋值" class="headerlink" title="【必须】避免未经校验的数据直接给会话赋值"></a>【必须】避免未经校验的数据直接给会话赋值</h4><p>防止会话信息被篡改，如恶意用户通过URL篡改手机号码等。</p><h3 id="加解密"><a href="#加解密" class="headerlink" title="加解密"></a>加解密</h3><h4 id="【建议】对称加密"><a href="#【建议】对称加密" class="headerlink" title="【建议】对称加密"></a>【建议】对称加密</h4><p>建议使用AES，秘钥长度128位以上。禁止使用DES算法，由于秘钥太短，其为目前已知不安全加密算法。使用AES加密算法请参考以下注意事项：</p><ul><li>AES算法如果采用CBC模式：每次加密时IV必须采用密码学安全的伪随机发生器（如/dev/urandom）,禁止填充全0等固定值。</li><li>AES算法如采用GCM模式，nonce须采用密码学安全的伪随机数</li><li>AES算法避免使用ECB模式，推荐使用GCM模式。</li></ul><h4 id="【建议】非对称加密"><a href="#【建议】非对称加密" class="headerlink" title="【建议】非对称加密"></a>【建议】非对称加密</h4><p>建议使用RSA算法，秘钥2048及以上。</p><h4 id="【建议】哈希算法"><a href="#【建议】哈希算法" class="headerlink" title="【建议】哈希算法"></a>【建议】哈希算法</h4><p>哈希算法推荐使用SHA-2及以上。对于签名场景，应使用HMAC算法。如果采用字符串拼接盐值后哈希的方式，禁止将盐值置于字符串开头，以避免哈希长度拓展攻击。</p><h4 id="【建议】密码存储策略"><a href="#【建议】密码存储策略" class="headerlink" title="【建议】密码存储策略"></a>【建议】密码存储策略</h4><p>建议采用随机盐+明文密码进行多轮哈希后存储密码。</p><h3 id="查询业务"><a href="#查询业务" class="headerlink" title="查询业务"></a>查询业务</h3><h4 id="【必须】返回信息最小化"><a href="#【必须】返回信息最小化" class="headerlink" title="【必须】返回信息最小化"></a>【必须】返回信息最小化</h4><p>返回用户信息应遵循最小化原则，避免将业务需求之外的用户信息返回到前端。</p><h4 id="【必须】个人敏感信息脱敏展示"><a href="#【必须】个人敏感信息脱敏展示" class="headerlink" title="【必须】个人敏感信息脱敏展示"></a>【必须】个人敏感信息脱敏展示</h4><p>在满足业务需求的情况下，个人敏感信息需脱敏展示,如：</p><ul><li>鉴权信息（如口令、密保答案、生理标识等）不允许展示</li><li>身份证只显示第一位和最后一位字符，如3****************1。</li><li>移动电话号码隐藏中间6位字符，如134******48。</li><li>工作地址/家庭地址最多显示到“区”一级。</li><li>银行卡号仅显示最后4位字符，如************8639</li></ul><h4 id="【必须】数据权限校验"><a href="#【必须】数据权限校验" class="headerlink" title="【必须】数据权限校验"></a>【必须】数据权限校验</h4><p>查询个人非公开信息时，需要对当前访问账号进行数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>验当前用户是否具备访问数据的权限</li></ol><h3 id="操作业务"><a href="#操作业务" class="headerlink" title="操作业务"></a>操作业务</h3><h4 id="【必须】部署CSRF防御机制"><a href="#【必须】部署CSRF防御机制" class="headerlink" title="【必须】部署CSRF防御机制"></a>【必须】部署CSRF防御机制</h4><p>CSRF是指跨站请求伪造（Cross-site request forgery），是web常见的攻击之一。对于可重放的敏感操作请求，需部署CSRF防御机制。可参考以下两种常见的CSRF防御方式</p><ul><li><p>设置CSRF Token</p><p>服务端给合法的客户颁发CSRF<br>Token，客户端在发送请求时携带该token供服务端校验，服务端拒绝token验证不通过的请求。以此来防止第三方构造合法的恶意操作链接。Token的作用域可以是Request级或者Session级。下面以Session级CSRF<br>Token进行示例</p><ol><li><p>登录成功后颁发Token，并同时存储在服务端Session中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String uuidToken = UUID.randomUUID().toString();</span><br><span class="line">map.put(<span class="string">&quot;token&quot;</span>, uuidToken);</span><br><span class="line">request.getSession().setAttribute(<span class="string">&quot;token&quot;</span>,uuidToken );</span><br><span class="line"><span class="keyword">return</span> map;</span><br></pre></td></tr></table></figure></li></ol></li></ul><ol start="2"><li><p>创建Filter</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CsrfFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;  </span><br><span class="line">   HttpSession session = req.getSession();</span><br><span class="line">   Object token = session.getAttribute(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   String requestToken = req.getParameter(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span>(StringUtils.isBlank(requestToken) || !requestToken.equals(token))&#123;</span><br><span class="line">         AjaxResponseWriter.write(req, resp, ServiceStatusEnum.ILLEGAL_TOKEN, <span class="string">&quot;非法的token&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li></ol><p>CSRF Token应具备随机性，保证其不可预测和枚举。另外由于浏览器会自动对表单所访问的域名添加相应的cookie信息，所以CSRF Token不应该通过Cookie传输。</p><ul><li><p>校验Referer头</p><p>通过检查HTTP请求的Referer字段是否属于本站域名，非本站域名的请求进行拒绝。</p><p>这种校验方式需要注意两点：</p><ol><li>要需要处理Referer为空的情况，当Referer为空则拒绝请求</li><li>注意避免例如qq.com.evil.com 部分匹配的情况。</li></ol></li></ul><h4 id="【必须】权限校验"><a href="#【必须】权限校验" class="headerlink" title="【必须】权限校验"></a>【必须】权限校验</h4><p>对于非公共操作，应当校验当前访问账号进行操作权限（常见于CMS）和数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>校验当前用户是否具备该操作权限</li><li>校验当前用户是否具备所操作数据的权限。避免越权。</li></ol><h4 id="【建议】加锁操作"><a href="#【建议】加锁操作" class="headerlink" title="【建议】加锁操作"></a>【建议】加锁操作</h4><p>对于有次数限制的操作，比如抽奖。如果操作的过程中资源访问未正确加锁。在高并发的情况下可能造成条件竞争，导致实际操作成功次数多于用户实际操作资格次数。此类操作应加锁处理。</p>]]></content>
      
      
      <categories>
          
          <category> 代码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库MySQL系列01之死锁原理及其解决方案研究</title>
      <link href="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/"/>
      <url>/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是死锁"><a href="#什么是死锁" class="headerlink" title="什么是死锁"></a>什么是死锁</h1><p>死锁是并发系统中常见的问题，同样也会出现在数据库MySQL的并发读写请求场景中。<br>当两个及以上的事务，双方都在等待对方释放已经持有的锁或因为加锁顺序不一致造成循环等待锁资源，就会出现“死锁”。<br>常见的报错信息为 Deadlock found when trying to get lock…<br>举例来说 A 事务持有 X1 锁 ，申请 X2 锁，B事务持有 X2 锁，申请 X1 锁。A 和 B 事务持有锁并且申请对方持有的锁进入循环等待，就造成了死锁。</p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img.png" class><p>如上图，是右侧的四辆汽车资源请求产生了回路现象，即死循环，导致了死锁。</p><h1 id="死锁出现要素"><a href="#死锁出现要素" class="headerlink" title="死锁出现要素"></a>死锁出现要素</h1><ul><li>两个或者两个以上事务</li><li>每个事务都已经持有锁并且申请新的锁</li><li>锁资源同时只能被同一个事务持有或者不兼容</li><li>事务之间因为持有锁和申请锁导致彼此循环等待</li></ul><h1 id="经典案例"><a href="#经典案例" class="headerlink" title="经典案例"></a>经典案例</h1><h2 id="案例一-事务并发-insert-唯一键冲突"><a href="#案例一-事务并发-insert-唯一键冲突" class="headerlink" title="案例一:事务并发 insert 唯一键冲突"></a>案例一:事务并发 insert 唯一键冲突</h2><p>表结构如下所示:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_1.png"></p><p>测试用例如下:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_2.png"></p><p>日志分析如下:</p><ul><li><p>事务 T2 insert into t7(id,a) values (26,10) 语句 insert 成功，持有 a=10 的 排他行锁( Xlocks rec but no gap )</p></li><li><p>事务 T1 insert into t7(id,a) values (30,10), 因为T2的第一条 insert 已经插入 a=10 的记录,事务 T1 insert a=10 则发生唯一键冲突,需要申请对冲突的唯一索引加上S Next-key Lock( 即 lock mode S waiting ) 这是一个间隙锁会申请锁住(,10],(10,20]之间的 gap 区域。</p></li><li><p>事务 T2 insert into t7(id,a) values (40，9)该语句插入的 a=9 的值在事务 T1 申请的 gap 锁4-10之间， 故需事务 T2 的第二条 insert 语句要等待事务 T1 的 S-Next-key Lock 锁释放,在日志中显示 lock_mode X locks gap before rec insert intention waiting 。</p></li></ul><h2 id="案例二-先-update-再-insert-的并发死锁问题"><a href="#案例二-先-update-再-insert-的并发死锁问题" class="headerlink" title="案例二:先 update 再 insert 的并发死锁问题"></a>案例二:先 update 再 insert 的并发死锁问题</h2><p>表结构如下，无数据:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_3.png"></p><p>测试用例如下:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_4.png"></p><p>死锁分析:<br>可以看到两个事务 update 不存在的记录，先后获得间隙锁( gap 锁)，gap 锁之间是兼容的所以在update环节不会阻塞。</p><p>两者都持有 gap 锁，然后去竞争插入意向锁。当存在其他会话持有 gap 锁的时候，当前会话申请不了插入意向锁，导致死锁。</p><h1 id="如何尽可能避免死锁"><a href="#如何尽可能避免死锁" class="headerlink" title="如何尽可能避免死锁"></a>如何尽可能避免死锁</h1><ul><li><p>合理的设计索引，区分度高的列放到组合索引前面，使业务 SQL 尽可能通过索引定位更少的行，减少锁竞争。</p></li><li><p>调整业务逻辑 SQL 执行顺序， 避免 update/delete 长时间持有锁的 SQL 在事务前面。</p></li><li><p>避免大事务，尽量将大事务拆成多个小事务来处理，小事务发生锁冲突的几率也更小。</p></li><li><p>以固定的顺序访问表和行。比如两个更新数据的事务，事务 A 更新数据的顺序为 1，2;事务 B 更新数据的顺序为 2，1。这样更可能会造成死锁。</p></li><li><p>在并发比较高的系统中，不要显式加锁，特别是是在事务里显式加锁。如 select … for update 语句，如果是在事务里（运行了 start transaction 或设置了autocommit 等于0）,那么就会锁定所查找到的记录。</p></li><li><p>尽量按主键/索引去查找记录，范围查找增加了锁冲突的可能性，也不要利用数据库做一些额外额度计算工作。比如有的程序会用到 “select … where … order by rand();”这样的语句，由于类似这样的语句用不到索引，因此将导致整个表的数据都被锁住。</p></li><li><p>优化 SQL 和表设计，减少同时占用太多资源的情况。比如说，减少连接的表，将复杂 SQL 分解为多个简单的 SQL。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 死锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>批处理框架之SpringBatch快速入门实践</title>
      <link href="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
      <url>/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h3 id="什么是SpringBatch"><a href="#什么是SpringBatch" class="headerlink" title="什么是SpringBatch"></a>什么是SpringBatch</h3><p>一个轻量级，全面的<strong>批处理框架，不是一个 schuedling 的框架</strong>。</p><p>一个标准的批处理程序：</p><ul><li>通常会从数据库，文件或者队列中读取大量的数据和记录，</li><li>然后对获取的数据进行处理，</li><li>然后将修改后的格式写回到数据库中。</li></ul><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img.png"></p><p>通常 Spring Batch 在离线模式下进行工作，不需要用户干预就能自动进行基本的批处理迭代，进行类似事务方式的处理。批处理是大多数 IT 目的一个组成部分，而 Spring Batch<br>是唯一能够提供健壮的企业级扩展性的批处理开源框架。</p><h3 id="什么情况下需要用到SpringBatch"><a href="#什么情况下需要用到SpringBatch" class="headerlink" title="什么情况下需要用到SpringBatch"></a>什么情况下需要用到SpringBatch</h3><p>在大型企业中，由于业务复杂、数据量大、数据格式不同、数据交互格式繁杂，并非所有的操作都能通过交互界面进行处理。而有一些操作需要定期读取大批量的数据，然后进行一系列的后续处理。这样的过程就是“批处理”。</p><ul><li>数据量大，从数万到数百万甚至上亿不等；</li><li>整个过程全部自动化，并预留一定接口进行自定义配置；</li><li>这样的应用通常是周期性运行，比如按日、周、月运行；</li><li>对数据处理的准确性要求高，并且需要容错机制、回滚机制、完善的日志监控等。</li></ul><h3 id="SpringBatch提供了哪些功能"><a href="#SpringBatch提供了哪些功能" class="headerlink" title="SpringBatch提供了哪些功能"></a>SpringBatch提供了哪些功能</h3><ul><li>事务管理：全批次事务(因为可能有小数据量的批处理或存在存储过程/脚本中)</li><li>基于Web的管理员接口</li><li>分阶段的企业消息驱动处理</li><li>极高容量和高性能的基于块的处理过程(通过优化和分区技术)</li><li>按顺序处理任务依赖（使用工作流驱动的批处理插件）</li><li>声明式的输入/输出操作</li><li>启动、终止、（失败后的手动或定时）重启任务</li><li>重试/跳过任务，部分处理跳过记录（例如，回滚）<details><summary>具体使用场景</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在处理百万级的数据过程过程中难免会出现异常。如果一旦出现异常而导致整个批处理工作终止的话那么会导致后续的数据无法被处理。Spring Batch内置了Retry（重试）和Skip（跳过）机制帮助我们轻松处理各种异常。我 们需要将异常分为三种类型。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> 第一种是<span class="strong">**需要进行Retry的异常**</span>，它们的特点是该异常可能会随着时间推移而消失，比如数据库目前有锁无法写入、web服务当前不可用、web服务满载等。所以对它们适合配置Retry机制。</span><br><span class="line"><span class="bullet">*</span> 第二种是<span class="strong">**需要Skip的异常**</span>，比如解析文件的某条数据出现异常等，因为对这些异常即使执行Retry每次的结果也都是相同，但又不想由于某条数据出错而停止对后续数据的处理。</span><br><span class="line"><span class="bullet">*</span> 第三种异常是<span class="strong">**需要让整个Job立刻失败的异常**</span>，比如如果出现了OutOfMemory的异常，那么需要整个Job立刻终止运行。</span><br><span class="line"></span><br><span class="line">一般来说需要Retry的异常也要配置Skip选项，从而保证后续的数据能够被继续处理。我们也可以配置SkipLimit选项保证当Skip的数据条目达到一定数量后及时终止整个Job。</span><br></pre></td></tr></table></figure></details></li></ul><h3 id="SpringBatch整体架构"><a href="#SpringBatch整体架构" class="headerlink" title="SpringBatch整体架构"></a>SpringBatch整体架构</h3><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_1.png"></p><p>Spring batch框架有4个主要组件：JobLauncher、Job、Step和JobRepository。</p><ul><li>JobLauncher（任务启动器）：通过它启动任务，可以理解为程序的入口。</li><li>Job（任务）：一个具体的任务。<ul><li>由一个或多个step组成，</li><li>通过JobBuilderFactory实例创建Bean，</li><li>使用next指向下一个step,  可以按照指定的逻辑顺序组合 step,</li><li>提供了我们给所有 step 设置相同属性的方法（例如一些事件监听，跳过策略）;</li></ul></li><li>Step（步骤）：一个具体的执行步骤，一个Job中可以有多个Step。</li><li>JobRepository（任务仓库）：存储数据的仓库，在任务执行的时候，需要用它来记录任务状态信息，可以看做是一个数据库的接口。</li></ul><h4 id="JOB"><a href="#JOB" class="headerlink" title="JOB"></a>JOB</h4><p>Job 是一个封装整个批处理过程的一个概念。Job 在 spring batch 的体系当中只是一个最顶层的一个抽象概念，体现在代码当中则它只是一个最上层的接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Batch domain object representing a job. Job is an explicit abstraction</span></span><br><span class="line"><span class="comment"> * representing the configuration of a job specified by a developer. It should</span></span><br><span class="line"><span class="comment"> * be noted that restart policy is applied to the job as a whole and not to a</span></span><br><span class="line"><span class="comment"> * step.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"> <span class="function">String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">boolean</span> <span class="title">isRestartable</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecution execution)</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersIncrementer <span class="title">getJobParametersIncrementer</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersValidator <span class="title">getJobParametersValidator</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Job 这个接口当中定义了五个方法，它的实现类主要有两种类型的 job，一个是 simplejob，另一个是 flowjob。</p><p>Spring Batch 以 SimpleJob 类的形式提供了 Job 接口的默认简单实现，它在 Job 之上创建了一些标准功能。一个使用 java config 的例子代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job footballJob() &#123;</span><br><span class="line">    return this.jobBuilderFactory.get(&quot;footballJob&quot;)</span><br><span class="line">                     .start(playerLoad())</span><br><span class="line">                     .next(gameLoad())</span><br><span class="line">                     .next(playerSummarization())</span><br><span class="line">                     .end()</span><br><span class="line">                     .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="JobInstance"><a href="#JobInstance" class="headerlink" title="JobInstance"></a>JobInstance</h4><p>他是 Job 的更加底层的一个抽象，他的定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobInstance</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobInstance.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> instance id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getInstanceId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>他的方法很简单，一个是返回 Job 的 id，另一个是返回 Job 的名字。</p><p>JobInstance 指的是 job 运行当中，作业执行过程当中的概念。</p><p>比如说现在有一个批处理的 job，它的功能是在一天结束时执行行一次。我们假定这个批处理 job 的名字为’EndOfDay’。在这个情况下，那么每天就会有一个逻辑意义上的 JobInstance, 而我们必须记录 job 的每次运行的情况。</p><h4 id="JobParameters"><a href="#JobParameters" class="headerlink" title="JobParameters"></a>JobParameters</h4><p>JobParameters 对象包含一组用于启动批处理作业的参数，它可以在运行期间用于识别或甚至用作参考数据。</p><p>例如, 我们前面的’EndOfDay’的 job 现在已经有了两个实例，一个产生于 1 月 1 日，另一个产生于 1 月 2 日，那么我们就可以定义两个 JobParameter 对象：一个的参数是 01-01, 另一个的参数是 01-02。</p><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_2.png"></p><p>因此，我么可以通过 Jobparameter 来操作正确的 JobInstance</p><h4 id="JobExecution"><a href="#JobExecution" class="headerlink" title="JobExecution"></a>JobExecution</h4><p>JobExecution 指的是单次尝试运行一个我们定义好的 Job 的代码层面的概念。job 的一次执行可能以失败也可能成功。只有当执行成功完成时，给定的与执行相对应的 JobInstance 才也被视为完成。</p><p>还是以前面描述的 EndOfDay 的 job 作为示例，假设第一次运行 01-01-2019 的 JobInstance 结果是失败。那么此时如果使用与第一次运行相同的 Jobparameter 参数（即 01-01-2019）作业参数再次运行，那么就会创建一个对应于之前 jobInstance 的一个新的 JobExecution 实例, JobInstance 仍然只有一个。</p><p>JobExecution 的接口定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobExecution</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobExecution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> execution id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getExecutionId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get batch status of this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> batch status value.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> BatchStatus <span class="title">getBatchStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered STARTED status. </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getStartTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered end status: COMPLETED, STOPPED, FAILED </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getEndTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get execution exit status.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> exit status.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getExitStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was created.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getCreateTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was last updated updated.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getLastUpdatedTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job parameters for this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> job parameters  </span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Properties <span class="title">getJobParameters</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>JobExecution 当中提供了一个方法 getBatchStatus 用于获取一个 job 某一次特地执行的一个状态。BatchStatus 是一个代表 job 状态的枚举类，其定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">BatchStatus</span> </span>&#123;</span><br><span class="line">    STARTING, STARTED, STOPPING, STOPPED, FAILED, COMPLETED, ABANDONED</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h4><p>每一个 Step 对象都封装了批处理作业的一个独立的阶段。事实上，每一个 Job 本质上都是由一个或多个步骤组成。每一个 step 包含定义和控制实际批处理所需的所有信息。任何特定的内容都由编写 Job 的开发人员自行决定。</p><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_3.png"></p><p>StepExecution 表示一次执行 Step, 每次运行一个 Step 时都会创建一个新的 StepExecution，类似于 JobExecution。但是，某个步骤可能由于其之前的步骤失败而无法执行。且仅当 Step 实际启动时才会创建 StepExecution。</p><p>一次 step 执行的实例由 StepExecution 类的对象表示。每个 StepExecution 都包含对其相应步骤的引用以及 JobExecution 和事务相关的数据，例如提交和回滚计数以及开始和结束时间。</p><p>此外，每个步骤执行都包含一个 ExecutionContext，其中包含开发人员需要在批处理运行中保留的任何数据，例如重新启动所需的统计信息或状态信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job JobFlowDemo1()&#123;</span><br><span class="line">    return jobBuilderFactory.get(&quot;jobFlowDemo1&quot;)</span><br><span class="line">//                .start(step1())</span><br><span class="line">//                .next(step2())</span><br><span class="line">//                .next(step3())</span><br><span class="line">//                .build();</span><br><span class="line">                .start(step1())</span><br><span class="line">                .on(&quot;COMPLETED&quot;).to(step2())</span><br><span class="line">                .from(step2()).on(&quot;COMPLETED&quot;).to(step3())</span><br><span class="line">                .from(step3()).end()</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">当step1 成功执行完成后，返回COMPLETED， 才调用step2进行下一步处理。但是过多的step，不易于程序维护和复用</span><br></pre></td></tr></table></figure><h4 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h4><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_4.png"></p><p>由于我们一次 batch 的任务可能会有很多的数据读写操作，因此一条一条的处理并向数据库提交的话效率不会很高，因此 spring batch 提供了 chunk 这个概念，我们可以设定一个 chunk size，spring batch 将一条一条处理数据，但不提交到数据库，只有当处理的数据数量达到 chunk size 设定的值得时候，才一起去 commit.</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Spring Batch为我们提供了非常实用的功能，对批处理场景进行了完善的抽象，它不仅能实现小数据的迁移，也能应对大企业的大数据实践应用。它让我们开发批处理应用可以事半功倍。  </p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring生态 </tag>
            
            <tag> SpringBatch </tag>
            
            <tag> 批处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之Kafka重平衡机制简读</title>
      <link href="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/"/>
      <url>/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h3 id="什么是Rebalance"><a href="#什么是Rebalance" class="headerlink" title="什么是Rebalance"></a>什么是Rebalance</h3><p>如果对RocketMQ或者对消息中间件有所了解的话，消费端在进行消息消费时至少需要先进行队列（分区）的负载，即一个消费组内的多个消费者如何对订阅的主题中的队列进行负载均衡,当消费者新增或减少、队列增加或减少时能否自动重平衡，做到应用无感知，直接决定了程序伸缩性，其说明图如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img0.png"></p><p>Rebalance本质上是一种协议，规定了一个Consumer Group下的所有的Consumer如何达成一致来分配订阅Topic的每个Partition；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">比如某个group下有5个consumer，它订阅了一个具有10个分区的topic。正常情况下，Kafka平均会为每个consumer分配2个分区。这个分配的过程就叫rebalance。</span><br></pre></td></tr></table></figure><h3 id="Kafka消费端基本流程"><a href="#Kafka消费端基本流程" class="headerlink" title="Kafka消费端基本流程"></a>Kafka消费端基本流程</h3><p>在介绍kafka消费端重平衡机制之前，我们首先简单来看看消费者拉取消息的流程，从整个流程来看重平衡的触发时机、在整个消费流程中所起的重要作用，消费端拉取消息的简要流程如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img1.png"></p><p>主要的关键点如下：</p><ul><li>判断KafkaConsumer对象是否处在多线程环境中。注意：<strong>该对象是多线程不安全的，不能有多个线程持有该对象。</strong></li><li>消费组初始化，包含了队列负载(重平衡)</li><li>消息拉取</li><li>消息消费拦截器处理</li></ul><p>关于poll方法的核心无非就是两个：<strong>重平衡</strong>与<strong>消费拉取</strong>，本篇文章将重点剖析Kafka消费者的重平衡机制。</p><h3 id="消费者队列负载-重平衡-机制"><a href="#消费者队列负载-重平衡-机制" class="headerlink" title="消费者队列负载(重平衡)机制"></a>消费者队列负载(重平衡)机制</h3><p>通过对updateAssignmentMetadataIfNeeded方法的源码剖析，最终调用的核心方法为ConsumerCoordinator的poll方法，核心流程图如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img2.png"></p><p>消费者协调器的核心流程关键点：</p><ul><li>消费者协调器寻找组协调器</li><li>队列负载(重平衡)</li><li>提交位点</li></ul><p><strong>Some Question</strong>  </p><ul><li>重平衡会阻塞消息消费吗？</li><li>Kafka的加入组协议哪些变更能有效减少重平衡</li><li>Kafka与RocketMQ的重平衡机制上各有什么优劣势</li></ul><h4 id="消费者协调器"><a href="#消费者协调器" class="headerlink" title="消费者协调器"></a>消费者协调器</h4><p>在Kafka中，在客户端每一个消费者会对应一个消费者协调器(ConsumerCoordinator),在服务端每一个broker会启动一个组协调器。</p><p>接下来将对该过程进行源码级别的跟踪，根据源码提练工作机制，该部分对应上面流程图中的：ensureCoordinatorReady方法。</p><details>    <summary>protected synchronized boolean ensureCoordinatorReady(final Timer timer)</summary>    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">protected synchronized boolean ensureCoordinatorReady(final Timer timer) &#123;</span><br><span class="line">    if (!coordinatorUnknown())</span><br><span class="line">        return true;</span><br><span class="line"></span><br><span class="line">    do &#123;</span><br><span class="line">        final RequestFuture&lt;Void&gt; future = lookupCoordinator();</span><br><span class="line">        client.poll(future, timer);</span><br><span class="line"></span><br><span class="line">        if (!future.isDone()) &#123;</span><br><span class="line">            // ran out of time</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (future.failed()) &#123;</span><br><span class="line">            if (future.isRetriable()) &#123;</span><br><span class="line">                log.debug(&quot;Coordinator discovery failed, refreshing metadata&quot;);</span><br><span class="line">                client.awaitMetadataUpdate(timer);</span><br><span class="line">            &#125; else</span><br><span class="line">                throw future.exception();</span><br><span class="line">        &#125; else if (coordinator != null &amp;&amp; client.isUnavailable(coordinator)) &#123;</span><br><span class="line">            // we found the coordinator, but the connection has failed, so mark</span><br><span class="line">            // it dead and backoff before retrying discovery</span><br><span class="line">            markCoordinatorUnknown();</span><br><span class="line">            timer.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; while (coordinatorUnknown() &amp;&amp; timer.notExpired());</span><br><span class="line"></span><br><span class="line">    return !coordinatorUnknown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>该方法的关键点如下：</p><ul><li>首先判断一下当前消费者是否已找到broker端的组协调器，如果以感知，则返回true。</li><li>如果当前并没有感知组协调器，则向服务端(broker)寻找该消费组的组协调器。</li><li>寻找组协调器的过程是一个同步过程，如果出现异常，则会触发重试，但引入了重试间隔机制。</li><li>如果未超时并且没有获取组协调器，则再次尝试(do while)。</li></ul><p>核心要点为<strong>lookupCoordinator</strong>方法，该方法的核心是<strong>选择一台负载最小的broker</strong>,构建请求，向broker端查询消费组的组协调器，代码如下：</p><details>    <summary>private RequestFuture<Void> sendFindCoordinatorRequest(Node node)</Void></summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Discover the current coordinator for the group. Sends a GroupMetadata request to</span><br><span class="line"> * one of the brokers. The returned future should be polled to get the result of the request.</span><br><span class="line"> * @return A request future which indicates the completion of the metadata request</span><br><span class="line"> */</span><br><span class="line">private RequestFuture&lt;Void&gt; sendFindCoordinatorRequest(Node node) &#123;</span><br><span class="line">    // initiate the group metadata request</span><br><span class="line">    log.debug(&quot;Sending FindCoordinator request to broker &#123;&#125;&quot;, node);</span><br><span class="line">    FindCoordinatorRequest.Builder requestBuilder =</span><br><span class="line">            new FindCoordinatorRequest.Builder(</span><br><span class="line">                    new FindCoordinatorRequestData()</span><br><span class="line">                        .setKeyType(CoordinatorType.GROUP.id())</span><br><span class="line">                        .setKey(this.groupId));</span><br><span class="line">    return client.send(node, requestBuilder)</span><br><span class="line">            .compose(new FindCoordinatorResponseHandler());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>查询组协调器的请求，核心参数为：</p><ul><li><p>ApiKeys apiKey<br>  请求API，类比RocketMQ的RequestCode，根据该值很容易找到服务端对应的处理代码，这里为ApiKeys.FIND_COORDINATOR。</p></li><li><p>String coordinatorKey<br>  协调器key，取消费组名称。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka服务端每一台Broker会创建一个组协调器(GroupCoordinator),每一个组协调器可以协调多个消费组，但一个消费组只会被分配给一个组协调器，那这里负载机制是什么呢？服务端众多Broker如何竞争该消费组的控制权呢？</span><br></pre></td></tr></table></figure></li><li><p>coordinatorType<br>协调器类型，默认为GROUP,表示普通消费组。</p></li><li><p>short minVersion<br>版本。</p></li></ul><p>针对客户端端请求，服务端统一入口为KafkaApis.scala，可以根据ApiKeys快速找到其处理入口：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img.png"><br>具体的处理逻辑在KafkaApis的handleFindCoordinatorRequest中，如下图所示:<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_1.png"></p><p>服务端为消费组分配协调器的核心算法竟然非常简单：</p><ul><li>根据消费组的名称，取hashcode，</li><li>然后与kafka内部topic(__consumer_offsets)的分区个数取模，</li><li>然后返回该分区所在的物理broker作为消费组的分组协调器</li><li>即内部并没有复杂的选举机制，这样也能更好的说明，客户端在发送请求时可以挑选负载最低的broker进行查询的原因。</li></ul><p>客户端收到响应结果后更新ConsumerCoordinator的(Node coordinator)属性，这样再次调用coordinatorUnknown()方法，将会返回false,至此完成消费端协调器的查找。</p><h4 id="消费者加入消费组流程剖析"><a href="#消费者加入消费组流程剖析" class="headerlink" title="消费者加入消费组流程剖析"></a>消费者加入消费组流程剖析</h4><p>用一张时序图来说明协调者一端是如何处理新成员入组的:<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_21.png"></p><p>在消费者获取到协调器后，根据上文提到的协调器处理流程，接下来消费者需要加入到消费者组中，加入到消费组也是参与队列负载机制的前提，接下来我们从源码角度分析一下消费组加入消费组的流程，对应上文中的<strong>AbstractCoordinator的ensureActiveGroup</strong>方法。</p><details>    <summary>boolean ensureActiveGroup(final Timer timer)</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Ensure the group is active (i.e., joined and synced)</span><br><span class="line"> *</span><br><span class="line"> * @param timer Timer bounding how long this method can block</span><br><span class="line"> * @return true iff the group is active</span><br><span class="line"> */</span><br><span class="line">boolean ensureActiveGroup(final Timer timer) &#123;</span><br><span class="line">    // always ensure that the coordinator is ready because we may have been disconnected</span><br><span class="line">    // when sending heartbeats and does not necessarily require us to rejoin the group.</span><br><span class="line">    if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    startHeartbeatThreadIfNeeded();</span><br><span class="line">    return joinGroupIfNeeded(timer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>该方法的核心关键点：</p><ul><li>在加入消费组之前必须确保该消费者已经感知到组协调器。</li><li>启动心跳线程，当消费者加入到消费组后处于MemberState.STABLE后需要定时向协调器上报心跳，表示存活，否则将从消费组中移除。</li><li>加入消费组。</li></ul><p>心跳线程稍后会详细介绍，先跟踪一下加入消费组的核心流程，具体实现方法为</p><details><summary>joinGroupIfneeded</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Joins the group without starting the heartbeat thread.</span><br><span class="line"> *</span><br><span class="line"> * Visible for testing.</span><br><span class="line"> *</span><br><span class="line"> * @param timer Timer bounding how long this method can block</span><br><span class="line"> * @return true iff the operation succeeded</span><br><span class="line"> */</span><br><span class="line">boolean joinGroupIfNeeded(final Timer timer) &#123;</span><br><span class="line">    while (rejoinNeededOrPending()) &#123;</span><br><span class="line">        if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span><br><span class="line">        // time if the client is woken up before a pending rebalance completes. This must be called</span><br><span class="line">        // on each iteration of the loop because an event requiring a rebalance (such as a metadata</span><br><span class="line">        // refresh which changes the matched subscription set) can occur while another rebalance is</span><br><span class="line">        // still in progress.</span><br><span class="line">        if (needsJoinPrepare) &#123;</span><br><span class="line">            onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">            needsJoinPrepare = false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        final RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br><span class="line">        client.poll(future, timer);</span><br><span class="line">        if (!future.isDone()) &#123;</span><br><span class="line">            // we ran out of time</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (future.succeeded()) &#123;</span><br><span class="line">            // Duplicate the buffer in case `onJoinComplete` does not complete and needs to be retried.</span><br><span class="line">            ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line">            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br><span class="line"></span><br><span class="line">            // We reset the join group future only after the completion callback returns. This ensures</span><br><span class="line">            // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            needsJoinPrepare = true;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            final RuntimeException exception = future.exception();</span><br><span class="line">            if (exception instanceof UnknownMemberIdException ||</span><br><span class="line">                    exception instanceof RebalanceInProgressException ||</span><br><span class="line">                    exception instanceof IllegalGenerationException ||</span><br><span class="line">                    exception instanceof MemberIdRequiredException)</span><br><span class="line">                continue;</span><br><span class="line">            else if (!future.isRetriable())</span><br><span class="line">                throw exception;</span><br><span class="line"></span><br><span class="line">            timer.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>接下来对该方法进行分步解读：</p><ol><li><p>加入消费组之前必须先获取对应的组协调器，因为后续所有的请求都是需要发送到组协调器上。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>每一次执行重平衡之前调用其回调函数，我们可以看看ConsumerCoordinatory的实现</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span><br><span class="line">// time if the client is woken up before a pending rebalance completes. This must be called</span><br><span class="line">// on each iteration of the loop because an event requiring a rebalance (such as a metadata</span><br><span class="line">// refresh which changes the matched subscription set) can occur while another rebalance is</span><br><span class="line">// still in progress.</span><br><span class="line">if (needsJoinPrepare) &#123;</span><br><span class="line">    onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">    needsJoinPrepare = false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void onJoinPrepare(int generation, String memberId) &#123;</span><br><span class="line">    // commit offsets prior to rebalance if auto-commit enabled</span><br><span class="line">    maybeAutoCommitOffsetsSync(time.timer(rebalanceTimeoutMs));</span><br><span class="line"></span><br><span class="line">    // execute the user&#x27;s callback before rebalance</span><br><span class="line">    ConsumerRebalanceListener listener = subscriptions.rebalanceListener();</span><br><span class="line">    Set&lt;TopicPartition&gt; revoked = subscriptions.assignedPartitions();</span><br><span class="line">    log.info(&quot;Revoking previously assigned partitions &#123;&#125;&quot;, revoked);</span><br><span class="line">    try &#123;</span><br><span class="line">        listener.onPartitionsRevoked(revoked);</span><br><span class="line">    &#125; catch (WakeupException | InterruptException e) &#123;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        log.error(&quot;User provided listener &#123;&#125; failed on partition revocation&quot;, listener.getClass().getName(), e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    isLeader = false;</span><br><span class="line">    subscriptions.resetGroupSubscription();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>消费端协调器在进行重平衡(加入一个新组)之前通常会执行如下操作：</p><ul><li>如果开启了自动提交位点，进行一次位点提交。</li><li>执行重平衡相关的事件监听器。</li></ul></li><li><p>向消费组的组协调器发送加入请求，但加入消费组并不是目的，而是手段，最终要达成的目的是进行队列的负载均衡。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br></pre></td></tr></table></figure></li><li><p>调用onJoinComplete方法，通知消费端协调器队列负载的最终结果</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line">onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br></pre></td></tr></table></figure><ul><li>generationId</li><li>memberId 成员id</li><li>protocol 协议名称，这里是consumer。</li><li>memberAssignment 队列负载结果，包含了分配给当前消费者的队列信息，其序列后的结果如图所示<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_2.png"></li></ul></li></ol><p>故队列的负载机制蕴含在构建请求中，接下来深入分析一下客户端与服务端详细的交互流程。</p><h5 id="构建加入消费组请求"><a href="#构建加入消费组请求" class="headerlink" title="构建加入消费组请求"></a>构建加入消费组请求</h5><p>构建加入消费组代码见AbstractCoordinator的sendJoinGroupRequest,其代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_3.png"></p><p>发起一次组加入请求，请求体主要包含如下信息：</p><ul><li>消费组的名称</li><li>session timeout，会话超时时间，默认为10s</li><li>memberId 消费组成员id,第一次为null，后续服务端会为该消费者分配一个唯一的id,构成为客户端id + uuid。</li><li>protocolType 协议类型，消费者加入消费组固定为 consumer</li><li>消费端支持的所有队列负载算法</li></ul><p>收到服务端响应后将会调用JoinGroupResponseHandler回掉，稍后会详细介绍。</p><h5 id="服务端响应逻辑"><a href="#服务端响应逻辑" class="headerlink" title="服务端响应逻辑"></a>服务端响应逻辑</h5><p>服务端处理入口：KafkaApis的handleJoinGroupRequest方法，该方法为委托给GroupCoordinator。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_4.png"></p><p>通过这个入口，基本可以看到服务端处理加入请求的关键点：</p><ul><li>从客户端请求中提取客户端的memberId,如果为空，表示第一次加入消费组，还未分配memberId。</li><li>如果协调器中不存在该消费组的信息，表示第一次加入，创建一个，并执行doUnknownJoinGroup(第一次加入消费组逻辑)</li><li>如果协调器中已存在消费组的信息，判断一下是否已达到<strong>最大消费者个数限制</strong>(默认不限制)，超过则会抛出异常；然后根据消费者是否是第一次加入进行对应的逻辑处理。</li></ul><p><strong>组协调器会为每一个路由到的消费组维护一个组元信息(GroupMetadata)，存储在HashMap&lt; String, GroupMetadata&gt;，每一个消费组云信息中存储了当前的所有的消费者，由消费者主动加入，组协调器可以主动剔除消费者。</strong></p><p>接下来分情况处理，来看一下第一次加入(doUnknownJoinGroup)与重新加入(doJoinGroup)分别详细探讨。</p><h6 id="初次加入消费组"><a href="#初次加入消费组" class="headerlink" title="初次加入消费组"></a>初次加入消费组</h6><p>初次加入消费组的代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_5.png"></p><p>关键点如下：</p><ul><li><p>首先来看一下该方法的参数含义：</p><ul><li>GroupMetadata group: 消费组的元信息，并未持久化，存储在内存中，一个消费组当前消费者的信息。 </li><li>boolean requireKnownMemberId: 是否一定需要知道客户端id,如果客户端请求版本为4,在加入消费组时需要明确知道对方的memberId。</li><li>String clientId: 客户端ID,消息组的memberId生成规则为 clientId + uuid</li><li>String clientHost: 消费端端ip地址 </li><li>int rebalanceTimeoutMs: 重平衡超时时间，取自消费端参数max.poll.interval.ms，默认为5分钟。</li><li>int sessionTimeoutMs: 会话超时时间，默认为10s</li><li>String protocolType: 协议类型，默认为consumer</li><li>List protocols: 客户端支持的队列负载算法。</li></ul></li><li><p>对客户端进行状态验证，其校验如下：</p><ul><li>如果消费者状态为dead，则返回UNKNOWN_MEMBER_ID</li><li>如果当前消费组的负载算法协议不支持新客户端端队列负载协议，则抛出UNKNOWN_MEMBER_ID，并提示不一致的队列负载协议。</li></ul></li><li><p>Kafka 的加入请求版本4在加入消费端组时使用有明确的客户端memberId，消费组将创建的memberId加入到组的pendingMember中，并向客户端返回MEMBER_ID_REQUIRED，引导客户端重新加入，客户端会使用服务端生成的memberId，重新发起加入消费组。</p></li><li><p>调用addMemberAndRebalance方法加入消费组并触发重平衡。</p></li></ul><p>接下来继续探究加入消费组并触发重平衡的具体逻辑，具体实现见GroupCoordinator的addMemberAndRebalance。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_6.png"></p><p>核心要点如下：</p><ul><li>组协调器为每一个消费者创建一个MemberMetadata对象。</li><li>如果消费组的状态为PreparingRebalance(此状态表示正在等待消费组加入)，并将组的newMemberAdded设置为true，表示有新成员加入，后续需要触发重平衡。</li><li>将消费组添加到组中，这里会触发一次<strong>消费组选主</strong>,选主逻辑：<strong>该消费组的第一个加入的消费者成为该消费组中的Leader</strong>, Leader的职责是什么呢？<br>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_7.png"><br>总体而言： <strong>消费组Leader的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案</strong>。<ul><li>为每一个消费者创建一个DelayedHeartbeat对象，用于检测会话超时，组协调器如果检测会话超时，会将该消费者移除组，会重新触发重平衡，消费者为了避免被组协调器移除消费组，需要按间隔发送心跳包。</li><li>根据当前消费组的状态是否需要进行重平衡。</li></ul></li></ul><p>接下来继续深入跟踪maybePrepareRebalance方法，其实现如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_8.png"></p><p>根据状态机的驱动规则，判断是否可以进入到PrepareRebalance，其判断逻辑就是根据状态机的驱动，判断当前状态是否可以进入到该状态，其具体实现是为每一个状态存储了一个可以进入当前状态的前驱状态集合。</p><p>如果符合状态驱动流程，消费组将进入到PrepareRebalance，其具体实现如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_9.png"></p><ul><li>如果当前消费组的状态为CompletingRebalance，需要重置队列分配动作，并让消费组重新加入到消费组，即重新发送JOIN_GROUP请求。具体实现技巧：<br>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_10.png"><ul><li>将所有消费者已按分配算法分配到的队列信息置空</li><li>将空的分配结果返回给消费者，并且错误码为REBALANCE_IN_PROGRESS，客户端收到该错会重新加入消费组。</li></ul></li><li>如果当前没有消费者，则创建InitialDelayedJoin，否则则创建DelayedJoin<ul><li>值得注意的是这里有一个参数：group.initial.rebalance.delay.ms，用于设置消费组进入到PreparingRebalance真正执行其业务逻辑的延迟时间，其主要目的是等待更多的消费者进入。</li><li>驱动消费组状态为PreparingRebalance。</li><li>尝试执行initialDelayedJoin或DelayedJoin的tryComplete方法，如果没有完成，则创建watch，等待执行完成，最终执行的是组协调器的相关方法，其说明如下：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_11.png"><br>接下来看一下组协调器的tryCompleteJoin方法，其实现如下图所示：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_12.png"></li><li>*完成PreparingRebalance状态的条件是: 已知的消费组都成功加入到消费组**。该方法返回true后，onCompleteJoin方法将被执行。</li></ul></li></ul><p>接下来看一下GroupCoordinator的onCompleteJoin方法的实现。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_13.png"></p><p>核心的关键点如下：</p><ul><li>驱动消费组的状态转化为CompletingRebalance，将进入到重平衡的第二个阶段(队列负载)</li><li>为每一个成员构建对应JoinResponse对象，其中三个关键点<ul><li>generationId 消费组每一次状态变更，该值加一</li><li>subProtocol 当前消费者组中所有消费者都支持的队列负载算法</li><li>leaderId 消费组中的leader，一个消费组中第一个加入的消费者为leader</li></ul></li></ul><p>接下来，消费者协调器将根据服务端返回的响应结果，进行第二阶段的重平衡，即进入到队列负载算法。</p><h6 id="已知memberId加入消费组处理逻辑"><a href="#已知memberId加入消费组处理逻辑" class="headerlink" title="已知memberId加入消费组处理逻辑"></a>已知memberId加入消费组处理逻辑</h6><p>组协调在已知memberid处理加入请求的核心处理代码在GroupCoordinator的doJoinGroup中，即重新加入请求。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_14.png"></p><ol><li>首先进行相关的错误校验<ul><li>如果消费组状态为Dead，返回错误unknown_member_id错误。</li><li>如果当前消费者支持的队列负载算法消费组并不支持，返回错误inconsistent_group_protocol</li><li>如果当前的memberid处在pendingMember中，对于这种重新加入的消费者会接受并触发重平衡。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">值得注意的是，在Kafka JOIN_REQUEST版本为4后，首先会在服务端生成memberId,并加入到pendingMember中，并立即向客户端返回memberId,引导客户端重新加入。</span><br></pre></td></tr></table></figure></li><li>如果消费组不存在该成员，返回错误，说明消费组已经将该消费者移除。</li></ul></li><li>根据消费组的状态采取不同的行为<ul><li>如果当前状态为PreparingRebalance  更新成员的元信息，按照需要触发重平衡。  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_15.png">  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PreparingRebalance状态，消费组在等待消费组中的消费者加入。</span><br></pre></td></tr></table></figure></li><li>如果状态为CompletingRebalance<ul><li><p>如果收到join group请求，但其元信息并没有发生变化(队列负载算法)，只需将最新的信息返回给消费者；</p></li><li><p>如果状态发生变更，则会进行再次回到重平衡的第一阶段，消费组重新加入。</p></li></ul>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_16.png">  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">消费组如果处于CompletingRebalance状态，其实不希望再收到Join Group请求，因为处于CompletingRebalance状态的消费组，正在等待消费者Leader分配队列。</span><br></pre></td></tr></table></figure></li><li>如果消费组处于Stable状态  如果成员是leader并且支持的协议发生变化，则进行重平衡，否则只需要将元信息发生给客户端即可。  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_17.png"></li></ul></li></ol><h6 id="客户端处理组协调器的Join-Group响应包"><a href="#客户端处理组协调器的Join-Group响应包" class="headerlink" title="客户端处理组协调器的Join Group响应包"></a>客户端处理组协调器的Join Group响应包</h6><p>客户端对Join_Group的响应处理在：JoinGroupResponseHandler，其核心实现如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_18.png"></p><p>关键点：</p><ul><li>队列的负载算法是由Leader节点来分配，</li><li>将分配结果通过向组协调器发送SYNC_GROUP请求，</li><li>然后组协调器从Leader节点获取分配算法后，</li><li>再返回给所有的消费者，</li><li>从而开始进行消费。</li></ul><h4 id="心跳与离开"><a href="#心跳与离开" class="headerlink" title="心跳与离开"></a>心跳与离开</h4><p>消费者通过消费者协调器与组协调器交互完成消费组的加入，但如何退出呢？例如当消费者宕机，协调器如何感知呢？</p><p>原来在Kafka中，消费者协调器会引入心跳机制，即定时向组协调器发送心跳包，在指定时间内未收到客户端的心跳包，表示会话过期，过期时间通过参数session.timeout.ms设置，默认为10s。<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_22.png"><br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_23.png"></p><p>通过对ConsumerCoordinator的poll流程可知，消费者协调器在得知消费组的组协调器后，就会启动心跳线程，其代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_19.png"></p><p>启动心跳线程后，主要关注HeartbeatThread的run方法。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_20.png"></p><p>心跳线程的核心要点如下：</p><ul><li>如果距离上一次心跳超过了会话时间，会断开与GroupCoordinator断开链接，并设置为coordinatorUnknow 为true，需要重新寻找组协调器。</li><li>如果此次心跳发送时间距离上一次心跳发送时间超过了pollTimeout，客户端将发送LEAVE_GROUP，离开消费组，并在下一个poll方法调用时重新进入加入消费组的操作，会再次触发重平衡。</li><li>如果两次心跳时间超过了单次心跳发送间隔，将发送消息。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">温馨提示：尽管心跳包通常是定时类任务，但kafka的心跳机制另辟蹊径，使用了Object的wait与notify，心跳线程与消息拉取线程相互协助，**每一次消息拉取，都会进行判断是否应该发送心跳包**。</span><br></pre></td></tr></table></figure><p>关于消费组的离开，服务端端处理逻辑比较简单，就不在这一一介绍了。</p><h3 id="重平衡机制总结"><a href="#重平衡机制总结" class="headerlink" title="重平衡机制总结"></a>重平衡机制总结</h3><p>Kafka的重平衡其实包含两个非常重要的阶段：</p><ul><li>消费组加入阶段(PreparingRebalance)<ul><li>此阶段是消费者陆续加入消费组，该组第一个加入的消费者被推举为Leader</li><li>当该组所有已知memberId的消费者全部加入后，状态驱动到CompletingRebalance。</li></ul></li><li>队列负载(CompletingRebalance)<ul><li>PreparingRebalance状态完成后，如果消费者被推举为Leader，<strong>Leader会采用该消费组中都支持的队列负载算法进行队列分布</strong>，然后将结果回报给组协调器；</li><li>如果消费者的角色为非Leader，会向组协调器发送同步队列分区算法，组协调器会将Leader节点分配的结果分配给消费者。</li></ul></li></ul><p><strong>消费组如果在进行重平衡操作，将会暂停消息消费（STW），频繁的重平衡会导致队列消息消费的速度受到极大的影响。</strong></p><p>与重平衡相关的消费端参数：</p><ul><li><p><strong>max.poll.interval.ms</strong></p><p>  两次poll方法调用的最大间隔时间，单位毫秒，默认为5分钟。如果消费端在该间隔内没有发起poll操作，该消费者将被剔除，触发重平衡，将该消费者分配的队列分配给其他消费者。</p></li><li><p><strong>session.timeout.ms</strong></p><p>  消费者与broker的心跳超时时间,默认10s，broker在指定时间内没有收到心跳请求，broker端将会将该消费者移出，并触发重平衡。</p></li><li><p><strong>heartbeat.interval.ms</strong></p><p>  心跳间隔时间，消费者会以该频率向broker发送心跳，默认为3s，主要是确保session不会失效。</p></li></ul><h4 id="重平衡触发条件—消费群组或者topic分区出现变化时"><a href="#重平衡触发条件—消费群组或者topic分区出现变化时" class="headerlink" title="重平衡触发条件—消费群组或者topic分区出现变化时"></a>重平衡触发条件—消费群组或者topic分区出现变化时</h4><ul><li>消费组内成员个数发生变化(<strong>这种情况在实际情况中更加常见。因为订阅分区数、以及订阅 topic 数都是我们主动改变才会发生，而组内消费组成员个数发生变化，则是更加随机的。</strong>)<ul><li>有新的消费者加入Consumer Group,</li><li>由消费者主动退出，Consumer Group/调用unsubscribe()取消对某Topic的订阅,</li><li>有消费者崩溃，可能由于长时间未向GroupCoordinator(协调者)发送心跳，GroupCoordinator会认为其已下线；</li></ul></li><li>订阅的 Topic 分区数出现变化；</li><li>订阅的 Topic 个数发生变化:<br>一个 consumer group 如果之前只订阅了 A topic，那么其组内的 consumer 知会消费 A topic 的消息。而如果现在新增订阅了 B topic，那么 kafka 就需要把 B topic 的 partition 分配给组内的 consumer 进行消费。</li></ul><h3 id="线上环境频繁重平衡问题实例"><a href="#线上环境频繁重平衡问题实例" class="headerlink" title="线上环境频繁重平衡问题实例"></a>线上环境频繁重平衡问题实例</h3><h4 id="消息处理逻辑太重，超过max-poll-interval-ms限制"><a href="#消息处理逻辑太重，超过max-poll-interval-ms限制" class="headerlink" title="消息处理逻辑太重，超过max.poll.interval.ms限制"></a>消息处理逻辑太重，超过max.poll.interval.ms限制</h4><h5 id="问题原因："><a href="#问题原因：" class="headerlink" title="问题原因："></a>问题原因：</h5><p>kafkaConsumer调用一次轮询方法只是拉取一次消息。客户端为了不断拉取消息，会用一个外部循环不断调用消费者的轮询方法。每次轮询到消息，在处理完这一批消息后，才会继续下一次轮询。但如果一次轮询返回的结构没办法及时处理完成，会有什么后果呢？服务端约定了和客户端max.poll.interval.ms，两次poll最大间隔。如果客户端处理一批消息花费的时间超过了这个限制时间，服务端可能就会把消费者客户端移除掉，并触发rebalance。</p><h5 id="引发出的其他问题："><a href="#引发出的其他问题：" class="headerlink" title="引发出的其他问题："></a>引发出的其他问题：</h5><p>拉取偏移量与提交偏移量：kafka的偏移量(offset)是由消费者进行管理的，偏移量有两种，拉取偏移量(position)与提交偏移量(committed)。拉取偏移量代表当前消费者分区消费进度。每次消息消费后，需要提交偏移量。在提交偏移量时，kafka会使用拉取偏移量的值作为分区的提交偏移量发送给协调者。</p><p>如果没有提交偏移量，下一次消费者重新与broker连接后，会从当前消费者group已提交到broker的偏移量处开始消费。</p><p>所以，问题就在这里，当我们处理消息时间太长时,已经被broker剔除，提交偏移量又会报错。所以拉取偏移量没有提交到broker，分区又rebalance。</p><p>下一次重新分配分区时，消费者会从最新的已提交偏移量处开始消费。</p><p>这里就出现了<strong>重复消费</strong>的问题。</p><h5 id="处理方案："><a href="#处理方案：" class="headerlink" title="处理方案："></a>处理方案：</h5><ol><li>调大max.poll.interval.ms参数值或优化消息处理逻辑 <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">max.poll.interval.ms</span>=<span class="string">300</span></span><br></pre></td></tr></table></figure></li><li>设置分区拉取阈值<br>kafkaConsumer调用一次轮询方法只是拉取一次消息。客户端为了不断拉取消息，会用一个外部循环不断调用轮询方法poll()。每次轮询后，在处理完这一批消息后，才会继续下一次的轮询。<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">max.poll.records</span> = <span class="string">50</span></span><br></pre></td></tr></table></figure></li><li>poll到的消息，处理完一条就提交一条，当出现提交失败时，马上跳出循环，这时候kafka就会进行rebalance,下一次会继续从当前offset进行消费。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之Kafka消息拉取机制简读</title>
      <link href="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/"/>
      <url>/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之Kafka消息发送者核心参数与工作机制</title>
      <link href="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/"/>
      <url>/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>本文将从Kafka Producer的配置属性为突破口，结合源码深入提炼出Kafka Producer的工作机制，方便大家更好使用Kafka Producer，并且胸有成竹的进行性能调优。</p><p>将Kafka Producer相关的参数分成如下几个类型：</p><ul><li>常规参数</li><li>工作原理(性能相关)参数(图解)</li></ul><p>本文会结合图解方式，重点阐述与Kafka生产者运作机制密切相关的参数。 </p><h3 id="Producer-核心流程一览"><a href="#Producer-核心流程一览" class="headerlink" title="Producer 核心流程一览"></a>Producer 核心流程一览</h3><p>producer也就是生产者，是kafka中消息的产生方，产生消息并提交给kafka集群完成消息的持久化。</p><h4 id="KafkaProducer构造方法"><a href="#KafkaProducer构造方法" class="headerlink" title="KafkaProducer构造方法"></a>KafkaProducer构造方法</h4><p>KafkaProducer构造方法主要是根据配置文件进行一些实例化操作</p><ol><li>解析clientId，若没有配置则由是producer-递增的数字</li><li>解析并实例化分区器partitioner</li><li>解析key、value的序列化方式并实例化</li><li>解析并实例化拦截器</li><li>解析并实例化RecordAccumulator</li><li>解析Broker地址</li><li>创建一个Sender线程并启动</li></ol><details><summary>一个KafkaProducer的小demo</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String[] args) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">        if (args.length != 2) &#123;</span><br><span class="line">            throw new IllegalArgumentException(&quot;usage: com.ding.KafkaProducerDemo bootstrap-servers topic-name&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        // kafka服务器ip和端口，多个用逗号分割</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, args[0]);</span><br><span class="line">        // 确认信号配置</span><br><span class="line">        // ack=0 代表producer端不需要等待确认信号，可用性最低</span><br><span class="line">        // ack=1 等待至少一个leader成功把消息写到log中，不保证follower写入成功，如果leader宕机同时follower没有把数据写入成功</span><br><span class="line">        // 消息丢失</span><br><span class="line">        // ack=all leader需要等待所有follower成功备份，可用性最高</span><br><span class="line">        props.put(&quot;ack&quot;, &quot;all&quot;);</span><br><span class="line">        // 重试次数</span><br><span class="line">        props.put(&quot;retries&quot;, 0);</span><br><span class="line">        // 批处理消息的大小，批处理可以增加吞吐量</span><br><span class="line">        props.put(&quot;batch.size&quot;, 16384);</span><br><span class="line">        // 延迟发送消息的时间</span><br><span class="line">        props.put(&quot;linger.ms&quot;, 1);</span><br><span class="line">        // 用来换出数据的内存大小</span><br><span class="line">        props.put(&quot;buffer.memory&quot;, 33554432);</span><br><span class="line">        // key 序列化方式</span><br><span class="line">        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        // value 序列化方式</span><br><span class="line">        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line"></span><br><span class="line">        // 创建KafkaProducer对象，创建时会启动Sender线程</span><br><span class="line">        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line">        for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">            // 往RecordAccumulator中写消息</span><br><span class="line">            Future&lt;RecordMetadata&gt; result = producer.send(new ProducerRecord&lt;&gt;(args[1], Integer.toString(i), Integer.toString(i)));</span><br><span class="line">            RecordMetadata rm = result.get();</span><br><span class="line">            System.out.println(&quot;topic: &quot; + rm.topic() + &quot;, partition: &quot; +  rm.partition() + &quot;, offset: &quot; + rm.offset());</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></details><p>相关参数:</p><ul><li><strong>bootstrap.servers</strong>: 配置Kafka broker的服务器地址列表，多个用英文逗号分开，可以不必写全，Kafka内部有自动感知Kafka broker的机制。</li><li><strong>key.serializer</strong>: 消息key的序列化策略，为org.apache.kafka.common.serialization接口的实现类。</li><li><strong>value.serializer</strong>: 消息体的序列化策略</li><li><strong>client.id</strong>: 客户端ID，如果不设置默认为producer-递增，<strong>强烈建议设置该值，尽量包含ip,port,pid</strong>。</li><li><strong>client.dns.lookup</strong>: 客户端寻找bootstrap地址的方式，支持如下两种方式：<ul><li><strong>resolve_canonical_bootstrap_servers_only</strong>: 这种方式，会依据bootstrap.servers提供的主机名(hostname)，根据主机上的名称服务返回其IP地址的数组(InetAddress.getAllByName)，然后依次获取inetAddress.getCanonicalHostName()，再建立tcp连接。<br><strong>一个主机可配置多个网卡，如果启用该功能，应该可以有效利用多网卡的优势，降低Broker的网络端负载压力。</strong></li><li><strong>use_all_dns_ips</strong>: 这种方式会直接使用bootstrap.servers中提供的hostname、port创建tcp连接，默认选项。</li></ul></li></ul><h4 id="KafkaProducer消息发送流程"><a href="#KafkaProducer消息发送流程" class="headerlink" title="KafkaProducer消息发送流程"></a>KafkaProducer消息发送流程</h4><p>Kafka将一条待发送的消息抽象为ProducerRecord对象，其数据结构是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic; <span class="comment">//目标topic</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition; <span class="comment">//目标partition</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;<span class="comment">//消息头信息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;   <span class="comment">//消息key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value; <span class="comment">//消息体</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp; <span class="comment">//消息时间戳</span></span><br><span class="line">    <span class="comment">//省略构造方法与成员方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>目前消息结构包括6个核心属性，分别是topic，partition，headers，key，value与timestamp，各属性含义如上也比较好理解，其中headers属性是Kafka 0.11.x 版本引入的，可以用它存储一些应用或业务相关的信息。</p><p>Kafka消息发送过程中主要涉及ProducerRecord对象的构建、分区选择、元数据的填充、ProducerRecord对象的序列化、进入消息缓冲池、完成消息的发送、接受broker的响应。</p><p>消息的发送入口是KafkaProducer.send方法，具体流程如下: </p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_3.png"></p><ol><li>确定topic信息</li><li>确定value信息</li><li>然后进行消息的序列化处理</li><li>由分区选择器确定对应的分区信息</li><li>将消息写入消息缓冲区</li><li>完成消息请求的发送</li><li>完成消息响应的处理</li></ol><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img.png"></p><p>总的来说，Kafka生产端发送数据过程涉及到序列化器Serializer、分区器Partitioner，消息缓存池Accumulator，还可能会涉及到拦截器Interceptor（这部分暂不做介绍）。</p><p>Kafka 的 Producer 发送消息采用的是异步发送的方式。</p><p>在消息发送的过程中，涉及到了 两个线程——<strong>main线程</strong>和 <strong>Sender线程</strong>，以及<strong>一个线程共享变量——RecordAccumulator。 main 线程将消息发送给 RecordAccumulator</strong>，Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka broker</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_4.png"></p><p>在消息发送端Kafka引入了批的概念，发送到服务端的消息通常不是一条一条发送，而是一批一批发送，一个批次对应源码层级为ProducerBatch对象。<br>相关参数：</p><ul><li><strong>batch.size</strong><br>该值用于设置每一个批次的内存大小,默认为16K,只有数据积累到 batch.size 之后，sender 才会发送数据。</li><li><strong>linger.ms</strong>:<br>Kafka希望一个批次一个批次去发送到Broker，应用程序往KafkaProducer中发送一条消息，首先会进入到内部缓冲区，具体是会进入到某一个批次中(ProducerBatch), 等待该批次堆满后一次发送到Broker，这样能提高消息的吞吐量，但其消息发送的延迟也会相应提高。<br>为了解决该问题，linger.ms参数应运而生。<br>它的作用是控制在缓存区中未积满时来控制消息发送线程的行为。 如果linger.ms 设置为 0表示立即发送，如果设置为大于0，则消息发送线程会等待这个值后才会向broker发送。有点类似于 TCP 领域的 Nagle 算法。.如果数据迟迟未达到 batch.size，sender 等待 linger.time 之后就会发送数据。</li></ul><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_1.png"></p><p>Kafka的每一个消息发送者，也就是KafkaProducer对象内部会有一块缓存区，缓冲区内存的组织会按照topic+parition构建双端队列。<br>相关参数：</p><ul><li><strong>buffer.memory</strong>:<br>指定缓存区大小，默认为32M</li><li><strong>delivery.timeout.ms</strong>:<br>默认为120s，该参数控制在双端队列中的过期时间，从进入双端队列开始计时，超过该值未被sender发送后会返回超时异常(TimeoutException)。</li></ul><p>队列中的每一个元素为一个ProducerBatch对象，表示一个消息发送批次，但发送线程将消息发送到Broker端时，一次可以包含多个批次。</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_2.png"></p><p>相关参数：</p><ul><li><p><strong>max.block.ms</strong>:<br>默认为60s，当消息发送者申请空闲内存时，如果在指定时间（包含发送端用于查找元信息的时间）内未申请到内存，消息发送端会直接报TimeoutException。</p></li><li><p><strong>max.request.size</strong>:<br>Send线程一次发送的最大字节数量，也就是Send线程向服务端一次消息发送请求的最大传输数据，默认为1M。</p></li><li><p><strong>request.timeout.ms</strong>:<br>请求的超时时间，主要是Kafka消息发送线程(Sender)与Broker端的网络通讯的请求超时时间。</p></li><li><p><strong>retries</strong>:<br>Kafka Sender线程从缓存区尝试发送到Broker端的重试次数，默认为Integer.MAX_VALUE。<br>为了避免无限重试，只针对可恢复的异常，例如Leader选举中这种异常就是可恢复的，重试最终是能解决问题的。</p></li><li><p><strong>max.in.flight.requests.per.connection</strong>:<br>设置每一个客户端与服务端连接，在应用层一个通道的积压消息数量，默认为5，有点类似Netty用高低水位线控制发送缓冲区中积压的多少，避免内存溢出。</p></li></ul><h5 id="RecordAccumulator"><a href="#RecordAccumulator" class="headerlink" title="RecordAccumulator"></a>RecordAccumulator</h5><p>RecordAccumulator是消息队列用于缓存消息，根据TopicPartition对消息分组</p><details><summary>RecordAccumulator源码解读</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Add a record to the accumulator, return the append result</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * The append result will contain the future metadata, and flag for whether the appended batch is full or a new batch is created</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> *</span><br><span class="line"> * @param tp The topic/partition to which this record is being sent</span><br><span class="line"> * @param timestamp The timestamp of the record</span><br><span class="line"> * @param key The key for the record</span><br><span class="line"> * @param value The value for the record</span><br><span class="line"> * @param headers the Headers for the record</span><br><span class="line"> * @param callback The user-supplied callback to execute when the request is complete</span><br><span class="line"> * @param maxTimeToBlock The maximum time in milliseconds to block for buffer memory to be available</span><br><span class="line"> */</span><br><span class="line">public RecordAppendResult append(TopicPartition tp,</span><br><span class="line">                                 long timestamp,</span><br><span class="line">                                 byte[] key,</span><br><span class="line">                                 byte[] value,</span><br><span class="line">                                 Header[] headers,</span><br><span class="line">                                 Callback callback,</span><br><span class="line">                                 long maxTimeToBlock) throws InterruptedException &#123;</span><br><span class="line">    // We keep track of the number of appending thread to make sure we do not miss batches in</span><br><span class="line">    // abortIncompleteBatches().</span><br><span class="line">    // ---记录进行applend的线程数---</span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    ByteBuffer buffer = null;</span><br><span class="line">    if (headers == null) headers = Record.EMPTY_HEADERS;</span><br><span class="line">    try &#123;</span><br><span class="line">        // check if we have an in-progress batch</span><br><span class="line">        // ---根据TopicPartition获取或新建Deque双端队列---</span><br><span class="line">        Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">        // ---尝试将消息加入到缓冲区中---</span><br><span class="line">        // ---加锁保证同一个TopicPartition写入有序---</span><br><span class="line">        synchronized (dq) &#123;</span><br><span class="line">            if (closed)</span><br><span class="line">                throw new KafkaException(&quot;Producer closed while send in progress&quot;);</span><br><span class="line">            // 尝试写入</span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            if (appendResult != null)</span><br><span class="line">                return appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // we don&#x27;t have an in-progress record batch try to allocate a new batch</span><br><span class="line">        byte maxUsableMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">        int size = Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line">        log.trace(&quot;Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;&quot;, size, tp.topic(), tp.partition());</span><br><span class="line">        // 尝试applend失败（返回null），会走到这里。如果tryApplend成功直接返回了</span><br><span class="line">        // 从BufferPool中申请内存空间，用于创建新的ProducerBatch</span><br><span class="line">        buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">        synchronized (dq) &#123;</span><br><span class="line">            // Need to check if producer is closed again after grabbing the dequeue lock.</span><br><span class="line">            if (closed)</span><br><span class="line">                throw new KafkaException(&quot;Producer closed while send in progress&quot;);</span><br><span class="line">            </span><br><span class="line">            // 注意这里，前面已经尝试添加失败了，且已经分配了内存，为何还要尝试添加？</span><br><span class="line">            // 因为可能已经有其他线程创建了ProducerBatch或者之前的ProducerBatch已经被Sender线程释放了一些空间，所以在尝试添加一次。这里如果添加成功，后面会在finally中释放申请的空间</span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            if (appendResult != null) &#123;</span><br><span class="line">                // Somebody else found us a batch, return the one we waited for! Hopefully this doesn&#x27;t happen often...</span><br><span class="line">                return appendResult;</span><br><span class="line">            &#125;</span><br><span class="line">            // 尝试添加失败了，新建ProducerBatch</span><br><span class="line">            MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">            ProducerBatch batch = new ProducerBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            incomplete.add(batch);</span><br><span class="line"></span><br><span class="line">            // 将buffer置为null,避免在finally汇总释放空间</span><br><span class="line">            // Don&#x27;t deallocate this buffer in the finally block as it&#x27;s being used in the record batch</span><br><span class="line">            buffer = null;</span><br><span class="line">            return new RecordAppendResult(future, dq.size() &gt; 1 || batch.isFull(), true);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 最后如果再次尝试添加成功，会释放之前申请的内存（为了新建ProducerBatch）</span><br><span class="line">        if (buffer != null)</span><br><span class="line">            free.deallocate(buffer);</span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers,</span><br><span class="line">                                     Callback callback, Deque&lt;ProducerBatch&gt; deque) &#123;</span><br><span class="line">    // 从双端队列的尾部取出ProducerBatch</span><br><span class="line">    ProducerBatch last = deque.peekLast();</span><br><span class="line">    if (last != null) &#123;</span><br><span class="line">        // 取到了，尝试添加消息</span><br><span class="line">        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, headers, callback, time.milliseconds());</span><br><span class="line">        // 空间不够，返回null</span><br><span class="line">        if (future == null)</span><br><span class="line">            last.closeForRecordAppends();</span><br><span class="line">        else</span><br><span class="line">            return new RecordAppendResult(future, deque.size() &gt; 1 || last.isFull(), false);</span><br><span class="line">    &#125;</span><br><span class="line">    // 取不到返回null</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br><span class="line">public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long now) &#123;</span><br><span class="line">    // 空间不够，返回null</span><br><span class="line">    if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) &#123;</span><br><span class="line">        return null;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 真正添加消息</span><br><span class="line">        Long checksum = this.recordsBuilder.append(timestamp, key, value, headers);</span><br><span class="line">        ...</span><br><span class="line">        FutureRecordMetadata future = ...</span><br><span class="line">        // future和回调callback进行关联    </span><br><span class="line">        thunks.add(new Thunk(callback, future));</span><br><span class="line">        ...</span><br><span class="line">        return future;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 将消息写入缓冲区</span><br><span class="line">RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey,serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line">if (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">    // 缓冲区满了或者新创建的ProducerBatch，唤起Sender线程</span><br><span class="line">    this.sender.wakeup();</span><br><span class="line">&#125;</span><br><span class="line">return result.future;</span><br></pre></td></tr></table></figure></details><h5 id="Sender"><a href="#Sender" class="headerlink" title="Sender"></a>Sender</h5><p>KafkaProducer的构造方法在实例化时启动一个KafkaThread线程来执行Sender</p><p>Sender主要流程如下： </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Sender.run</span><br><span class="line">Sender.runOnce</span><br><span class="line">Sender.sendProducerData</span><br><span class="line">// 获取集群信息</span><br><span class="line">Metadata.fetch</span><br><span class="line">// 获取可以发送消息的分区且已经获取到了leader分区的节点</span><br><span class="line">RecordAccumulator.ready</span><br><span class="line">// 根据准备好的节点信息从缓冲区中获取topicPartion对应的Deque队列中取出ProducerBatch信息</span><br><span class="line">RecordAccumulator.drain</span><br><span class="line">// 将消息转移到每个节点的生产请求队列中</span><br><span class="line">Sender.sendProduceRequests</span><br><span class="line">// 为消息创建生产请求队列</span><br><span class="line">Sender.sendProducerRequest</span><br><span class="line">KafkaClient.newClientRequest</span><br><span class="line">// 下面是发送消息</span><br><span class="line">KafkaClient.sent</span><br><span class="line">NetWorkClient.doSent</span><br><span class="line">Selector.send</span><br><span class="line">// 其实上面并不是真正执行I/O，只是写入到KafkaChannel中</span><br><span class="line">// poll 真正执行I/O</span><br><span class="line">KafkaClient.poll</span><br></pre></td></tr></table></figure><details><summary></summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// KafkaProducer构造方法启动Sender</span><br><span class="line">String ioThreadName = NETWORK_THREAD_PREFIX + &quot; | &quot; + clientId;</span><br><span class="line">this.ioThread = new KafkaThread(ioThreadName, this.sender, true);</span><br><span class="line">this.ioThread.start();</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// Sender-&gt;run()-&gt;runOnce()</span><br><span class="line">long currentTimeMs = time.milliseconds();</span><br><span class="line">// 发送生产的消息</span><br><span class="line">long pollTimeout = sendProducerData(currentTimeMs);</span><br><span class="line">// 真正执行I/O操作</span><br><span class="line">client.poll(pollTimeout, currentTimeMs);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 获取集群信息</span><br><span class="line">Cluster cluster = metadata.fetch();</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 获取准备好可以发送消息的分区且已经获取到leader分区的节点</span><br><span class="line">RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);</span><br><span class="line">// ReadyCheckResult 包含可以发送消息且获取到leader分区的节点集合、未获取到leader分区节点的topic集合</span><br><span class="line">public final Set&lt;Node&gt; 的节点;</span><br><span class="line">public final long nextReadyCheckDelayMs;</span><br><span class="line">public final Set&lt;String&gt; unknownLeaderTopics;</span><br></pre></td></tr></table></figure><p>ready方法主要是遍历在上面介绍RecordAccumulator添加消息的容器，Map&lt;TopicPartition, Deque&gt;，从集群信息中根据TopicPartition获取leader分区所在节点，找不到对应leader节点但有要发送的消息的topic添加到unknownLeaderTopics中。同时把那些根据TopicPartition可以获取leader分区且消息满足发送的条件的节点添加到的节点中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// 遍历batches</span><br><span class="line">for (Map.Entry&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; entry : this.batches.entrySet()) &#123;</span><br><span class="line">    TopicPartition part = entry.getKey();</span><br><span class="line">    Deque&lt;ProducerBatch&gt; deque = entry.getValue();</span><br><span class="line">    // 根据TopicPartition从集群信息获取leader分区所在节点</span><br><span class="line">    Node leader = cluster.leaderFor(part);</span><br><span class="line">    synchronized (deque) &#123;</span><br><span class="line">        if (leader == null &amp;&amp; !deque.isEmpty()) &#123;</span><br><span class="line">            // 添加未找到对应leader分区所在节点但有要发送的消息的topic</span><br><span class="line">            unknownLeaderTopics.add(part.topic());</span><br><span class="line">        &#125; else if (!readyNodes.contains(leader) &amp;&amp; !isMuted(part, nowMs)) &#123;</span><br><span class="line">....</span><br><span class="line">                if (sendable &amp;&amp; !backingOff) &#123;</span><br><span class="line">                    // 添加准备好的节点</span><br><span class="line">                    readyNodes.add(leader);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后对返回的unknownLeaderTopics进行遍历，将topic加入到metadata信息中，调用metadata.requestUpdate方法请求更新metadata信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for (String topic : result.unknownLeaderTopics)</span><br><span class="line">    this.metadata.add(topic);</span><br><span class="line">    result.unknownLeaderTopics);</span><br><span class="line">this.metadata.requestUpdate();</span><br></pre></td></tr></table></figure><p>对已经准备好的节点进行最后的检查，移除那些节点连接没有就绪的节点，主要根据KafkaClient.ready方法进行判断</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">long notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">while (iter.hasNext()) &#123;</span><br><span class="line">    Node node = iter.next();</span><br><span class="line">    // 调用KafkaClient.ready方法验证节点连接是否就绪</span><br><span class="line">    if (!this.client.ready(node, now)) &#123;</span><br><span class="line">        // 移除没有就绪的节点</span><br><span class="line">        iter.remove();</span><br><span class="line">        notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面开始创建生产消息的请求</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 从RecordAccumulator中取出TopicPartition对应的Deque双端队列，然后从双端队列头部取出ProducerBatch，作为要发送的信息</span><br><span class="line">Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);</span><br></pre></td></tr></table></figure><p>把消息封装成ClientRequest</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0,requestTimeoutMs, callback);</span><br></pre></td></tr></table></figure><p>调用KafkaClient发送消息（并非真正执行I/O），涉及到KafkaChannel。Kafka的通信采用的是NIO方式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// NetworkClient.doSent方法</span><br><span class="line">String destination = clientRequest.destination();</span><br><span class="line">RequestHeader header = clientRequest.makeHeader(request.version());</span><br><span class="line">...</span><br><span class="line">Send send = request.toSend(destination, header);</span><br><span class="line">InFlightRequest inFlightRequest = new InFlightRequest(clientRequest,header,isInternalRequest,request,send,now);</span><br><span class="line">this.inFlightRequests.add(inFlightRequest);</span><br><span class="line">selector.send(send);</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">// Selector.send方法    </span><br><span class="line">String connectionId = send.destination();</span><br><span class="line">KafkaChannel channel = openOrClosingChannelOrFail(connectionId);</span><br><span class="line">if (closingChannels.containsKey(connectionId)) &#123;</span><br><span class="line">    this.failedSends.add(connectionId);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        channel.setSend(send);</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>到这里，发送消息的工作准备的差不多了，调用KafkaClient.poll方法，真正执行I/O操作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.poll(pollTimeout, currentTimeMs);</span><br></pre></td></tr></table></figure></details><p>用一张图总结Sender线程的流程</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_6.png"></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>Kafka生产消息的主要流程，涉及到主线程往RecordAccumulator中写入消息，同时后台的Sender线程从RecordAccumulator中获取消息，使用NIO的方式把消息发送给Kafka，用一张图总结</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_5.png"></p><h3 id="Producer分区器"><a href="#Producer分区器" class="headerlink" title="Producer分区器"></a>Producer分区器</h3><p>分区器partitioner，可以实现自己的partitioner，比如根据key分区，可以保证相同key分到同一个分区，对保证顺序很有用。</p><p>相关参数：</p><ul><li><strong>partitioner.class</strong>:<br>消息发送队列负载算法，其默 DefaultPartitioner，路由算法如下：<ul><li>如果指定了 key，则使用 key 的 hashcode 与分区数取模。</li><li>如果未指定 key，则轮询所有的分区(用随机数对可用分区取模, counter值初始值是随机的，但后面都是递增的，所以可以算到roundrobin)。</li></ul></li></ul><h3 id="Producer-压缩算法"><a href="#Producer-压缩算法" class="headerlink" title="Producer 压缩算法"></a>Producer 压缩算法</h3><p>Kafka支持的压缩算法还是很可观的：GZIP、Snappy、LZ4，默认情况下不进行消息压缩，毕竟会消耗很大一部分cpu时间，导致send方法处理时间变慢。启动LZ4 进行消息压缩的producer的吞吐量是最高的。</p><p><strong>发送方与Broker 服务器采用相同的压缩类型，可有效避免在Broker服务端进行消息的压缩与解压缩，大大降低Broker的CPU使用压力</strong></p><p>相关参数：</p><ul><li><strong>compression.type</strong>:<br>消息的压缩算法，目前可选值：none、gzip、snappy、lz4、zstd，<strong>默认不压缩，建议与Kafka服务器配置的一样</strong>。</li></ul><p>当然Kafka服务端可以配置的压缩类型为 producer，即采用与发送方配置的压缩类型。</p><h3 id="Producer-interceptor"><a href="#Producer-interceptor" class="headerlink" title="Producer interceptor"></a>Producer interceptor</h3><p>拦截器是新版本才出现的一个特性，并且是非必须的。</p><p>interceptor 核心的函数有: </p><ul><li>onSend（在消息序列化计算分区之前就被调用）</li><li>onAcknowleagement（被应答前或者说在发送失败时，这个方法是运行在producer的I/O线程中的，所以说如果存在很多重逻辑的话会导致严重影响处理消息的速率）</li><li>close。通常是通过为clients定制一部分通用且简单的逻辑时才会使用的。</li></ul><p>相关参数: </p><ul><li><strong>interceptor.classes</strong>:<br>拦截器列表，kafka运行在消息真正发送到broker之前对消息进行拦截加工。</li></ul><h3 id="数据可靠性保证"><a href="#数据可靠性保证" class="headerlink" title="数据可靠性保证"></a>数据可靠性保证</h3><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后都需要向producer发送ack(acknowledgement 确认收到)，如果producer收到ack,就会进行下一轮的发送，否则重新发送数据。</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_7.png"></p><h4 id="副本数据同步策略"><a href="#副本数据同步策略" class="headerlink" title="副本数据同步策略"></a>副本数据同步策略</h4><table><thead><tr><th align="left">方案</th><th align="left">优点</th><th align="left">缺点</th></tr></thead><tbody><tr><td align="left">半数以上完成同步，就发送ack</td><td align="left">延迟低</td><td align="left">选举新的leader时，容忍n台节点故障，需要2n+1个副本</td></tr><tr><td align="left">全部完成同步，才发送ack</td><td align="left">选举新的leader时，容忍n台节点故障，需要n+1个副本</td><td align="left">延迟高</td></tr></tbody></table><p>Kafka选择了第二种方案，原因如下：</p><p>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1 个副本，而 Kafka 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</p><p>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</p><h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h4><p>采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据， 但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去， 直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p><p>Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集合。当 ISR 中的 follower 完成数据的同步之后，leader 就会给 follower 发送 ack。如果 follower 长时间未向 leader 同步数据 ， 则该 follower 将被踢出ISR ， 该时间阈值由replica.lag.time.max.ms 参数设定。Leader 发生故障之后，就会从 ISR 中选举新的 leader。</p><h4 id="ack-应答机制"><a href="#ack-应答机制" class="headerlink" title="ack 应答机制"></a>ack 应答机制</h4><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等 ISR 中的 follower 全部接收成功。</p><p>所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p><ul><li>0: 表示生产者不关心该条消息在 broker 端的处理结果，只要调用 KafkaProducer 的 send 方法返回后即认为成功，显然这种方式是最不安全的，因为 Broker 端可能压根都没有收到该条消息或存储失败。</li><li>1: 等待至少一个leader成功把消息写到log中，不保证follower写入成功，如果leader宕机同时follower没有把数据写入成功，数据丢失。</li><li>all 或 -1: 表示消息不仅需要 Leader 节点已存储该消息，并且要求其副本（准确的来说是 ISR 中的节点）全部存储才认为已提交，才向客户端返回提交成功。这是最严格的持久化保障，当然性能也最低。<ul><li>但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成数据重复。</li></ul></li></ul><p>相关参数:</p><ul><li><strong>acks</strong>:<br>ack应答级别</li></ul><h4 id="故障处理细节"><a href="#故障处理细节" class="headerlink" title="故障处理细节"></a>故障处理细节</h4><p>Log文件中的HW和LEO</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_8.png"></p><p>LEO：指的是每个副本最大的 offset；<br>HW：指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。</p><ul><li>follower 故障: follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘 记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。 等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重 新加入 ISR 了</li><li>leader 故障: leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader 同步数据。</li></ul><p><strong>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p><h3 id="消息队列投递语义"><a href="#消息队列投递语义" class="headerlink" title="消息队列投递语义"></a>消息队列投递语义</h3><ul><li>At Least Once 可以保证数据不丢失，但是不能保证数据不重复。</li><li>At Most Once 可以保证数据不重复，但是不能保证数据不丢失。</li><li>对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即 Exactly Once 语义。</li></ul><p>Kafka投递语义实现方案：</p><ul><li><p>将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 At Least Once 语义。</p></li><li><p>相对的，将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被 发送一次，即 At Most Once 语义。</p></li></ul><p>在 0.11 版本以前的 Kafka，对Exactly Once 语义是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。</p><p>对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11 版本的 Kafka，引入了一项重大特性：<strong>幂等性</strong>。</p><pre><code>所谓的幂等性就是指 Producer 不论向 Server 发送多少次重复数据，Server 端都只会持久化一条。</code></pre><p>幂等性结合 At Least Once 语义，就构成了 Kafka 的 Exactly Once 语义。即：</p><p><strong>At Least Once + 幂等性 = Exactly Once</strong></p><p>相关参数: </p><ul><li><strong>enable.idempotence</strong>: 是否开启发送端的幂等，默认为false。</li><li><strong>acks</strong>: all</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。 </span><br><span class="line">开启幂等性的 Producer 在初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。</span><br><span class="line">而 Broker 端会对做缓存，当具有相同主键的消息提交时，Broker 只会持久化一条。</span><br></pre></td></tr></table></figure><p>但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以<strong>幂等性无法保证分区跨会话的 Exactly Once</strong></p><h3 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h3><ul><li><strong>send.buffer.bytes</strong>: 网络通道(TCP)的发送缓存区大小，默认为128K。</li><li><strong>receive.buffer.bytes</strong>: 网络通道(TCP)的接收缓存区大小，默认为32K。</li><li><strong>reconnect.backoff.ms</strong>: 重新建立链接的等待时长，默认为50ms，属于底层网络参数，基本无需关注。</li><li><strong>reconnect.backoff.max.ms</strong>: 重新建立链接的最大等待时长，默认为1s，连续两次对同一个连接建立重连，等待时间会在reconnect.backoff.ms的初始值上成指数级递增，但超过max后，将不再指数级递增。</li><li><strong>transaction.timeout.ms</strong>: 事务协调器等待客户端的事务状态反馈的最大超时时间，默认为60s。</li><li><strong>transactional.id</strong>: 事务id,用于在一个事务中唯一标识一个客户端</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之Kafka复制原理</title>
      <link href="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/"/>
      <url>/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/img.png"></p><h4 id="HW（High-Watermark）："><a href="#HW（High-Watermark）：" class="headerlink" title="HW（High Watermark）："></a>HW（High Watermark）：</h4><ul><li>在分区高水位以下的消息被认为是已提交消息，反之就是未提交消息；</li><li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的；</li><li>小于等于HW值的所有消息都被认为是“已备份”的（replicated）。</li></ul><h4 id="LEO（Log-End-Offset）"><a href="#LEO（Log-End-Offset）" class="headerlink" title="LEO（Log End Offset）"></a>LEO（Log End Offset）</h4><ul><li>记录了该副本底层日志(log)中下一条消息的位移值（注意是下一条消息！！）</li><li>数字 15 所在的方框是虚线，这就说明，这个副本当前只有 15 条消息，位移值是从 0 到 14，下一条新消息的位移是 15；</li></ul><h3 id="更新机制"><a href="#更新机制" class="headerlink" title="更新机制"></a>更新机制</h3><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/img_1.png"></p><p><strong>流程如下</strong></p><ol><li>生产者写入消息到leader副本</li><li>leader副本LEO值更新</li><li>follower副本尝试拉取消息，发现有消息可以拉取，更新自身LEO</li><li>follower副本继续尝试拉取消息，这时会更新remote副本LEO，同时会更新leader副本的HW</li><li>完成4步骤后，leader副本会将已更新过的HW发送给所有follower副本</li><li>follower副本接收leader副本HW，更新自身的HW</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kafka副本之间的数据复制既不是完全的同步复制，也不是单纯的异步复制；</span><br><span class="line">Leader副本的HW更新原则：取当前leader副本的LEO和所有remote副本的LEO的最小值</span><br><span class="line">Follower副本的HW更新原则：取leader副本发送的HW和自身的LEO中的最小值</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列01之Kafka为什么这么快</title>
      <link href="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/"/>
      <url>/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/</url>
      
        <content type="html"><![CDATA[<ul><li>partition 并行处理</li><li>顺序写磁盘，充分利用磁盘特性</li><li>利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率</li><li>采用了零拷贝技术</li><li>Producer 生产的数据持久化到 broker，采用 mmap 文件映射，实现顺序的快速写入</li><li>Customer 从 broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer进行网络发送，减少 CPU 消耗</li></ul><h2 id="详细解读"><a href="#详细解读" class="headerlink" title="详细解读"></a>详细解读</h2><p>无论 kafka 作为 MQ 也好，作为存储层也罢，无非就是两个功能（好简单的样子），一是 Producer 生产的数据存到 broker，二是 Consumer 从 broker 读取数据。那 Kafka 的快也就体现在读写两个方面了，下面我们就聊聊 Kafka 快的原因。</p><h3 id="利用-Partition-实现并行处理"><a href="#利用-Partition-实现并行处理" class="headerlink" title="利用 Partition 实现并行处理"></a>利用 Partition 实现并行处理</h3><p>我们都知道 Kafka 是一个 Pub-Sub 的消息系统，无论是发布还是订阅，都要指定 Topic。</p><p>Topic 只是一个逻辑的概念。每个 Topic 都包含一个或多个 Partition，不同 Partition 可位于不同节点。</p><p>一方面，由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p><p>能并行处理，速度肯定会有提升，多个工人肯定比一个工人干的快。</p><h3 id="顺序写磁盘"><a href="#顺序写磁盘" class="headerlink" title="顺序写磁盘"></a>顺序写磁盘</h3><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img.png"><br>Kafka 中每个分区是一个有序的，不可变的消息序列，新的消息不断追加到 partition 的末尾，这个就是顺序写。</p><p>由于磁盘有限，不可能保存所有数据，实际上作为消息系统 Kafka 也没必要保存所有数据，需要删除旧的数据。</p><p>又由于顺序写入的原因，所以 Kafka 采用各种删除策略删除数据的时候，并非通过使用“读 - 写”模式去修改文件，而是将 Partition 分为多个 Segment，每个 Segment 对应一个物理文件，通过删除整个文件的方式去删除 Partition 内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。</p><h4 id="简单扯扯磁盘-IO-的那些事"><a href="#简单扯扯磁盘-IO-的那些事" class="headerlink" title="简单扯扯磁盘/IO 的那些事"></a>简单扯扯磁盘/IO 的那些事</h4><p>硬盘性能的制约因素是什么？如何根据磁盘I/O特性来进行系统设计？<br>硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。<br>实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img2.png"></p><p>由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示：</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img1.png"></p><p>影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。<br>机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。<br>在许多的开源框架如 Kafka、HBase 中，都通过追加写的方式来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。  </p><p>感兴趣的同学可以看看 <a href="https://link.zhihu.com/?target=https://tech.meituan.com/2017/05/19/about-desk-io.html">磁盘I/O那些事</a></p><p>磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。</p><h3 id="充分利用-Page-Cache"><a href="#充分利用-Page-Cache" class="headerlink" title="充分利用 Page Cache"></a>充分利用 Page Cache</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache。</span><br><span class="line">  每一个 Page Cache 包含若干 Buffer Cache。</span><br><span class="line">* Page Cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read/write 操作的时候。</span><br><span class="line">* Buffer Cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。</span><br></pre></td></tr></table></figure><p>使用 Page Cache 的好处：</p><ul><li>I/O Scheduler 会将连续的小块写组装成大块的物理写从而提高性能</li><li>I/O Scheduler 会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</li><li>充分利用所有空闲内存（非 JVM 内存）。如果使用应用层 Cache（即 JVM 堆内存），会增加 GC 负担</li><li>读操作可直接在 Page Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 Page Cache）交换数据</li><li>如果进程重启，JVM 内的 Cache 会失效，但 Page Cache 仍然可用</li></ul><p>Broker 收到数据后，写磁盘时只是将数据写入 Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache 内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由 Kafka 层面的 Replication 机制去解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。也正因如此，Kafka 虽然提供了 flush.messages 和 flush.ms 两个参数将 Page Cache 中的数据强制 Flush 到磁盘，但是 Kafka 并不建议使用。</p><h3 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h3><p>Kafka 中存在大量的网络数据持久化到磁盘（Producer 到 Broker）和磁盘文件通过网络发送（Broker 到 Consumer）的过程。这一过程的性能直接影响 Kafka 的整体吞吐量。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的权限。</span><br><span class="line">为了避免用户进程直接操作内核，保证内核安全，操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space），一部分是用户空间（User-space）。</span><br></pre></td></tr></table></figure><p>传统的 Linux 系统中，标准的 I/O 接口（例如read，write）都是基于数据拷贝操作的，即 I/O 操作会导致数据在内核地址空间的缓冲区和用户地址空间的缓冲区之间进行拷贝，所以标准 I/O 也被称作缓存 I/O。这样做的好处是，如果所请求的数据已经存放在内核的高速缓冲存储器中，那么就可以减少实际的 I/O 操作，但坏处就是数据拷贝的过程，会导致 CPU 开销。</p><p>我们把 Kafka 的生产和消费简化成如下两个过程来看：</p><ul><li>网络数据持久化到磁盘 (Producer 到 Broker)</li><li>磁盘文件通过网络发送（Broker 到 Consumer）</li></ul><h4 id="1-网络数据持久化到磁盘-Producer-到-Broker"><a href="#1-网络数据持久化到磁盘-Producer-到-Broker" class="headerlink" title="1) 网络数据持久化到磁盘 (Producer 到 Broker)"></a>1) 网络数据持久化到磁盘 (Producer 到 Broker)</h4><p>传统模式下，数据从网络传输到文件需要 4 次数据拷贝、4 次上下文切换和两次系统调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = socket.read()// 读取网络数据 </span><br><span class="line">File file = new File() </span><br><span class="line">file.write(data)// 持久化到磁盘 </span><br><span class="line">file.flush()</span><br></pre></td></tr></table></figure><p>这一过程实际上发生了四次数据拷贝：</p><ul><li>首先通过 DMA copy 将网络数据拷贝到内核态 Socket Buffer</li><li>然后应用程序将内核态 Buffer 数据读入用户态（CPU copy）</li><li>接着用户程序将用户态 Buffer 再拷贝到内核态（CPU copy）</li><li>最后通过 DMA copy 将数据拷贝到磁盘文件</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DMA（Direct Memory Access）：直接存储器访问。DMA 是一种无需 CPU 的参与，让外设和系统内存之间进行双向数据传输的硬件机制。使用 DMA 可以使系统 CPU 从实际的 I/O 数据传输过程中摆脱出来，从而大大提高系统的吞吐率。</span><br></pre></td></tr></table></figure><p>其中伴随着四次上下文切换，如图所示</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img3.png"></p><p>数据落盘通常都是非实时的，kafka 生产者数据持久化也是如此。Kafka 的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高 I/O 效率，就是上一节提到的 Page Cache。</p><p>对于 kafka 来说，Producer 生产的数据存到 broker，这个过程读取到 socket buffer 的网络数据，其实可以直接在内核空间完成落盘。并没有必要将 socket buffer 的网络数据，读取到应用进程缓冲区；在这里应用进程缓冲区其实就是 broker，broker 收到生产者的数据，就是为了持久化。</p><p><strong>在此特殊场景下</strong>：接收来自 socket buffer 的网络数据，应用进程不需要中间处理、直接进行持久化时。可以使用 <strong>mmpp</strong> 内存文件映射。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Memory Mapped Files：简称 mmap，也有叫 MMFile 的，使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射。从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程。它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。</span><br><span class="line">使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销。</span><br><span class="line">mmap 也有一个很明显的缺陷——不可靠，写到 mmap 中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。Kafka 提供了一个参数——producer.type 来控制是不是主动flush；如果 Kafka 写入到 mmap 之后就立即 flush 然后再返回 Producer 叫同步(sync)；写入 mmap 之后立即返回 Producer 不调用 flush 就叫异步(async)，默认是 sync。</span><br></pre></td></tr></table></figure><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img4.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。</span><br><span class="line">它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。</span><br><span class="line">目前零拷贝技术主要有三种类型：</span><br><span class="line">直接I/O：</span><br><span class="line">        数据直接跨过内核，在用户地址空间与I/O设备之间传递，内核只是进行必要的虚拟存储配置等辅助工作；</span><br><span class="line">避免内核和用户空间之间的数据拷贝：</span><br><span class="line">        当应用程序不需要对数据进行访问时，则可以避免将数据从内核空间拷贝到用户空间</span><br><span class="line">        * mmap</span><br><span class="line">        * sendfile</span><br><span class="line">        * splice &amp;&amp; tee</span><br><span class="line">        * sockmap</span><br><span class="line">copy on write：</span><br><span class="line">        写时拷贝技术，数据不需要提前拷贝，而是当需要修改的时候再进行部分拷贝。</span><br></pre></td></tr></table></figure><h4 id="2-磁盘文件通过网络发送（Broker-到-Consumer）"><a href="#2-磁盘文件通过网络发送（Broker-到-Consumer）" class="headerlink" title="2) 磁盘文件通过网络发送（Broker 到 Consumer）"></a>2) 磁盘文件通过网络发送（Broker 到 Consumer）</h4><p>传统方式实现：先读取磁盘、再用 socket 发送，实际也是进过四次 copy</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buffer = File.read</span><br><span class="line">Socket.send(buffer)</span><br></pre></td></tr></table></figure><p>这一过程可以类比上边的生产消息：</p><ul><li>首先通过系统调用将文件数据读入到内核态 Buffer（DMA 拷贝）</li><li>然后应用程序将内存态 Buffer 数据读入到用户态 Buffer（CPU 拷贝）</li><li>接着用户程序通过 Socket 发送数据时将用户态 Buffer 数据拷贝到内核态 Buffer（CPU 拷贝）</li><li>最后通过 DMA 拷贝将数据拷贝到 NIC Buffer </li></ul><p>Linux 2.4+ 内核通过 sendfile 系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件 - 网络发送由一个 sendfile 调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img5.png"></p><p>Kafka 在这里采用的方案是通过 NIO 的 transferTo/transferFrom 调用操作系统的 sendfile 实现零拷贝。总共发生 2 次内核数据拷贝、2 次上下文切换和一次系统调用，消除了 CPU 数据拷贝</p><h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>在很多情况下，系统的瓶颈不是 CPU 或磁盘，而是网络IO。</p><p>因此，除了操作系统提供的低级批处理之外，Kafka 的客户端和 broker 还会在通过网络发送数据之前，在一个批处理中累积多条记录 (包括读和写)。记录的批处理分摊了网络往返的开销，使用了更大的数据包从而提高了带宽利用率。</p><h3 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h3><p>Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息中间件 </tag>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库连接池之HikariCP实现详解</title>
      <link href="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/"/>
      <url>/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是数据库连接池，为什么需要数据库连接池"><a href="#什么是数据库连接池，为什么需要数据库连接池" class="headerlink" title="什么是数据库连接池，为什么需要数据库连接池"></a>什么是数据库连接池，为什么需要数据库连接池</h2><p>从根本上而言，数据库连接池和我们常用的线程池一样，都属于池化资源，它在程序初始化时创建一定数量的数据库连接对象并将其保存在一块内存区中。</p><p>它允许应用程序重复使用一个现有的数据库连接，当需要执行 SQL 时，我们是直接从连接池中获取一个连接，而不是重新建立一个数据库连接，当 SQL 执行完，也并不是将数据库连接真的关掉，而是将其归还到数据库连接池中。</p><p>我们可以通过配置连接池的参数来控制连接池中的初始连接数、最小连接、最大连接、最大空闲时间等参数，来保证访问数据库的数量在一定可控制的范围类，防止系统崩溃，同时保证用户良好的体验。</p><p>数据库连接池示意图如下所示：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img.png"></p><p>因为数据库连接是有限且代价昂贵，创建和释放数据库连接都非常耗时，频繁地进行这样的操作将占用大量的性能开销，进而导致网站的响应速度下降，甚至引起服务器崩溃。</p><p>因此使用数据库连接池的核心作用，就是<strong>避免数据库连接频繁创建和销毁，节省系统开销</strong>。</p><h3 id="常见数据库连接池对比分析"><a href="#常见数据库连接池对比分析" class="headerlink" title="常见数据库连接池对比分析"></a>常见数据库连接池对比分析</h3><p>这里详细总结了常见数据库连接池的各项功能比较，我们重点分析下当前主流的阿里巴巴Druid与HikariCP，HikariCP在性能上是完全优于Druid连接池的。</p><p>而Druid的性能稍微差点是由于锁机制的不同，并且Druid提供更丰富的功能，包括监控、sql拦截与解析等功能，两者的侧重点不一样，HikariCP追求极致的高性能。</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_1.png"></p><p>下面是官网提供的性能对比图，在性能上面这五种数据库连接池的排序如下：HikariCP&gt;druid&gt;tomcat-jdbc&gt;dbcp&gt;c3p0：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_2.png"></p><h3 id="一个简单的小问题"><a href="#一个简单的小问题" class="headerlink" title="一个简单的小问题"></a>一个简单的小问题</h3><pre><code>连接池本身的性能消耗在整个调用链路中通常占比不大，连接池的性能关键点是：连接是否LRU方式重用，是否支持PSCache（PreparedStatementCache）。</code></pre><h2 id="HikariCP数据库连接池简介"><a href="#HikariCP数据库连接池简介" class="headerlink" title="HikariCP数据库连接池简介"></a>HikariCP数据库连接池简介</h2><p>HikariCP 号称是史上性能最好的数据库连接池，SpringBoot 2.0将它设置为默认的数据源连接池。</p><p>Hikari相比起其它连接池的性能高了非常多，那么，这是怎么做到的呢？</p><p>通过查看HikariCP官网介绍，对于HikariCP所做优化总结如下：</p><ol><li><p><strong>字节码精简</strong> ：优化代码，编译后的字节码量极少，使得CPU缓存可以加载更多的程序代码；</p><p> HikariCP在优化并精简字节码上也下了功夫，使用第三方的Java字节码修改类库Javassist来生成委托实现动态代理.动态代理的实现在ProxyFactory类，速度更快，相比于JDK Proxy生成的字节码更少，精简了很多不必要的字节码。</p></li><li><p><strong>优化代理和拦截器</strong>：减少代码，例如HikariCP的Statement proxy只有100行代码，只有BoneCP的十分之一；</p></li><li><p><strong>自定义数组类型（FastStatementList）代替ArrayList</strong>：避免ArrayList每次get()都要进行range check，避免调用remove()时的从头到尾的扫描（由于连接的特点是后获取连接的先释放）；</p></li><li><p><strong>自定义集合类型（ConcurrentBag）</strong>：提高并发读写的效率；</p></li><li><p><strong>其他针对BoneCP缺陷的优化</strong>，比如对于耗时超过一个CPU时间片的方法调用的研究。</p></li></ol><h2 id="HikariCP详细设计之类图和流程图"><a href="#HikariCP详细设计之类图和流程图" class="headerlink" title="HikariCP详细设计之类图和流程图"></a>HikariCP详细设计之类图和流程图</h2><p>开始前先来了解下HikariCP获取一个连接时类间的交互流程，方便下面详细流程的阅读。</p><p>获取连接时的类间交互：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_3.png"></p><h2 id="HikariCP详细设计之流程源码解读"><a href="#HikariCP详细设计之流程源码解读" class="headerlink" title="HikariCP详细设计之流程源码解读"></a>HikariCP详细设计之流程源码解读</h2><h3 id="主流程1：获取连接流程"><a href="#主流程1：获取连接流程" class="headerlink" title="主流程1：获取连接流程"></a>主流程1：获取连接流程</h3><p>HikariCP获取连接时的入口是<code>HikariDataSource</code>里的<code>getConnection</code>方法，现在来看下该方法的具体流程：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_4.png"></p><p>上述为HikariCP获取连接时的流程图，由图可知:</p><ul><li>每个datasource对象里都会持有一个HikariPool对象，记为pool;</li><li>初始化后的datasource对象pool是空的，所以第一次getConnection的时候会进行实例化pool属性（参考主流程1），初始化的时候需要将当前datasource里的config属性传过去，用于pool的初始化，最终标记sealed;</li><li>然后根据pool对象调用getConnection方法（参考流程1.1），获取成功后返回连接对象。</li></ul><h4 id="流程1-1：通过HikariPool获取连接对象"><a href="#流程1-1：通过HikariPool获取连接对象" class="headerlink" title="流程1.1：通过HikariPool获取连接对象"></a>流程1.1：通过HikariPool获取连接对象</h4><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_6.png"></p><ul><li>从最开始的结构图可知，每个HikariPool里都维护一个ConcurrentBag对象，用于存放连接对象。</li><li>由上图可以看到，实际上HikariPool的getConnection就是从ConcurrentBag里获取连接的（调用其borrow方法获得，对应ConnectionBag主流程），</li><li>在长连接检查这块，与之前说的Druid不同，这里的长连接判活检查在连接对象没有被标记为“已丢弃”时，只要距离上次使用超过500ms每次取出都会进行检查（500ms是默认值，可通过配置<code>com.zaxxer.hikari.aliveBypassWindowMs</code>的系统参数来控制），也就是说HikariCP对长连接的活性检查很频繁，但是其并发性能依旧优于Druid，说明<strong>频繁的长连接检查并不是导致连接池性能高低的关键所在</strong>。<ul><li>这个其实是由于HikariCP的无锁实现，在高并发时对CPU的负载没有其他连接池那么高而产生的并发性能差异，后面会说HikariCP的具体做法；</li><li>即使是Druid，在获取连接、生成连接、归还连接时都进行了锁控制。</li><li>Druid里的连接池资源是多线程共享的，不可避免的会有锁竞争，有锁竞争意味着线程状态的变化会很频繁，线程状态变化频繁意味着CPU上下文切换也将会很频繁。</li></ul></li></ul><p>主体流程：</p><ul><li>如果拿到的连接为空，直接报错；</li><li>不为空则进行相应的检查<ul><li>如果检查通过，则包装成ConnectionProxy对象返回给业务方；</li><li>不通过则调用closeConnection方法关闭连接（对应流程1.1.2，该流程会触发ConcurrentBag的remove方法丢弃该连接，然后把实际的驱动连接交给closeConnectionExecutor线程池，异步关闭驱动连接）。</li></ul></li></ul><h5 id="流程1-1-1：连接判活"><a href="#流程1-1-1：连接判活" class="headerlink" title="流程1.1.1：连接判活"></a>流程1.1.1：连接判活</h5><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_7.png"></p><p>承接上面的<code>流程1.1</code>里的判活流程，来看下判活是如何做的</p><ul><li>首先说验证方法（注意这里该方法接受的这个connection对象不是poolEntry，而是poolEntry持有的实际驱动的连接对象），<ul><li>Druid是根据驱动程序里是否存在ping方法来判断是否启用ping的方式判断连接是否存活;</li><li>但是到了HikariCP则更加简单粗暴，仅根据是否配置了connectionTestQuery觉定是否启用ping：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.isUseJdbc4Validation = config.getConnectionTestQuery() == null;</span><br></pre></td></tr></table></figure></li><li>所以一般驱动如果不是特别低的版本，不建议配置该项，否则便会走createStatement+excute的方式，相比ping简单发送心跳数据，这种方式显然更低效。</li></ul></li><li>超时时间<ul><li>在刚进来还会通过驱动的连接对象重新给它设置一遍networkTimeout的值，使之变成validationTimeout，表示一次验证的超时时间；</li><li>因为在使用ping方法校验时，是没办法通过类似statement那样可以setQueryTimeout的，所以只能由网络通信的超时时间来控制，这个时间可以通过jdbc的连接参数socketTimeout来控制：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbc:mysql://127.0.0.1:3306/xxx?socketTimeout=250</span><br></pre></td></tr></table></figure></li><li>这个值最终会被赋值给HikariCP的networkTimeout字段，这就是为什么最后那一步使用这个字段来还原驱动连接超时属性的原因；</li><li>最后那里为啥要再次还原呢？这就很容易理解了，因为验证结束了，连接对象还存活的情况下，它的networkTimeout的值这时仍然等于validationTimeout（不合预期），显然在拿出去用之前，需要恢复成本来的值，也就是HikariCP里的networkTimeout属性。</li></ul></li></ul><h5 id="流程1-1-2：关闭连接对象"><a href="#流程1-1-2：关闭连接对象" class="headerlink" title="流程1.1.2：关闭连接对象"></a>流程1.1.2：关闭连接对象</h5><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_8.png"></p><p>这个流程简单来说就是把流程1.1.1中验证不通过的死连接，主动关闭的一个流程。</p><ul><li>首先会把这个连接对象从ConnectionBag里移除，</li><li>然后把实际的物理连接交给一个线程池去异步执行，这个线程池就是在主流程2里初始化池的时候初始化的线程池closeConnectionExecutor，</li><li>然后异步任务内开始实际的关连接操作，</li><li>因为主动关闭了一个连接相当于少了一个连接，所以还会触发一次扩充连接池（参考<code>主流程5</code>）操作。</li></ul><h3 id="主流程2：初始化池对象"><a href="#主流程2：初始化池对象" class="headerlink" title="主流程2：初始化池对象"></a>主流程2：初始化池对象</h3><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_5.png"></p><p>该流程用于初始化整个连接池，这个流程会给连接池内所有的属性做初始化的工作，其中比较主要的几个流程上图已经指出，简单概括一下：</p><ol><li>利用config初始化各种连接池属性，并且产生一个用于生产物理连接的数据源DriverDataSource</li><li>初始化存放连接对象的核心类connectionBag</li><li>初始化一个延时任务线程池类型的对象houseKeepingExecutorService，用于后续执行一些延时/定时类任务（比如连接泄漏检查延时任务，参考流程2.2以及<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B4%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%BC%A9%E5%AE%B9">主流程4：连接池缩容</a>，除此之外maxLifeTime后主动回收关闭连接也是交由该对象来执行的，这个过程可以参考主流程3）</li><li>预热连接池，HikariCP会在该流程的checkFailFast里初始化好一个连接对象放进池子内，当然触发该流程得保证initializationTimeout &gt; 0时（默认值1），这个配置属性表示留给预热操作的时间（默认值1在预热失败时不会发生重试）。与Druid通过initialSize控制预热连接对象数不一样的是，HikariCP仅预热进池一个连接对象。</li><li>初始化一个线程池对象addConnectionExecutor，用于后续扩充连接对象</li><li>初始化一个线程池对象closeConnectionExecutor，用于关闭一些连接对象，怎么触发关闭任务呢？可以参考流程1.1.2</li></ol><h4 id="流程2-1：HikariCP监控设置"><a href="#流程2-1：HikariCP监控设置" class="headerlink" title="流程2.1：HikariCP监控设置"></a>流程2.1：HikariCP监控设置</h4><p>不同于Druid那样监控指标那么多，HikariCP会把我们非常关心的几项指标暴露给我们，</p><p>比如当前连接池内闲置连接数、总连接数、一个连接被用了多久归还、创建一个物理连接花费多久等，</p><p>HikariCP的连接池的监控我们这一节专门详细的分解一下，首先找到HikariCP下面的metrics文件夹，这下面放置了一些规范实现的监控接口等，还有一些现成的实现（比如HikariCP自带对prometheus、micrometer、dropwizard的支持，不太了解后面两个，prometheus下文直接称为普罗米修斯）：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_9.png"></p><p>下面，来着重看下接口的定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这个接口的实现主要负责收集一些动作的耗时</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IMetricsTracker</span> <span class="keyword">extends</span> <span class="title">AutoCloseable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">//这个方法触发点在创建实际的物理连接时（主流程3），用于记录一个实际的物理连接创建所耗费的时间</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionCreatedMillis</span><span class="params">(<span class="keyword">long</span> connectionCreatedMillis)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点在getConnection时（主流程1），用于记录获取一个连接时实际的耗时</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionAcquiredNanos</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> elapsedAcquiredNanos)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点在回收连接时（主流程6），用于记录一个连接从被获取到被回收时所消耗的时间</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionUsageMillis</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> elapsedBorrowedMillis)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点也在getConnection时（主流程1），用于记录获取连接超时的次数，每发生一次获取连接超时，就会触发一次该方法的调用</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionTimeout</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>触发点都了解清楚后，再来看看MetricsTrackerFactory的接口定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//用于创建IMetricsTracker实例，并且按需记录PoolStats对象里的属性（这个对象里的属性就是类似连接池当前闲置连接数之类的线程池状态类指标）</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">MetricsTrackerFactory</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">//返回一个IMetricsTracker对象，并且把PoolStats传了过去</span></span><br><span class="line">    <span class="function">IMetricsTracker <span class="title">create</span><span class="params">(String poolName, PoolStats poolStats)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的接口用法见注释，针对新出现的PoolStats类，我们来看看它做了什么：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">PoolStats</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicLong reloadAt; <span class="comment">//触发下次刷新的时间（时间戳）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> timeoutMs; <span class="comment">//刷新下面的各项属性值的频率，默认1s，无法改变</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 总连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> totalConnections;</span><br><span class="line">    <span class="comment">// 闲置连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> idleConnections;</span><br><span class="line">    <span class="comment">// 活动连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> activeConnections;</span><br><span class="line">    <span class="comment">// 由于无法获取到可用连接而阻塞的业务线程数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> pendingThreads;</span><br><span class="line">    <span class="comment">// 最大连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> maxConnections;</span><br><span class="line">    <span class="comment">// 最小连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> minConnections;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PoolStats</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.timeoutMs = timeoutMs;</span><br><span class="line">        <span class="keyword">this</span>.reloadAt = <span class="keyword">new</span> AtomicLong();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这里以获取最大连接数为例，其他的跟这个差不多</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getMaxConnections</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (shouldLoad()) &#123; <span class="comment">//是否应该刷新</span></span><br><span class="line">            update(); <span class="comment">//刷新属性值，注意这个update的实现在HikariPool里，因为这些属性值的直接或间接来源都是HikariPool</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> maxConnections;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">()</span></span>; <span class="comment">//实现在↑上面已经说了</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldLoad</span><span class="params">()</span> </span>&#123; <span class="comment">//按照更新频率来决定是否刷新属性值</span></span><br><span class="line">        <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> now = currentTime();</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> reloadTime = reloadAt.get();</span><br><span class="line">            <span class="keyword">if</span> (reloadTime &gt; now) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (reloadAt.compareAndSet(reloadTime, plusMillis(now, timeoutMs))) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上这里就是这些属性获取和触发刷新的地方，那么这个对象是在哪里被生成并且丢给<code>MetricsTrackerFactory</code>的<code>create</code>方法的呢？这就是本节所需要讲述的要点：<code>主流程2</code>里的设置监控器的流程，来看看那里发生了什么事吧：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">//监控器设置方法（此方法在HikariPool中，metricsTracker属性就是HikariPool用来触发IMetricsTracker里方法调用的）</span><br><span class="line">public void setMetricsTrackerFactory(MetricsTrackerFactory metricsTrackerFactory) &#123;</span><br><span class="line">    if (metricsTrackerFactory != null) &#123;</span><br><span class="line">        //MetricsTrackerDelegate是包装类，是HikariPool的一个静态内部类，是实际持有IMetricsTracker对象的类，也是实际触发IMetricsTracker里方法调用的类</span><br><span class="line">        //这里首先会触发MetricsTrackerFactory类的create方法拿到IMetricsTracker对象，然后利用getPoolStats初始化PoolStat对象，然后也一并传给MetricsTrackerFactory</span><br><span class="line">        this.metricsTracker = new MetricsTrackerDelegate(metricsTrackerFactory.create(config.getPoolName(), getPoolStats()));</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        //不启用监控，直接等于一个没有实现方法的空类</span><br><span class="line">        this.metricsTracker = new NopMetricsTrackerDelegate();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private PoolStats getPoolStats() &#123;</span><br><span class="line">    //初始化PoolStats对象，并且规定1s触发一次属性值刷新的update方法</span><br><span class="line">    return new PoolStats(SECONDS.toMillis(1)) &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void update() &#123;</span><br><span class="line">            //实现了PoolStat的update方法，刷新各个属性的值</span><br><span class="line">            this.pendingThreads = HikariPool.this.getThreadsAwaitingConnection();</span><br><span class="line">            this.idleConnections = HikariPool.this.getIdleConnections();</span><br><span class="line">            this.totalConnections = HikariPool.this.getTotalConnections();</span><br><span class="line">            this.activeConnections = HikariPool.this.getActiveConnections();</span><br><span class="line">            this.maxConnections = config.getMaximumPoolSize();</span><br><span class="line">            this.minConnections = config.getMinimumIdle();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里HikariCP的监控器就算是注册进去了，所以要想实现自己的监控器拿到上面的指标，要经过如下步骤：</p><ol><li>新建一个类实现IMetricsTracker接口，我们这里将该类记为IMetricsTrackerImpl</li><li>新建一个类实现MetricsTrackerFactory接口，我们这里将该类记为MetricsTrackerFactoryImpl，并且将上面的IMetricsTrackerImpl在其create方法内实例化</li><li>将MetricsTrackerFactoryImpl实例化后调用HikariPool的setMetricsTrackerFactory方法注册到Hikari连接池。</li></ol><p>上面没有提到PoolStats里的属性怎么监控，这里来说下。</p><p>由于create方法是调用一次就没了，create方法只是接收了PoolStats对象的实例，如果不处理，那么随着create调用的结束，这个实例针对监控模块来说就失去持有了，所以这里如果想要拿到PoolStats里的属性，就需要开启一个守护线程，让其持有PoolStats对象实例，并且定时获取其内部属性值，然后push给监控系统，如果是<strong>普罗米修斯等使用pull方式获取监控数据的监控系统</strong>，可以效仿HikariCP原生普罗米修斯监控的实现，自定义一个Collector对象来接收PoolStats实例，这样普罗米修斯就可以定期拉取了，比如HikariCP根据普罗米修斯监控系统自己定义的<code>MetricsTrackerFactory</code>实现（对应<code>PrometheusMetricsTrackerFactory</code>类）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public IMetricsTracker create(String poolName, PoolStats poolStats) &#123;</span><br><span class="line">    getCollector().add(poolName, poolStats); //将接收到的PoolStats对象直接交给Collector，这样普罗米修斯服务端每触发一次采集接口的调用，PoolStats都会跟着执行一遍内部属性获取流程</span><br><span class="line">    return new PrometheusMetricsTracker(poolName, this.collectorRegistry); //返回IMetricsTracker接口的实现类</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//自定义的Collector</span><br><span class="line">private HikariCPCollector getCollector() &#123;</span><br><span class="line">    if (collector == null) &#123;</span><br><span class="line">        //注册到普罗米修斯收集中心</span><br><span class="line">        collector = new HikariCPCollector().register(this.collectorRegistry);</span><br><span class="line">    &#125;</span><br><span class="line">    return collector;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上面的解释可以知道在HikariCP中如何自定义一个自己的监控器，以及相比Druid的监控，有什么区别。 </p><h4 id="流程2-2：连接泄漏的检测与告警"><a href="#流程2-2：连接泄漏的检测与告警" class="headerlink" title="流程2.2：连接泄漏的检测与告警"></a>流程2.2：连接泄漏的检测与告警</h4><p>本节对应<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里的<a href="#%E6%B5%81%E7%A8%8B2.2%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B3%84%E6%BC%8F%E7%9A%84%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%91%8A%E8%AD%A6">子流程2.2</a>，在初始化池对象时，初始化了一个叫做<code>leakTaskFactory</code>的属性，本节来看下它具体是用来做什么的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个连接被拿出去使用时间超过leakDetectionThreshold（可配置，默认0）未归还的，会触发一个连接泄漏警告，通知业务方目前存在连接泄漏的问题。</span><br></pre></td></tr></table></figure><p><strong>过程详解</strong>:</p><p>该属性是<code>ProxyLeakTaskFactory</code>类型对象，且它还会持有<code>houseKeepingExecutorService</code>这个线程池对象，用于生产<code>ProxyLeakTask</code>对象，然后利用上面的<code>houseKeepingExecutorService</code>延时运行该对象里的run方法。</p><p>该流程的触发点在上面的<a href="#%E6%B5%81%E7%A8%8B1.1.1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%88%A4%E6%B4%BB">流程1.1</a>最后包装成ProxyConnection对象的那一步，来看看具体的流程图：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_10.png"></p><p>每次在<a href="#%E6%B5%81%E7%A8%8B1.1.1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%88%A4%E6%B4%BB">流程1.1</a>那里生成ProxyConnection对象时，都会触发上面的流程。</p><p>由流程图可以知道，ProxyConnection对象持有PoolEntry和ProxyLeakTask的对象，其中初始化ProxyLeakTask对象时就用到了leakTaskFactory对象，通过其schedule方法可以进行ProxyLeakTask的初始化，并将其实例传递给ProxyConnection进行初始化赋值</p><p><code>ps：由图知ProxyConnection在触发回收事件时，会主动取消这个泄漏检查任务，这也是ProxyConnection需要持有ProxyLeakTask对象的原因</code></p><p>只有在leakDetectionThreshold不等于0的时候才会生成一个带有实际延时任务的ProxyLeakTask对象，否则返回无实际意义的空对象。所以要想启用连接泄漏检查，首先要把leakDetectionThreshold配置设置上，这个属性表示经过该时间后借出去的连接仍未归还，则触发连接泄漏告警。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ProxyConnection之所以要持有ProxyLeakTask对象，是因为它可以监听到连接是否触发归还操作，如果触发，则调用cancel方法取消延时任务，防止误告。</span><br></pre></td></tr></table></figure><p>由此流程可以知道，跟Druid一样，HikariCP也有连接对象泄漏检查，与Druid主动回收连接相比，HikariCP实现更加简单，仅仅是在触发时打印警告日志，不会采取具体的强制回收的措施。</p><p>与Druid一样，默认也是关闭这个流程的，因为实际开发中一般使用第三方框架，框架本身会保证及时的close连接，防止连接对象泄漏，开启与否还是取决于业务是否需要，如果一定要开启，如何设置leakDetectionThreshold的大小也是需要考虑的一件事。</p><h3 id="主流程3：生成连接对象"><a href="#主流程3：生成连接对象" class="headerlink" title="主流程3：生成连接对象"></a>主流程3：生成连接对象</h3><p>本节来讲下<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里的<code>createEntry</code>方法，这个方法利用PoolBase里的DriverDataSource对象生成一个实际的连接对象（如果忘记DriverDatasource是哪里初始化的了，可以看下主流程2里PoolBase的initializeDataSource方法的作用），然后用PoolEntry类包装成PoolEntry对象：</p><details><summary>现在来看下这个包装类有哪些主要属性</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PoolEntry</span> <span class="keyword">implements</span> <span class="title">IConcurrentBagEntry</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(PoolEntry.class);</span><br><span class="line">    <span class="comment">//通过cas来修改state属性</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> AtomicIntegerFieldUpdater stateUpdater;</span><br><span class="line"></span><br><span class="line">    Connection connection; <span class="comment">//实际的物理连接对象</span></span><br><span class="line">    <span class="keyword">long</span> lastAccessed; <span class="comment">//触发回收时刷新该时间，表示“最近一次使用时间”</span></span><br><span class="line">    <span class="keyword">long</span> lastBorrowed; <span class="comment">//getConnection里borrow成功后刷新该时间，表示“最近一次借出的时间”</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;FieldCanBeLocal&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state = <span class="number">0</span>; <span class="comment">//连接状态，枚举值：IN_USE（使用中）、NOT_IN_USE（闲置中）、REMOVED（已移除）、RESERVED（标记为保留中）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> evict; <span class="comment">//是否被标记为废弃，很多地方用到（比如流程1.1靠这个判断连接是否已被废弃，再比如主流程4里时钟回拨时触发的直接废弃逻辑）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> ScheduledFuture&lt;?&gt; endOfLife; <span class="comment">//用于在超过连接生命周期（maxLifeTime）时废弃连接的延时任务，这里poolEntry要持有该对象，主要是因为在对象主动被关闭时（意味着不需要在超过maxLifeTime时主动失效了），需要cancel掉该任务</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> FastList openStatements; <span class="comment">//当前该连接对象上生成的所有的statement对象，用于在回收连接时主动关闭这些对象，防止存在漏关的statement</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> HikariPool hikariPool; <span class="comment">//持有pool对象</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isReadOnly; <span class="comment">//是否为只读</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isAutoCommit; <span class="comment">//是否存在事务</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面就是整个<code>PoolEntry</code>对象里所有的属性，这里再说下<em><strong>endOfLife</strong></em>对象。</p><p>它是一个利用houseKeepingExecutorService这个线程池对象做的延时任务，这个延时任务一般在创建好连接对象后maxLifeTime左右的时间触发</p><details><summary>具体来看下createEntry代码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">private PoolEntry createPoolEntry() &#123;</span><br><span class="line"></span><br><span class="line">        final PoolEntry poolEntry = newPoolEntry(); //生成实际的连接对象</span><br><span class="line"></span><br><span class="line">        final long maxLifetime = config.getMaxLifetime(); //拿到配置好的maxLifetime</span><br><span class="line">        if (maxLifetime &gt; 0) &#123; //&lt;=0的时候不启用主动过期策略</span><br><span class="line">            // 计算需要减去的随机数</span><br><span class="line">            // 源注释：variance up to 2.5% of the maxlifetime</span><br><span class="line">            final long variance = maxLifetime &gt; 10_000 ? ThreadLocalRandom.current().nextLong(maxLifetime / 40) : 0;</span><br><span class="line">            final long lifetime = maxLifetime - variance; //生成实际的延时时间</span><br><span class="line">            poolEntry.setFutureEol(houseKeepingExecutorService.schedule(</span><br><span class="line">                    () -&gt; &#123; //实际的延时任务，这里直接触发softEvictConnection，而softEvictConnection内则会标记该连接对象为废弃状态，然后尝试修改其状态为STATE_RESERVED，若成功，则触发closeConnection（对应流程1.1.2）</span><br><span class="line">                        if (softEvictConnection(poolEntry, &quot;(connection has passed maxLifetime)&quot;, false /* not owner */)) &#123;</span><br><span class="line">                            addBagItem(connectionBag.getWaitingThreadCount()); //回收完毕后，连接池内少了一个连接，就会尝试新增一个连接对象</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    lifetime, MILLISECONDS)); //给endOfLife赋值，并且提交延时任务，lifetime后触发</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return poolEntry;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //触发新增连接任务</span><br><span class="line">    public void addBagItem(final int waiting) &#123;</span><br><span class="line">        //前排提示：addConnectionQueue和addConnectionExecutor的关系和初始化参考主流程2</span><br><span class="line"></span><br><span class="line">        //当添加连接的队列里已提交的任务超过那些因为获取不到连接而发生阻塞的线程个数时，就进行提交连接新增连接的任务</span><br><span class="line">        final boolean shouldAdd = waiting - addConnectionQueue.size() &gt;= 0; // Yes, &gt;= is intentional.</span><br><span class="line">        if (shouldAdd) &#123;</span><br><span class="line">            //提交任务给addConnectionExecutor这个线程池，PoolEntryCreator是一个实现了Callable接口的类，下面将通过流程图的方式介绍该类的call方法</span><br><span class="line">            addConnectionExecutor.submit(poolEntryCreator);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></details></details><p>可以知道，HikariCP一般通过createEntry方法来新增一个连接入池，每个连接被包装成PoolEntry对象，在创建好对象时，同时会提交一个延时任务来关闭废弃该连接，这个时间就是我们配置的maxLifeTime，为了保证不在同一时间失效，HikariCP还会利用maxLifeTime减去一个随机数作为最终的延时任务延迟时间，然后在触发废弃任务时，还会触发addBagItem，进行连接添加任务（因为废弃了一个连接，需要往池子里补充一个），该任务则交给由<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里定义好的addConnectionExecutor线程池执行，那么，现在来看下这个异步添加连接对象的任务流程：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_11.png"></p><p>这个流程就是往连接池里加连接用的，跟<code>createEntry</code>结合起来说是因为这俩流程是紧密相关的，除此之外，<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B5%EF%BC%9A%E6%89%A9%E5%85%85%E8%BF%9E%E6%8E%A5%E6%B1%A0">主流程5：扩充连接池</a>也会触发该任务。</p><h3 id="主流程4：连接池缩容"><a href="#主流程4：连接池缩容" class="headerlink" title="主流程4：连接池缩容"></a>主流程4：连接池缩容</h3><p>HikariCP会按照 <strong>minIdle</strong> 定时清理闲置过久的连接，这个定时任务在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2：初始化池对象</a>时被启用，跟上面的流程一样，也是利用 <strong>houseKeepingExecutorService</strong> 这个线程池对象做该定时任务的执行器。</p><details><summary>来看下主流程2里是怎么启用该任务的</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//housekeepingPeriodMs的默认值是30s，所以定时任务的间隔为30s</span><br><span class="line">this.houseKeeperTask = houseKeepingExecutorService.scheduleWithFixedDelay(new HouseKeeper(), 100L, housekeepingPeriodMs, MILLISECONDS);</span><br></pre></td></tr></table></figure></details><p>那么本节主要来说下HouseKeeper这个类，该类实现了Runnable接口，回收逻辑主要在其run方法内，来看看run方法的逻辑流程图：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_12.png"></p><p>上面的流程就是HouseKeeper的run方法里具体做的事情，由于系统时间回拨会导致该定时任务回收一些连接时产生误差。<br>因此存在如下判断：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//now就是当前系统时间，previous就是上次触发该任务时的时间，housekeepingPeriodMs就是隔多久触发该任务一次</span><br><span class="line">//也就是说plusMillis(previous, housekeepingPeriodMs)表示当前时间</span><br><span class="line">//如果系统时间没被回拨，那么plusMillis(now, 128)一定是大于当前时间的，如果被系统时间被回拨</span><br><span class="line">//回拨的时间超过128ms，那么下面的判断就成立，否则永远不会成立</span><br><span class="line">if (plusMillis(now, 128) &lt; plusMillis(previous, housekeepingPeriodMs))</span><br></pre></td></tr></table></figure><p>这是hikariCP在解决系统时钟被回拨时做出的一种措施，通过流程图可以看到，它是直接把池子里所有的连接对象取出来挨个儿的标记成废弃，并且尝试把状态值修改为<code>STATE_RESERVED</code>（后面会说明这些状态，这里先不深究）。</p><p>如果系统时钟没有发生改变（绝大多数情况会命中这一块的逻辑），由图知，会把当前池内所有处于<code>闲置状态(STATE_NOT_IN_USE)</code>的连接拿出来，然后计算需要检查的范围，然后循环着修改连接的状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//拿到所有处于闲置状态的连接</span><br><span class="line">final List notInUse = connectionBag.values(STATE_NOT_IN_USE);</span><br><span class="line">//计算出需要被检查闲置时间的数量，简单来说，池内需要保证最小minIdle个连接活着，所以需要计算出超出这个范围的闲置对象进行检查</span><br><span class="line">int toRemove = notInUse.size() - config.getMinIdle();</span><br><span class="line">for (PoolEntry entry : notInUse) &#123;</span><br><span class="line">  //在检查范围内，且闲置时间超出idleTimeout，然后尝试将连接对象状态由STATE_NOT_IN_USE变为STATE_RESERVED成功</span><br><span class="line">  if (toRemove &gt; 0 &amp;&amp; elapsedMillis(entry.lastAccessed, now) &gt; idleTimeout &amp;&amp; connectionBag.reserve(entry)) &#123;</span><br><span class="line">    closeConnection(entry, &quot;(connection has passed idleTimeout)&quot;); //满足上述条件，进行连接关闭</span><br><span class="line">    toRemove--;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">fillPool(); //因为可能回收了一些连接，所以要再次触发连接池扩充流程检查下是否需要新增连接。</span><br></pre></td></tr></table></figure><p>上面的代码就是流程图里对应的没有回拨系统时间时的流程逻辑。</p><p>该流程在<code>idleTimeout大于0（默认等于0）并且minIdle小于maxPoolSize</code>的时候才会启用，默认是不启用的，若需要启用，可以按照条件来配置。</p><h3 id="主流程5：扩充连接池"><a href="#主流程5：扩充连接池" class="headerlink" title="主流程5：扩充连接池"></a>主流程5：扩充连接池</h3><p>这个流程主要依附<code>HikariPool</code>里的<code>fillPool</code>方法，这个方法已经在上面很多流程里出现过了，它的作用就是<strong>在触发连接废弃、连接池连接不够用时，发起扩充连接数的操作</strong>。</p><details><summary>下面看下源码（为了使代码结构更加清晰，对源码做了细微改动）</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// PoolEntryCreator关于call方法的实现流程在主流程3里已经看过了，但是这里却有俩PoolEntryCreator对象，</span><br><span class="line">// 这是个较细节的地方，用于打日志用，不再说这部分，为了便于理解，只需要知道这俩对象执行的是同一块call方法即可</span><br><span class="line">private final PoolEntryCreator poolEntryCreator = new PoolEntryCreator(null);</span><br><span class="line">private final PoolEntryCreator postFillPoolEntryCreator = new PoolEntryCreator(&quot;After adding &quot;);</span><br><span class="line"></span><br><span class="line">private synchronized void fillPool() &#123;</span><br><span class="line">  // 这个判断就是根据当前池子里相关数据，推算出需要扩充的连接数，</span><br><span class="line">  // 判断方式就是利用最大连接数跟当前连接总数的差值，与最小连接数与当前池内闲置的连接数的差值，取其最小的那一个得到</span><br><span class="line">  int needAdd = Math.min(maxPoolSize - connectionBag.size(),</span><br><span class="line">  minIdle - connectionBag.getCount(STATE_NOT_IN_USE));</span><br><span class="line"></span><br><span class="line">  //减去当前排队的任务，就是最终需要新增的连接数</span><br><span class="line">  final int connectionsToAdd = needAdd - addConnectionQueue.size();</span><br><span class="line">  for (int i = 0; i &lt; connectionsToAdd; i++) &#123;</span><br><span class="line">    //一般循环的最后一次会命中postFillPoolEntryCreator任务，其实就是在最后一次会打印一次日志而已（可以忽略该干扰逻辑）</span><br><span class="line">    addConnectionExecutor.submit((i &lt; connectionsToAdd - 1) ? poolEntryCreator : postFillPoolEntryCreator);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>最终这个新增连接的任务也是交由<code>addConnectionExecutor线程池</code>来处理的，而任务的主题也是<code>PoolEntryCreator</code>，这个流程可以参考<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B3%EF%BC%9A%E7%94%9F%E6%88%90%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1">主流程3：生成连接对象</a>.</p><p>然后needAdd的推算：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Math.min(最大连接数 - 池内当前连接总数, 最小连接数 - 池内闲置的连接数)</span><br></pre></td></tr></table></figure><p>根据这个方式判断，可以保证池内的连接数永远不会超过maxPoolSize，也永远不会低于minIdle。在连接吃紧的时候，可以保证每次触发都以minIdle的数量扩容。</p><p><code>因此如果在maxPoolSize跟minIdle配置的值一样的话，在池内连接吃紧的时候，就不会发生任何扩容了。</code></p><h3 id="主流程6：连接回收"><a href="#主流程6：连接回收" class="headerlink" title="主流程6：连接回收"></a>主流程6：连接回收</h3><p>最开始说过，最终真实的物理连接对象会被包装成PoolEntry对象，存放进ConcurrentBag，然后获取时，PoolEntry对象又会被再次包装成ProxyConnection对象暴露给使用方的，那么触发连接回收，实际上就是触发ProxyConnection里的close方法：</p><details><summary>查看源码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public final void close() throws SQLException &#123;</span><br><span class="line">  // 原注释：Closing statements can cause connection eviction, so this must run before the conditional below</span><br><span class="line">  closeStatements(); //此连接对象在业务方使用过程中产生的所有statement对象，进行统一close，防止漏close的情况</span><br><span class="line">  if (delegate != ClosedConnection.CLOSED_CONNECTION) &#123;</span><br><span class="line">    leakTask.cancel(); //取消连接泄漏检查任务，参考流程2.2</span><br><span class="line">    try &#123;</span><br><span class="line">      if (isCommitStateDirty &amp;&amp; !isAutoCommit) &#123; //在存在执行语句后并且还打开了事务，调用close时需要主动回滚事务</span><br><span class="line">        delegate.rollback(); //回滚</span><br><span class="line">        lastAccess = currentTime(); //刷新&quot;最后一次使用时间&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">      delegate = ClosedConnection.CLOSED_CONNECTION;</span><br><span class="line">      poolEntry.recycle(lastAccess); //触发回收</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>它最终会调用PoolEntry的recycle方法进行回收，除此之外，连接对象的最后一次使用时间也是在这个时候刷新的，该时间是个很重要的属性，可以用来判断一个连接对象的闲置时间.</p><details><summary>来看下PoolEntry的recycle方法</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void recycle(final long lastAccessed) &#123;</span><br><span class="line">  if (connection != null) &#123;</span><br><span class="line">    this.lastAccessed = lastAccessed; //刷新最后使用时间</span><br><span class="line">    hikariPool.recycle(this); //触发HikariPool的回收方法，把自己传过去</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>之前有说过，每个PoolEntry对象都持有HikariPool的对象，方便触发连接池的一些操作，由上述代码可以看到，最终还是会触发HikariPool里的recycle方法：</p><details><summary>再来看下HikariPool的recycle方法</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void recycle(final PoolEntry poolEntry) &#123;</span><br><span class="line">  metricsTracker.recordConnectionUsage(poolEntry); //监控指标相关，忽略</span><br><span class="line">  connectionBag.requite(poolEntry); //最终触发connectionBag的requite方法归还连接，该流程参考ConnectionBag主流程里的requite方法部分</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h3 id="ConcurrentBag主流程"><a href="#ConcurrentBag主流程" class="headerlink" title="ConcurrentBag主流程"></a>ConcurrentBag主流程</h3><p>当前主流数据库连接池实现方式，大都用两个阻塞队列来实现。一个用于保存空闲数据库连接的队列 idle，另一个用于保存忙碌数据库连接的队列 busy；获取连接时将空闲的数据库连接从 idle 队列移动到 busy 队列，而关闭连接时将数据库连接从 busy 移动到 idle。这种方案将并发问题委托给了阻塞队列，实现简单，但是性能并不是很理想。因为 Java SDK 中的阻塞队列是用锁实现的，而高并发场景下锁的争用对性能影响很大。</p><p>HiKariCP 并没有使用 Java SDK 中的阻塞队列，而是自己实现了一个叫做 ConcurrentBag 的并发容器，在连接池（多线程数据交互）的实现上具有比LinkedBlockingQueue和LinkedTransferQueue更优越的性能。</p><p>ConcurrentBag 中的关键属性</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 存放共享元素，用于存储所有的数据库连接</span><br><span class="line">private final CopyOnWriteArrayList&lt;T&gt; sharedList;</span><br><span class="line">// 在 ThreadLocal 缓存线程本地的数据库连接，避免线程争用</span><br><span class="line">private final ThreadLocal&lt;List&lt;Object&gt;&gt; threadList;</span><br><span class="line">// 等待数据库连接的线程数</span><br><span class="line">private final AtomicInteger waiters;</span><br><span class="line">// 接力队列，用来分配数据库连接</span><br><span class="line">private final SynchronousQueue&lt;T&gt; handoffQueue;</span><br></pre></td></tr></table></figure><p>这个类用来存放最终的PoolEntry类型的连接对象，提供了基本的增删查的功能，被HikariPool持有，上面那么多的操作，几乎都是在HikariPool中完成的，HikariPool用来管理实际的连接生产动作和回收动作，实际操作的却是ConcurrentBag类，梳理下上面所有流程的触发点：</p><ul><li>流程1.1：通过HikariPool获取连接时，通过调用<strong>ConcurrentBag.borrow</strong>拿到一个连接对象。</li><li>流程1.1.2：触发关闭连接时，会通过<strong>ConcurrentBag.remove</strong>移除连接对象，由前面的流程可知关闭连接触发点为：连接超过最大生命周期maxLifeTime主动废弃、健康检查不通过主动废弃、连接池缩容。</li><li>主流程2：初始化HikariPool时初始化ConcurrentBag（构造方法），预热时通过createEntry拿到连接对象，调用<strong>ConcurrentBag.add</strong>添加连接到ConcurrentBag。</li><li>主流程3：通过异步添加连接时，通过调用<strong>ConcurrentBag.add</strong>添加连接到ConcurrentBag，由前面的流程可知添加连接触发点为：连接超过最大生命周期maxLifeTime主动废弃连接后、连接池扩容。</li><li>主流程4：连接池缩容任务，通过调用<strong>ConcurrentBag.values</strong>筛选出需要的做操作的连接对象，然后再通过<strong>ConcurrentBag.reserve</strong>完成对连接对象状态的修改，然后会通过流程1.1.2触发关闭和移除连接操作。</li><li>主流程6：通过<strong>ConcurrentBag.requite</strong>归还一个连接。</li></ul><p>通过触发点整理，可以知道该结构里的主要方法，就是上面触发点里整理的部分。</p><details><summary>具体看下该类的基本定义和主要方法</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcurrentBag</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">IConcurrentBagEntry</span>&gt; <span class="keyword">implements</span> <span class="title">AutoCloseable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CopyOnWriteArrayList&lt;T&gt; sharedList; <span class="comment">//最终存放PoolEntry对象的地方，它是一个CopyOnWriteArrayList</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> weakThreadLocals; <span class="comment">//默认false，为true时可以让一个连接对象在下方threadList里的list内处于弱引用状态，防止内存泄漏（参见备注1）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ThreadLocal&lt;List&lt;Object&gt;&gt; threadList; <span class="comment">//线程级的缓存，从sharedList拿到的连接对象，会被缓存进当前线程内，borrow时会先从缓存中拿，从而达到池内无锁实现</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IBagStateListener listener; <span class="comment">//内部接口，HikariPool实现了该接口，主要用于ConcurrentBag主动通知HikariPool触发添加连接对象的异步操作（也就是主流程3里的addConnectionExecutor所触发的流程）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger waiters; <span class="comment">//当前因为获取不到连接而发生阻塞的业务线程数，这个在之前的流程里也出现过，比如主流程3里addBagItem就会根据该指标进行判断是否需要新增连接</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> closed; <span class="comment">//标记当前ConcurrentBag是否已被关闭</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SynchronousQueue&lt;T&gt; handoffQueue; <span class="comment">//这是个即产即销的队列，用于在连接不够用时，及时获取到add方法里新创建的连接对象，详情可以参考下面borrow和add的代码</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//内部接口，PoolEntry类实现了该接口</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IConcurrentBagEntry</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//连接对象的状态，前面的流程很多地方都已经涉及到了，比如主流程4的缩容</span></span><br><span class="line">        <span class="keyword">int</span> STATE_NOT_IN_USE = <span class="number">0</span>; <span class="comment">//闲置</span></span><br><span class="line">        <span class="keyword">int</span> STATE_IN_USE = <span class="number">1</span>; <span class="comment">//使用中</span></span><br><span class="line">        <span class="keyword">int</span> STATE_REMOVED = -<span class="number">1</span>; <span class="comment">//已废弃</span></span><br><span class="line">        <span class="keyword">int</span> STATE_RESERVED = -<span class="number">2</span>; <span class="comment">//标记保留，介于闲置和废弃之间的中间状态，主要由缩容那里触发修改</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">int</span> expectState, <span class="keyword">int</span> newState)</span></span>; <span class="comment">//尝试利用cas修改连接对象的状态值</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setState</span><span class="params">(<span class="keyword">int</span> newState)</span></span>; <span class="comment">//设置状态值</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">int</span> <span class="title">getState</span><span class="params">()</span></span>; <span class="comment">//获取状态值</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//参考上面listener属性的解释</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IBagStateListener</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">addBagItem</span><span class="params">(<span class="keyword">int</span> waiting)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">borrow</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">final</span> TimeUnit timeUnit)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//回收连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requite</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//添加连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//移除连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//根据连接状态值获取当前池子内所有符合条件的连接集合</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List <span class="title">values</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取当前池子内所有的连接</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List <span class="title">values</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//利用cas把传入的连接对象的state从 STATE_NOT_IN_USE 变为 STATE_RESERVED</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">reserve</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取当前池子内符合传入状态值的连接数量</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>ConcurrentBag 实现采用了queue-stealing的机制获取元素：首先尝试从ThreadLocal中获取属于当前线程的元素来避免锁竞争，如果没有可用元素则再次从共享的CopyOnWriteArrayList中获取。此外，ThreadLocal和CopyOnWriteArrayList在ConcurrentBag中都是成员变量，线程间不共享，避免了伪共享(false sharing)的发生。同时因为线程本地存储中的连接是可以被其他线程窃取的，在共享队列中获取空闲连接，所以需要用 CAS 方法防止重复分配。</p><details><summary>ConcurrentBag具体方法详细阅读</summary><h4 id="borrow"><a href="#borrow" class="headerlink" title="borrow"></a>borrow</h4><p>这个方法用来获取一个可用的连接对象，触发点为流程1.1，HikariPool就是利用该方法获取连接的。</p><details><summary>下面来看下该方法做了什么</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">public T borrow(long timeout, final TimeUnit timeUnit) throws InterruptedException &#123;</span><br><span class="line">    // 源注释：Try the thread-local list first</span><br><span class="line">    final List&lt;Object&gt; list = threadList.get(); //首先从当前线程的缓存里拿到之前被缓存进来的连接对象集合</span><br><span class="line">    for (int i = list.size() - 1; i &gt;= 0; i--) &#123;</span><br><span class="line">        final Object entry = list.remove(i); //先移除，回收方法那里会再次add进来</span><br><span class="line">        final T bagEntry = weakThreadLocals ? ((WeakReference&lt;T&gt;) entry).get() : (T) entry; //默认不启用弱引用</span><br><span class="line">        // 获取到对象后，通过cas尝试把其状态从STATE_NOT_IN_USE 变为 STATE_IN_USE，注意，这里如果其他线程也在使用这个连接对象，</span><br><span class="line">        // 并且成功修改属性，那么当前线程的cas会失败，那么就会继续循环尝试获取下一个连接对象</span><br><span class="line">        if (bagEntry != null &amp;&amp; bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">            return bagEntry; //cas设置成功后，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 源注释：Otherwise, scan the shared list ... then poll the handoff queue</span><br><span class="line">    final int waiting = waiters.incrementAndGet(); //如果缓存内找不到一个可用的连接对象，则认为需要“回源”，waiters+1</span><br><span class="line">    try &#123;</span><br><span class="line">        for (T bagEntry : sharedList) &#123;</span><br><span class="line">            //循环sharedList，尝试把连接状态值从STATE_NOT_IN_USE 变为 STATE_IN_USE</span><br><span class="line">            if (bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">                // 源注释：If we may have stolen another waiter&#x27;s connection, request another bag add.</span><br><span class="line">                if (waiting &gt; 1) &#123; //阻塞线程数大于1时，需要触发HikariPool的addBagItem方法来进行添加连接入池，这个方法的实现参考主流程3</span><br><span class="line">                    listener.addBagItem(waiting - 1);</span><br><span class="line">                &#125;</span><br><span class="line">                return bagEntry; //cas设置成功，跟上面的逻辑一样，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //走到这里说明不光线程缓存里的列表竞争不到连接对象，连sharedList里也找不到可用的连接，这时则认为需要通知HikariPool，该触发添加连接操作了</span><br><span class="line">        listener.addBagItem(waiting);</span><br><span class="line"></span><br><span class="line">        timeout = timeUnit.toNanos(timeout); //这时候开始利用timeout控制获取时间</span><br><span class="line">        do &#123;</span><br><span class="line">            final long start = currentTime();</span><br><span class="line">            //尝试从handoffQueue队列里获取最新被加进来的连接对象（一般新入的连接对象除了加进sharedList之外，还会被offer进该队列）</span><br><span class="line">            final T bagEntry = handoffQueue.poll(timeout, NANOSECONDS);</span><br><span class="line">            //如果超出指定时间后仍然没有获取到可用的连接对象，或者获取到对象后通过cas设置成功，这两种情况都不需要重试，直接返回对象</span><br><span class="line">            if (bagEntry == null || bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">                return bagEntry;</span><br><span class="line">            &#125;</span><br><span class="line">            //走到这里说明从队列内获取到了连接对象，但是cas设置失败，说明又该对象又被其他线程率先拿去用了，若时间还够，则再次尝试获取</span><br><span class="line">            timeout -= elapsedNanos(start); //timeout减去消耗的时间，表示下次循环可用时间</span><br><span class="line">        &#125; while (timeout &gt; 10_000); //剩余时间大于10s时才继续进行，一般情况下，这个循环只会走一次，因为timeout很少会配的比10s还大</span><br><span class="line"></span><br><span class="line">        return null; //超时，仍然返回null</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        waiters.decrementAndGet(); //这一步出去后，HikariPool收到borrow的结果，算是走出阻塞，所以waiters-1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>仔细看下注释，该过程大致分成三个主要步骤：</p><ol><li>从线程缓存获取连接</li><li>获取不到再从sharedList里获取</li><li>都获取不到则触发添加连接逻辑，并尝试从队列里获取新生成的连接对象</li></ol><h4 id="add"><a href="#add" class="headerlink" title="add"></a>add</h4><p>这个流程会添加一个连接对象进入bag，通常由<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B3%EF%BC%9A%E7%94%9F%E6%88%90%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1">主流程3：生成连接对象</a>里的addBagItem方法通过addConnectionExecutor异步任务触发添加操作，该方法主流程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public void add(final T bagEntry) &#123;</span><br><span class="line"></span><br><span class="line">    sharedList.add(bagEntry); //直接加到sharedList里去</span><br><span class="line"></span><br><span class="line">    // 源注释：spin until a thread takes it or none are waiting</span><br><span class="line">    // 参考borrow流程，当存在线程等待获取可用连接，并且当前新入的这个连接状态仍然是闲置状态，且队列里无消费者等待获取时，发起一次线程调度</span><br><span class="line">    while (waiters.get() &gt; 0 &amp;&amp; bagEntry.getState() == STATE_NOT_IN_USE &amp;&amp; !handoffQueue.offer(bagEntry)) &#123; //注意这里会offer一个连接对象入队列</span><br><span class="line">        yield();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结合borrow来理解的话，这里在存在等待线程时会添加一个连接对象入队列，可以让borrow里发生等待的地方更容易poll到这个连接对象。</p><h4 id="requite"><a href="#requite" class="headerlink" title="requite"></a>requite</h4><p>这个流程会回收一个连接，该方法的触发点在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B6%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%9B%9E%E6%94%B6">主流程6：连接回收</a></p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public void requite(final T bagEntry) &#123;</span><br><span class="line">    bagEntry.setState(STATE_NOT_IN_USE); //回收意味着使用完毕，更改state为STATE_NOT_IN_USE状态</span><br><span class="line"></span><br><span class="line">    for (int i = 0; waiters.get() &gt; 0; i++) &#123; //如果存在等待线程的话，尝试传给队列，让borrow获取</span><br><span class="line">        if (bagEntry.getState() != STATE_NOT_IN_USE || handoffQueue.offer(bagEntry)) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        else if ((i &amp; 0xff) == 0xff) &#123;</span><br><span class="line">            parkNanos(MICROSECONDS.toNanos(10));</span><br><span class="line">        &#125;</span><br><span class="line">        else &#123;</span><br><span class="line">            yield();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    final List&lt;Object&gt; threadLocalList = threadList.get();</span><br><span class="line">    if (threadLocalList.size() &lt; 50) &#123; //线程内连接集合的缓存最多50个，这里回收连接时会再次加进当前线程的缓存里，方便下次borrow获取</span><br><span class="line">        threadLocalList.add(weakThreadLocals ? new WeakReference&lt;&gt;(bagEntry) : bagEntry); //默认不启用弱引用，若启用的话，则缓存集合里的连接对象没有内存泄露的风险</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h4><p>这个负责从池子里移除一个连接对象，触发点在流程1.1.2。</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public boolean remove(final T bagEntry) &#123;</span><br><span class="line">    // 下面两个cas操作，都是从其他状态变为移除状态，任意一个成功，都不会走到下面的warn log</span><br><span class="line">    if (!bagEntry.compareAndSet(STATE_IN_USE, STATE_REMOVED) &amp;&amp; !bagEntry.compareAndSet(STATE_RESERVED, STATE_REMOVED) &amp;&amp; !closed) &#123;</span><br><span class="line">        LOGGER.warn(&quot;Attempt to remove an object from the bag that was not borrowed or reserved: &#123;&#125;&quot;, bagEntry);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 直接从sharedList移除掉</span><br><span class="line">    final boolean removed = sharedList.remove(bagEntry);</span><br><span class="line">    if (!removed &amp;&amp; !closed) &#123;</span><br><span class="line">        LOGGER.warn(&quot;Attempt to remove an object from the bag that does not exist: &#123;&#125;&quot;, bagEntry);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return removed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>移除时仅仅移除了sharedList里的对象，各个线程内缓存的那一份集合里对应的对象并没有被移除，这个时候会不会存在该连接再次从缓存里拿到呢？</p><p>会的，但是不会返回出去，而是直接remove掉了，仔细看borrow的代码发现状态不是闲置状态的时候，取出来时就会remove掉，然后也拿不出去，自然也不会触发回收方法。</p><h4 id="values"><a href="#values" class="headerlink" title="values"></a>values</h4><p>该方法存在重载方法，用于返回当前池子内连接对象的集合，触发点在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B4%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%BC%A9%E5%AE%B9">主流程4：连接池缩容</a>，代码如下：</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public List values(final int state) &#123;</span><br><span class="line">    //过滤出来符合状态值的对象集合逆序后返回出去</span><br><span class="line">    final List list = sharedList.stream().filter(e -&gt; e.getState() == state).collect(Collectors.toList());</span><br><span class="line">    Collections.reverse(list);</span><br><span class="line">    return list;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public List values() &#123;</span><br><span class="line">    //返回全部连接对象（注意下方clone为浅拷贝）</span><br><span class="line">    return (List) sharedList.clone();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="reserve"><a href="#reserve" class="headerlink" title="reserve"></a>reserve</h4><p>该方法单纯将连接对象的状态值由STATE_NOT_IN_USE修改为STATE_RESERVED，触发点仍然是主流程4，缩容时使用：</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public boolean reserve(final T bagEntry)&#123;</span><br><span class="line">   return bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_RESERVED);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="getCount"><a href="#getCount" class="headerlink" title="getCount"></a>getCount</h4><p>该方法用于返回池内符合某个状态值的连接的总数量，触发点为主流程5，扩充连接池时用于获取闲置连接总数。</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public int getCount(final int state)&#123;</span><br><span class="line">   int count = 0;</span><br><span class="line">   for (IConcurrentBagEntry e : sharedList) &#123;</span><br><span class="line">      if (e.getState() == state) &#123;</span><br><span class="line">         count++;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   return count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details></details><h2 id="基于FastList的性能优化"><a href="#基于FastList的性能优化" class="headerlink" title="基于FastList的性能优化"></a>基于FastList的性能优化</h2><p>首先我们来看一下执行数据库操作规范化的操作步骤：</p><ol><li>通过数据源获取一个数据库连接；</li><li>创建 Statement；</li><li>执行 SQL；</li><li>通过 ResultSet 获取 SQL 执行结果；</li><li>释放 ResultSet；</li><li>释放 Statement；</li><li>释放数据库连接。</li></ol><p>当前所有数据库连接池都是严格地根据这个顺序来进行数据库操作的，为了防止最后的释放操作，各类数据库连接池都会把创建的 Statement 保存在数组 ArrayList 里，来保证当关闭连接的时候，可以依次将数组中的所有 Statement 关闭。</p><p>HiKariCP 在处理这一步骤中，认为 ArrayList 的某些方法操作存在优化空间，因此对List接口的精简实现，针对List接口中核心的几个方法进行优化，其他部分与ArrayList基本一致。</p><ul><li>首先是get()方法<ul><li>ArrayList每次调用get()方法时都会进行rangeCheck检查索引是否越界，FastList的实现中去除了这一检查，是因为数据库连接池满足索引的合法性，能保证不会越界，此时rangeCheck就属于无效的计算开销，所以不用每次都进行越界检查。省去频繁的无效操作，可以明显地减少性能消耗。</li></ul></li><li>其次是remove方法<ul><li>当通过 conn.createStatement() 创建一个 Statement 时，需要调用 ArrayList 的 add() 方法加入到 ArrayList 中，这个是没有问题的；但是当通过 stmt.close() 关闭 Statement 的时候，需要调用 ArrayList 的 remove() 方法来将其从 ArrayList 中删除，而ArrayList的remove(Object)方法是从头开始遍历数组，而FastList是从数组的尾部开始遍历，因此更为高效。</li><li>相比于ArrayList的 remove()代码， FastList 去除了检查范围 和 从头到尾遍历检查元素的步骤，其性能更快。</li></ul></li></ul><p>总体而言，FastList 的优化点还是很简单的。相比ArrayList仅仅是去掉了rage检查，扩容优化等细节处，删除时数组从后往前遍历查找元素等微小的调整，从而追求性能极致。</p><p>当然FastList 对于 ArrayList 的优化，我们不能说ArrayList不好。所谓定位不同、追求不同，ArrayList作为通用容器，更追求安全、稳定，操作前rangeCheck检查，对非法请求直接抛出异常，更符合 fail-fast(快速失败)机制，而FastList追求的是性能极致。</p><h2 id="通过字节码修改类库Javassist完成字节码精简"><a href="#通过字节码修改类库Javassist完成字节码精简" class="headerlink" title="通过字节码修改类库Javassist完成字节码精简"></a>通过字节码修改类库Javassist完成字节码精简</h2><p>待补充，具体实现参考文章<a href="https://mp.weixin.qq.com/s?__biz=MzUzNTY4NTYxMA==&mid=2247483812&idx=1&sn=0fa3e648f853b840ed8a1c2f19468d6d&chksm=fa80f121cdf778379c70219665ef9c36d66dd0d6c6547add55a8fd920d523c6738835af308f7&scene=21#wechat_redirect">HikariCP源码分析之字节码修改类库Javassist委托实现动态代理</a></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring生态 </tag>
            
            <tag> 池化设计 </tag>
            
            <tag> 数据库连接池 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式协调组件之Zookeeper基础概念入门</title>
      <link href="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"/>
      <url>/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式协调组件"><a href="#什么是分布式协调组件" class="headerlink" title="什么是分布式协调组件"></a>什么是分布式协调组件</h2><p>讲Zookeeper之前，首先我们了解下什么是”分布式协调组件“。</p><p>所谓的“分布式协调组件”，就是我们在分布式应用开发中，为了协调分布式系统中各个机器协同运行而使用到的“公共组件”。比如Zookeeper、Redis等，都可以看作是“分布式协调组件”。</p><p>这里很容易可以看到，分布式环境中的“分布式协调组件”，和单机环境中的“多线程协调组件”（比如Java多线程并发工具包），其实是类似的东西。</p><p>不同的是: </p><ul><li>多线程协调组件是在同一台机器的内存中；而分布式协调组件的调用则是需要通过网络通信的，“网络不可达”的不确定性，就加大了使用分布式协调组件的使用难度</li><li>可用性：多线程协调组件是单机应用中的一部分，完全不需要担心某个并发变量会“挂掉”；而分布式协调组件一般是独立运行的，如何保障分布式协调组件的高可用，是一个很复杂的命题。比如一般会通过集群保障高可用，而集群里的机器之间如何保障数据一致性，则又是一个更加复杂的命题</li><li>分布式协调组件还需要考虑性能问题、可扩展性等</li></ul><h3 id="常用的分布式协调组件"><a href="#常用的分布式协调组件" class="headerlink" title="常用的分布式协调组件"></a>常用的分布式协调组件</h3><p><strong>全局功能数据存储/有功能的组件</strong>：</p><ul><li>K-V类：redis、memcache</li><li>Zookeeper</li><li>消息队列</li><li>配置中心：Spring Cloud Config等</li></ul><p><strong>持久数据存储</strong>：</p><ul><li>MySQL</li><li>MongoDB</li></ul><h3 id="分布式协调组件应用场景"><a href="#分布式协调组件应用场景" class="headerlink" title="分布式协调组件应用场景"></a>分布式协调组件应用场景</h3><ul><li>分布式session</li><li>分布式计数器</li><li>分布式锁</li><li>分布式队列：<ul><li>先入先出队列</li><li>要等所有队列元素聚集之后才能统一安排执行的Barrier模型队列</li></ul></li><li>分布式配置</li><li>分布式协调 / 通知</li><li>数据发布、订阅</li><li>软负载均衡：域名 -&gt; IP和端口号配置</li><li>命名服务：在分布式环境中，上层应用需要一个全局唯一的名字，类似于数据库中的主键</li><li>集群管理：<ul><li>集群监控（进群运行时状态收集）</li><li>集群控制（对集群进行操作和控制）</li></ul></li><li>Master选举</li></ul><h2 id="分布式协调组件Zookeeper概览"><a href="#分布式协调组件Zookeeper概览" class="headerlink" title="分布式协调组件Zookeeper概览"></a>分布式协调组件Zookeeper概览</h2><h3 id="ZooKeeper-实现了什么"><a href="#ZooKeeper-实现了什么" class="headerlink" title="ZooKeeper 实现了什么"></a>ZooKeeper 实现了什么</h3><p>ZooKeeper 是一个开源的分布式协调服务，它的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。</p><p><strong>原语</strong>： 操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。具有不可分割性·即原语的执行必须是连续的，在执行过程中不允许被中断。</p><p>ZooKeeper为我们提供了高可用、高性能、稳定的分布式数据一致性解决方案，通常被用于实现诸如<strong>数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列</strong>等功能。</p><p>另外，ZooKeeper 将<strong>数据保存在内存</strong>中，性能是非常棒的。</p><ul><li>在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。</li></ul><p><code>“读”多于“写”是协调服务的典型场景</code></p><h3 id="ZooKeeper-特点"><a href="#ZooKeeper-特点" class="headerlink" title="ZooKeeper 特点"></a>ZooKeeper 特点</h3><ul><li><p><strong>顺序一致性</strong>： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。</p></li><li><p><strong>原子性</strong>： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。</p></li><li><p><strong>单一系统映像</strong>： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。</p></li><li><p><strong>可靠性</strong>： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。</p></li></ul><h3 id="ZooKeeper-典型应用场景"><a href="#ZooKeeper-典型应用场景" class="headerlink" title="ZooKeeper 典型应用场景"></a>ZooKeeper 典型应用场景</h3><ul><li><p><strong>分布式锁</strong>： 通过创建唯一节点获得分布式锁，当获得锁的一方执行完相关代码或者是挂掉之后就释放锁。</p></li><li><p><strong>命名服务</strong>： 可以通过 ZooKeeper 的顺序节点生成全局唯一 ID</p></li><li><p><strong>数据发布/订阅</strong>：通过 Watcher 机制可以很方便地实现数据发布/订阅。当你将数据发布到 ZooKeeper 被监听的节点上，其他机器可通过监听 ZooKeeper 上节点的变化来实现配置的动态更新。</p></li></ul><h2 id="Zookeeper重要概念"><a href="#Zookeeper重要概念" class="headerlink" title="Zookeeper重要概念"></a>Zookeeper重要概念</h2><h3 id="Data-model（数据模型）"><a href="#Data-model（数据模型）" class="headerlink" title="Data model（数据模型）"></a>Data model（数据模型）</h3><p>ZooKeeper 数据模型采用层次化的多叉树形结构，每个节点上都可以存储数据，这些数据可以是数字、字符串或者是二级制序列。并且。每个节点还可以拥有 N 个子节点，最上层是根节点以“/”来代表。每个数据节点在 ZooKeeper 中被称为 znode，它是 ZooKeeper 中数据的最小单元。并且，每个 znode 都一个唯一的路径标识。</p><p>强调一句：ZooKeeper 主要是用来协调服务的，而不是用来存储业务数据的，所以<strong>不要放比较大的数据在znode上</strong>，ZooKeeper 给出的上限是每个结点的数据大小最大是 1M。</p><p>ZooKeeper 节点路径标识方式和 Unix 文件系统路径非常相似，都是由一系列使用斜杠”/“进行分割的路径表示，开发员可以向这个节点中写人数据，也可以在节点下面创建子节点。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/b26842dad2872eb0498fdf2bb1471cee.jpeg#pic_center"></p><h3 id="znode（数据节点）"><a href="#znode（数据节点）" class="headerlink" title="znode（数据节点）"></a>znode（数据节点）</h3><h4 id="znode节点分类"><a href="#znode节点分类" class="headerlink" title="znode节点分类"></a>znode节点分类</h4><ul><li><p>持久（PERSISTENT）节点： 一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。</p></li><li><p>临时（EPHEMERAL）节点： 临时节点的生命周期是与客户端会话（session）绑定的，会话消失则节点消失。并且，临时节点只能做叶子节点，不能创建子节点。</p></li><li><p>持久顺序（PERSISTENT_SEQUENTIAL）节点：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如/node1/app0000000001 、/node1/app0000000002 。</p></li><li><p>临时顺序（EPHEMERAL_SEQUENTIAL）节点：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。</p></li></ul><h4 id="znode-数据结构"><a href="#znode-数据结构" class="headerlink" title="znode 数据结构"></a>znode 数据结构</h4><p>每个 znode 由 2 部分组成:</p><ul><li>stat ：状态信息</li><li>data ： 节点存放的数据的具体内容</li></ul><p>Stat 类中包含了一个数据节点的所有状态信息的字段，包括事务 ID-cZxid、节点创建时间-ctime 和子节点个数-numChildren 等等，详细信息参考下表。</p><table><thead><tr><th>znode 状态信息</th><th>解释</th></tr></thead><tbody><tr><td>cZxid</td><td>create ZXID，即该数据节点被创建时的事务 id</td></tr><tr><td>ctime</td><td>create time，即该节点的创建时间</td></tr><tr><td>mZxid</td><td>modified ZXID，即该节点最终一次更新时的事务 id</td></tr><tr><td>mtime</td><td>modified time，即该节点最后一次的更新时间</td></tr><tr><td>pZxid</td><td>该节点的子节点列表最后一次修改时的事务 id，只有子节点列表变更才会更新 pZxid，子节点内容变更不会更新</td></tr><tr><td>cversion</td><td>子节点版本号，当前节点的子节点每次变化时值增加 1</td></tr><tr><td>dataVersion</td><td>数据节点内容版本号，节点创建时为 0，每更新一次节点内容(不管内容有无变化)该版本号的值增加 1</td></tr><tr><td>aclVersion</td><td>节点的 ACL 版本号，表示该节点 ACL 信息变更次数</td></tr><tr><td>ephemeralOwner</td><td>创建该临时节点的会话的 sessionId；如果当前节点为持久节点，则 ephemeralOwner=0</td></tr><tr><td>dataLength</td><td>数据节点内容长度</td></tr><tr><td>numChildren</td><td>当前节点的子节点个数</td></tr></tbody></table><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>前面我们已经提到，对应于每个 znode，ZooKeeper 都会为其维护一个叫作 <strong>Stat</strong>的数据结构，Stat 中记录了这个 znode 的三个相关的版本：</p><ul><li><p>  <strong>dataVersion</strong> ：当前 znode 节点的版本号</p></li><li><p>  <strong>cversion</strong> ： 当前 znode 子节点的版本</p></li><li><p>  <strong>aclVersion</strong> ： 当前 znode 的 ACL 的版本。</p></li></ul><h3 id="ACL（权限控制）"><a href="#ACL（权限控制）" class="headerlink" title="ACL（权限控制）"></a><strong>ACL（权限控制）</strong></h3><p>ZooKeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。</p><p>对于 znode 操作的权限，ZooKeeper 提供了以下 5 种：</p><ul><li><p>  <strong>CREATE</strong> : 能创建子节点</p></li><li><p>  <strong>READ</strong> ：能获取节点数据和列出其子节点</p></li><li><p>  <strong>WRITE</strong> : 能设置/更新节点数据</p></li><li><p>  <strong>DELETE</strong> : 能删除子节点</p></li><li><p>  <strong>ADMIN</strong> : 能设置节点 ACL 的权限</p></li></ul><p>其中尤其需要注意的是，<strong>CREATE</strong>和<strong>DELETE</strong>这两种权限都是针对<strong>子节点</strong>的权限控制。</p><p>对于身份认证，提供了以下几种方式：</p><ul><li><p>  <strong>world</strong> ： 默认方式，所有用户都可无条件访问。</p></li><li><p>  <strong>auth</strong>: 不使用任何 id，代表任何已认证的用户。</p></li><li><p>  <strong>digest</strong>: 用户名:密码认证方式： <em>username:password</em> 。</p></li><li><p>  <strong>ip</strong>: 对指定 ip 进行限制。</p></li></ul><h3 id="Watcher"><a href="#Watcher" class="headerlink" title="Watcher"></a><strong>Watcher</strong></h3><p>Watcher（事件监听器），是 ZooKeeper 中的一个很重要的特性。ZooKeeper允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper实现分布式协调服务的重要特性。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/be40875cd45d92900b44c4d39dedcb57.jpeg"></p><p><em>用到 ZooKeeper 基本离不开 Watcher（事件监听器）机制。</em></p><h3 id="会话（Session）"><a href="#会话（Session）" class="headerlink" title="会话（Session）"></a><strong>会话（Session）</strong></h3><p>Session 可以看作是 ZooKeeper 服务器与客户端的之间的一个 TCP 长连接，通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的 Watcher 事件通知。</p><p>Session 有一个属性叫做：sessionTimeout ，sessionTimeout代表会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。</p><p>另外，在为客户端创建会话之前，服务端首先会为每个客户端都分配一个 sessionID。由于 sessionID是 ZooKeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。</p><h2 id="ZooKeeper-集群"><a href="#ZooKeeper-集群" class="headerlink" title="ZooKeeper 集群"></a>ZooKeeper 集群</h2><p>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的，通常 3 台服务器就可以构成一个 ZooKeeper 集群了。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/8de274eb6351bdf85a64e4ce1a4b9f65.png"></p><p>上图中每一个 Server 代表一个安装 ZooKeeper 服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 ZAB 协议（ZooKeeper Atomic Broadcast）来保持数据的一致性。</p><p><strong>最典型集群模式： Master/Slave 模式（主备模式）</strong>。</p><p>在这种模式中，通常 Master 服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。</p><h3 id="ZooKeeper-集群角色"><a href="#ZooKeeper-集群角色" class="headerlink" title="ZooKeeper 集群角色"></a>ZooKeeper 集群角色</h3><table><thead><tr><th><strong>角色</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>Leader</td><td>为客户端提供读和写的服务，负责投票的发起和决议，更新系统状态。</td></tr><tr><td>Follower</td><td>为客户端提供读服务，如果是写服务则转发给 Leader。在选举过程中参与投票。</td></tr><tr><td>Observer</td><td>为客户端提供读服务器，如果是写服务则转发给 Leader。不参与选举过程中的投票，也不参与“过半写成功”策略。在不影响写性能的情况下提升集群的读性能。此角色于 ZooKeeper3.3 系列新增的角色。</td></tr></tbody></table><h3 id="Zookeeper-Leader选举"><a href="#Zookeeper-Leader选举" class="headerlink" title="Zookeeper Leader选举"></a>Zookeeper Leader选举</h3><p>当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，就会进入 Leader 选举过程，这个过程会选举产生新的 Leader 服务器。</p><p>这个过程大致是这样的：</p><ol><li><p> <strong>Leader election（选举阶段）</strong>: 节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。</p></li><li><p> <strong>Discovery（发现阶段）</strong>: 在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。</p></li><li><p> <strong>Synchronization（同步阶段）</strong>: 同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。</p></li><li><p> <strong>Broadcast（广播阶段）</strong>: 到了这个阶段，ZooKeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。</p></li></ol><h3 id="ZooKeeper-集群中的服务器状态"><a href="#ZooKeeper-集群中的服务器状态" class="headerlink" title="ZooKeeper 集群中的服务器状态"></a><strong>ZooKeeper 集群中的服务器状态</strong></h3><ul><li><p>  <strong>LOOKING</strong>: 寻找 Leader。</p></li><li><p>  <strong>LEADING</strong>: Leader 状态，对应的节点为 Leader。</p></li><li><p>  <strong>FOLLOWING</strong>: Follower 状态，对应的节点为 Follower。</p></li><li><p>  <strong>OBSERVING</strong>: Observer 状态，对应节点为 Observer，该节点不参与 Leader 选举。</p></li></ul><h3 id="ZooKeeper-集群为啥最好奇数台"><a href="#ZooKeeper-集群为啥最好奇数台" class="headerlink" title="ZooKeeper 集群为啥最好奇数台"></a><strong>ZooKeeper 集群为啥最好奇数台</strong></h3><p>ZooKeeper 集群在宕掉几个 ZooKeeper 服务器之后，如果剩下的 ZooKeeper 服务器个数大于宕掉的个数的话整个 ZooKeeper 才依然可用。假如我们的集群中有 n 台 ZooKeeper 服务器，那么也就是剩下的服务数必须大于 n/2。先说一下结论，2n 和 2n-1 的容忍度是一样的，都是n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。 比如假如我们有 3 台，那么最大允许宕掉 1 台 ZooKeeper 服务器，如果我们有 4 台的的时候也同样只允许宕掉 1 台。 假如我们有 5 台，那么最大允许宕掉 2 台ZooKeeper 服务器，如果我们有 6 台的的时候也同样只允许宕掉 2 台。</p><h2 id="ZAB-协议和Paxos-算法"><a href="#ZAB-协议和Paxos-算法" class="headerlink" title="ZAB 协议和Paxos 算法"></a>ZAB 协议和Paxos 算法</h2><p>Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像Paxos算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。</p><h3 id="ZAB-协议介绍"><a href="#ZAB-协议介绍" class="headerlink" title="ZAB 协议介绍"></a><strong>ZAB 协议介绍</strong></h3><p>ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。</p><p><strong>ZAB 协议两种基本的模式：崩溃恢复和消息广播</strong></p><p>ZAB 协议包括两种基本的模式，分别是</p><ul><li><p><strong>崩溃恢复</strong>：当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。<br>  其中，<strong>所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致</strong>。</p></li><li><p><strong>消息广播</strong>：<strong>当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。</strong><br>  当一台同样遵守ZAB协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。</p></li></ul><p>具体ZAB协议介绍可参考 <a href="https://dbaplus.cn/news-141-1875-1.html">实例详解ZooKeeper ZAB协议、分布式锁与领导选举</a></p><h2 id="Zookeeper总结"><a href="#Zookeeper总结" class="headerlink" title="Zookeeper总结"></a>Zookeeper总结</h2><ol><li><p>ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。</p></li><li><p>为了保证高可用，最好是以集群形态来部署ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么ZooKeeper 本身仍然是可用的。</p></li><li><p>ZooKeeper 将数据保存在内存中，这也就保证了高吞吐量和低延迟</p></li></ol><ul><li>但是内存限制了能够存储的容量不太大，此限制也是保持 znode 中存储的数据量较小的进一步原因。</li></ul><ol start="4"><li><p>ZooKeeper 是高性能的。<br>在“读”多于“写”的应用程序中尤其地明显，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</p></li><li><p>ZooKeeper 有临时节点的概念。  </p></li></ol><ul><li>当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。  </li><li>持久节点是指一旦这个 znode 被创建了，除非主动进行 znode 的移除操作，否则这个 znode 将一直保存在 ZooKeeper 上。</li></ul><ol start="6"><li>ZooKeeper 底层其实只提供了两个功能：</li></ol><ul><li>管理（存储、读取）用户程序提交的数据；</li><li>为用户程序提供数据节点监听服务。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ZOOKEEPER </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统00之如何设计一个高并发系统</title>
      <link href="/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/"/>
      <url>/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p>为啥会有高并发？为啥高并发就很牛逼？</p><p>很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。<br>所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。</p><p>设计一个高并发系统可以简单分为以下 6 点：</p><ul><li>系统拆分</li><li>缓存</li><li>MQ</li><li>分库分表</li><li>读写分离</li><li>ElasticSearch</li></ul><p><img src="/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/img_1.png"></p><h3 id="系统拆分"><a href="#系统拆分" class="headerlink" title="系统拆分"></a>系统拆分</h3><p>将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存，必须得用缓存。大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。</p><h3 id="MQ"><a href="#MQ" class="headerlink" title="MQ"></a>MQ</h3><p>MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。</p><h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h3><p>分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 sql 跑的性能。</p><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。</p><h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>Elasticsearch，简称 ES。</p><p>ES 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 设计理念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统03之高并发三大利器之降级</title>
      <link href="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%8D%E7%BA%A7/"/>
      <url>/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%8D%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h3 id="什么是服务降级"><a href="#什么是服务降级" class="headerlink" title="什么是服务降级"></a>什么是服务降级</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。</span><br></pre></td></tr></table></figure><p>服务降级主要用于当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，将一些 不重要 或 不紧急 的服务或任务进行服务的 <strong>延迟使用</strong> 或 <strong>暂停使用</strong>。</p><p>降级就是为了解决资源不足和访问量增加的矛盾。</p><h3 id="服务降级方式"><a href="#服务降级方式" class="headerlink" title="服务降级方式"></a>服务降级方式</h3><ul><li><strong>延迟服务</strong>：定时任务处理、或者mq延时处理。比如新用户注册送多少优惠券可以提示用户优惠券会24小时到达用户账号中，我们可以选择再凌晨流量较小的时候，批量去执行送券</li><li><strong>页面降级</strong>：页面点击按钮全部置灰，或者页面调整成为一个静态页面显示“系统正在维护中，。。。。”。</li><li><strong>关闭非核心服务</strong>：比如电商关闭推荐服务、关闭运费险、退货退款等。保证主流程的核心服务下单付款就好。</li><li><strong>写降级</strong>：比如秒杀抢购，我们可以只进行Cache的更新返回，然后通过mq异步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。</li><li><strong>读降级</strong>：比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景。</li></ul><h3 id="服务熔断"><a href="#服务熔断" class="headerlink" title="服务熔断"></a>服务熔断</h3><h4 id="服务雪崩"><a href="#服务雪崩" class="headerlink" title="服务雪崩"></a>服务雪崩</h4><p>多个微服务之间调用的时候，比如A服务调用了B服务，B服务调用了C服务，然后C服务由于机器宕机或者网略故障， 然后就会导致B服务调用C服务的时候超时，然后A服务调用B服务也会超时，最终整个链路都不可用了，导致整个系统不可用就跟雪蹦一样。</p><h4 id="雪崩效应产生的几种场景"><a href="#雪崩效应产生的几种场景" class="headerlink" title="雪崩效应产生的几种场景"></a>雪崩效应产生的几种场景</h4><p><strong>突增流量</strong>：比如一大波爬虫，或者黑客攻击等。<br><strong>程序bug</strong>：代码死循环，或者资源未释放等。<br><strong>硬件原因</strong>：机器宕机、机房断电、光纤被挖断等。  </p><h4 id="服务熔断-1"><a href="#服务熔断-1" class="headerlink" title="服务熔断"></a>服务熔断</h4><p>熔断机制是应对雪崩效应的一种微服务链路保护机制，在互联网系统中当下游的服务因为某种原因突然变得不可用或响应过慢，上游服务为了保证自己整体服务的可用性，暂时不再继续调用目标服务，直接快速返回，快速释放资源。如果目标服务情况好转则恢复调用。</p><h3 id="熔断和降级的比较"><a href="#熔断和降级的比较" class="headerlink" title="熔断和降级的比较"></a>熔断和降级的比较</h3><h4 id="共性"><a href="#共性" class="headerlink" title="共性"></a>共性</h4><ul><li>目的很一致：都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段，都是为了保证系统的稳定。</li><li>最终表现类似:对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用；</li><li>粒度一般都是服务级别:当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）；</li><li>自治性要求很高: 熔断模式一般都是服务基于策略的自动触发，比如</li><li>降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段；</li></ul><h4 id="差异性"><a href="#差异性" class="headerlink" title="差异性"></a>差异性</h4><ul><li>触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；</li><li>管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）熔断是降级方式的一种体现。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 降级 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统02之高并发三大利器之缓存</title>
      <link href="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/"/>
      <url>/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h2 id="缓存分类"><a href="#缓存分类" class="headerlink" title="缓存分类"></a>缓存分类</h2><ul><li>分布式缓存： 如redis、memcached等</li><li>本地（进程内）缓存： 如ehcache、GuavaCache、Caffeine等</li></ul><h2 id="缓存特性"><a href="#缓存特性" class="headerlink" title="缓存特性"></a>缓存特性</h2><h3 id="命中率"><a href="#命中率" class="headerlink" title="命中率"></a>命中率</h3><p>命中率=命中数/（命中数+没有命中数）当某个请求能够通过访问缓存而得到响应时，称为缓存命中。缓存命中率越高，缓存的利用率也就越高。</p><h3 id="最大空间"><a href="#最大空间" class="headerlink" title="最大空间"></a>最大空间</h3><p>缓存中可以容纳最大元素的数量。当缓存存放的数据超过最大空间时，就需要根据淘汰算法来淘汰部分数据存放新到达的数据。</p><h3 id="淘汰算法"><a href="#淘汰算法" class="headerlink" title="淘汰算法"></a>淘汰算法</h3><p>缓存的存储空间有限制，当缓存空间被用满时，如何保证在稳定服务的同时有效提升命中率？这就由缓存淘汰算法来处理，设计适合自身数据特征的淘汰算法能够有效提升缓存命中率。<br>常见的淘汰算法有：</p><ul><li><p>FIFO(first in first out)「先进先出」<br>最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。「适用于保证高频数据有效性场景，优先保障最新数据可用」。</p></li><li><p>LFU(less frequently used)「最少使用」<br>无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。「适用于保证高频数据有效性场景」。</p></li><li><p>LRU(least recently used)「最近最少使用」<br>无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。「比较适用于热点数据场景，优先保证热点数据的有效性。」</p></li></ul><h2 id="本地缓存"><a href="#本地缓存" class="headerlink" title="本地缓存"></a>本地缓存</h2><p>常见本地缓存有以下几种实现方式：</p><p><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/img.png"></p><p>其中性能最佳的是Caffeine，了解更详细信息参考： <a href="https://mp.weixin.qq.com/s?__biz=MzIyMjQwMTgyNA==&mid=2247483811&idx=1&sn=9d0b207044b5fe447169d630a7f77aab&scene=21#wechat_redirect">本地缓存性能之王</a></p><h2 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h2><p>分布式缓存详细信息参考redis系列文章</p><h2 id="缓存更新方案"><a href="#缓存更新方案" class="headerlink" title="缓存更新方案"></a>缓存更新方案</h2><p>我们一般的缓存更新主要有以下几种更新策略：</p><ul><li>先更新缓存，再更新数据库</li><li>先更新数据库，再更新缓存</li><li>先删除缓存，再更新数据库</li><li>先更新数据源库，再删除缓存</li></ul><p>至于选择哪种更新策略的话，没有绝对的选择，可以根据自己的业务情况来选择适合自己的。<br>不过一般推荐的话是选择 「<strong>先更新数据源库，再删除缓存</strong>」。</p><h2 id="缓存常见问题"><a href="#缓存常见问题" class="headerlink" title="缓存常见问题"></a>缓存常见问题</h2><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>大量查询数据库不存在数据，缓存无数据，大量无效请求落库。</p><p>解决方案</p><ul><li>数据库不存在数据写空值入缓存</li></ul><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>大规模缓存崩溃，大量请求落库。</p><p>解决方案</p><ul><li>事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。</li><li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li><li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>热点key失效瞬间大量请求落库。</p><p>解决方案</p><ul><li>基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>更新不频繁且更新时间段，加互斥锁保证少量请求重建缓存。</li><li>数据更新频繁或更新时间长，定时线程主动重建缓存。</li></ul><h3 id="缓存双写一致性"><a href="#缓存双写一致性" class="headerlink" title="缓存双写一致性"></a>缓存双写一致性</h3><p>缓存使用方法：<br>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。<br>更新的时候，先更新数据库，然后再删除缓存。</p><p>不一致解决方案</p><ul><li>初级：先删除缓存，再更新数据库。</li><li>高并发：使用队列做轻异步，多个并发更新请求阻塞过滤。（必须压测防止长时间阻塞积压）</li></ul><h3 id="redis并发竞争"><a href="#redis并发竞争" class="headerlink" title="redis并发竞争"></a>redis并发竞争</h3><p>多客户端同时并发写key，后来的数据先改。</p><p>解决方案：</p><ul><li>Redis存在CAS方案</li><li>实现分布式锁</li><li>写前判断版本号</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统01之高并发三大利器之限流</title>
      <link href="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/"/>
      <url>/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/</url>
      
        <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h2 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h2><h3 id="快速失败-–-滑动时间窗口"><a href="#快速失败-–-滑动时间窗口" class="headerlink" title="快速失败 – 滑动时间窗口"></a>快速失败 – 滑动时间窗口</h3><p>滑动窗口算法是将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期<br><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/%E6%BB%91%E5%8A%A8%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3.png"></p><h3 id="排队等待-漏桶算法"><a href="#排队等待-漏桶算法" class="headerlink" title="排队等待 - 漏桶算法"></a>排队等待 - 漏桶算法</h3><p>漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。<br><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/%E6%BC%8F%E6%A1%B6%E7%AE%97%E6%B3%95.png"></p><p>首先，我们有一个固定容量的桶，有水流进来，也有水流出去。对于流进来的水来说，我们无法预计一共有多少水会流进来，也无法预计水流的速度。但是对于流出去的水来说，这个桶可以固定水流出的速率。而且，当桶满了之后，多余的水将会溢出。</p><p>我们将算法中的水换成实际应用中的请求，我们可以看到漏桶算法天生就限制了请求的速度。当使用了漏桶算法，我们可以保证接口会以一个常速速率来处理请求。所以漏桶算法天生不会出现临界问题。<br>漏桶算法可以粗略的认为就是注水漏水过程，往桶中<strong>以一定速率流出水，以任意速率流入水</strong>，当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。</p><h3 id="Warm-Up-令牌桶算法"><a href="#Warm-Up-令牌桶算法" class="headerlink" title="Warm Up - 令牌桶算法"></a>Warm Up - 令牌桶算法</h3><p>首先，我们有一个固定容量的桶，桶里存放着令牌（token）。<br>桶一开始是空的，token以 一个固定的速率r往桶里填充，直到达到桶的容量，多余的令牌将会被丢弃。<br>每当一个请求过来时，就会尝试从桶里移除一个令牌，如果没有令牌的话，请求无法通过。</p><p><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/aegar-6o1hz.png"></p><h4 id="解决问题："><a href="#解决问题：" class="headerlink" title="解决问题："></a>解决问题：</h4><ul><li>Warm Up（冷启动/预热）：通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。</li></ul><h3 id="各算法适用场景"><a href="#各算法适用场景" class="headerlink" title="各算法适用场景"></a>各算法适用场景</h3><ul><li>计数法用于简单粗暴的连接池数量等。</li><li>令牌桶可以用来保护自己，主要用来对调用者频率进行限流，为的是让自己不被打垮。所以如果自己本身有处理能力的时候，如果流量突发（实际消费能力强于配置的流量限制），那么实际处理速率可以超过配置的限制。</li><li>漏桶算法，这是用来保护他人，也就是保护他所调用的系统。主要场景是，当调用的第三方系统本身没有保护机制，或者有流量限制的时候，我们的调用速度不能超过他的限制，由于我们不能更改第三方系统，所以只有在主调方控制。这个时候，即使流量突发，也必须舍弃。因为消费能力是第三方决定的。</li></ul><p>** 简单粗暴场景用计数法。如果要让自己的系统不被打垮，用令牌桶。如果保证别人的系统不被打垮，用漏桶。**</p><h2 id="流量控制组件对比"><a href="#流量控制组件对比" class="headerlink" title="流量控制组件对比"></a>流量控制组件对比</h2><p><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/stickPicture.png"></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.cnblogs.com/xuwc/p/9123078.html">高并发系统限流-漏桶算法和令牌桶算法</a></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 限流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>状态机系列之SpringStatusMachine详解</title>
      <link href="/2020/07/15/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/"/>
      <url>/2020/07/15/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是状态机"><a href="#什么是状态机" class="headerlink" title="什么是状态机"></a>什么是状态机</h2><p>有限状态机是一种用来进行对象行为建模的工具，其作用主要是描述对象在它的生命周期内所经历的状态序列，以及如何响应来自外界的各种事件。</p><p>在电商场景（订单、物流、售后）、社交（IM消息投递）、分布式集群管理（分布式计算平台任务编排）等场景都有大规模的使用。</p><h3 id="状态机的要素"><a href="#状态机的要素" class="headerlink" title="状态机的要素"></a>状态机的要素</h3><ul><li><strong>现态</strong>：指当前所处的状态</li><li><strong>条件</strong>：又称“事件”，当一个条件被满足，将会触发一个动作，或者执行一次状态的迁移</li><li><strong>动作</strong>：条件满足后执行的动作。动作执行完毕后，可以迁移到新的状态，也可以仍旧保持原状态。动作不是必须的，当条件满足后，也可以不执行任何动作，直接迁移到新的状态。<ul><li>进入动作：在进入状态时进行</li><li>退出动作：在退出状态时进行</li><li>输入动作：依赖于当前状态和输入条件进行</li><li>转移动作：在进行特定转移时进行</li></ul></li><li><strong>次态</strong>：条件满足后要迁往的新状态。“次态”是相对于“现态”而言的，“次态”一旦被激活，就转换成“现态”。</li></ul><h3 id="什么时候需要用到状态机"><a href="#什么时候需要用到状态机" class="headerlink" title="什么时候需要用到状态机"></a>什么时候需要用到状态机</h3><p>Spring文档指出，在以下情况下，项目很适合使用状态机：</p><ul><li>您可以将应用程序或其结构的一部分表示为状态。</li><li>您想将复杂的逻辑拆分为更小的可管理任务。</li><li>应用程序已经遇到了（例如）异步发生的并发问题。</li></ul><p>如果满足以下条件，您已经在尝试实现状态机 ：  </p><ul><li>使用布尔标志或枚举对情况进行建模。</li><li>具有仅对应用程序生命周期的一部分有意义的变量。</li><li>遍历if / else结构并检查是否设置了特定的标志或枚举，然后进一步对当标志和枚举的某些组合存在或不存在时的处理方式作进一步的例外。</li></ul><h4 id="使用状态机的优缺点"><a href="#使用状态机的优缺点" class="headerlink" title="使用状态机的优缺点"></a>使用状态机的优缺点</h4><p><strong>优点</strong></p><ul><li>状态及转换与业务解耦；</li><li>代码的可维护性增强；</li><li>对于流程复杂易变的业务场景能大减轻维护和测试的难度。</li></ul><p><strong>缺点</strong></p><ul><li>事务不好控制；</li><li>增加更多的类。<h3 id="状态机对比"><a href="#状态机对比" class="headerlink" title="状态机对比"></a>状态机对比</h3></li></ul><table><thead><tr><th>状态机</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>stateless4j</td><td>轻量级<br>支持基本事件迁移<br>二次开发难度低</td><td>不支持持久化和上下文传参</td></tr><tr><td>squirrel-foundation</td><td>功能齐全<br>StatueMachine精简版</td><td>—</td></tr><tr><td>Spring StatusMachine</td><td>功能齐全<br>&ensp; 状态：初始终止、历史状态、连接交并；<br>&ensp; 延迟事件;<br>&ensp; Guard;<br>&ensp; 持久化;<br>&ensp; JPA<br>使用方便<br>&ensp; 配置+注解，文档齐全</td><td>学习成本较高<br>状态机已捕获异常，需要手动编码处理异常，单个状态机可以被共享，需要builder多个实例<br>同时使用多个状态机事务需要手工控制</td></tr></tbody></table><h3 id="Spring-StatusMachine使用案例"><a href="#Spring-StatusMachine使用案例" class="headerlink" title="Spring StatusMachine使用案例"></a>Spring StatusMachine使用案例</h3><p>假设在一个业务系统中，有这样一个对象，它有三个状态：草稿、待发布、发布完成，针对这三个状态的业务动作也比较简单，分别是：上线、发布、回滚。该业务状态机如下图所示。<br><img src="/2020/07/15/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/img.png"></p><p>创建一个基础的Spring Boot工程，在主pom文件中加入Spring StateMachine的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--加入spring statemachine的依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.statemachine<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-statemachine-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.3.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>定义状态枚举和事件枚举，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 状态枚举</span></span><br><span class="line"><span class="comment">**/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">States</span> </span>&#123;</span><br><span class="line">    DRAFT,</span><br><span class="line">    PUBLISH_TODO,</span><br><span class="line">    PUBLISH_DONE,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 事件枚举</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Events</span> </span>&#123;</span><br><span class="line">  ONLINE,</span><br><span class="line">  PUBLISH,</span><br><span class="line">  ROLLBACK</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成状态机的配置，包括：（1）状态机的初始状态和所有状态；（2）状态之间的转移规则</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="comment">// @EnableStateMachine批注时，它将在应用程序启动时自动创建默认状态机。</span></span><br><span class="line"><span class="meta">@EnableStateMachine</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StateMachineConfig</span> <span class="keyword">extends</span> <span class="title">EnumStateMachineConfigurerAdapter</span>&lt;<span class="title">States</span>, <span class="title">Events</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(StateMachineStateConfigurer&lt;States, Events&gt; states)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        states.withStates().initial(States.DRAFT).states(EnumSet.allOf(States.class));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(StateMachineTransitionConfigurer&lt;States, Events&gt; transitions)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        transitions.withExternal()</span><br><span class="line">            .source(States.DRAFT).target(States.PUBLISH_TODO)</span><br><span class="line">            .event(Events.ONLINE)</span><br><span class="line">            .and()</span><br><span class="line">            .withExternal()</span><br><span class="line">            .source(States.PUBLISH_TODO).target(States.PUBLISH_DONE)</span><br><span class="line">            .event(Events.PUBLISH)</span><br><span class="line">            .and()</span><br><span class="line">            .withExternal()</span><br><span class="line">            .source(States.PUBLISH_DONE).target(States.DRAFT)</span><br><span class="line">            .event(Events.ROLLBACK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个测试业务对象，状态机的状态转移都会反映到该业务对象的状态变更上</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WithStateMachine</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BizBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@see</span> States</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String status = States.DRAFT.name();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;PUBLISH_TODO&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">online</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作上线，待发布. target status:&#123;&#125;&quot;</span>, States.PUBLISH_TODO.name());</span><br><span class="line">        setStatus(States.PUBLISH_TODO.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;PUBLISH_DONE&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">publish</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作发布,发布完成. target status:&#123;&#125;&quot;</span>, States.PUBLISH_DONE.name());</span><br><span class="line">        setStatus(States.PUBLISH_DONE.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;DRAFT&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rollback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作回滚,回到草稿状态. target status:&#123;&#125;&quot;</span>, States.DRAFT.name());</span><br><span class="line">        setStatus(States.DRAFT.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编写测试用例，这里我们使用CommandLineRunner接口代替，定义了一个StartupRunner，在该类的run方法中启动状态机、发送不同的事件，通过日志验证状态机的流转过程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StartupRunner</span> <span class="keyword">implements</span> <span class="title">CommandLineRunner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    StateMachine&lt;States, Events&gt; stateMachine;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(String... args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        stateMachine.start();</span><br><span class="line">        stateMachine.sendEvent(Events.ONLINE);</span><br><span class="line">        stateMachine.sendEvent(Events.PUBLISH);</span><br><span class="line">        stateMachine.sendEvent(Events.ROLLBACK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>使用步骤总结：</strong></p><ul><li>定义状态枚举和事件枚举</li><li>定义状态机的初始状态和所有状态</li><li>定义状态之间的转移规则</li><li>在业务对象中使用状态机，编写响应状态变化的监听器方法</li></ul><p>使用Spring StateMachine的好处在于自己无需关心状态机的实现细节，只需要关心业务有什么状态、它们之间的转移规则是什么、每个状态转移后真正要进行的业务操作。</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>Spring State Machine可以做的事情还很多。 </p><ul><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#statemachine-config-states">状态可以嵌套</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-security">可以配置为检查是否允许过渡的防护措施</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-extendedstate">允许定义选择状态，接合状态等的伪状态</a> </li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-triggers">事件可以由操作或在计时器上触发</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-persist">状态机可以持久化以提高性能</a> </li></ul><p>要浏览所有内容，您需要研究 <a href="https://docs.spring.io/spring-statemachine/docs/current/reference/">Spring StateMachine文档</a> 并确定适合您的特定情况的文档。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 状态机 </tag>
            
            <tag> Spring生态 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码规范之BigDecimal的equals方法等值比较引坑</title>
      <link href="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/"/>
      <url>/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/</url>
      
        <content type="html"><![CDATA[<p>BigDecimal，相信对于很多人来说都不陌生，很多人都知道他的用法，这是一种java.math包中提供的一种可以用来进行精确运算的类型。</p><p>很多人都知道，在进行金额表示、金额计算等场景，不能使用double、float等类型，而是要使用对精度支持的更好的BigDecimal。</p><p>所以，很多支付、电商、金融等业务中，BigDecimal的使用非常频繁。而且不得不说这是一个非常好用的类，其内部自带了很多方法，如加，减，乘，除等运算方法都是可以直接调用的。</p><p>除了需要用BigDecimal表示数字和进行数字运算以外，代码中还经常需要对于数字进行相等判断。</p><p>关于BigDecimal等值判断的这个知识点，在最新版的《阿里巴巴Java开发手册》中也有说明：<br><img src="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_1.png"></p><p>那么，为什么会有这样的要求呢？背后的思考是什么呢？</p><p>其实，我在之前的CodeReview中，看到过以下这样的低级错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(bigDecimal == bigDecimal1)&#123;</span><br><span class="line">    // 两个数相等</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种错误，相信聪明的读者一眼就可以看出问题，因为BigDecimal是对象，所以不能用==来判断两个数字的值是否相等。</p><p>以上这种问题，在有一定的经验之后，还是可以避免的，但是聪明的读者，看一下以下这行代码，你觉得他有问题吗：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(bigDecimal.equals(bigDecimal1))&#123;</span><br><span class="line">    // 两个数相等</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以明确的告诉大家，以上这种写法，可能得到的结果和你预想的不一样！</p><p>先来做个实验，运行以下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal bigDecimal = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal1 = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal.equals(bigDecimal1));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal2 = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal3 = new BigDecimal(1.0);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal2.equals(bigDecimal3));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal4 = new BigDecimal(&quot;1&quot;);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal5 = new BigDecimal(&quot;1.0&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal4.equals(bigDecimal5));</span><br></pre></td></tr></table></figure><p>以上代码，输出结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">true</span><br><span class="line"></span><br><span class="line">true</span><br><span class="line"></span><br><span class="line">false</span><br></pre></td></tr></table></figure><h3 id="BigDecimal的equals原理"><a href="#BigDecimal的equals原理" class="headerlink" title="BigDecimal的equals原理"></a>BigDecimal的equals原理</h3><p>通过以上代码示例，我们发现，在使用BigDecimal的equals方法对1和1.0进行比较的时候，有的时候是true（当使用int、double定义BigDecimal时），有的时候是false（当使用String定义BigDecimal时）。</p><p>那么，为什么会出现这样的情况呢，我们先来看下BigDecimal的equals方法。</p><p>在BigDecimal的JavaDoc中其实已经解释了其中原因：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Compares this  BigDecimal with the specified Object for equality.  Unlike compareTo, this method considers two BigDecimal objects equal only if they are equal in value and scale (thus 2.0 is not equal to 2.00 when compared by  this method)</span><br></pre></td></tr></table></figure><p>大概意思就是，equals方法和compareTo并不一样，equals方法会比较两部分内容，分别是<strong>值(value)<strong>和</strong>标度(scale)</strong></p><p><img src="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_2.png"></p><p>到这里，我们大概解释清楚了，之所以equals比较bigDecimal4和bigDecimal5的结果是false，是因为标度不同。</p><p>那么，为什么标度不同呢？为什么bigDecimal2和bigDecimal3的标度是一样的（当使用int、double定义BigDecimal时），而bigDecimal4和bigDecimal5却不一样（当使用String定义BigDecimal时）呢？</p><h3 id="为什么标度不同"><a href="#为什么标度不同" class="headerlink" title="为什么标度不同"></a>为什么标度不同</h3><p>这个就涉及到BigDecimal的标度问题了，这个问题其实是比较复杂的，由于不是本文的重点，这里面就简单介绍一下吧。</p><p>首先，BigDecimal一共有以下4个构造方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal(int)</span><br><span class="line"></span><br><span class="line">BigDecimal(double) </span><br><span class="line"></span><br><span class="line">BigDecimal(long) </span><br><span class="line"></span><br><span class="line">BigDecimal(String)</span><br></pre></td></tr></table></figure><p>以上四个方法，创建出来的的BigDecimal的标度是不同的。</p><ul><li><p><strong>BigDecimal(long) 和BigDecimal(int)</strong><br>首先，最简单的就是BigDecimal(long) 和BigDecimal(int)，<strong>因为是整数，所以标度就是0</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public BigDecimal(int val) &#123;</span><br><span class="line">  this.intCompact = val;</span><br><span class="line">  this.scale = 0;</span><br><span class="line">  this.intVal = null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public BigDecimal(long val) &#123;</span><br><span class="line">  this.intCompact = val;</span><br><span class="line">  this.intVal = (val == INFLATED) ? INFLATED_BIGINT : null;</span><br><span class="line">  this.scale = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>BigDecimal(double)</strong><br>而对于BigDecimal(double), 当我们使用new BigDecimal(0.1)创建一个BigDecimal 的时候，其实创建出来的值并不是正好等于0.1的，而是0.1000000000000000055511151231257827021181583404541015625 。这是因为doule自身表示的只是一个近似值。</p><p>那么，无论我们使用new BigDecimal(0.1)还是new BigDecimal(0.10)定义，他的近似值都是0.1000000000000000055511151231257827021181583404541015625这个，那么他的标度就是这个数字的位数，即55。</p><p><img src="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_3.png"> </p><p>其他的浮点数也同样的道理。对于new BigDecimal(1.0)这样的形式来说，因为他本质上也是个整数，所以他创建出来的数字的标度就是0。</p><p>所以，因为BigDecimal(1.0)和BigDecimal(1.00)的标度是一样的，所以在使用equals方法比较的时候，得到的结果就是true。</p></li><li><p><strong>BigDecimal(string)</strong><br>而对于BigDecimal(double) ，当我们使用new BigDecimal(“0.1”)创建一个BigDecimal 的时候，其实创建出来的值正好就是等于0.1的。那么他的标度也就是1。</p><p>如果使用new BigDecimal(“0.10000”)，那么创建出来的数就是0.10000，标度也就是5。</p></li></ul><p>所以，因为BigDecimal(“1.0”)和BigDecimal(“1.00”)的标度不一样，所以在使用equals方法比较的时候，得到的结果就是false。</p><h3 id="如何比较BigDecimal"><a href="#如何比较BigDecimal" class="headerlink" title="如何比较BigDecimal"></a>如何比较BigDecimal</h3><p>前面，我们解释了BigDecimal的equals方法，其实不只是会比较数字的值，还会对其标度进行比较。</p><p>所以，当我们使用equals方法判断判断两个数是否相等的时候，是极其严格的。</p><p>那么，如果我们只想判断两个BigDecimal的值是否相等，那么该如何判断呢？</p><p><strong>BigDecimal中提供了compareTo方法，这个方法就可以只比较两个数字的值，如果两个数相等，则返回0。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal bigDecimal4 = new BigDecimal(&quot;1&quot;);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal5 = new BigDecimal(&quot;1.0000&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal4.compareTo(bigDecimal5));</span><br></pre></td></tr></table></figure><p>以上代码，输出结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0</span><br></pre></td></tr></table></figure><p>其源码如下：</p><p><img src="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_4.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>BigDecimal是一个非常好用的表示高精度数字的类，其中提供了很多丰富的方法。</p><p>但是，他的equals方法使用的时候需要谨慎，因为他在比较的时候，不仅比较两个数字的值，还会比较他们的标度，只要这两个因素有一个是不相等的，那么结果也是false</p><p>如果读者想要对两个BigDecimal的数值进行比较的话，可以使用compareTo方法。</p>]]></content>
      
      
      <categories>
          
          <category> 代码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统04之分布式锁</title>
      <link href="/2020/06/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>/2020/06/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁"></a>什么是分布式锁</h2><ul><li>分布式模型下，数据只有一份，需要锁技术控制某一时刻修改数据的进程数。 </li><li>不仅需要保证进程可见，还需要考虑进程与锁的网络问题 </li><li>可以将标记存在内存，但是内存不是进程分配而是公共内存（redis、zk）,保证标记互斥。</li></ul><h2 id="Java分布式锁需求"><a href="#Java分布式锁需求" class="headerlink" title="Java分布式锁需求"></a>Java分布式锁需求</h2><ul><li>同一个方法在同一时间只能被一台机器上一个线程执行。</li><li>可重入（避免死锁）</li><li>阻塞锁（业务需求） </li><li>公平锁（业务需求） </li><li>高可用、高性能获取/释放锁</li></ul><h2 id="Java分布式锁解决方案"><a href="#Java分布式锁解决方案" class="headerlink" title="Java分布式锁解决方案"></a>Java分布式锁解决方案</h2><h3 id="基于数据库"><a href="#基于数据库" class="headerlink" title="基于数据库"></a>基于数据库</h3><p>基于表主键唯一做分布式锁</p><h3 id="基于redis"><a href="#基于redis" class="headerlink" title="基于redis"></a>基于redis</h3><h4 id="基于-redis-的-SETNX-、EXPIRE-方法做分布式锁"><a href="#基于-redis-的-SETNX-、EXPIRE-方法做分布式锁" class="headerlink" title="基于 redis 的 SETNX()、EXPIRE() 方法做分布式锁"></a>基于 redis 的 SETNX()、EXPIRE() 方法做分布式锁</h4><p>使用步骤：</p><ul><li>setnx(lockkey, 1) 返回1，占位成功</li><li>expire()对lockkey设置超时时间，避免死锁</li><li>执行完业务后，delete命令删除key</li></ul><p>在 expire() 命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题。</p><h4 id="基于-redis-的-setnx-、get-和-getset-方法来实现分布式锁。"><a href="#基于-redis-的-setnx-、get-和-getset-方法来实现分布式锁。" class="headerlink" title="基于 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。"></a>基于 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。</h4><p>使用步骤</p><ul><li>setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。</li><li>get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。</li><li>计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。</li><li>判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</li><li>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</li></ul><h4 id="分布式锁Redlock"><a href="#分布式锁Redlock" class="headerlink" title="分布式锁Redlock"></a>分布式锁Redlock</h4><p>解决问题：<br>解决redis分布式锁的单点故障问题</p><p>使用步骤：</p><ul><li>获取当前时间（毫秒数）。</li><li>按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败，比如该Redis节点不可用，或者该Redis节点上的锁已经被其它客户端持有（注：Redlock原文中这里只提到了Redis节点不可用的情况，但也应该包含其它的失败情况）。</li><li>计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。</li><li>如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。</li><li>如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的Redis Lua脚本）。</li></ul><h4 id="基于-REDISSON-做分布式锁"><a href="#基于-REDISSON-做分布式锁" class="headerlink" title="基于 REDISSON 做分布式锁"></a>基于 REDISSON 做分布式锁</h4><p>redis 官方的分布式锁组件，解决超时时间设置不合理问题。每获得一个锁时，只设置一个很短的超时时间，同时起一个线程在每次快要到超时时间时去刷新锁的超时时间。在释放锁的同时结束这个线程。</p><h3 id="zookeeper实现分布式锁"><a href="#zookeeper实现分布式锁" class="headerlink" title="zookeeper实现分布式锁"></a>zookeeper实现分布式锁</h3><p>其实基于ZooKeeper，就是使用它的临时有序节点来实现的分布式锁。</p><p><img src="/2020/06/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/img_1.png"><br>当某客户端要进行逻辑的加锁时，就在zookeeper上的某个指定节点的目录下，去生成一个唯一的临时有序节点， 然后判断自己是否是这些有序节点中序号最小的一个。</p><ul><li>如果是，则算是获取了锁。</li><li>如果不是，则说明没有获取到锁，那么就需要在序列中找到比自己小的那个节点，并对其调用exist()方法，对其注册事件监听，当监听到这个节点被删除了，那就再去判断一次自己当初创建的节点是否变成了序列中最小的。<ul><li>如果是，则获取锁，如果不是，则重复上述步骤。</li></ul></li></ul><p>当释放锁的时候，只需将这个临时节点删除即可。</p><h2 id="redis分布式锁和zookeeper分布式锁的区别"><a href="#redis分布式锁和zookeeper分布式锁的区别" class="headerlink" title="redis分布式锁和zookeeper分布式锁的区别"></a>redis分布式锁和zookeeper分布式锁的区别</h2><h3 id="优缺点对比"><a href="#优缺点对比" class="headerlink" title="优缺点对比"></a>优缺点对比</h3><p>对于redis的分布式锁而言：</p><ul><li><p>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</p></li><li><p>redis的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮</p><ul><li>即便使用redlock算法来实现，在某些复杂场景下，也无法保证其实现100%没有问题，关于redlock的讨论可以看How to do distributed locking</li></ul></li></ul><p>但是另一方面使用redis实现分布式锁在很多企业中非常常见，而且大部分情况下都不会遇到所谓的“极端复杂场景”</p><p>所以使用redis作为分布式锁也不失为一种好的方案，最重要的一点是redis的性能很高，可以支撑高并发的获取、释放锁操作。</p><p>对于zk分布式锁而言:</p><ul><li><p>zookeeper天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</p></li><li><p>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</p></li></ul><p>但是zk也有其缺点：如果有较多的客户端频繁的申请加锁、释放锁，对于zk集群的压力会比较大。</p><h3 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h3><p>就个人而言的话，我<strong>比较推崇zk实现的锁</strong>：</p><p>因为redis是有可能存在隐患的，可能会导致数据不对的情况。但是，怎么选用要看具体在公司的场景了。</p><p>如果公司里面有zk集群条件，优先选用zk实现，但是如果说公司里面只有redis集群，没有条件搭建zk集群。</p><p>那么其实用redis来实现也可以，另外还可能是系统设计者考虑到了系统已经有redis，但是又不希望再次引入一些外部依赖的情况下，可以选用redis。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 锁 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于JVMTI技术的Jar包字节码加密技术初探</title>
      <link href="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%9F%BA%E4%BA%8EJVMTI%E6%8A%80%E6%9C%AF%E7%9A%84Jar%E5%8C%85%E5%AD%97%E8%8A%82%E7%A0%81%E5%8A%A0%E5%AF%86%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/"/>
      <url>/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%9F%BA%E4%BA%8EJVMTI%E6%8A%80%E6%9C%AF%E7%9A%84Jar%E5%8C%85%E5%AD%97%E8%8A%82%E7%A0%81%E5%8A%A0%E5%AF%86%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="JVMTI的定义及原理"><a href="#JVMTI的定义及原理" class="headerlink" title="JVMTI的定义及原理"></a>JVMTI的定义及原理</h2><p>在介绍JVMTI之前，需要先了解下Java平台调试体系JPDA（Java PlatformDebugger Architecture）。它是Java虚拟机为调试和监控虚拟机专门提供的一套接口。</p><p>如下图所示，JPDA被抽象为三层实现。其中JVMTI就是JVM对外暴露的接口。 JDI是实现了JDWP通信协议的客户端，调试器通过它和JVM中被调试程序通信。</p><p>JVMTI 本质上是在JVM内部的许多事件进行了埋点。通过这些埋点可以给外部提供当前上下文的一些信息。甚至可以接受外部的命令来改变下一步的动作。外部程序一般利用C/C++实现一个JVMTIAgent，在Agent里面注册一些JVM事件的回调。当事件发生时JVMTI调用这些回调方法。Agent可以在回调方法里面实现自己的逻辑。</p><p>JVMTIAgent是以动态链接库的形式被虚拟机加载的。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%9F%BA%E4%BA%8EJVMTI%E6%8A%80%E6%9C%AF%E7%9A%84Jar%E5%8C%85%E5%AD%97%E8%8A%82%E7%A0%81%E5%8A%A0%E5%AF%86%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/img.png"></p><h2 id="JVMTI的历史"><a href="#JVMTI的历史" class="headerlink" title="JVMTI的历史"></a>JVMTI的历史</h2><p>JVMTI 的前身是JVMDI（Java Virtual Machine Debug Interface）和 JVMPI（Java Virtual Machine Profiler Interface），它们原来分别被用于提供调试 Java 程序以及 Java 程序调节性能的功能。</p><p>在 J2SE 5.0 之后 JDK 取代了JVMDI 和 JVMPI 这两套接口，JVMDI 在最新的 Java SE 6 中已经不提供支持，而 JVMPI 也计划在 Java SE 7 后被彻底取代。</p><h2 id="JVMTI的功能"><a href="#JVMTI的功能" class="headerlink" title="JVMTI的功能"></a>JVMTI的功能</h2><p>JVMTI处于整个JPDA 体系的最底层，所有调试功能本质上都需要通过 JVMTI 来提供。</p><p>从大的方面来说，JVMTI 提供了可用于 debug 和profiler 的接口；同时，在 Java 5/6 中，虚拟机接口也增加了监听（Monitoring），线程分析（Thread analysis）以及覆盖率分析（Coverage Analysis）等功能。</p><p>从小的方面来说包含了虚拟机中线程、内存、堆、栈、类、方法、变量，事件、定时器处理等等诸多功能。 具体可以参考<a href="https://docs.oracle.com/javase/1.5.0/docs/guide/jvmti/jvmti.html">oracle的文档</a></p><p>通过这些接口，开发人员不仅可以调试在该虚拟机上运行的 Java 程序，还能查看它们运行的状态，设置回调函数，控制某些环境变量，从而优化程序性能。</p><h2 id="基于JVMTI的项目加解密实现"><a href="#基于JVMTI的项目加解密实现" class="headerlink" title="基于JVMTI的项目加解密实现"></a>基于JVMTI的项目加解密实现</h2><p><strong>参考DEMO中jvmti-encrypt模块项目实现</strong></p><h2 id="Agent加载与回调函数的执行分析"><a href="#Agent加载与回调函数的执行分析" class="headerlink" title="Agent加载与回调函数的执行分析"></a>Agent加载与回调函数的执行分析</h2><h3 id="Agent启动"><a href="#Agent启动" class="headerlink" title="Agent启动"></a>Agent启动</h3><p>Agent 是在 Java 虚拟机启动之时加载的，这个加载处于虚拟机初始化的早期。</p><p>在这个时间点上：</p><ul><li>所有的 Java 类都未被初始化；</li><li>所有的对象实例都未被创建；</li><li>因而，没有任何 Java 代码被执行；</li></ul><p>但在这个时候，我们已经可以：</p><ul><li>操作 JVMTI 的 Capability 参数；</li><li>使用系统参数</li></ul><p>动态库被加载之后，虚拟机会先寻找一个 Agent 入口函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JNIEXPORT jint JNICALL Agent_OnLoad(JavaVM *vm, char *options, void *reserved)</span><br></pre></td></tr></table></figure><p>在这个函数中，虚拟机传入了一个 JavaVM 指针，以及命令行的参数。</p><p>通过 JavaVM，我们可以获得 JVMTI 的指针，并获得 JVMTI 函数的使用能力，所有的 JVMTI 函数都通过这个 jvmtiEnv 获取，不同的虚拟机实现提供的函数细节可能不一样，但是使用的方式是统一的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jint ret = vm-&gt;GetEnv((void **)&amp;jvmti, JVMTI_VERSION);</span><br></pre></td></tr></table></figure><p>这里传入的版本信息参数很重要，不同的 JVMTI 环境所提供的功能以及处理方式都可能有所不同，不过它在同一个虚拟机中会保持不变。</p><p>命令行参数事实上就是上面启动命令行中的 options 部分，在 Agent 实现中需要进行解析并完成后续处理工作。参数传入的字符串仅仅在 Agent_OnLoad 函数里有效。</p><p>需要强调的是，这个时候由于虚拟机并未完成初始化工作，并不是所有的 JVMTI 函数都可以被使用。</p><p>Agent 还可以在运行时加载。具体说来，虚拟机会在运行时监听并接受 Agent 的加载，在这个时候，它会使用 Agent 的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JNIEXPORT jint JNICALL Agent_OnAttach(JavaVM* vm, char *options, void *reserved);</span><br></pre></td></tr></table></figure><p>同样的在这个初始化阶段，不是所有的 JVMTI 的 Capability 参数都处于可操作状态，而且 options 这个 char 数组在这个函数运行之后就会被丢弃，如果需要，需要做好保留工作。</p><p>Agent 的主要功能是通过一系列的在虚拟机上设置的回调（callback）函数完成的，一旦某些事件发生，Agent 所设置的回调函数就会被调用，来完成特定的需求。</p><h3 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h3><p>最后，Agent 完成任务，或者虚拟机关闭的时候，虚拟机都会调用一个类似于类析构函数的方法来完成最后的清理任务，注意这个函数和虚拟机自己的 VM_DEATH 事件是不同的。</p><h3 id="执行逻辑分析"><a href="#执行逻辑分析" class="headerlink" title="执行逻辑分析"></a>执行逻辑分析</h3><p><a href="https://www.jianshu.com/p/8775c1542b52">参考文档</a></p>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVMTI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA线上故障排查全套路</title>
      <link href="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/"/>
      <url>/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<p>线上故障主要会包括cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。</p><p>同时例如jstack、jmap等工具也是不囿于一个方面的问题的，基本上出问题就是df、free、top 三连，然后依次jstack、jmap伺候，具体问题具体分析即可。</p><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><p>一般来讲我们首先会排查cpu方面的问题。cpu异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁gc以及上下文切换过多。而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用jstack来分析对应的堆栈情况。</p><h3 id="使用jstack分析cpu问题"><a href="#使用jstack分析cpu问题" class="headerlink" title="使用jstack分析cpu问题"></a>使用jstack分析cpu问题</h3><p>我们先用ps命令找到对应进程的pid(如果你有好几个目标进程，可以先用top看一下哪个占用比较高)。<br>接着用top -H -p pid来找到cpu使用率比较高的一些线程<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img.png"><br>然后将占用最高的pid转换为16进制printf ‘%x\n’ pid得到nid<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_1.png"><br>接着直接在jstack中找到相应的堆栈信息jstack pid |grep ‘nid’ -C5 –color<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_2.png"><br>可以看到我们已经找到了nid为0x42的堆栈信息，接着只要仔细分析一番即可。</p><p>当然更常见的是我们对整个jstack文件进行分析，通常我们会比较关注WAITING和TIMED_WAITING的部分，BLOCKED就不用说了。我们可以使用命令cat jstack.log | grep “java.lang.Thread.State” | sort -nr | uniq -c来对jstack的状态有一个整体的把握，如果WAITING之类的特别多，那么多半是有问题啦。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_3.png"></p><h3 id="频繁gc"><a href="#频繁gc" class="headerlink" title="频繁gc"></a>频繁gc</h3><p>当然我们还是会使用jstack来分析问题，但有时候我们可以先确定下gc是不是太频繁，使用<strong>jstat -gc pid 1000</strong>命令来对gc分代变化情况进行观察，</p><ul><li>1000表示采样间隔(ms)</li><li>S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU分别代表两个Survivor区、Eden区、老年代、元数据区的容量和使用量。</li><li>YGC/YGT、FGC/FGCT、GCT则代表YoungGc、FullGc的耗时和次数以及总耗时。</li></ul><p>如果看到gc比较频繁，再针对gc方面做进一步分析，具体可以参考一下gc章节的描述。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_4.png"></p><h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>针对频繁上下文问题，我们可以使用vmstat命令来进行查看<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_5.png"><br>cs(context switch)一列则代表了上下文切换的次数。<br>如果我们希望对特定的pid进行监控那么可以使用 pidstat -w pid命令，cswch和nvcswch表示自愿及非自愿切换。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_6.png"></p><h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><p>磁盘问题和cpu一样是属于比较基础的。首先是磁盘空间方面，我们直接使用<strong>df -hl</strong>来查看文件系统状态<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_7.png"><br>更多时候，磁盘问题还是性能上的问题。我们可以通过iostatiostat -d -k -x来进行分析<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_8.png"><br>最后一列%util可以看到每块磁盘写入的程度，而rrqpm/s以及wrqm/s分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。</p><p>另外我们还需要知道是哪个进程在进行读写，一般来说开发自己心里有数，或者用iotop命令来进行定位文件读写的来源。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_9.png"><br>不过这边拿到的是tid，我们要转换成pid，可以通过readlink来找到pidreadlink -f /proc/*/task/tid/../..。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_10.png"><br>找到pid之后就可以看这个进程具体的读写情况cat /proc/pid/io<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_11.png"><br>我们还可以通过lsof命令来确定具体的文件读写情况lsof -p pid<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_12.png"></p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><p>内存问题排查起来相对比CPU麻烦一些，场景也比较多。主要包括OOM、GC问题和堆外内存。一般来讲，我们会先用free命令先来检查一发内存的各种情况。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_13.png"></p><h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>内存问题大多还都是堆内内存问题。表象上主要分为OOM和StackOverflow。</p><h4 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h4><p><strong>Exception in thread “main” java.lang.OutOfMemoryError: unable to create new native thread</strong></p><p>这个意思是没有足够的内存空间给线程分配java栈，基本上还是线程池代码写的有问题，比如说忘记shutdown，所以说应该首先从代码层面来寻找问题，使用jstack或者jmap。如果一切都正常，JVM方面可以通过指定Xss来减少单个thread stack的大小。另外也可以在系统层面，可以通过修改/etc/security/limits.confnofile和nproc来增大os对线程的限制<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_14.png"></p><p><strong>Exception in thread “main” java.lang.OutOfMemoryError: Java heap space</strong></p><p>这个意思是堆的内存占用已经达到-Xmx设置的最大值，应该是最常见的OOM错误了。解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过jstack和jmap去定位问题。如果说一切都正常，才需要通过调整Xmx的值来扩大内存。</p><p><strong>Caused by: java.lang.OutOfMemoryError: Meta space</strong></p><p>这个意思是元数据区的内存占用已经达到XX:MaxMetaspaceSize设置的最大值，排查思路和上面的一致，参数方面可以通过XX:MaxPermSize来进行调整(这里就不说1.8以前的永久代了)。</p><h4 id="Stack-Overflow"><a href="#Stack-Overflow" class="headerlink" title="Stack Overflow"></a>Stack Overflow</h4><p>栈内存溢出，这个大家见到也比较多。</p><p><strong>Exception in thread “main” java.lang.StackOverflowError</strong></p><p>表示线程栈需要的内存大于Xss值，同样也是先进行排查，参数方面通过Xss来调整，但调整的太大可能又会引起OOM。</p><h4 id="使用JMAP定位代码内存泄漏"><a href="#使用JMAP定位代码内存泄漏" class="headerlink" title="使用JMAP定位代码内存泄漏"></a>使用JMAP定位代码内存泄漏</h4><p>上述关于OOM和StackOverflow的代码排查方面，我们一般使用JMAPjmap -dump:format=b,file=filename pid来导出dump文件<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_15.png"></p><p>通过mat(Eclipse Memory Analysis Tools)导入dump文件进行分析，内存泄漏问题一般我们直接选Leak Suspects即可，mat给出了内存泄漏的建议。另外也可以选择Top Consumers来查看最大对象报告。和线程相关的问题可以选择thread overview进行分析。除此之外就是选择Histogram类概览来自己慢慢分析，大家可以搜搜mat的相关教程。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_16.png"></p><p>日常开发中，代码产生内存泄漏是比较常见的事，并且比较隐蔽，需要开发者更加关注细节。比如说每次请求都new对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发gc；ByteBuffer缓存分配不合理等都会造成代码OOM。</p><p>另一方面，我们可以在启动参数中指定-XX:+HeapDumpOnOutOfMemoryError来保存OOM时的dump文件。</p><h4 id="gc问题和线程"><a href="#gc问题和线程" class="headerlink" title="gc问题和线程"></a>gc问题和线程</h4><p>gc问题除了影响cpu也会影响内存，排查思路也是一致的。一般先使用jstat来查看分代变化情况，比如youngGC或者fullGC次数是不是太多呀；EU、OU等指标增长是不是异常呀等。</p><p>线程的话太多而且不被及时gc也会引发oom，大部分就是之前说的unable to create new native thread。除了jstack细细分析dump文件外，我们一般先会看下总体线程，通过pstreee -p pid |wc -l。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_17.png"></p><p>或者直接通过查看/proc/pid/task的数量即为线程数量。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_18.png"></p><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>如果碰到堆外内存溢出，那可真是太不幸了。首先堆外内存溢出表现就是物理常驻内存增长快，报错的话视使用方式都不确定，如果由于使用Netty导致的，那错误日志里可能会出现OutOfDirectMemoryError错误，如果直接是DirectByteBuffer，那会报OutOfMemoryError: Direct buffer memory。</p><p>堆外内存溢出往往是和NIO的使用相关，一般我们先通过pmap来查看下进程占用的内存情况pmap -x pid | sort -rn -k3 | head -30，这段意思是查看对应pid倒序前30大的内存段。这边可以再一段时间后再跑一次命令看看内存增长情况，或者和正常机器比较可疑的内存段在哪里。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_19.png"></p><p>我们如果确定有可疑的内存端，需要通过gdb来分析gdb –batch –pid {pid} -ex “dump memory filename.dump {内存起始地址} {内存起始地址+内存块大小}”</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_20.png"></p><p>获取dump文件后可用heaxdump进行查看hexdump -C filename | less，不过大多数看到的都是二进制乱码。</p><p>NMT是Java7U40引入的HotSpot新特性，配合jcmd命令我们就可以看到具体内存组成了。需要在启动参数中加入 -XX:NativeMemoryTracking=summary 或者 -XX:NativeMemoryTracking=detail，会有略微性能损耗。</p><p>一般对于堆外内存缓慢增长直到爆炸的情况来说，可以先设一个基线jcmd pid VM.native_memory baseline。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_21.png"></p><p>然后等放一段时间后再去看看内存增长的情况，通过jcmd pid VM.native_memory detail.diff(summary.diff)做一下summary或者detail级别的diff。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_22.png"><br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_23.png"></p><p>可以看到jcmd分析出来的内存十分详细，包括堆内、线程以及gc(所以上述其他内存异常其实都可以用nmt来分析)，这边堆外内存我们重点关注Internal的内存增长，如果增长十分明显的话那就是有问题了。</p><p>detail级别的话还会有具体内存段的增长情况，如下图。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_24.png"></p><p>此外在系统层面，我们还可以使用strace命令来监控内存分配 strace -f -e “brk,mmap,munmap” -p pid</p><p>这边内存分配信息主要包括了pid和内存地址。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_25.png"><br>不过其实上面那些操作也很难定位到具体的问题点，关键还是要看错误日志栈，找到可疑的对象，搞清楚它的回收机制，然后去分析对应的对象。比如DirectByteBuffer分配内存的话，是需要full GC或者手动system.gc来进行回收的(所以最好不要使用-XX:+DisableExplicitGC)。那么其实我们可以跟踪一下DirectByteBuffer对象的内存情况，通过jmap -histo:live pid手动触发fullGC来看看堆外内存有没有被回收。如果被回收了，那么大概率是堆外内存本身分配的太小了，通过-XX:MaxDirectMemorySize进行调整。如果没有什么变化，那就要使用jmap去分析那些不能被gc的对象，以及和DirectByteBuffer之间的引用关系了。</p><h3 id="GC问题"><a href="#GC问题" class="headerlink" title="GC问题"></a>GC问题</h3><p>堆内内存泄漏总是和GC异常相伴。不过GC问题不只是和内存问题相关，还有可能引起CPU负载、网络问题等系列并发症，只是相对来说和内存联系紧密些，所以我们在此单独总结一下GC相关问题。</p><p>我们在cpu章介绍了使用jstat来获取当前GC分代变化信息。而更多时候，我们是通过GC日志来排查问题的，在启动参数中加上-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps来开启GC日志。</p><p>常见的Young GC、Full GC日志含义在此就不做赘述了。</p><p>针对gc日志，我们就能大致推断出youngGC与fullGC是否过于频繁或者耗时过长，从而对症下药。我们下面将对G1垃圾收集器来做分析，这边也建议大家使用G1-XX:+UseG1GC。</p><h4 id="youngGC过频繁"><a href="#youngGC过频繁" class="headerlink" title="youngGC过频繁"></a>youngGC过频繁</h4><p>youngGC频繁一般是短周期小对象较多，先考虑是不是Eden区/新生代设置的太小了，看能否通过调整-Xmn、-XX:SurvivorRatio等参数设置来解决问题。如果参数正常，但是young gc频率还是太高，就需要使用Jmap和MAT对dump文件进行进一步排查了</p><h4 id="youngGC耗时过长"><a href="#youngGC耗时过长" class="headerlink" title="youngGC耗时过长"></a>youngGC耗时过长</h4><p>耗时过长问题就要看GC日志里耗时耗在哪一块了。以G1日志为例，可以关注Root Scanning、Object Copy、Ref Proc等阶段。Ref Proc耗时长，就要注意引用相关的对象。Root Scanning耗时长，就要注意线程数、跨代引用。Object Copy则需要关注对象生存周期。而且耗时分析它需要横向比较，就是和其他项目或者正常时间段的耗时比较。比如说图中的Root Scanning和正常时间段比增长较多，那就是起的线程太多了。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_26.png"></p><h4 id="触发fullGC"><a href="#触发fullGC" class="headerlink" title="触发fullGC"></a>触发fullGC</h4><p>G1中更多的还是mixedGC，但mixedGC可以和youngGC思路一样去排查。触发fullGC了一般都会有问题，G1会退化使用Serial收集器来完成垃圾的清理工作，暂停时长达到秒级别，可以说是半跪了。</p><p>fullGC的原因可能包括以下这些，以及参数调整方面的一些思路：</p><ul><li><p>并发阶段失败：在并发标记阶段，MixGC之前老年代就被填满了，那么这时候G1就会放弃标记周期。这种情况，可能就需要增加堆大小，或者调整并发标记线程数-XX:ConcGCThreads。</p></li><li><p>晋升失败：在GC的时候没有足够的内存供存活/晋升对象使用，所以触发了Full GC。这时候可以通过-XX:G1ReservePercent来增加预留内存百分比，减少-XX:InitiatingHeapOccupancyPercent来提前启动标记，-XX:ConcGCThreads来增加标记线程数也是可以的。</p></li><li><p>大对象分配失败：大对象找不到合适的region空间进行分配，就会进行fullGC，这种情况下可以增大内存或者增大-XX:G1HeapRegionSize。</p></li><li><p>程序主动执行System.gc()：不要随便写就对了。</p></li></ul><p>另外，我们可以在启动参数中配置-XX:HeapDumpPath=/xxx/dump.hprof来dump fullGC相关的文件，并通过jinfo来进行gc前后的dump</p><p>jinfo -flag +HeapDumpBeforeFullGC pid</p><p>jinfo -flag +HeapDumpAfterFullGC pid</p><p>这样得到2份dump文件，对比后主要关注被gc掉的问题对象来定位问题。</p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>涉及到网络层面的问题一般都比较复杂，场景多，定位难，成为了大多数开发的噩梦，应该是最复杂的了。这里会举一些例子，并从tcp层、应用层以及工具的使用等方面进行阐述。</p><h3 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h3><p>超时错误大部分处在应用层面，所以这块着重理解概念。超时大体可以分为连接超时和读写超时，某些使用连接池的客户端框架还会存在获取连接超时和空闲连接清理超时。</p><ul><li><p>读写超时。readTimeout/writeTimeout，有些框架叫做so_timeout或者socketTimeout，均指的是数据读写超时。注意这边的超时大部分是指逻辑上的超时。soa的超时指的也是读超时。读写超时一般都只针对客户端设置。</p></li><li><p>连接超时。connectionTimeout，客户端通常指与服务端建立连接的最大时间。服务端这边connectionTimeout就有些五花八门了，jetty中表示空闲连接清理时间，tomcat则表示连接维持的最大时间。</p></li><li><p>其他。包括连接获取超时connectionAcquireTimeout和空闲连接清理超时idleConnectionTimeout。多用于使用连接池或队列的客户端或服务端框架。</p></li></ul><p>我们在设置各种超时时间中，需要确认的是尽量保持客户端的超时小于服务端的超时，以保证连接正常结束。</p><p>在实际开发中，我们关心最多的应该是接口的读写超时了。</p><p>如何设置合理的接口超时是一个问题。如果接口超时设置的过长，那么有可能会过多地占用服务端的tcp连接。而如果接口设置的过短，那么接口超时就会非常频繁。</p><p>服务端接口明明rt降低，但客户端仍然一直超时又是另一个问题。这个问题其实很简单，客户端到服务端的链路包括网络传输、排队以及服务处理等，每一个环节都可能是耗时的原因。</p><h3 id="TCP队列溢出"><a href="#TCP队列溢出" class="headerlink" title="TCP队列溢出"></a>TCP队列溢出</h3><p>tcp队列溢出是个相对底层的错误，它可能会造成超时、rst等更表层的错误。因此错误也更隐蔽，所以我们单独说一说。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_27.png"></p><p>如上图所示，这里有两个队列：syns queue(半连接队列）、accept queue（全连接队列）。三次握手，在server收到client的syn后，把消息放到syns queue，回复syn+ack给client，server收到client的ack，如果这时accept queue没满，那就从syns queue拿出暂存的信息放入accept queue中，否则按tcp_abort_on_overflow指示的执行。</p><p>tcp_abort_on_overflow 0表示如果三次握手第三步的时候accept queue满了那么server扔掉client发过来的ack。tcp_abort_on_overflow 1则表示第三步的时候如果全连接队列满了，server发送一个rst包给client，表示废掉这个握手过程和这个连接，意味着日志里可能会有很多connection reset / connection reset by peer。</p><p>那么在实际开发中，我们怎么能快速定位到tcp队列溢出呢？</p><p><strong>netstat命令，执行netstat -s | egrep “listen|LISTEN”</strong><br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_28.png"><br>如上图所示，overflowed表示全连接队列溢出的次数，sockets dropped表示半连接队列溢出的次数。</p><p><strong>ss命令，执行ss -lnt=</strong><br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_29.png"><br>上面看到Send-Q 表示第三列的listen端口上的全连接队列最大为5，第一列Recv-Q为全连接队列当前使用了多少。</p><p>接着我们看看怎么设置全连接、半连接队列大小吧：</p><p>全连接队列的大小取决于min(backlog, somaxconn)。backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数。而半连接队列的大小取决于max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog)。</p><p>在日常开发中，我们往往使用servlet容器作为服务端，所以我们有时候也需要关注容器的连接队列大小。在tomcat中backlog叫做acceptCount，在jetty里面则是acceptQueueSize。</p><h3 id="RST异常"><a href="#RST异常" class="headerlink" title="RST异常"></a>RST异常</h3><p>RST包表示连接重置，用于关闭一些无用的连接，通常表示异常关闭，区别于四次挥手。</p><p>在实际开发中，我们往往会看到connection reset / connection reset by peer错误，这种情况就是RST包导致的。</p><h3 id="端口不存在"><a href="#端口不存在" class="headerlink" title="端口不存在"></a>端口不存在</h3><p>如果像不存在的端口发出建立连接SYN请求，那么服务端发现自己并没有这个端口则会直接返回一个RST报文，用于中断连接。</p><h3 id="主动代替FIN终止连接"><a href="#主动代替FIN终止连接" class="headerlink" title="主动代替FIN终止连接"></a>主动代替FIN终止连接</h3><p>一般来说，正常的连接关闭都是需要通过FIN报文实现，然而我们也可以用RST报文来代替FIN，表示直接终止连接。实际开发中，可设置SO_LINGER数值来控制，这种往往是故意的，来跳过TIMED_WAIT，提供交互效率，不闲就慎用。</p><h3 id="客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接"><a href="#客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接" class="headerlink" title="客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接"></a>客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接</h3><p>我们上面讲的tcp队列溢出发送RST包其实也是属于这一种。这种往往是由于某些原因，一方无法再能正常处理请求连接了(比如程序崩了，队列满了)，从而告知另一方关闭连接。</p><p>接收到的TCP报文不在已知的TCP连接内</p><p>比如，一方机器由于网络实在太差TCP报文失踪了，另一方关闭了该连接，然后过了许久收到了之前失踪的TCP报文，但由于对应的TCP连接已不存在，那么会直接发一个RST包以便开启新的连接。</p><h3 id="一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文"><a href="#一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文" class="headerlink" title="一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文"></a>一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文</h3><p>这种大多也和网络环境相关了，网络环境差可能会导致更多的RST报文。</p><p>之前说过RST报文多会导致程序报错，在一个已关闭的连接上读操作会报connection reset，而在一个已关闭的连接上写操作则会报connection reset by peer。通常我们可能还会看到broken pipe错误，这是管道层面的错误，表示对已关闭的管道进行读写，往往是在收到RST，报出connection reset错后继续读写数据报的错，这个在glibc源码注释中也有介绍。</p><p>我们在排查故障时候怎么确定有RST包的存在呢？当然是使用tcpdump命令进行抓包，并使用wireshark进行简单分析了。tcpdump -i en0 tcp -w xxx.cap，en0表示监听的网卡。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_30.png"></p><p>接下来我们通过wireshark打开抓到的包，可能就能看到如下图所示，红色的就表示RST包了。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_31.png"></p><h3 id="TIME-WAIT和CLOSE-WAIT"><a href="#TIME-WAIT和CLOSE-WAIT" class="headerlink" title="TIME_WAIT和CLOSE_WAIT"></a>TIME_WAIT和CLOSE_WAIT</h3><p>TIME_WAIT和CLOSE_WAIT是啥意思相信大家都知道。<br>在线上时，我们可以直接用命令netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’来查看time-wait和close_wait的数量</p><p>用ss命令会更快ss -ant | awk ‘{++S[$1]} END {for(a in S) print a, S[a]}’</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_32.png"></p><h3 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT"></a>TIME_WAIT</h3><p>time_wait的存在一是为了丢失的数据包被后面连接复用，二是为了在2MSL的时间范围内正常关闭连接。它的存在其实会大大减少RST包的出现。</p><p>过多的time_wait在短连接频繁的场景比较容易出现。这种情况可以在服务端做一些内核参数调优:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br></pre></td></tr></table></figure><p>当然我们不要忘记在NAT环境下因为时间戳错乱导致数据包被拒绝的坑了，另外的办法就是改小tcp_max_tw_buckets，超过这个数的time_wait都会被干掉，不过这也会导致报time wait bucket table overflow的错。</p><h3 id="CLOSE-WAIT"><a href="#CLOSE-WAIT" class="headerlink" title="CLOSE_WAIT"></a>CLOSE_WAIT</h3><p>close_wait往往都是因为应用程序写的有问题，没有在ACK后再次发起FIN报文。close_wait出现的概率甚至比time_wait要更高，后果也更严重。往往是由于某个地方阻塞住了，没有正常关闭连接，从而渐渐地消耗完所有的线程。</p><p>想要定位这类问题，最好是通过jstack来分析线程堆栈来排查问题，具体可参考上述章节。这里仅举一个例子。</p><p>开发同学说应用上线后CLOSE_WAIT就一直增多，直到挂掉为止，jstack后找到比较可疑的堆栈是大部分线程都卡在了countdownlatch.await方法，找开发同学了解后得知使用了多线程但是确没有catch异常，修改后发现异常仅仅是最简单的升级sdk后常出现的class not found。</p>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线上问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统03之分布式事务</title>
      <link href="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
      <url>/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式事务"><a href="#什么是分布式事务" class="headerlink" title="什么是分布式事务"></a>什么是分布式事务</h2><p>分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。</p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。</p><h2 id="分布式系统一致性基础算法"><a href="#分布式系统一致性基础算法" class="headerlink" title="分布式系统一致性基础算法"></a>分布式系统一致性基础算法</h2><h3 id="Paxos算法"><a href="#Paxos算法" class="headerlink" title="Paxos算法"></a>Paxos算法</h3><p>Paxos 算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一，其解决的问题就是在分布式系统中如何就某个值（决议）达成一致 。</p><p>在 Paxos 中主要有三个角色，分别为 Proposer提案者、Acceptor表决者、Learner学习者。Paxos 算法和 2PC 一样，也有两个阶段，分别为 Prepare 和 accept 阶段。  </p><ul><li>prepare 阶段<ul><li>Proposer提案者：负责提出 proposal，每个提案者在提出提案时都会首先获取到一个 具有全局唯一性的、递增的提案编号N，即在整个集群中是唯一的编号 N，然后将该编号赋予其要提出的提案，在第一阶段是只将提案编号发送给所有的表决者。  </li><li>Acceptor表决者：每个表决者在 accept 某提案后，会将该提案编号N记录在本地，这样每个表决者中保存的已经被 accept 的提案中会存在一个编号最大的提案，其编号假设为 maxN。每个表决者仅会 accept 编号大于自己本地 maxN 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 Proposer。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_1.png"></li></ul></li><li>accept 阶段<br>当一个提案被 Proposer 提出后，如果 Proposer 收到了超过半数的 Acceptor 的批准（Proposer 本身同意），那么此时 Proposer 会给所有的 Acceptor 发送真正的提案（你可以理解为第一阶段为试探），这个时候 Proposer 就会发送提案的内容和提案编号。<br>表决者收到提案请求后会再次比较本身已经批准过的最大提案编号和该提案编号，如果该提案编号 大于等于 已经批准过的最大提案编号，那么就 accept 该提案（此时执行提案内容但不提交），随后将情况返回给 Proposer 。如果不满足则不回应或者返回 NO 。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_2.png"><br>当 Proposer 收到超过半数的 accept ，那么它这个时候会向所有的 acceptor 发送提案的提交请求。需要注意的是，因为上述仅仅是超过半数的 acceptor 批准执行了该提案内容，其他没有批准的并没有执行该提案内容，所以这个时候需要向未批准的 acceptor 发送提案内容和提案编号并让它无条件执行和提交，而对于前面已经批准过该提案的 acceptor 来说 仅仅需要发送该提案的编号 ，让 acceptor 执行提交就行了。<br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_3.png"><br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。</li></ul><h4 id="Paxos算法的死循环问题"><a href="#Paxos算法的死循环问题" class="headerlink" title="Paxos算法的死循环问题"></a>Paxos算法的死循环问题</h4><p>其实就有点类似于两个人吵架，小明说我是对的，小红说我才是对的，两个人据理力争的谁也不让谁🤬🤬。<br>比如说，此时提案者 P1 提出一个方案 M1，完成了 Prepare 阶段的工作，这个时候 acceptor 则批准了 M1，但是此时提案者 P2 同时也提出了一个方案 M2，它也完成了 Prepare 阶段的工作。然后 P1 的方案已经不能在第二阶段被批准了（因为 acceptor 已经批准了比 M1 更大的 M2），所以 P1 自增方案变为 M3 重新进入 Prepare 阶段，然后 acceptor ，又批准了新的 M3 方案，它又不能批准 M2 了，这个时候 M2 又自增进入 Prepare 阶段。<br>就这样无休无止的永远提案下去，这就是 paxos 算法的死循环问题。<br>那么如何解决呢？很简单，人多了容易吵架，我现在 就允许一个能提案 就行了。</p><h3 id="Raft-算法"><a href="#Raft-算法" class="headerlink" title="Raft 算法"></a>Raft 算法</h3><h2 id="分布式事务解决方案"><a href="#分布式事务解决方案" class="headerlink" title="分布式事务解决方案"></a>分布式事务解决方案</h2><h3 id="XA规范-协议"><a href="#XA规范-协议" class="headerlink" title="XA规范/协议"></a>XA规范/协议</h3><p>X/Open组织（现在的Open Group）定义了一套DTP（Distributed Transaction Processing）分布式事务处理模型，主要包含以下四部分：</p><ul><li>AP（应用程序） </li><li>TM（事务管理器）：交易中间件</li><li>RM（资源管理器）：数据库</li><li>CRM（通信资源管理器）：消息中间件</li></ul><p><strong>XA规范</strong>则是DTP模型定义TM和RM之间通讯的接口规范。  </p><p>XA接口函数由数据库厂商提供。<br>TM用它来通知数据库事务的开始、结束、提交、回滚。<br>基于XA规范衍生出下面的二阶段提交（2PC）、三阶段提交（3PC）。  </p><p>XA规范包括两套函数，以xa_开头的及以ax_开头的。<br>以下的函数使事务管理器可以对资源管理器进行的操作：</p><ul><li>xa_open,xa_close：建立和关闭与资源管理器的连接。</li><li>xa_start,xa_end：开始和结束一个本地事务。</li><li>xa_prepare,xa_commit,xa_rollback：预提交、提交、回滚一个本地事务。</li><li>xa_recover：回滚一个已进行预提交的事务。</li><li>ax_开头的函数使资源管理器可以动态地在事务管理器中进行注册，并可以对XID(TRANSACTION IDS)进行操作。</li><li>ax_reg,ax_unreg；允许一个资源管理器在一个TMS(TRANSACTION MANAGER SERVER)中动态注册或撤消注册。<br>XA的一些问题：</li><li>性能（阻塞、响应时间增加、死锁）；</li><li>依赖于独立的J2EE中间件，Weblogic、Jboss，后期轻量级的Atomikos、Narayana、Bitronix；</li><li>不是所有资源(RM)都支持XA协议；</li></ul><h4 id="JTA（Java-Transaction-API）"><a href="#JTA（Java-Transaction-API）" class="headerlink" title="JTA（Java Transaction API）"></a>JTA（Java Transaction API）</h4><p>即Java的事务API，基于XA实现，也就是RM需要支持XA，所以也有JTA(XA)的说法，JTA仅定义了接口。主要包括javax.sql.XADataResource、javax.sql.XAConnection、javax.sql.XAException、javax.transaction.xa.XAResource、javax.transaction.Xid。 目下JTA的实现有几种形式：</p><ul><li>J2EE容器提供的JTA实现（Weblogic、JBoss ）；</li><li>JOTM（Java Open Transaction Manager）、Atomikos，可独立于J2EE容器的环境下实现JTA；</li></ul><h4 id="二阶段提交（2PC）"><a href="#二阶段提交（2PC）" class="headerlink" title="二阶段提交（2PC）"></a>二阶段提交（2PC）</h4><p>2PC就是分布式事务中将事务分为两步进行提交。基于数据库的XA协议完成事务本质上就是二阶段提交（XA、JTA/JTS）。</p><ul><li><p>协调者（Coordinater）：事务管理器（TM）</p></li><li><p>参与者（participants）：资源管理器（RM）<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_4.png"></p></li><li><p><strong>准备阶段</strong>：  </p><ul><li>协调者向参与者发送prepare信息，以询问参与者是否能够提交事务；</li><li>参与者在收到prepare信息后，进行本地事务的预处理，但不提交。并根据处理结果返回，失败not commit or 成功ready ；</li></ul></li><li><p><strong>提交阶段</strong>：  </p><ul><li>如协调者收到参与者的失败消息，则向每个参与者发送rollback消息进行回滚；</li><li>所有参与者都返回ready，则向每个参与者发送提交commit消息，通知参与者进行事务提交；</li></ul></li></ul><p>两阶段提交的一些问题:</p><ul><li>同步阻塞，事务执行过程中所有参与者都是阻塞型的，第三方参与者访问参与者占有的资源时会被阻塞；</li><li>单点故障，协调者一旦发生故障，参与者会被阻塞。尤其在提交阶段，所有参与者都处于锁定资源状态中，无法完成事务操作；（可以选择新的协调者，但无法解决参与者被阻塞的问题）；</li><li>数据不一致，提交阶段协调者向参与者发送commit信息，发生局部网络故障，会导致存在参与者未收到commit信息无法提交事务情况，导致出现数据不一致现象；</li></ul><h4 id="三阶段提交（3PC）"><a href="#三阶段提交（3PC）" class="headerlink" title="三阶段提交（3PC）"></a>三阶段提交（3PC）</h4><p>相比于2PC，3PC把2PC的准备阶段再次进行拆分，并且3PC引入了参与者超时机制。</p><ul><li>canCommit：协调者询问参与者，是否具备执行事务的条件，参与者进行自身事务必要条件的检查；</li><li>preCommit：协调者通知参与者进行事务的预提交；</li><li>doCommit：协调者根据preCommit阶段参与者的反馈结果通知参与者是否进行事务提交或是进行事务回滚。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_5.png"></li></ul><h4 id="TCC事务补偿方案"><a href="#TCC事务补偿方案" class="headerlink" title="TCC事务补偿方案"></a>TCC事务补偿方案</h4><p>TCC的核心思想就是校验、资源锁定、补偿，对每个操作（Try）都提供确认（Confirm）和取消（cancel）的操作，这样根据操作的结果，来确认是进行Confirm还是Cancel。<br>可以看出XA的两阶段提交是基于资源层面的，而TCC也是一种两阶段提交，但它是基于应用层面的。</p><ul><li>Try：主要负责对业务进行数据检查和资源预留，例如：对资金进行冻结；对状态更改为处理中；</li><li>Confirm：确认执行业务的操作，例如：进行实际资金扣除；更改状态为最终结果；</li><li>Cancel：取消执行业务的操作，例如：解冻资金；更改状态为未处理；</li></ul><p>TCC存在的一些问题：</p><ul><li>业务操作的是不同服务的Try来进行资源预留，每个Try都是独立完成本地事务，因此不会对资源一直加锁。</li><li>业务服务需要提供try、confirm、cancel，业务侵入性强，如不适用三方框架要做到对各阶段状态的感知，比较麻烦。</li><li>Confirm/Cancel要做幂等性设计。</li></ul><p>常用TCC框架：<br>tcc-transaction、ByteTCC、spring-cloud-rest-tcc、Himly</p><p>常见的微服务系统大部分接口调用是同步的，这时候使用TCC来保证一致性是比较合适的。</p><h4 id="SAGA"><a href="#SAGA" class="headerlink" title="SAGA"></a>SAGA</h4><p>Saga的核心是补偿，与TCC不同的是Saga不需要Try，而是直接进行confirm、cancel操作。  </p><ul><li>Confirm：依次按顺序依次执行资源操作，各个资源直接处理本地事务，如无问题，二阶段什么都不用做；</li><li>Cancel：异常情况下需要调用的补偿事务（逆操作）来保证数据的一致性。</li></ul><p>可以看出，Saga和TCC有些类似，都是补偿型事务</p><p>优势：</p><ul><li>一阶段提交本地事务，无锁，高性能；</li><li>事件驱动模式，参与者可异步执行，高吞吐；</li><li>应用成本低，补偿服务易于实现；</li></ul><p>劣势：</p><ul><li>无法保证隔离性（脏写）</li></ul><h4 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h4><p>有一些情况，服务间调用时异步的，服务A将消息发送到MQ，服务B进行消息的消费。这时我们就需要用到可靠消息最终一致性来解决分布式事务问题</p><ul><li>可靠消息：即这个消息一定是可靠的，并且最终一定需要被消费的。 </li><li>最终一致性：过程中数据存在一定时间内的不一致，但超过限定时间后，需要最终会保持一致。</li></ul><p>保证以上两点的情况下，可以通过消息中间件（RocketMQ）来完成分布式事务处理，因为RocketMQ支持事务消息，可以方便的让我们进行分布式事务控制。</p><p>RocketMQ的事务消息的原理：<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_6.png"></p><p>half message：半消息，此时消息不能被consumer所发现和消费，需producer进行二次消息确认。</p><ul><li>producer发送half message给MQ Server；</li><li>producer根据MQ Server应答结果判断half message是否发送成功；</li><li>producer处理本地事务；</li><li>producer发送最终确认消息commit / rollback；</li><li>commit：consumer对消息可见并进行消费；</li><li>rollback：discard抛弃消息，consumer无法进行消息消费；</li></ul><p>如遇异常情况下step4最终确认消息为达到MQ Server，MQ Server会定期查询当前处于半消息状态下的消息，主动进行消息回查来询问producer该消息的最终状态；</p><ul><li>producer检查本地事务执行的最终结果；</li><li>producer根据检查到的结果，再次提交确认消息，MQ Server仍然按照step4进行后续操作。</li></ul><p>事务消息发送对应步骤1、2、3、4，事务消息回查对应步骤5、6、7。<br>由以上步骤可以看出通过事务性消息的两步操作，避免了消息直接投递所产生一些问题。最终投递到MQ Server的消息，是真实可靠且必须被消费的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="分布式事务设计权衡点"><a href="#分布式事务设计权衡点" class="headerlink" title="分布式事务设计权衡点"></a>分布式事务设计权衡点</h3><ul><li>实现复杂度：事务模式与当前业务结合，实施成本是否过高；</li><li>业务侵入性：基于注解、XML、补偿逻辑； </li><li>TC/TM部署：独立部署、与应用部署；</li><li>性能：回滚概率、回滚所付出的代价、响应时间、吞吐量；</li><li>高可用：数据库、注册中心、配置中心</li><li>持久化：文件、数据库；</li><li>同步/异步：分布式事务执行过程中是否阻塞，还是非阻塞；</li></ul><h3 id="分布式事务解决方案对比"><a href="#分布式事务解决方案对比" class="headerlink" title="分布式事务解决方案对比"></a>分布式事务解决方案对比</h3><p>分布式系统中，基于不同的一致性需求产生了不同的分布式事务解决方案，追求强一致的两阶段提交、追求最终一致性的柔性事务和事务消息等等。  </p><p>我们综合对比下几种分布式事务解决方案：  </p><ul><li>一致性保证：XA &gt; TCC = SAGA &gt; 事务消息  </li><li>业务友好性：XA &gt; 事务消息 &gt; SAGA &gt; TCC  </li><li>性 能 损 耗：XA &gt; TCC &gt; SAGA = 事务消息</li></ul><p>在柔性事务解决方案中，虽然SAGA和TCC看上去可以保证数据的最终一致性，但分布式系统的生产环境复杂多变，某些情况是可以导致柔性事务机制失效的，所以无论使用那种方案，都需要最终的兜底策略，人工校验，修复数据。</p><h3 id="分布式事务框架Seata"><a href="#分布式事务框架Seata" class="headerlink" title="分布式事务框架Seata"></a>分布式事务框架Seata</h3><p>阿里开源的Seata 是一款分布式事务解决方案，提供了 AT、TCC、SAGA 和 XA 事务模式。</p><p>Seata架构的亮点主要有几个:</p><ul><li>应用层基于SQL解析实现了自动补偿，从而最大程度的降低业务侵入性；</li><li>将分布式事务中TC（事务协调者）独立部署，负责事务的注册、回滚（支持多种注册中心形式以及本地文件形式）；</li><li>通过全局锁实现了写隔离与读隔离。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 事务 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统02之分布式ID解决方案</title>
      <link href="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么需要分布式ID"><a href="#为什么需要分布式ID" class="headerlink" title="为什么需要分布式ID"></a>为什么需要分布式ID</h2><p>在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如数据量太大之后，往往需要对进行对数据进行分库分表，分库分表后需要有一个唯一 ID 来标识一条数据或消息，数据库的自增 ID 显然不能满足需求。</p><h2 id="分布式ID生成方案"><a href="#分布式ID生成方案" class="headerlink" title="分布式ID生成方案"></a>分布式ID生成方案</h2><p><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/img_1.png"></p><h3 id="数据库自增ID"><a href="#数据库自增ID" class="headerlink" title="数据库自增ID"></a>数据库自增ID</h3><p>需要一个单独的Mysql实例，虽然可行，但是基于性能与可靠性来考虑的话都不够，业务系统每次需要一个ID时，都需要请求数据库获取，性能低，并且如果此数据库实例下线了，那么将影响所有的业务系统。</p><h3 id="数据库多主模式"><a href="#数据库多主模式" class="headerlink" title="数据库多主模式"></a>数据库多主模式</h3><p>多个数据库主节点实例，单独设置步长防止产生相同ID，或者使用号段模式每个节点生产部分号段的ID</p><h3 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h3><p>核心思想是：分布式ID固定是一个long型的数字，一个long型占8个字节，也就是64个bit，原始snowflake算法中对于bit的分配如下图：<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/img.png"></p><ul><li>第一个bit位是标识部分，在java中由于long的最高位是符号位，正数是0，负数是1，一般生成的ID为正数，所以固定为0。</li><li>时间戳部分占41bit，这个是毫秒级的时间，一般实现上不会存储当前的时间戳，而是时间戳的差值（当前时间-固定的开始时间），这样可以使产生的ID从更小值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69年</li><li>工作机器id占10bit，这里比较灵活，比如，可以使用前5位作为数据中心机房标识，后5位作为单机房机器标识，可以部署1024个节点。</li><li>序列号部分占12bit，支持同一毫秒内同一个节点可以生成4096个ID</li><li>备注： 工作机器ID可以通过某种改造自动生成。</li></ul><h3 id="Redis自增ID"><a href="#Redis自增ID" class="headerlink" title="Redis自增ID"></a>Redis自增ID</h3><p>使用Redis来生成分布式ID，其实和利用Mysql自增ID类似，可以利用Redis中的incr命令来实现原子性的自增与返回，比如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set seq_id 1 // 初始化自增ID为1 OK </span><br><span class="line">127.0.0.1:6379&gt; incr seq_id // 增加1，并返回 (integer) 2 </span><br><span class="line">127.0.0.1:6379&gt; incr seq_id // 增加1，并返回</span><br><span class="line">备注：使用redis需要考虑持久化问题,RDB&amp;AOF。</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统01之分布式系统理论</title>
      <link href="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"/>
      <url>/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><h3 id="名词解析"><a href="#名词解析" class="headerlink" title="名词解析"></a>名词解析</h3><p>CAP理论作为分布式系统的基础理论,它描述的是一个分布式系统在以下三个特性中：</p><ul><li><strong>一致性（Consistency）</strong><ul><li>所有节点访问同一份最新的数据副本</li></ul></li><li><strong>可用性（Availability）</strong><ul><li>非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。</li></ul></li><li><strong>分区容错性（Partition tolerance）</strong><ul><li>分布式系统出现网络分区（多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域）的时候，仍然能够对外提供服务。<br>最多满足其中的两个特性。 </li></ul></li></ul><p>也就是下图所描述的。分布式系统要么满足CA,要么CP，要么AP。无法同时满足CAP。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/img.png"></p><h3 id="CAP三者不可兼得，该如何取舍："><a href="#CAP三者不可兼得，该如何取舍：" class="headerlink" title="CAP三者不可兼得，该如何取舍："></a>CAP三者不可兼得，该如何取舍：</h3><ul><li><strong>CA</strong>: 优先保证一致性和可用性，放弃分区容错。 这也意味着放弃系统的扩展性，系统不再是分布式的，有违设计的初衷。<ul><li>当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。</li><li><strong>因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。</strong></li></ul></li><li><strong>CP</strong>: 优先保证一致性和分区容错性，放弃可用性。 在<strong>数据一致性要求比较高的场合</strong>(譬如:zookeeper,Hbase) 是比较常见的做法，一旦发生网络故障或者消息丢失，就会牺牲用户体验，等恢复之后用户才逐渐能访问。</li><li><strong>AP</strong>: 优先保证可用性和分区容错性，放弃一致性。 NoSQL中的Cassandra 就是这种架构。跟CP一样，放弃一致性不是说一致性就不保证了，而是逐渐的变得一致。</li></ul><h3 id="实际应用案例–注册中心"><a href="#实际应用案例–注册中心" class="headerlink" title="实际应用案例–注册中心"></a>实际应用案例–注册中心</h3><p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos…。 </p><ul><li>ZooKeeper 保证的是 CP。<br>任何时刻对 ZooKeeper 的读请求都能得到一致性的结果。<br>但是， ZooKeeper 不保证每次请求的可用性，比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。</li><li>Eureka 保证的则是 AP。<br>Eureka 在设计的时候就是优先保证 A （可用性）。<br>在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。<br>因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。<br>Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。   </li><li>Nacos 不仅支持 CP 也支持 AP。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等。<br>如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”（网络连接通信正常）的话，我们要思考如何保证 CA。</p><h2 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h2><h3 id="BASE理论名词解析"><a href="#BASE理论名词解析" class="headerlink" title="BASE理论名词解析"></a>BASE理论名词解析</h3><ul><li><strong>基本可用（Basically Available）</strong><br>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。<br>什么叫允许损失部分可用性呢？ <ul><li>响应时间上的损失: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。 </li><li>系统功能上的损失：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。</li></ul></li><li><strong>软状态（Soft State）</strong><br>软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</li><li><strong>最终一致性（Eventually Consistent）</strong><br>虽然允许软状态，但是系统不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。<br>实际工程实践中，最终一致性分为5种：<ul><li>因果一致性（Causal consistency）<br>如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。</li><li>读己之所写（Read your writes）<br>节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。</li><li>会话一致性（Session consistency）<br>系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</li><li>单调读一致性（Monotonic read consistency）<br>如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。</li><li>单调写一致性（Monotonic write consistency）<br>一个系统要能够保证来自同一个节点的写操作被顺序的执行。</li></ul></li></ul><h3 id="系统一致性说明"><a href="#系统一致性说明" class="headerlink" title="系统一致性说明"></a>系统一致性说明</h3><ul><li><strong>强一致性</strong>：系统写入了什么，读出来的就是什么。 </li><li><strong>弱一致性</strong>：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</li><li><strong>最终一致性</strong>：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</li></ul><h3 id="BASE理论的核心思想"><a href="#BASE理论的核心思想" class="headerlink" title="BASE理论的核心思想"></a>BASE理论的核心思想</h3><p>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</span><br></pre></td></tr></table></figure><p>CAP的3选2实际是个伪命题，实际上，系统没有发生P(分区)的话，必须在C（一致性）和A（可用性）之间任选其一。<br>分区的情况很少出现，CAP在大多时间能够同时满足C和A。<br>对于分区存在或者探知其影响的情况下，需要提供一种预备策略做出处理：</p><ul><li>探知分区的发生；</li><li>进入显示的分区模式，限制某些操作；</li><li>启动恢复过程，恢复数据一致性，补偿分区发生期间的错误。</li></ul><p>因此，AP方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。<br>在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。</p><h2 id="ACID本地事务四大特性"><a href="#ACID本地事务四大特性" class="headerlink" title="ACID本地事务四大特性"></a>ACID本地事务四大特性</h2><ul><li><strong>原子性（atomicity）</strong><br>一个事务中的所有操作，不可分割，要么全部成功，要么全部失败；</li><li><strong>一致性（consistency）</strong><br>一个事务执行前与执行后数据的完整性必须保持一致；</li><li><strong>隔离性（isolation）</strong><br>一个事务的执行，不能被其他事务干扰，多并发时事务之间要相互隔离；</li><li><strong>持久性（durability）</strong><br>一个事务一旦被提交，它对数据库中数据的改变是永久性的。</li></ul><h2 id="幂等性设计"><a href="#幂等性设计" class="headerlink" title="幂等性设计"></a>幂等性设计</h2><p>幂等（Idempotent）是一个数学与计算机学中的概念。f(n) = 1^n // 无论n等于多少，f(n)永远值等于1；在程序中，使用相同参数执行同一个方法，每一次执行结果都是相同的，即具有幂等性。</p><h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><ul><li>ACID 是数据库事务完整性的理论，</li><li>CAP 是分布式系统设计理论，</li><li>BASE 是 CAP 理论中 AP 方案的延伸。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 设计理念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统00之什么是分布式系统</title>
      <link href="/2020/06/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
      <url>/2020/06/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式系统"><a href="#什么是分布式系统" class="headerlink" title="什么是分布式系统"></a>什么是分布式系统</h2><p>分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。</p><p>分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是<strong>利用更多的机器，处理更多的数据</strong>。</p><p>首先需要明确的是，只有</p><ul><li>单个节点的处理能力无法满足日益增长的计算、存储任务</li><li>且硬件的提升（加内存、加磁盘、使用更好的CPU）高昂到得不偿失</li><li>应用程序也不能进一步优化  </li></ul><p>我们才需要考虑分布式系统。</p><p>因为，分布式系统要解决的问题本身就是和单机系统一样的，而由于分布式系统多节点、通过网络通信的拓扑结构，会引入很多单机系统没有的问题，为了解决这些问题又会引入更多的机制、协议，带来更多的问题。</p><p>分布式系统怎么将任务分发到这些计算机节点呢，很简单的思想，分而治之，即分片（partition）。对于计算，那么就是对计算任务进行切换，每个节点算一些，最终汇总就行了，这就是MapReduce的思想；对于存储，更好理解一下，每个节点存一部分数据就行了。当数据规模变大的时候，Partition是唯一的选择，同时也会带来一些好处：</p><ul><li>提升性能和并发，操作被分发到不同的分片，相互独立</li><li>提升系统的可用性，即使部分分片不能用，其他分片不会受到影响</li></ul><p>理想的情况下，有分片就行了，但事实的情况却不大理想。</p><p>原因在于，分布式系统中有大量的节点，且通过网络通信。单个节点的故障（进程crash、断电、磁盘损坏）是个小概率事件，但整个系统的故障率会随节点的增加而指数级增加，网络通信也可能出现断网、高延迟的情况。在这种一定会出现的“异常”情况下，分布式系统还是需要继续稳定的对外提供服务，即需要较强的容错性。最简单的办法，就是冗余或者复制集（Replication），即多个节点负责同一个任务，最为常见的就是分布式存储中，多个节点复杂存储同一份数据，以此增强可用性与可靠性。同时，Replication也会带来性能的提升，比如数据的locality可以减少用户的等待时间。</p><p><img src="/2020/06/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/img.png"></p><p>Partition和Replication是解决分布式系统问题的一记组合拳，很多具体的问题都可以用这个思路去解决。但这并不是银弹，往往是为了解决一个问题，会引入更多的问题，比如为了可用性与可靠性保证，引用了冗余（复制集）。有了冗余，各个副本间的一致性问题就变得很头疼，一致性在系统的角度和用户的角度又有不同的等级划分。如果要保证强一致性，那么会影响可用性与性能，在一些应用（比如电商、搜索）是难以接受的。如果是最终一致性，那么就需要处理数据冲突的情况。CAP、FLP这些理论告诉我们，在分布式系统中，没有最佳的选择，都是需要权衡，做出最合适的选择。</p><h2 id="分布式系统面临的挑战"><a href="#分布式系统面临的挑战" class="headerlink" title="分布式系统面临的挑战"></a>分布式系统面临的挑战</h2><ul><li><p>异构的机器与网络：</p><p>  分布式系统中的机器，配置不一样，其上运行的服务也可能由不同的语言、架构实现，因此处理能力也不一样；节点间通过网络连接，而不同网络运营商提供的网络的带宽、延时、丢包率又不一样。怎么保证大家齐头并进，共同完成目标，这四个不小的挑战。</p></li><li><p>普遍的节点故障：</p><p>  虽然单个节点的故障概率较低，但节点数目达到一定规模，出故障的概率就变高了。分布式系统需要保证故障发生的时候，系统仍然是可用的，这就需要监控节点的状态，在节点故障的情况下将该节点负责的计算、存储任务转移到其他节点</p></li><li><p>不可靠的网络：</p><p>  节点间通过网络通信，而网络是不可靠的。可能的网络问题包括：网络分割、延时、丢包、乱序。</p><p>  相比单机过程调用，网络通信最让人头疼的是超时：节点A向节点B发出请求，在约定的时间内没有收到节点B的响应，那么B是否处理了请求，这个是不确定的，这个不确定会带来诸多问题，最简单的，是否要重试请求，节点B会不会多次处理同一个请求。</p></li></ul><p>总而言之，分布式的挑战来自<strong>不确定性</strong>，不确定计算机什么时候crash、断电，不确定磁盘什么时候损坏，不确定每次网络通信要延迟多久，也不确定通信对端是否处理了发送的消息。而分布式的规模放大了这个不确定性，不确定性是令人讨厌的，所以有诸多的分布式理论、协议来保证在这种不确定性的情况下，系统还能继续正常工作。</p><h2 id="分布式系统特性与衡量标准"><a href="#分布式系统特性与衡量标准" class="headerlink" title="分布式系统特性与衡量标准"></a>分布式系统特性与衡量标准</h2><ul><li><p><strong>透明性</strong><br>使用分布式系统的用户并不关心系统是怎么实现的，也不关心读到的数据来自哪个节点，对用户而言，分布式系统的最高境界是用户根本感知不到这是一个分布式系统。</p></li><li><p><strong>可扩展性</strong><br>分布式系统的根本目标就是为了处理单个计算机无法处理的任务，当任务增加的时候，分布式系统的处理能力需要随之增加。简单来说，要比较方便的通过增加机器来应对数据量的增长，同时，当任务规模缩减的时候，可以撤掉一些多余的机器，达到动态伸缩的效果</p></li><li><p><strong>可用性与可靠性</strong><br>一般来说，分布式系统是需要长时间甚至7*24小时提供服务的。可用性是指系统在各种情况对外提供服务的能力，简单来说，可以通过不可用时间与正常服务时间的必知来衡量；而可靠性而是指计算结果正确、存储的数据不丢失。</p></li><li><p><strong>高性能</strong><br>不管是单机还是分布式系统，大家都非常关注性能。不同的系统对性能的衡量指标是不同的，最常见的：高并发，单位时间内处理的任务越多越好；低延迟：每个任务的平均时间越少越好。这个其实跟操作系统CPU的调度策略很像</p></li><li><p><strong>一致性</strong><br>分布式系统为了提高可用性可靠性，一般会引入冗余（复制集）。那么如何保证这些节点上的状态一致，这就是分布式系统不得不面对的一致性问题。一致性有很多等级，一致性越强，对用户越友好，但会制约系统的可用性；一致性等级越低，用户就需要兼容数据不一致的情况，但系统的可用性、并发性很高很多。</p></li></ul><h2 id="一个简化的架构图"><a href="#一个简化的架构图" class="headerlink" title="一个简化的架构图"></a>一个简化的架构图</h2><p><img src="/2020/06/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/img_2.png"></p><h3 id="概念及其实现"><a href="#概念及其实现" class="headerlink" title="概念及其实现"></a>概念及其实现</h3><p>负载均衡：<br>Nginx：高性能、高并发的web服务器；功能包括负载均衡、反向代理、静态内容缓存、访问控制；工作在应用层</p><p>LVS： Linux virtual server，基于集群技术和Linux操作系统实现一个高性能、高可用的服务器；工作在网络层</p><p>webserver：<br>Java：Tomcat，Apache，Jboss</p><p>Python：gunicorn、uwsgi、twisted、webpy、tornado</p><p>service：<br>SOA、微服务、spring boot，django</p><p>容器：<br>docker，kubernetes</p><p>cache：<br>memcache、redis等</p><p>协调中心：<br>zookeeper、etcd等</p><p>zookeeper使用了Paxos协议Paxos是强一致性，高可用的去中心化分布式。zookeeper的使用场景非常广泛，之后细讲。</p><p>rpc框架：<br>grpc、dubbo、brpc</p><p>dubbo是阿里开源的Java语言开发的高性能RPC框架，在阿里系的诸多架构中，都使用了dubbo + spring boot</p><p>消息队列：<br>kafka、rabbitMQ、rocketMQ、QSP</p><p>消息队列的应用场景：异步处理、应用解耦、流量削锋和消息通讯</p><p>实时数据平台：<br>storm、akka</p><p>离线数据平台：<br>hadoop、spark</p><p>PS: spark、akka、kafka都是scala语言写的，看到这个语言还是很牛逼的</p><p>dbproxy：<br>cobar也是阿里开源的，在阿里系中使用也非常广泛，是关系型数据库的sharding + replica 代理</p><p>db：<br>mysql、oracle、MongoDB、HBase</p><p>搜索：<br>elasticsearch、solr</p><p>日志：<br>rsyslog、elk、flume</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 设计理念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之分布式定时调度Elastic-Job解析</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Elastic-Job%E8%A7%A3%E6%9E%90/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Elastic-Job%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>待完善，具体信息参考： </p><p><a href="http://www.iocoder.cn/categories/Elastic-Job-Lite/?vip&architect-awesome">Elastic-Job-Lite 源码解析</a></p><p><a href="http://www.iocoder.cn/categories/Elastic-Job-Cloud/?vip&architect-awesome">Elastic-Job-Cloud 源码解析</a></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之分布式定时调度Quartz集群基本实现原理</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="Quartz集群架构"><a href="#Quartz集群架构" class="headerlink" title="Quartz集群架构"></a>Quartz集群架构</h3><p>一个Quartz集群中的每个节点是一个独立的Quartz应用，它又管理着其他的节点。这就意味着你必须对每个节点分别启动或停止。Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的，如图2.1所示。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img.png"></p><h3 id="Quartz集群相关数据库表"><a href="#Quartz集群相关数据库表" class="headerlink" title="Quartz集群相关数据库表"></a>Quartz集群相关数据库表</h3><p>因为Quartz集群依赖于数据库，所以必须首先创建Quartz数据库表，Quartz发布包中包括了所有被支持的数据库平台的SQL脚本。这些SQL脚本存放于<quartz_home>/docs/dbTables 目录下。</quartz_home></p><p>这里采用的Quartz 1.8.4版本，总共12张表，不同版本，表个数可能不同。数据库为mysql，用tables_mysql.sql创建数据库表。</p><p>Quartz 1.8.4在mysql数据库中生成的表：<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img_1.png"></p><p>Quartz数据表简介：<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img_2.png"></p><h3 id="Quartz-Scheduler在集群中的启动流程"><a href="#Quartz-Scheduler在集群中的启动流程" class="headerlink" title="Quartz Scheduler在集群中的启动流程"></a>Quartz Scheduler在集群中的启动流程</h3><p>Quartz Scheduler自身是察觉不到被集群的，只有配置给Scheduler的JDBC JobStore才知道。<br>当Quartz Scheduler启动时，它调用JobStore的schedulerStarted()方法，它告诉JobStore Scheduler已经启动了。<br>schedulerStarted() 方法是在JobStoreSupport类中实现的。<br>JobStoreSupport类会根据<strong>quartz.properties</strong>文件中的设置来确定Scheduler实例是否参与到集群中。<br>假如配置了集群，一个新的ClusterManager类的实例就被创建、初始化并启动。<br>ClusterManager是在JobStoreSupport类中的一个内嵌类，继承了java.lang.Thread，它会定期运行，并对Scheduler实例执行检入的功能。<br>Scheduler也要查看是否有任何一个别的集群节点失败了。检入操作执行周期在quartz.properties中配置。</p><h4 id="侦测失败的Scheduler节点"><a href="#侦测失败的Scheduler节点" class="headerlink" title="侦测失败的Scheduler节点"></a>侦测失败的Scheduler节点</h4><p>当一个Scheduler实例执行检入时，它会查看是否有其他的Scheduler实例在到达他们所预期的时间还未检入。这是通过检查SCHEDULER_STATE表中Scheduler记录在LAST_CHEDK_TIME列的值是否早于org.quartz.jobStore.clusterCheckinInterval来确定的。如果一个或多个节点到了预定时间还没有检入，那么运行中的Scheduler就假定它(们) 失败了。</p><h4 id="从故障实例中恢复Job"><a href="#从故障实例中恢复Job" class="headerlink" title="从故障实例中恢复Job"></a>从故障实例中恢复Job</h4><p>当一个Sheduler实例在执行某个Job时失败了，有可能由另一正常工作的Scheduler实例接过这个Job重新运行。要实现这种行为，配置给JobDetail对象的Job可恢复属性必须设置为true（job.setRequestsRecovery(true)）。如果可恢复属性被设置为false(默认为false)，当某个Scheduler在运行该job失败时，它将不会重新运行；而是由另一个Scheduler实例在下一次触发时间触发。Scheduler实例出现故障后多快能被侦测到取决于每个Scheduler的检入间隔（即2.3中提到的org.quartz.jobStore.clusterCheckinInterval）。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><h4 id="时间同步问题"><a href="#时间同步问题" class="headerlink" title="时间同步问题"></a>时间同步问题</h4><p>Quartz实际并不关心你是在相同还是不同的机器上运行节点。当集群放置在不同的机器上时，称之为水平集群。节点跑在同一台机器上时，称之为垂直集群。对于垂直集群，存在着单点故障的问题。这对高可用性的应用来说是无法接受的，因为一旦机器崩溃了，所有的节点也就被终止了。对于水平集群，存在着时间同步问题。</p><p>节点用时间戳来通知其他实例它自己的最后检入时间。假如节点的时钟被设置为将来的时间，那么运行中的Scheduler将再也意识不到那个结点已经宕掉了。另一方面，如果某个节点的时钟被设置为过去的时间，也许另一节点就会认定那个节点已宕掉并试图接过它的Job重运行。最简单的同步计算机时钟的方式是使用某一个Internet时间服务器(Internet Time Server ITS)。</p><h4 id="节点争抢Job问题"><a href="#节点争抢Job问题" class="headerlink" title="节点争抢Job问题"></a>节点争抢Job问题</h4><p>因为Quartz使用了一个随机的负载均衡算法， Job以随机的方式由不同的实例执行。Quartz官网上提到当前，还不存在一个方法来指派(钉住) 一个 Job 到集群中特定的节点。</p><h4 id="从集群获取Job列表问题"><a href="#从集群获取Job列表问题" class="headerlink" title="从集群获取Job列表问题"></a>从集群获取Job列表问题</h4><p>当前，如果不直接进到数据库查询的话，还没有一个简单的方式来得到集群中所有正在执行的Job列表。请求一个Scheduler实例，将只能得到在那个实例上正运行Job的列表。Quartz官网建议可以通过写一些访问数据库JDBC代码来从相应的表中获取全部的Job信息。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
            <tag> Quartz </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之分布式定时调度优秀国产调度系统</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h3 id="opencron"><a href="#opencron" class="headerlink" title="opencron"></a>opencron</h3><p>opencron 是一个功能完善且通用的开源定时任务调度系统，拥有先进可靠的自动化任务管理调度功能，提供可操作的 web 图形化管理满足多种场景下各种复杂的定时任务调度，同时集成了 linux 实时监控、webssh 等功能特性。</p><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img.png"></p><h3 id="LTS"><a href="#LTS" class="headerlink" title="LTS"></a>LTS</h3><p>LTS，light-task-scheduler，是一款分布式任务调度框架, 支持实时任务、定时任务和 Cron 任务。有较好的伸缩性和扩展性，提供对 Spring 的支持（包括 Xml 和注解），提供业务日志记录器。支持节点监控、任务执行监、JVM 监控，支持动态提交、更改、停止任务。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_1.png"></p><h3 id="XXL-JOB"><a href="#XXL-JOB" class="headerlink" title="XXL-JOB"></a>XXL-JOB</h3><p>XXL-JOB 是一个轻量级分布式任务调度框架，支持通过 Web 页面对任务进行 CRUD 操作，支持动态修改任务状态、暂停/恢复任务，以及终止运行中任务，支持在线配置调度任务入参和在线查看调度结果。</p><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_2.png"></p><h3 id="Elastic-Job"><a href="#Elastic-Job" class="headerlink" title="Elastic-Job"></a>Elastic-Job</h3><p>Elastic-Job 是一个分布式调度解决方案，由两个相互独立的子项目 Elastic-Job-Lite 和 Elastic-Job-Cloud 组成。定位为轻量级无中心化解决方案，使用 jar 包的形式提供分布式任务的协调服务。支持分布式调度协调、弹性扩容缩容、失效转移、错过执行作业重触发、并行调度、自诊断和修复等等功能特性。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_3.png"></p><h3 id="Uncode-Schedule"><a href="#Uncode-Schedule" class="headerlink" title="Uncode-Schedule"></a>Uncode-Schedule</h3><p>Uncode-Schedule 是基于 ZooKeeper + Quartz / spring task 的分布式任务调度组件，确保每个任务在集群中不同节点上不重复的执行。支持动态添加和删除任务，支持添加 ip 黑名单，过滤不需要执行任务的节点。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_4.png"></p><h3 id="Antares"><a href="#Antares" class="headerlink" title="Antares"></a>Antares</h3><p>Antares 是一款基于 Quartz 机制的分布式任务调度管理平台，内部重写执行逻辑，一个任务仅会被服务器集群中的某个节点调度。用户可通过对任务预分片，有效提升任务执行效率；也可通过控制台 antares-tower 对任务进行基本操作，如触发，暂停，监控等。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_5.png"></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之单机定时调度Quartz使用总结及原理解析</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="Quartz可以用来做什么？"><a href="#Quartz可以用来做什么？" class="headerlink" title="Quartz可以用来做什么？"></a>Quartz可以用来做什么？</h2><p>在某一个有规律的时间点干某件事。<br>并且时间的触发的条件可以非常复杂（比如每月最后一个工作日的17:50），复杂到需要一个专门的框架来干这个事。<br>Quartz就是来干这样的事，你给它一个触发条件的定义，它负责到了时间点，触发相应的Job起来干活。</p><h2 id="Quartz使用总结"><a href="#Quartz使用总结" class="headerlink" title="Quartz使用总结"></a>Quartz使用总结</h2><h3 id="从简单示例看Quartz核心设计"><a href="#从简单示例看Quartz核心设计" class="headerlink" title="从简单示例看Quartz核心设计"></a>从简单示例看Quartz核心设计</h3><h4 id="一个简单的Demo程序"><a href="#一个简单的Demo程序" class="headerlink" title="一个简单的Demo程序"></a>一个简单的Demo程序</h4><p>这里面的所有例子都是基于Quartz 2.2.1</p><details><summary>点击展开/收起</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.quartz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DateBuilder.newDate;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.JobBuilder.newJob;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.SimpleScheduleBuilder.simpleSchedule;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.TriggerBuilder.newTrigger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.GregorianCalendar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Scheduler;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Trigger;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.StdSchedulerFactory;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.calendar.AnnualCalendar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuartzTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//创建scheduler</span></span><br><span class="line">            Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义一个Trigger</span></span><br><span class="line">            Trigger trigger = newTrigger().withIdentity(<span class="string">&quot;trigger1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//定义name/group</span></span><br><span class="line">                .startNow()<span class="comment">//一旦加入scheduler，立即生效</span></span><br><span class="line">                .withSchedule(simpleSchedule() <span class="comment">//使用SimpleTrigger</span></span><br><span class="line">                    .withIntervalInSeconds(<span class="number">1</span>) <span class="comment">//每隔一秒执行一次</span></span><br><span class="line">                    .repeatForever()) <span class="comment">//一直执行，奔腾到老不停歇</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义一个JobDetail</span></span><br><span class="line">            JobDetail job = newJob(HelloQuartz.class) <span class="comment">//定义Job类为HelloQuartz类，这是真正的执行逻辑所在</span></span><br><span class="line">                .withIdentity(<span class="string">&quot;job1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//定义name/group</span></span><br><span class="line">                .usingJobData(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;quartz&quot;</span>) <span class="comment">//定义属性</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//加入这个调度</span></span><br><span class="line">            scheduler.scheduleJob(job, trigger);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//启动之</span></span><br><span class="line">            scheduler.start();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//运行一段时间后关闭</span></span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            scheduler.shutdown(<span class="keyword">true</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.quartz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.quartz.DisallowConcurrentExecution;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Job;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionContext;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloQuartz</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        JobDetail detail = context.getJobDetail();</span><br><span class="line">        String name = detail.getJobDataMap().getString(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;say hello to &quot;</span> + name + <span class="string">&quot; at &quot;</span> + <span class="keyword">new</span> Date());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="Quartz核心元素："><a href="#Quartz核心元素：" class="headerlink" title="Quartz核心元素："></a>Quartz核心元素：</h4><ul><li><p>Scheduler：调度器。<br>负责整个定时系统的调度，内部通过线程池进行调度。</p></li><li><p>Trigger： 定义触发的条件。<br>主要有四种类型：SimpleTrigger、CronTrigger、DataIntervalTrigger、NthIncludedTrigger，在项目中常用的为：SimpleTrigger和CronTrigger。。</p></li><li><p>JobDetail：定义任务数据。<br>记录Job的名字、组及任务执行的具体类和任务执行所需要的参数</p></li><li><p>Job： 真正的执行逻辑。  </p></li></ul><p>为什么设计成JobDetail + Job，不直接使用Job？<br>这是因为任务是有可能并发执行，如果Scheduler直接使用Job，就会存在对同一个Job实例并发访问的问题。<br>而JobDetail &amp; Job 方式，sheduler每次执行，都会根据JobDetail创建一个新的Job实例，这样就可以规避并发访问的问题。</p><h4 id="核心元素之间的关系"><a href="#核心元素之间的关系" class="headerlink" title="核心元素之间的关系"></a>核心元素之间的关系</h4><ul><li>先由SchedulerFactory创建Scheduler调度器</li><li>由调度器去调取即将执行的Trigger</li><li>执行时获取到对于的JobDetail信息</li><li>找到对应的Job类执行业务逻辑</li></ul><h3 id="Quartz-API"><a href="#Quartz-API" class="headerlink" title="Quartz API"></a>Quartz API</h3><p>Quartz的API的风格在2.x以后，采用的是DSL风格（通常意味着fluent interface风格），就是示例中newTrigger()那一段东西。它是通过Builder实现的，就是以下几个。（** 下面大部分代码都要引用这些Builder ** )</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//job相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.JobBuilder.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">//trigger相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.TriggerBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.SimpleScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.CronScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DailyTimeIntervalScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.CalendarIntervalScheduleBuilder.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">//日期相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DateBuilder.*;</span><br></pre></td></tr></table></figure><p>DSL风格写起来会更加连贯，畅快，而且由于不是使用setter的风格，语义上会更容易理解一些。对比一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JobDetail jobDetail=new JobDetailImpl(&quot;jobDetail1&quot;,&quot;group1&quot;,HelloQuartz.class);</span><br><span class="line">jobDetail.getJobDataMap().put(&quot;name&quot;, &quot;quartz&quot;);</span><br><span class="line"></span><br><span class="line">SimpleTriggerImpl trigger=new SimpleTriggerImpl(&quot;trigger1&quot;,&quot;group1&quot;);</span><br><span class="line">trigger.setStartTime(new Date());</span><br><span class="line">trigger.setRepeatInterval(1);</span><br><span class="line">trigger.setRepeatCount(-1);</span><br></pre></td></tr></table></figure><h3 id="关于name和group"><a href="#关于name和group" class="headerlink" title="关于name和group"></a>关于name和group</h3><p>JobDetail和Trigger都有name和group。</p><p>name是它们在这个sheduler里面的唯一标识。如果我们要更新一个JobDetail定义，只需要设置一个name相同的JobDetail实例即可。</p><p>group是一个组织单元，sheduler会提供一些对整组操作的API，比如 scheduler.resumeJobs()。</p><h3 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a>Trigger</h3><h4 id="StartTime-amp-EndTime"><a href="#StartTime-amp-EndTime" class="headerlink" title="StartTime &amp; EndTime"></a>StartTime &amp; EndTime</h4><p>startTime和endTime指定的Trigger会被触发的时间区间。在这个区间之外，Trigger是不会被触发的。</p><p>** 所有Trigger都会包含这两个属性 **</p><h4 id="优先级（Priority）"><a href="#优先级（Priority）" class="headerlink" title="优先级（Priority）"></a>优先级（Priority）</h4><p>当scheduler比较繁忙的时候，可能在同一个时刻，有多个Trigger被触发了，但资源不足（比如线程池不足）。那么这个时候比剪刀石头布更好的方式，就是设置优先级。优先级高的先执行。</p><p>需要注意的是，优先级只有在同一时刻执行的Trigger之间才会起作用，如果一个Trigger是9:00，另一个Trigger是9:30。那么无论后一个优先级多高，前一个都是先执行。</p><p>优先级的值默认是5，当为负数时使用默认值。最大值似乎没有指定，但建议遵循Java的标准，使用1-10，不然鬼才知道看到【优先级为10】是时，上头还有没有更大的值。</p><h4 id="Misfire-错失触发）策略"><a href="#Misfire-错失触发）策略" class="headerlink" title="Misfire(错失触发）策略"></a>Misfire(错失触发）策略</h4><p>类似的Scheduler资源不足的时候，或者机器崩溃重启等，有可能某一些Trigger在应该触发的时间点没有被触发，也就是Miss Fire了。这个时候Trigger需要一个策略来处理这种情况。每种Trigger可选的策略各不相同。</p><p>这里有两个点需要重点注意：</p><ul><li>MisFire的触发是有一个阀值，这个阀值是配置在JobStore的。比RAMJobStore是org.quartz.jobStore.misfireThreshold。只有超过这个阀值，才会算MisFire。小于这个阀值，Quartz是会全部重新触发。</li></ul><p>所有MisFire的策略实际上都是解答两个问题：</p><ul><li>已经MisFire的任务还要重新触发吗？</li><li>如果发生MisFire，要调整现有的调度时间吗？</li></ul><details><summary>比如SimpleTrigger的MisFire策略有</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>IGNORE<span class="emphasis">_MISFIRE_</span>POLICY</span><br><span class="line"></span><br><span class="line"><span class="code">    这个不是忽略已经错失的触发的意思，而是说忽略MisFire策略。它会在资源合适的时候，重新触发所有的MisFire任务，并且不会影响现有的调度时间。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    比如，SimpleTrigger每15秒执行一次，而中间有5分钟时间它都MisFire了，一共错失了20个，5分钟后，假设资源充足了，并且任务允许并发，它会被一次性触发。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    这个属性是所有Trigger都适用。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>FIRE<span class="emphasis">_NOW</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  忽略已经MisFire的任务，并且立即执行调度。这通常只适用于只执行一次的任务。</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">* MISFIRE_</span>INSTRUCTION<span class="emphasis">_RESCHEDULE_</span>NOW<span class="emphasis">_WITH_</span>EXISTING<span class="emphasis">_REPEAT_</span>COUNT</span><br><span class="line"></span><br><span class="line">  将startTime设置当前时间，立即重新调度任务，包括的MisFire的</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NOW_</span>WITH<span class="emphasis">_REMAINING_</span>REPEAT<span class="emphasis">_COUNT</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  类似MISFIRE_</span>INSTRUCTION<span class="emphasis">_RESCHEDULE_</span>NOW<span class="emphasis">_WITH_</span>EXISTING<span class="emphasis">_REPEAT_</span>COUNT，区别在于会忽略已经MisFire的任务</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_EXISTING_</span>COUNT</span><br><span class="line"></span><br><span class="line">  在下一次调度时间点，重新开始调度任务，包括的MisFire的</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_REMAINING_</span>COUNT</span><br><span class="line"></span><br><span class="line">  类似于MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_EXISTING_</span>COUNT，区别在于会忽略已经MisFire的任务。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>SMART<span class="emphasis">_POLICY</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  所有的Trigger的MisFire默认值都是这个，大致意思是“把处理逻辑交给聪明的Quartz去决定”。基本策略是，</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  * 如果是只执行一次的调度，使用MISFIRE_</span>INSTRUCTION<span class="emphasis">_FIRE_</span>NOW</span><br><span class="line"><span class="bullet">  *</span> 如果是无限次的调度(repeatCount是无限的)，使用MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_REMAINING_</span>COUNT</span><br><span class="line"><span class="bullet">  *</span> 否则，使用MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NOW_</span>WITH<span class="emphasis">_EXISTING_</span>REPEAT<span class="emphasis">_COUNT</span></span><br></pre></td></tr></table></figure></details><h4 id="Calendar"><a href="#Calendar" class="headerlink" title="Calendar"></a>Calendar</h4><p>这里的Calendar不是jdk的java.util.Calendar，不是为了计算日期的。它的作用是在于补充Trigger的时间。可以排除或加入某一些特定的时间点。</p><p>以”每月25日零点自动还卡债“为例，我们想排除掉每年的2月25号零点这个时间点（因为有2.14，所以2月一定会破产）。这个时间，就可以用Calendar来实现。</p><details><summary>例子</summary><pre><code>AnnualCalendar cal = new AnnualCalendar(); //定义一个每年执行Calendar，精度为天，即不能定义到2.25号下午2:00java.util.Calendar excludeDay = new GregorianCalendar();excludeDay.setTime(newDate().inMonthOnDay(2, 25).build());cal.setDayExcluded(excludeDay, true);  //设置排除2.25这个日期scheduler.addCalendar("FebCal", cal, false, false); //scheduler加入这个Calendar//定义一个TriggerTrigger trigger = newTrigger().withIdentity("trigger1", "group1").startNow()//一旦加入scheduler，立即生效.modifiedByCalendar("FebCal") //使用Calendar !!.withSchedule(simpleSchedule().withIntervalInSeconds(1).repeatForever()).build();</code></pre></details><p>Quartz体贴地为我们提供以下几种Calendar，注意，所有的Calendar既可以是排除，也可以是包含，取决于：</p><ul><li>HolidayCalendar。指定特定的日期，比如20140613。精度到天。</li><li>DailyCalendar。指定每天的时间段（rangeStartingTime, rangeEndingTime)，格式是HH:MM[:SS[:mmm]]。也就是最大精度可以到毫秒。</li><li>WeeklyCalendar。指定每星期的星期几，可选值比如为java.util.Calendar.SUNDAY。精度是天。</li><li>MonthlyCalendar。指定每月的几号。可选值为1-31。精度是天</li><li>AnnualCalendar。 指定每年的哪一天。使用方式如上例。精度是天。</li><li>CronCalendar。指定Cron表达式。精度取决于Cron表达式，也就是最大精度可以到秒。</li></ul><h4 id="其他属性"><a href="#其他属性" class="headerlink" title="其他属性"></a>其他属性</h4><ul><li><p>Durability(耐久性？)</p><p>如果一个任务不是durable，那么当没有Trigger关联它的时候，它就会被自动删除。</p></li><li><p>RequestsRecovery</p><p>如果一个任务是”requests recovery”，那么当任务运行过程非正常退出时（比如进程崩溃，机器断电，但不包括抛出异常这种情况），Quartz再次启动时，会重新运行一次这个任务实例。</p><p>可以通过JobExecutionContext.isRecovering()查询任务是否是被恢复的。</p></li></ul><h4 id="Trigger实现类"><a href="#Trigger实现类" class="headerlink" title="Trigger实现类"></a>Trigger实现类</h4><h5 id="SimpleTrigger"><a href="#SimpleTrigger" class="headerlink" title="SimpleTrigger"></a>SimpleTrigger</h5><p>指定从某一个时间开始，以一定的时间间隔（单位是毫秒）执行的任务。</p><p>它适合的任务类似于：9:00 开始，每隔1小时，执行一次。</p><p>它的属性有：</p><ul><li>repeatInterval 重复间隔</li><li>repeatCount 重复次数。实际执行次数是 repeatCount+1。因为在startTime的时候一定会执行一次。<strong>下面有关repeatCount 属性的都是同理</strong></li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">simpleSchedule()</span><br><span class="line">        .withIntervalInHours(1) //每小时执行一次</span><br><span class="line">        .repeatForever() //次数不限</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">simpleSchedule()</span><br><span class="line">    .withIntervalInMinutes(1) //每分钟执行一次</span><br><span class="line">    .withRepeatCount(10) //次数为10次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="CalendarIntervalTrigger"><a href="#CalendarIntervalTrigger" class="headerlink" title="CalendarIntervalTrigger"></a>CalendarIntervalTrigger</h5><p>类似于SimpleTrigger，指定从某一个时间开始，以一定的时间间隔执行的任务。<br>但是不同的是SimpleTrigger指定的时间间隔为毫秒，没办法指定每隔一个月执行一次（每月的时间间隔不是固定值），而CalendarIntervalTrigger支持的间隔单位有秒，分钟，小时，天，月，年，星期。</p><p>相较于SimpleTrigger有两个优势：1、更方便，比如每隔1小时执行，你不用自己去计算1小时等于多少毫秒。 2、支持不是固定长度的间隔，比如间隔为月和年。但劣势是精度只能到秒。</p><p>它适合的任务类似于：9:00 开始执行，并且以后每周 9:00 执行一次</p><p>它的属性有:</p><ul><li>interval 执行间隔</li><li>intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）</li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">calendarIntervalSchedule()</span><br><span class="line">    .withIntervalInDays(1) //每天执行一次</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">calendarIntervalSchedule()</span><br><span class="line">    .withIntervalInWeeks(1) //每周执行一次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="DailyTimeIntervalTrigger"><a href="#DailyTimeIntervalTrigger" class="headerlink" title="DailyTimeIntervalTrigger"></a>DailyTimeIntervalTrigger</h5><p>指定每天的某个时间段内，以一定的时间间隔执行任务。并且它可以支持指定星期。</p><p>它适合的任务类似于：指定每天9:00 至 18:00 ，每隔70秒执行一次，并且只要周一至周五执行。</p><p>它的属性有:</p><ul><li>startTimeOfDay 每天开始时间</li><li>endTimeOfDay 每天结束时间</li><li>daysOfWeek 需要执行的星期</li><li>interval 执行间隔</li><li>intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）</li><li>repeatCount 重复次数</li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dailyTimeIntervalSchedule()</span><br><span class="line">    .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始</span><br><span class="line">    .endingDailyAt(TimeOfDay.hourAndMinuteOfDay(16, 0)) //16：00 结束 </span><br><span class="line">    .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行</span><br><span class="line">    .withIntervalInHours(1) //每间隔1小时执行一次</span><br><span class="line">    .withRepeatCount(100) //最多重复100次（实际执行100+1次）</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">dailyTimeIntervalSchedule()</span><br><span class="line">    .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始</span><br><span class="line">    .endingDailyAfterCount(10) //每天执行10次，这个方法实际上根据 startTimeOfDay+interval*count 算出 endTimeOfDay</span><br><span class="line">    .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行</span><br><span class="line">    .withIntervalInHours(1) //每间隔1小时执行一次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="CronTrigger"><a href="#CronTrigger" class="headerlink" title="CronTrigger"></a>CronTrigger</h5><p>适合于更复杂的任务，它支持类型于Linux Cron的语法（并且更强大）。基本上它覆盖了以上三个Trigger的绝大部分能力（但不是全部）—— 当然，也更难理解。</p><p>它适合的任务类似于：每天0:00,9:00,18:00各执行一次。</p><p>它的属性只有:</p><p>Cron表达式。但这个表示式本身就够复杂了。</p><h3 id="JobDetail-amp-Job"><a href="#JobDetail-amp-Job" class="headerlink" title="JobDetail &amp; Job"></a>JobDetail &amp; Job</h3><p>JobDetail是任务的定义，而Job是任务的执行逻辑。在JobDetail里会引用一个Job Class定义。</p><details><summary>一个最简单的例子</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JobTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> SchedulerException, IOException </span>&#123;</span><br><span class="line">           JobDetail job=newJob()</span><br><span class="line">               .ofType(DoNothingJob.class) <span class="comment">//引用Job Class</span></span><br><span class="line">               .withIdentity(<span class="string">&quot;job1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//设置name/group</span></span><br><span class="line">               .withDescription(<span class="string">&quot;this is a test job&quot;</span>) <span class="comment">//设置描述</span></span><br><span class="line">               .usingJobData(<span class="string">&quot;age&quot;</span>, <span class="number">18</span>) <span class="comment">//加入属性到ageJobDataMap</span></span><br><span class="line">               .build();</span><br><span class="line"></span><br><span class="line">           job.getJobDataMap().put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;quertz&quot;</span>); <span class="comment">//加入属性name到JobDataMap</span></span><br><span class="line"></span><br><span class="line">           <span class="comment">//定义一个每秒执行一次的SimpleTrigger</span></span><br><span class="line">           Trigger trigger=newTrigger()</span><br><span class="line">                   .startNow()</span><br><span class="line">                   .withIdentity(<span class="string">&quot;trigger1&quot;</span>)</span><br><span class="line">                   .withSchedule(simpleSchedule()</span><br><span class="line">                       .withIntervalInSeconds(<span class="number">1</span>)</span><br><span class="line">                       .repeatForever())</span><br><span class="line">                   .build();</span><br><span class="line"></span><br><span class="line">           Scheduler sche=StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line">           sche.scheduleJob(job, trigger);</span><br><span class="line"></span><br><span class="line">           sche.start();</span><br><span class="line"></span><br><span class="line">           System.in.read();</span><br><span class="line"></span><br><span class="line">           sche.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DoNothingJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;do nothing&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>从上例我们可以看出，要定义一个任务，需要干几件事：</p><ul><li>创建一个org.quartz.Job的实现类，并实现实现自己的业务逻辑。比如上面的DoNothingJob。</li><li>定义一个JobDetail，引用这个实现类</li><li>加入scheduleJob</li></ul><p>Quartz调度一次任务，会干如下的事：</p><ul><li>JobClass jobClass=JobDetail.getJobClass()</li><li>Job jobInstance=jobClass.newInstance()。所以Job实现类，必须有一个public的无参构建方法。</li><li>jobInstance.execute(JobExecutionContext context)。JobExecutionContext是Job运行的上下文，可以获得Trigger、Scheduler、JobDetail的信息。</li></ul><p>也就是说，每次调度都会创建一个新的Job实例，这样的好处是有些任务并发执行的时候，不存在对临界资源的访问问题——当然，如果需要共享JobDataMap的时候，还是存在临界资源的并发访问的问题。</p><h4 id="JobDataMap"><a href="#JobDataMap" class="headerlink" title="JobDataMap"></a>JobDataMap</h4><p>每一个JobDetail都会有一个JobDataMap。JobDataMap本质就是一个Map的扩展类，只是提供了一些更便捷的方法，比如getString()之类的。</p><p>我们可以在定义JobDetail，加入属性值，方式有二：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">newJob().usingJobData(&quot;age&quot;, 18) //加入属性到ageJobDataMap</span><br><span class="line"></span><br><span class="line"> or</span><br><span class="line"></span><br><span class="line">job.getJobDataMap().put(&quot;name&quot;, &quot;quertz&quot;); //加入属性name到JobDataMap</span><br></pre></td></tr></table></figure><p>然后在Job中可以获取这个JobDataMap的值，方式同样有二：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloQuartz</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        JobDetail detail = context.getJobDetail();</span><br><span class="line">        JobDataMap map = detail.getJobDataMap(); <span class="comment">//方法一：获得JobDataMap</span></span><br><span class="line">        System.out.println(<span class="string">&quot;say hello to &quot;</span> + name + <span class="string">&quot;[&quot;</span> + map.getInt(<span class="string">&quot;age&quot;</span>) + <span class="string">&quot;]&quot;</span> + <span class="string">&quot; at &quot;</span></span><br><span class="line">                           + <span class="keyword">new</span> Date());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//方法二：属性的setter方法，会将JobDataMap的属性自动注入</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123; </span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于同一个JobDetail实例，执行的多个Job实例，是共享同样的JobDataMap，也就是说，如果你在任务里修改了里面的值，会对其他Job实例（并发的或者后续的）造成影响。</p><p>除了JobDetail，Trigger同样有一个JobDataMap，共享范围是所有使用这个Trigger的Job实例。</p><h4 id="Job并发"><a href="#Job并发" class="headerlink" title="Job并发"></a>Job并发</h4><p>Job是有可能并发执行的，比如一个任务要执行10秒中，而调度算法是每秒中触发1次，那么就有可能多个任务被并发执行。</p><p>有时候我们并不想任务并发执行，比如这个任务要去”获得数据库中所有未发送邮件的名单“，如果是并发执行，就需要一个数据库锁去避免一个数据被多次处理。这个时候一个@DisallowConcurrentExecution解决这个问题。</p><p>就是这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DoNothingJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="meta">@DisallowConcurrentExecution</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;do nothing&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，@DisallowConcurrentExecution是对JobDetail实例生效，也就是如果你定义两个JobDetail，引用同一个Job类，是可以并发执行的。</p><h4 id="JobExecutionException"><a href="#JobExecutionException" class="headerlink" title="JobExecutionException"></a>JobExecutionException</h4><p>Job.execute()方法是不允许抛出除JobExecutionException之外的所有异常的（包括RuntimeException)，所以编码的时候，最好是try-catch住所有的Throwable，小心处理。</p><h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>Scheduler就是Quartz的大脑，所有任务都是由它来设施。</p><p>Schduelr包含一个两个重要组件: JobStore和ThreadPool。</p><p>JobStore是会来存储运行时信息的，包括Trigger,Schduler,JobDetail，业务锁等。它有多种实现RAMJob(内存实现)，JobStoreTX(JDBC，事务由Quartz管理），JobStoreCMT(JDBC，使用容器事务)，ClusteredJobStore(集群实现)、TerracottaJobStore(什么是Terractta)。</p><p>ThreadPool就是线程池，Quartz有自己的线程池实现。所有任务的都会由线程池执行。</p><h4 id="SchedulerFactory"><a href="#SchedulerFactory" class="headerlink" title="SchedulerFactory"></a>SchedulerFactory</h4><p>SchdulerFactory，顾名思义就是来用创建Schduler了，有两个实现：DirectSchedulerFactory和 StdSchdulerFactory。前者可以用来在代码里定制你自己的Schduler参数。后者是直接读取classpath下的quartz.properties（不存在就都使用默认值）配置来实例化Schduler。通常来讲，我们使用StdSchdulerFactory也就足够了。</p><p>SchdulerFactory本身是支持创建RMI stub的，可以用来管理远程的Scheduler，功能与本地一样，可以远程提交个Job什么的。</p><p>DirectSchedulerFactory的创建接口</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Same as</span><br><span class="line">     * &#123;@link DirectSchedulerFactory#createScheduler(ThreadPool threadPool, JobStore jobStore)&#125;,</span><br><span class="line">     * with the addition of specifying the scheduler name and instance ID. This</span><br><span class="line">     * scheduler can only be retrieved via</span><br><span class="line">     * &#123;@link DirectSchedulerFactory#getScheduler(String)&#125;</span><br><span class="line">     *</span><br><span class="line">     * @param schedulerName</span><br><span class="line">     *          The name for the scheduler.</span><br><span class="line">     * @param schedulerInstanceId</span><br><span class="line">     *          The instance ID for the scheduler.</span><br><span class="line">     * @param threadPool</span><br><span class="line">     *          The thread pool for executing jobs</span><br><span class="line">     * @param jobStore</span><br><span class="line">     *          The type of job store</span><br><span class="line">     * @throws SchedulerException</span><br><span class="line">     *           if initialization failed</span><br><span class="line">     */</span><br><span class="line">    public void createScheduler(String schedulerName,</span><br><span class="line">            String schedulerInstanceId, ThreadPool threadPool, JobStore jobStore)</span><br><span class="line">        throws SchedulerException;</span><br></pre></td></tr></table></figure><p>StdSchdulerFactory的配置例子，更多配置，参考<a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/">Quartz配置指南</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">org.quartz.scheduler.instanceName = DefaultQuartzScheduler</span><br><span class="line">org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool</span><br><span class="line">org.quartz.threadPool.threadCount = 10 </span><br><span class="line">org.quartz.threadPool.threadPriority = 5</span><br><span class="line">org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true</span><br><span class="line">org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore</span><br></pre></td></tr></table></figure><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>JobStore <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-09">介绍</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/">配置</a></li></ul></li><li>集群: <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-11">介绍</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/ConfigJDBCJobStoreClustering">配置</a></li></ul></li><li>RMI</li><li>监听器 <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-07">TriggerListeners and JobListeners</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-08">SchedulerListeners</a></li></ul></li><li>插件</li></ul><p>主要的资料来自<a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/">官方文档</a>，这里有教程，例子，配置等，非常详细</p><h2 id="Quartz源码解析"><a href="#Quartz源码解析" class="headerlink" title="Quartz源码解析"></a>Quartz源码解析</h2><h3 id="Quartz启动流程"><a href="#Quartz启动流程" class="headerlink" title="Quartz启动流程"></a>Quartz启动流程</h3><p>当服务器启动时，Spring就加载相关的bean。<br>SchedulerFactoryBean实现了InitializingBean接口，因此在初始化bean的时候，会执行afterPropertiesSet方法，该方法将会调用SchedulerFactory(DirectSchedulerFactory 或者 StdSchedulerFactory，通常用StdSchedulerFactory)创建Scheduler。==<br>我们在SchedulerFactoryBean配置类中配了相关的配置及配置文件参数，所以会读取配置文件参数，初始化各个组件。  </p><p>关键组件如下：</p><ul><li><strong>ThreadPool</strong>：一般是使用SimpleThreadPool(线程数量固定的线程池),SimpleThreadPool创建了一定数量的WorkerThread实例来使得Job能够在线程中进行处理。WorkerThread是定义在SimpleThreadPool类中的内部类，它实质上就是一个线程。<br>在SimpleThreadPool中有三个list：workers-存放池中所有的线程引用，availWorkers-存放所有空闲的线程，busyWorkers-存放所有工作中的线程；配置如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool</span><br><span class="line">org.quartz.threadPool.threadCount=3</span><br><span class="line">org.quartz.threadPool.threadPriority=5</span><br></pre></td></tr></table></figure></li><li><strong>JobStore</strong>： 初始化定时任务的数据存储方式，分为两种：<ul><li>存储在内存的RAMJobStore<br>存取速度非常快，但是由于其在系统被停止后所有的数据都会丢失，所以在集群应用中，必须使用JobStoreSupport</li><li>存储在数据库的JobStoreSupport(包括JobStoreTX和JobStoreCMT两种实现，JobStoreCMT是依赖于容器来进行事务的管理，而JobStoreTX是自己管理事务） </li></ul></li><li><strong>QuartzSchedulerThread</strong>： 初始化调度线程，在初始化的时候paused=true,halted=false,虽然线程开始运行了，但是paused=true，线程会一直等待，直到start方法将paused置为false；SchedulerFactoryBean还实现了SmartLifeCycle接口，因此初始化完成后，会执行start()方法，该方法将主要会执行以下的几个动作：<ul><li>创建ClusterManager线程并启动线程:该线程用来进行集群故障检测和处理</li><li>创建MisfireHandler线程并启动线程:该线程用来进行misfire任务的处理</li><li>置QuartzSchedulerThread的paused=false，调度线程才真正开始调度</li></ul>整个启动流程图如下：<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img.png"><br>流程图简要说明：<ol><li>先读取配置文件</li><li>初始化SchedulerFactoryBean</li><li>初始化SchedulerFactory</li><li>实例化执行线程池（TheadPool）</li><li>实例化数据存储</li><li>初始化QuartzScheduler(为Scheduler的简单实现，包括调度作业、注册JobListener实例等方法。)</li><li>new一个QuartzSchedulerThread调度线程（负责执行在QuartzScheduler中注册的触发触发器的线程。），并开始运行</li><li>调度开始，注册监听器，注册Job和Trigger</li><li>SchedulerFactoryBean初始化完成后执行start()方法</li><li>创建ClusterManager线程并启动线程</li><li>创建MisfireHandler线程并启动线程</li><li>置QuartzSchedulerThread的paused=false，调度线程真正开始调度，开始执行run方法</li></ol></li></ul><h3 id="Quartz-线程视图"><a href="#Quartz-线程视图" class="headerlink" title="Quartz 线程视图"></a>Quartz 线程视图</h3><p>在Quartz中，有两类线程，Scheduler调度线程和任务执行线程，其中任务执行线程通常使用一个线程池维护一组线程。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_3.png"></p><p>Scheduler调度线程主要有两个：执行常规调度的线程，和执行misfiredtrigger的线程。  </p><ul><li>常规调度线程轮询存储的所有trigger，如果有需要触发的trigger，即到达了下一次触发的时间，则从任务执行线程池获取一个空闲线程，执行与该trigger关联的任务。<br>— Misfire线程是扫描所有的trigger，查看是否有misfiredtrigger，如果有的话根据misfire的策略分别处理(fire now OR wait for the next fire)。</li></ul><h3 id="QuartzSchedulerThread逻辑具体介绍"><a href="#QuartzSchedulerThread逻辑具体介绍" class="headerlink" title="QuartzSchedulerThread逻辑具体介绍"></a>QuartzSchedulerThread逻辑具体介绍</h3><p>类中主要的方法就是run方法，下面主要对run方法进行介绍：</p><details><summary>源码解析</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//只有当Quartzscheduler执行start方法时被调用</span><br><span class="line">void togglePause(boolean pause) &#123;</span><br><span class="line">    synchronized(this.sigLock) &#123;</span><br><span class="line">        this.paused = pause;</span><br><span class="line">        if (this.paused) &#123;</span><br><span class="line">          this.signalSchedulingChange(0L);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          this.sigLock.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">public void run() &#123;</span><br><span class="line">    boolean lastAcquireFailed = false;</span><br><span class="line">    label214:</span><br><span class="line">    //此处判断调度器是否终止</span><br><span class="line">    while(!this.halted.get()) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            synchronized(this.sigLock) &#123;</span><br><span class="line">                //此处判断调度器是否终止或是否暂停，由于我们在初始化的时候</span><br><span class="line">                //将paused=true，那么调度线程此时不会真正开始执行只会在不断循环阻塞</span><br><span class="line">                //只有当Quartzscheduler执行start方法时调用togglePause开始将</span><br><span class="line">                //paused置为false,run方法开始真正运行</span><br><span class="line">                while(this.paused &amp;&amp; !this.halted.get()) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        this.sigLock.wait(1000L);</span><br><span class="line">                    &#125; catch (InterruptedException var23) &#123;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                if (this.halted.get()) &#123;</span><br><span class="line">                    break;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            //取出执行线程池中空闲的线程数量</span><br><span class="line">            int availThreadCount = this.qsRsrcs.getThreadPool().blockForAvailableThreads();</span><br><span class="line">            if (availThreadCount &gt; 0) &#123;</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">            //如果可用线程数量足够那么查看30秒内需要触发的触发器。如果没有的</span><br><span class="line">            //话那么就是30后再次扫描，其中方法中三个参数idleWaitTime为如果</span><br><span class="line">            //没有的再次扫描的时间，第二个为最多取几个，最后一个参数</span><br><span class="line">            //batchTimeWindow，这个参数默认是0，同样是一个时间范围，如果</span><br><span class="line">            //有两个任务只差一两秒，而执行线程数量满足及batchTimeWindow时间</span><br><span class="line">            //也满足的情况下就会两个都取出来</span><br><span class="line"></span><br><span class="line">            triggers = this.qsRsrcs.getJobStore().acquireNextTriggers(now + this.idleWaitTime, Math.min(availThreadCount, this.qsRsrcs.getMaxBatchSize()), this.qsRsrcs.getBatchTimeWindow());</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">            //trigger列表是以下次执行时间排序查出来的</span><br><span class="line">            //在列表不为空的时候进行后续操作</span><br><span class="line">            if (triggers != null &amp;&amp; !triggers.isEmpty()) &#123;</span><br><span class="line">            now = System.currentTimeMillis();</span><br><span class="line">            //取出集合中最早执行的触发器</span><br><span class="line">            long triggerTime = ((OperableTrigger)triggers.get(0)).getNextFireTime().getTime();</span><br><span class="line">            //判断距离执行时间是否大于两毫秒</span><br><span class="line">            for(long timeUntilTrigger = triggerTime - now; timeUntilTrigger &gt; 2L; timeUntilTrigger = triggerTime - now) &#123;</span><br><span class="line">                synchronized(this.sigLock) &#123;</span><br><span class="line">                    if (this.halted.get()) &#123;</span><br><span class="line">                        break;</span><br><span class="line">                    &#125;</span><br><span class="line">                    //判断是否还有更早的trigger</span><br><span class="line">                    if (!this.isCandidateNewTimeEarlierWithinReason(triggerTime, false)) &#123;</span><br><span class="line">                    //没有的话进行简单的阻塞，到时候再执行</span><br><span class="line">                        try &#123;</span><br><span class="line">                            now = System.currentTimeMillis();</span><br><span class="line">                            timeUntilTrigger = triggerTime - now;</span><br><span class="line">                            if (timeUntilTrigger &gt;= 1L) &#123;</span><br><span class="line">                                this.sigLock.wait(timeUntilTrigger);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; catch (InterruptedException var22) &#123;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //开始根据需要执行的trigger从数据库中获取相应的JobDetail</span><br><span class="line">                 if (goAhead) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        List&lt;TriggerFiredResult&gt; res = this.qsRsrcs.getJobStore().triggersFired(triggers);</span><br><span class="line">                        if (res != null) &#123;</span><br><span class="line">                            bndles = res;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; catch (SchedulerException var24) &#123;</span><br><span class="line">                        this.qs.notifySchedulerListenersError(&quot;An error occurred while firing triggers &#x27;&quot; + triggers + &quot;&#x27;&quot;, var24);</span><br><span class="line">                        int i = 0;</span><br><span class="line"></span><br><span class="line">                        while(true) &#123;</span><br><span class="line">                            if (i &gt;= triggers.size()) &#123;</span><br><span class="line">                                continue label214;</span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                            ++i;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //将查询到的结果封装成为 TriggerFiredResult</span><br><span class="line">                 for(int i = 0; i &lt; ((List)bndles).size(); ++i) &#123;</span><br><span class="line">                    TriggerFiredResult result = (TriggerFiredResult)((List)bndles).get(i);</span><br><span class="line">                    TriggerFiredBundle bndle = result.getTriggerFiredBundle();</span><br><span class="line">                    Exception exception = result.getException();</span><br><span class="line">                    if (exception instanceof RuntimeException) &#123;</span><br><span class="line">                        this.getLog().error(&quot;RuntimeException while firing trigger &quot; + triggers.get(i), exception);</span><br><span class="line">                        this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                    &#125; else if (bndle == null) &#123;</span><br><span class="line">                        this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        JobRunShell shell = null;</span><br><span class="line"></span><br><span class="line">                        try &#123;</span><br><span class="line">                        //把任务封装成JobRunShell线程任务，然后放到线程池中跑动。</span><br><span class="line">                            shell = this.qsRsrcs.getJobRunShellFactory().createJobRunShell(bndle);</span><br><span class="line">                            shell.initialize(this.qs);</span><br><span class="line">                        &#125; catch (SchedulerException var27) &#123;</span><br><span class="line">                            this.qsRsrcs.getJobStore().triggeredJobComplete((OperableTrigger)triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR);</span><br><span class="line">                            continue;</span><br><span class="line">                        &#125;</span><br><span class="line">                        //runInThread方法加Job放入对应的工作线程进行执行Job</span><br><span class="line">                        if (!this.qsRsrcs.getThreadPool().runInThread(shell)) &#123;</span><br><span class="line">                            this.getLog().error(&quot;ThreadPool.runInThread() return false!&quot;);</span><br><span class="line">                            this.qsRsrcs.getJobStore().triggeredJobComplete((OperableTrigger)triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure></details><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_1.png"></p><p>总结下来:</p><ol><li>先获取线程池中的可用线程数量（若没有可用的会阻塞，直到有可用的）；</li><li>获取30m内要执行的trigger(即acquireNextTriggers)获取trigger的锁，通过select …for update方式实现；获取30m内（可配置）要执行的triggers（需要保证集群节点的时间一致），若@ConcurrentExectionDisallowed且列表存在该条trigger则跳过，否则更新trigger状态为ACQUIRED(刚开始为WAITING)；插入firedTrigger表，状态为ACQUIRED;（注意：在RAMJobStore中，有个timeTriggers，排序方式是按触发时间nextFireTime排的；JobStoreSupport从数据库取出triggers时是按照nextFireTime排序）;</li><li>待直到获取的trigger中最先执行的trigger在2ms内；</li><li>triggersFired：<ol><li>更新firedTrigger的status=EXECUTING;</li><li>更新trigger下一次触发的时间; </li><li>更新trigger的状态：无状态的trigger-&gt;WAITING，有状态的trigger-&gt;BLOCKED，若nextFireTime==null -&gt;COMPLETE；</li><li>commit connection,释放锁；</li></ol></li><li>针对每个要执行的trigger，创建JobRunShell，并放入线程池执行：<ol><li>execute:执行job</li><li>获取TRIGGER_ACCESS锁</li><li>若是有状态的job：更新trigger状态：BLOCKED-&gt;WAITING,PAUSED_BLOCKED-&gt;BLOCKED</li><li>若@PersistJobDataAfterExecution，则updateJobData</li><li>删除firedTrigger</li><li>commit connection，释放锁</li></ol></li></ol><h3 id="misfireHandler线程"><a href="#misfireHandler线程" class="headerlink" title="misfireHandler线程"></a>misfireHandler线程</h3><p>下面这些原因可能造成 misfired job:</p><ol><li>系统因为某些原因被重启。在系统关闭到重新启动之间的一段时间里，可能有些任务会被 misfire；</li><li>Trigger 被暂停（suspend）的一段时间里，有些任务可能会被 misfire；</li><li>线程池中所有线程都被占用，导致任务无法被触发执行，造成 misfire；</li><li>有状态任务在下次触发时间到达时，上次执行还没有结束；为了处理 misfired job，Quartz 中为 trigger定义了处理策略，主要有下面两种：MISFIRE_INSTRUCTION_FIRE_ONCE_NOW：针对 misfired job马上执行一次；MISFIRE_INSTRUCTION_DO_NOTHING：忽略 misfired job，等待下次触发；默认是MISFIRE_INSTRUCTION_SMART_POLICY，该策略在CronTrigger中=MISFIRE_INSTRUCTION_FIRE_ONCE_NOW线程默认1分钟执行一次；在一个事务中，默认一次最多recovery 20个；</li></ol><p>执行流程：<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_2.png"></p><ol><li>若配置(默认为true，可配置)成获取锁前先检查是否有需要recovery的trigger，先获取misfireCount；</li><li>获取TRIGGER_ACCESS锁；</li><li>hasMisfiredTriggersInState：获取misfired的trigger，默认一个事务里只能最大20个misfired trigger（可配置），misfired判断依据：status=waiting,next_fire_time &lt; current_time-misfirethreshold(可配置，默认1min)</li><li>notifyTriggerListenersMisfired</li><li>updateAfterMisfire:获取misfire策略(默认是MISFIRE_INSTRUCTION_SMART_POLICY，该策略在CronTrigger中=MISFIRE_INSTRUCTION_FIRE_ONCE_NOW)，根据策略更新nextFireTime；</li><li>将nextFireTime等更新到trigger表；</li><li>commit connection，释放锁8.如果还有更多的misfired，sleep短暂时间(为了集群负载均衡)，否则sleep misfirethreshold时间，后继续轮询；</li></ol>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
            <tag> Quartz </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之单机定时调度Linux定时任务cron</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/</url>
      
        <content type="html"><![CDATA[<p>实现linux定时任务有：cron、anacron、at,使用最多的是cron任务</p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul><li>cron–服务名；</li><li>crond–linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似；</li><li>crontab–是定制好的计划任务表，一个设置cron的工具</li></ul><h2 id="软件包安装"><a href="#软件包安装" class="headerlink" title="软件包安装"></a>软件包安装</h2><p>要使用cron服务，先要安装vixie-cron软件包和crontabs软件包，两个软件包作用如下：</p><ul><li>vixie-cron软件包是cron的主程序。<ul><li>查看是否安装了cron软件包: rpm -qa|grep vixie-cron</li></ul></li><li>crontabs软件包是用来安装、卸装、或列举用来驱动 cron 守护进程的表格的程序。<ul><li>查看是否安装了crontabs软件包:rpm -qa|grep crontabs</li></ul></li></ul><p>如果没有安装，则执行如下命令安装软件包(软件包必须存在)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh vixie-cron-4.1-54.FC5*</span><br><span class="line">rpm -ivh crontabs*</span><br></pre></td></tr></table></figure><p>如果本地没有安装包，在能够连网的情况下可以在线安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install vixie-cron</span><br><span class="line">yum install crontabs</span><br></pre></td></tr></table></figure><h3 id="查看crond服务是否运行"><a href="#查看crond服务是否运行" class="headerlink" title="查看crond服务是否运行"></a>查看crond服务是否运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pgrep crond 或 </span><br><span class="line">/sbin/service crond status 或 </span><br><span class="line">ps -elf|grep crond|grep -v &quot;grep&quot;</span><br></pre></td></tr></table></figure><h3 id="crond服务操作命令"><a href="#crond服务操作命令" class="headerlink" title="crond服务操作命令"></a>crond服务操作命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/sbin/service crond start //启动服务  </span><br><span class="line">/sbin/service crond stop //关闭服务  </span><br><span class="line">/sbin/service crond restart //重启服务  </span><br><span class="line">/sbin/service crond reload //重新载入配置</span><br></pre></td></tr></table></figure><h2 id="配置定时任务"><a href="#配置定时任务" class="headerlink" title="配置定时任务"></a>配置定时任务</h2><p>cron有两个配置文件，一个是一个全局配置文件（/etc/crontab），是针对系统任务的；一组是crontab命令生成的配置文件（/var/spool/cron下的文件），是针对某个用户的.定时任务配置到任意一个中都可以。</p><p>查看全局配置文件配置情况: <code>cat /etc/crontab</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">　---------------------------------------------</span><br><span class="line">　　SHELL=/bin/bash</span><br><span class="line">　　PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">　　MAILTO=root</span><br><span class="line">　　HOME=/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">　　#</span><span class="bash"> run-parts</span></span><br><span class="line">　　01 * * * * root run-parts /etc/cron.hourly</span><br><span class="line">　　02 4 * * * root run-parts /etc/cron.daily</span><br><span class="line">　　22 4 * * 0 root run-parts /etc/cron.weekly</span><br><span class="line">　　42 4 1 * * root run-parts /etc/cron.monthly</span><br><span class="line">　　----------------------------------------------</span><br></pre></td></tr></table></figure><p>查看用户下的定时任务:crontab -l或cat /var/spool/cron/用户名</p><h3 id="crontab任务配置基本格式"><a href="#crontab任务配置基本格式" class="headerlink" title="crontab任务配置基本格式"></a>crontab任务配置基本格式</h3><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-----------------------------------------------------------------------</span><br><span class="line">*   *　 *　 *　 *　　command</span><br><span class="line">分钟(0-59)　小时(0-23)　日期(1-31)　月份(1-12)　星期(0-6,0代表星期天)　 命令</span><br><span class="line">第1列表示分钟1～59 每分钟用*或者 */1表示</span><br><span class="line">第2列表示小时1～23（0表示0点）</span><br><span class="line">第3列表示日期1～31</span><br><span class="line">第4列表示月份1～12</span><br><span class="line">第5列标识号星期0～6（0表示星期天）</span><br><span class="line">第6列要运行的命令</span><br><span class="line"></span><br><span class="line">-----------------------------------------------------------------------</span><br><span class="line">在以上任何值中，星号（*）可以用来代表所有有效的值。譬如，月份值中的星号意味着在满足其它制约条件后每月都执行该命令。</span><br><span class="line">整数间的短线（-）指定一个整数范围。譬如，1-4 意味着整数 1、2、3、4。</span><br><span class="line">用逗号（,）隔开的一系列值指定一个列表。譬如，3, 4, 6, 8 标明这四个指定的整数。</span><br><span class="line">正斜线（/）可以用来指定间隔频率。在范围后加上 /&lt;integer&gt; 意味着在范围内可以跳过 integer。譬如，0-59/2 可以用来在分钟字段定义每两分钟。间隔频率值还可以和星号一起使用。例如，*/3 的值可以用在月份字段中表示每三个月运行一次任务。</span><br><span class="line">开头为井号（#）的行是注释，不会被处理</span><br><span class="line">-----------------------------------------------------------------------</span><br></pre></td></tr></table></figure><details><summary>使用实例</summary><pre><code>实例1：每1分钟执行一次command命令：* * * * * command<p>实例2：每小时的第3和第15分钟执行<br>命令：3,15 * * * * command</p><p>实例3：在上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 * * * command</p><p>实例4：每隔两天的上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 */2 * * command</p><p>实例5：每个星期一的上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 * * 1 command</p><p>实例6：每晚的21:30重启smb<br>命令：30 21 * * * /etc/init.d/smb restart</p><p>实例7：每月1、10、22日的4 : 45重启smb<br>命令：45 4 1,10,22 * * /etc/init.d/smb restart</p><p>实例8：每周六、周日的1 : 10重启smb<br>命令：10 1 * * 6,0 /etc/init.d/smb restart</p><p>实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb<br>命令：0,30 18-23 * * * /etc/init.d/smb restart</p><p>实例10：每星期六的晚上11 : 00 pm重启smb<br>命令：0 23 * * 6 /etc/init.d/smb restart</p><p>实例11：每一小时重启smb<br>命令：* */1 * * * /etc/init.d/smb restart</p><p>实例12：晚上11点到早上7点之间，每隔一小时重启smb<br>命令：* 23-7/1 * * * /etc/init.d/smb restart</p><p>实例13：每月的4号与每周一到周三的11点重启smb<br>命令：0 11 4 * mon-wed /etc/init.d/smb restart</p><p>实例14：一月一号的4点重启smb<br>命令：0 4 1 jan * /etc/init.d/smb restart</p><p>实例15：每小时执行/etc/cron.hourly目录内的脚本<br>命令：01   *   *   *   *     root run-parts /etc/cron.hourly<br>说明：<br>run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了</p></code></pre><p></p></details><h2 id="cron实现原理"><a href="#cron实现原理" class="headerlink" title="cron实现原理"></a>cron实现原理</h2><h3 id="基本原理图解"><a href="#基本原理图解" class="headerlink" title="基本原理图解"></a>基本原理图解</h3><p>fork 进程 + sleep 轮询<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img_1.png"><br>Cron每分钟做一次检查，看看哪个命令可执行。</p><p>从上图可以看到，有4次fork，这4次fork分别是：</p><ul><li>第一个fork，让Cron自己成为Daemon进程，即成为守护进程；</li><li>第二个fork，当Cron检查到有命令需要执行时被创建，但注意它并不执行命令，执行命令由它的子进程来做；</li><li>第三个fork，有些版本调用的是vfork，但有些版本却是fork，它是负责执行Cron命令的进程，即会调用execle()的进程；</li><li>第四个fork不是必须的，只有为Cron命令配置了标准输入才会用：<br><code>*/1 * * * * /tmp/X/x%1234567890</code><br>像上面有个百分符“%”，后面跟一串，则会有第四个fork，它的作用是将“%”后面的内容作为标准输入传递给第三个fork出来的进程。</li></ul><p>注意fork出来的进程没有忽略(ignore)管道信号(SIGPIPE)，所以如果遇到SIGPIPE，则会导致进程无声无息的退出，比如标准输主输出重定向管道的读端被关闭了，写时就会触发SIGPIPE。</p><p>实践中，可能会遇到child_process()在做上述所说的第三个fork前因SIGPIPE信号退出，导致难以理解的问题。其中一个现象 是：Cron命令被执行了若干次，但之后再也不执行了，原因在于第二个fork出来的进程因SIGPIPE退出了，导致没有进行第三个fork，因此 Cron命令没有被调用(总是由execle()调用)。</p><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img_2.png"></p><h3 id="一个诡异的问题"><a href="#一个诡异的问题" class="headerlink" title="一个诡异的问题"></a>一个诡异的问题</h3><p>你有可能遇到这样的情况，假设在cron中有如下一条配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo hello &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>观察到它正常运行几次后，就不再运行了，或者一次也不能，但确认无其它问题，因此十分诡异。</p><p>这个问题的原因，有可能是因为有共享库Hook了cron，共享库代码触发了SIGPIPE，导致了第二个fork出的进程退出，没来得及执行vfork。</p><p>fork出来的子进程，没有对SIGPIPE进行任何处理，默认行为是悄悄退出进程。通过修改/etc/ld.so.preload，可以将共享库注入到非关联的进程中，可通过ldd观察到这种依赖，使用LD_PRELOAD也可以达到同样的效果。</p><h3 id="crontab编辑后cron异常"><a href="#crontab编辑后cron异常" class="headerlink" title="crontab编辑后cron异常"></a>crontab编辑后cron异常</h3><p>使用crontab编辑后，cron卡住不动(不是指进程卡住了，而是指命令没有被调用)，原因可能是因为“tcb table full”，最简单的办法是重启cron。</p><p>建议避免写下面这样的嵌套命令语句，它有可能导致cron不能正常工作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo &quot;`date +%H:%M:%S` hello&quot; &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>“echo”中嵌套了“date”，可以改成脚本调用，或者不嵌套命令，如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo &quot;hello&quot; &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>一个现象是有一个cron子进程(如下述的14786)不退出了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ps -ef|grep cron</span></span><br><span class="line"></span><br><span class="line">root     10325     1  0 15:08 ?        00:00:00 /usr/sbin/cron</span><br><span class="line">root     14786 10325  0 15:13 ?        00:00:00 /usr/sbin/cron</span><br></pre></td></tr></table></figure><p>gdb看到的调用栈为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">0  0xffffe410 <span class="keyword">in</span> __kernel_vsyscall ()</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1  0xb7e88a63 <span class="keyword">in</span> __read_nocancel () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">2  0xb7e38e38 <span class="keyword">in</span> _IO_file_read_internal () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">3  0xb7e3a0bb <span class="keyword">in</span> _IO_new_file_underflow () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">4  0xb7e3a7fb <span class="keyword">in</span> _IO_default_uflow_internal () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">5  0xb7e3bb2d <span class="keyword">in</span> __uflow () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">6  0xb7e35b7b <span class="keyword">in</span> getc () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">7  0x80005d73 <span class="keyword">in</span> ?? () from /usr/sbin/cron</span></span><br></pre></td></tr></table></figure><p>strace看到如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> strace -f -p 14786</span></span><br><span class="line"></span><br><span class="line">Process 14786 attached</span><br><span class="line">read(7,</span><br></pre></td></tr></table></figure><p>借助lsof可以看到：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cron    14786 root    7r  FIFO        0,6         117960708 pipe</span><br></pre></td></tr></table></figure><p>为一个管道，read()挂住的原因可能是因为管道另一端所在进程调用_exit()退出而不是调用exit()退出。</p><p>这个时候只有人工kill这个挂起的cron子进程。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
