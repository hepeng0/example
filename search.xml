<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>网络是怎么连接的-浏览器输入一个网址的全过程</title>
      <link href="/2022/08/11/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84-%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"/>
      <url>/2022/08/11/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84-%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>网络是由很多计算机等设备相互连接组成的，因此在通信的过程中需要确定正确的通信对象，并将请求和响应发送给它们。</p><p>而请求和响应在传递的过程中可能会丢失或损坏。</p><p>我们需要一种机制，无论遇到任何情况都能够将请求和响应准确无误地发送给对方。</p><p>由于请求和响应都是由0和1组成的数字信息，所以可以说，我们需要的是一种<strong>能够将数字信息搬运到指定目的地的机制</strong>。</p><p>这种机制是由操作系统中的网络控制软件，以及交换机、路由器等设备分工合作来实现的。</p><p>它的基本思路是将数字信息分割成一个一个的小块，然后装入一些被称为“包”（Packet）的容器中来运送。</p><pre><code>包相当于信件或者包裹，而交换机和路由器则相当于邮局或快递公司的分拣处理区。包的头部存有目的地等控制信息，通过许多交换机和路由器的接力，就可以根据控制信息对这些包进行分拣，然后将它们一步一步地搬运到目的地</code></pre><p>这个负责搬运数字信息的机制，再加上浏览器和Web服务器这些网络应用程序，这两部分就组成了网络。</p><h3 id="一切从浏览器中输入网址开始"><a href="#一切从浏览器中输入网址开始" class="headerlink" title="一切从浏览器中输入网址开始"></a>一切从浏览器中输入网址开始</h3><h4 id="浏览器要先解析URL"><a href="#浏览器要先解析URL" class="headerlink" title="浏览器要先解析URL"></a>浏览器要先解析URL</h4><p>实际上，浏览器本身是一个具备多种客户端功能的综合性客户端软件，因此它需要一些东西来判断应该使用其中哪种功能来访问相应的数据，URL也就有了各种不同的格式。</p><p><img src="/2022/08/11/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84-%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/img.png" alt="URL的各种协议"></p><p>我们根据HTTP的规格，对URL进行拆分，就可以得到浏览器解析URL的过程：</p><p><img src="/2022/08/11/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84-%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/img_1.png" alt="Web浏览器解析URL过程"></p><h4 id="生成HTTP请求消息"><a href="#生成HTTP请求消息" class="headerlink" title="生成HTTP请求消息"></a>生成HTTP请求消息</h4><p>对URL进行解析之后，浏览器确定了Web服务器和文件名，接下来就是根据这些信息来生成HTTP请求消息了。</p><p>实际上，HTTP消息在格式上是有严格规定的，因此浏览器和Web服务器会按照规定的格式来生成请求消息。</p><p><img src="/2022/08/11/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9E%E6%8E%A5%E7%9A%84-%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/img_2.png" alt="HTTP消息格式"></p><h3 id="向DNS服务器查询Web服务器的IP地址"><a href="#向DNS服务器查询Web服务器的IP地址" class="headerlink" title="向DNS服务器查询Web服务器的IP地址"></a>向DNS服务器查询Web服务器的IP地址</h3><p>对于DNS服务器，我们的计算机上一定有相应的DNS客户端（称为DNS解析器），根据域名查询IP地址时，浏览器会使用Socket库中的解析器。</p><p>调用解析器后，解析器会向DNS服务器发送查询消息，然后DNS服务器会返回响应消息。响应消息中包含查询到的IP地址，解析器会取出IP地址，并将其写入浏览器指定的内存地址中。</p><p>浏览器在向Web服务器发送消息时，只要从该内存地址取出IP地址，并将它与HTTP请求消息一起交给操作系统就可以了。</p><h4 id="DNS解析器的内部原理"><a href="#DNS解析器的内部原理" class="headerlink" title="DNS解析器的内部原理"></a>DNS解析器的内部原理</h4><ul><li>浏览器调用解析器</li><li>浏览器对于程序被暂停，Socket库中的解析器开始运行，完成应用程序委托的操作（控制流程转移）；</li><li>当控制流程转移到解析器后，解析器会生成要发送给DNS服务器的查询消息；</li><li>委托给操作系统内部的协议栈来执行消息发送（解析器本身也不具备使用网络收发数据的功能）；</li><li>解析器调用协议栈后，控制流程会再次转移，协议栈会执行发送消息的操作，然后通过网卡将消息发送给DNS服务器；<ul><li>DNS服务器地址在TCP/IP事先已经设置完成</li></ul></li><li>协议栈将DNS服务器返回信息传递给解析器；</li><li>解析器取出IP地址写入应用程序指定内存中；</li><li>应用程序从内存中取出地址，委托协议栈发送消息。</li></ul><h4 id="全世界DNS服务器大接力"><a href="#全世界DNS服务器大接力" class="headerlink" title="全世界DNS服务器大接力"></a>全世界DNS服务器大接力</h4><p>DNS服务器会从域名与IP地址的对照表中查找相应的记录，并返回IP地址。 然而，互联网中存在着不计其数的服务器，将这些服务器的信息全部保存在一台DNS服务器中是不可能的，因此一定会出现在DNS服务器中找不到要查询的信息的情况。</p><p>因此，我们需要将信息分布保存在多台DNS服务器中，这些DNS服务器多次相互配合接力，从而找到要查询的信息。</p><ul><li>DNS服务器中的所有信息都是按照域名以分层次的结构来保存的<ul><li>用句点分隔</li><li>越靠右的位置层级越高</li></ul></li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统总结之如何设计一个高吞吐的系统概述</title>
      <link href="/2022/07/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%90%9E%E5%90%90%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"/>
      <url>/2022/07/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%90%9E%E5%90%90%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h3 id="多级缓存"><a href="#多级缓存" class="headerlink" title="多级缓存"></a>多级缓存</h3><ul><li>多级缓存机制，读写各一层缓存，减少并发冲突</li><li>请求消息放入缓冲，批量处理，减少后续网络请求</li></ul><h3 id="池化资源复用-amp-削峰填谷"><a href="#池化资源复用-amp-削峰填谷" class="headerlink" title="池化资源复用&amp;削峰填谷"></a>池化资源复用&amp;削峰填谷</h3><ul><li>大量采用池化技术，如线程池、连接池等减少资源申请和销毁</li><li>懒加载机制，当使用到时，采取请求数据，并且缓存。</li></ul><h3 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h3><ul><li>减少使用synchronized，大量使用Atomic，volatile，cas等基于乐观思想实现的锁机制</li><li>使用synchronized时，采用分段加锁机制，减少并发冲突时间等待</li></ul><h3 id="NIO-多路复用"><a href="#NIO-多路复用" class="headerlink" title="NIO-多路复用"></a>NIO-多路复用</h3><ul><li>采用NIO，多路复用机制实现少量线程支持大量客户端连接及请求</li></ul><h3 id="空间换时间"><a href="#空间换时间" class="headerlink" title="空间换时间"></a>空间换时间</h3><ul><li>大量使用并发安全集合，队列，列表，解决复杂数据结构并发安全，减少使用synchronized关键字，提升并发性能</li><li>耗时逻辑，利用数据结构和算法将耗时操作分散在各个逻辑中，比如redis中字典的扩容操作</li><li>压缩时间复杂度，设计优秀方案、算法、数据结构，用少量空间换时间</li></ul><h3 id="存储-amp-传输性能优化"><a href="#存储-amp-传输性能优化" class="headerlink" title="存储&amp;传输性能优化"></a>存储&amp;传输性能优化</h3><ul><li>压缩存储数据格式，少用基于java对象序列化，基于二进制保存</li><li>顺序读写</li><li>采用DMA，减少用户态和内核态频繁切换，减少性能消耗</li><li>采用os cache，减少磁盘IO操作，理论牺牲小部分数据丢失，增加处理能力</li><li>采用ByteBuffer Pool，使用堆外内存，复用内存空间，减少内存开辟和销毁性能消耗</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 设计理论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统第三步之一个新进程的诞生</title>
      <link href="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/"/>
      <url>/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/</url>
      
        <content type="html"><![CDATA[<p>第一步和第二步，为我们这个第三步做了充足的铺垫工作。</p><ul><li>第一步 进入内核前的苦力活</li><li>第二步 大战前期的初始化工作</li></ul><p>到了第三步，简单说就是从内核态切换到用户态，然后通过 fork 创建出一个新的进程，再之后老进程进入死循环。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    // 第二部分的内容，各种初始化工作</span><br><span class="line">    ...</span><br><span class="line">    // 第三部分的内容，一个新进程的诞生</span><br><span class="line">    move_to_user_mode();</span><br><span class="line">    if (!fork()) &#123;</span><br><span class="line">        // 新进程里干了啥，是第四部分的内容</span><br><span class="line">        init();</span><br><span class="line">    &#125;</span><br><span class="line">    // 死循环，操作系统怠速状态</span><br><span class="line">    for(;;) pause();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至于 fork 出来的新进程做了什么事，就是 init 函数里的故事里，这个不在第三部分的讨论范畴。</p><p>所以你看，一共就两行代码，顶多再算上最后一行的死循环，三行，就把创建新进程这个事搞定了。</p><p>再加上新进程里要做的 init 函数，一共四行代码，就走到了 main 函数的结尾，也就标志着操作系统启动完毕！</p><p>但就是这没有多少个字母的四行代码，是整个操作系统的精髓所在，也是最难的四行代码。</p><h3 id="整体概览"><a href="#整体概览" class="headerlink" title="整体概览"></a>整体概览</h3><h4 id="move-to-user-mode"><a href="#move-to-user-mode" class="headerlink" title="move_to_user_mode"></a>move_to_user_mode</h4><p>直译过来即可，就是转变为用户态模式。因为 Linux 将操作系统特权级分为用户态与内核态两种，之前都处于内核态，现在要先转变为用户态，仅此而已。</p><p>一旦转变为了用户态，那么之后的代码将一直处于用户态的模式，除非发生了中断，比如用户发出了系统调用的中断指令，那么此时将会从用户态陷入内核态，不过当中断处理程序执行完之后，又会通过中断返回指令从内核态回到用户态。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img.png"></p><p>整个过程被操作系统的机制拿捏的死死的，始终让用户进程处于用户态运行，必要的时候陷入一下内核态，但很快就会被返回而再次回到用户态，是不是非常无奈？</p><h4 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h4><p>这是创建一个新进程的意思，而且所有用户进程想要创建新的进程，都需要调用这个函数。</p><p>原来操作系统只有一个执行流，就是我们一直看过来的所有代码，就是进程 0，只不过我们并没有意识到它也是一个进程。调用完 fork 之后，现在又多了一个进程，叫做进程 1。</p><p>当然，更准确的说法是，我们一路看过来的代码能够被我们自信地称作进程 0 的确切时刻，是我们在 <code>进程调度初始化 sched_init</code> 里为当前执行流添加了一个进程管理结构到 task 数组里，同时开启了定时器以及时钟中断的那一个时刻。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_1.png"></p><p>因为此时时钟中断到来之后，就可以执行到我们的进程调度程序，进程调度程序才会去这个 task 数组里挑选合适的进程进行切换。所以此时，我们当前执行的代码，才真正有了一个进程的身份，才勉强得到了一个可以被称为进程 0 的资格，毕竟还没有其他进程参与竞争。</p><h4 id="init"><a href="#init" class="headerlink" title="init"></a>init</h4><p>只有进程 1 会走到这个分支来执行。</p><p>这里的代码可太多了，它本身需要完成如加载根文件系统的任务，同时这个方法将又会创建出一个新的进程 2，在进程 2 里又会加载与用户交互的 shell 程序，此时操作系统就正式成为了用户可用的一个状态了。</p><h4 id="pause"><a href="#pause" class="headerlink" title="pause"></a>pause</h4><p>当没有任何可运行的进程时，操作系统会悬停在这里，达到怠速状态。没啥好说的，操作系统就是由中断驱动的一个死循环。</p><p>一共四句话，切换到用户态，创建新进程，初始化，然后悬停怠速。</p><h3 id="从内核态到用户态"><a href="#从内核态到用户态" class="headerlink" title="从内核态到用户态"></a>从内核态到用户态</h3><h4 id="让进程无法逃出用户态"><a href="#让进程无法逃出用户态" class="headerlink" title="让进程无法逃出用户态"></a>让进程无法逃出用户态</h4><p>我相信你肯定听说过操作系统的内核态与用户态，用户进程都在用户态这个特权级下运行，而有时程序想要做一些内核态才允许做的事情，比如读取硬盘的数据，就需要通过系统调用，来请求操作系统在内核态特权级下执行一些指令。</p><p>我们现在的代码，还是在内核态下运行，之后操作系统达到怠速状态时，是以用户态的 shell 进程运行，随时等待着来自用户输入的命令。</p><p>所以，就在这一步，也就是 <code>move_to_user_mode</code> 这行代码，作用就是将当前代码的特权级，从内核态变为用户态。</p><p>一旦转变为了用户态，那么之后的代码将一直处于用户态的模式，除非发生了中断，比如用户发出了系统调用的中断指令，那么此时将会从用户态陷入内核态，不过当中断处理程序执行完之后，又会通过中断返回指令从内核态回到用户态。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_2.png"></p><p>整个过程被操作系统的机制拿捏的死死的，始终让用户进程处于用户态运行，必要的时候陷入一下内核态，但很快就会被返回而再次回到用户态，是不是非常无奈？这样操作系统就掌控了控制权，而用户进程再怎么折腾也无法逃出这个模式。</p><h4 id="内核态与用户态的本质-特权级"><a href="#内核态与用户态的本质-特权级" class="headerlink" title="内核态与用户态的本质-特权级"></a>内核态与用户态的本质-特权级</h4><p>首先从一个最大的视角来看，这一切都源于 CPU 的保护机制。</p><p>CPU 为了配合操作系统完成保护机制这一特性，分别设计了<strong>分段保护机制</strong>与<strong>分页保护机制</strong>。</p><p>参考<a href="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/" title="操作系统第一步之进入内核前的苦力活">操作系统第一步之进入内核前的苦力活</a>， 将 cr0 寄存器的 PE 位开启时，就开启了保护模式，也即开启了分段保护机制。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_3.png"></p><p>将 cr0 寄存器的 PG 位开启时，就开启了分页模式，也即开启了分页保护机制。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_4.png"></p><p>有关特权级的保护，实际上属于分段保护机制的一种。具体怎么保护的呢？由于这里的细节比较繁琐，所以我举个例子简单理解下即可，实际上的特权级检查规则要比我说的多好多内容。</p><p>我们目前正在执行的代码地址，是通过 CPU 中的两个寄存器 cs : eip 指向的对吧？cs 寄存器是代码段寄存器，里面存着的是段选择子，还记得它的结构么？</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_5.png"></p><p>这里面的低端两位，此时表示 CPL，也就是当前所处的特权级，假如我们现在这个时刻，CS 寄存器的后两位为 3，二进制就是 11，就表示是当前处理器处于用户态这个特权级。</p><p>假如我们此时要跳转到另一处内存地址执行，在最终的汇编指令层面无非就是 jmp、call 和中断。我们拿 jmp 跳转来举例。</p><ul><li>如果是短跳转，也就是直接 jmp xxx，那不涉及到段的变换，也就没有特权级检查这回事。</li><li>如果是长跳转，也就是 jmp yyy : xxx，这里的 yyy 就是另一个要跳转到的段的段选择子结构。</li></ul><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_6.png"></p><p>这个结构仍然是一样的段选择子结构，只不过这里的低端两位，表示 RPL，也就是请求特权级，表示我想请求的特权级是什么。</p><p>同时，CPU 会拿这个段选择子去全局描述符表中寻找段描述符，从中找到段基址。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_7.png"></p><p>那还记得段描述符的样子么？</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_8.png"></p><p>你看，这里面又有个 DPL，这表示目标代码段特权级，也就是即将要跳转过去的那个段的特权级。</p><p>好了，我们总结一下简图，就是这三个玩意的比较。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_9.png"></p><p>这里的检查规则比较多，简单说，绝大多数情况下，要求 CPL 必须等于 DPL，才会跳转成功，否则就会报错。</p><p>也就是说，当前代码所处段的特权级，必须要等于要跳转过去的代码所处的段的特权级，那就只能<strong>用户态往用户态跳，内核态往内核态跳</strong>，这样就防止了处于用户态的程序，跳转到内核态的代码段中做坏事。</p><p>这只是代码段跳转时所做的特权级检查，还有访问内存数据时也会有数据段的特权级检查，这里就不展开了。</p><p>最终的效果是，<strong>处于内核态的代码可以访问任何特权级的数据段，处于用户态的代码则只可以访问用户态的数据段</strong>，这也就实现了内存数据读写的保护。</p><p>说了这么多，其实就是，<strong>代码跳转只能同特权级，数据访问只能高特权级访问低特权级</strong>。</p><h4 id="特权级转换的方式"><a href="#特权级转换的方式" class="headerlink" title="特权级转换的方式"></a>特权级转换的方式</h4><p>从内核态转变为用户态，那如果代码跳转只能同特权级跳，我们现在处于内核态，要怎么样才能跳转到用户态呢？</p><p>Intel 设计了好多种特权级转换的方式，中断和中断返回就是其中的一种。</p><p><strong>处于用户态的程序，通过触发中断，可以进入内核态，之后再通过中断返回，又可以恢复为用户态</strong>。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_2.png"></p><p>而<strong>系统调用</strong>就是这么玩的，用户通过 int 0x80 中断指令触发了中断，CPU 切换至内核态，执行中断处理程序，之后中断程序返回，又从内核态切换回用户态。</p><p>但有个问题是，我们当前的代码，此时就是处于内核态，并不是由一个用户态程序通过中断而切换到的内核态，那怎么回到原来的用户态呢？答案还是，通过中断返回。</p><p>没有中断也能中断返回？可以的，Intel 设计的 CPU 就是这样不符合人们的直觉，中断和中断返回的确是应该配套使用的，但也可以单独使用，我们看代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...    </span><br><span class="line">    move_to_user_mode();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">define move_to_user_mode() \</span></span><br><span class="line"><span class="bash">_asm &#123; \</span></span><br><span class="line"><span class="bash">    _asm mov eax,esp \</span></span><br><span class="line"><span class="bash">    _asm push 00000017h \</span></span><br><span class="line"><span class="bash">    _asm push eax \</span></span><br><span class="line"><span class="bash">    _asm pushfd \</span></span><br><span class="line"><span class="bash">    _asm push 0000000fh \</span></span><br><span class="line"><span class="bash">    _asm push offset l1 \</span></span><br><span class="line"><span class="bash">    _asm iretd /* 执行中断返回指令*/ \</span></span><br><span class="line"><span class="bash">_asm l1: mov eax,17h \</span></span><br><span class="line"><span class="bash">    _asm mov ds,ax \</span></span><br><span class="line"><span class="bash">    _asm mov es,ax \</span></span><br><span class="line"><span class="bash">    _asm mov fs,ax \</span></span><br><span class="line"><span class="bash">    _asm mov gs,ax \</span></span><br><span class="line"><span class="bash">&#125;</span></span><br></pre></td></tr></table></figure><p>你看，这个方法里直接就执行了中断返回指令 iretd。 那么为什么之前进行了一共五次的压栈操作呢？ </p><p>因为中断返回理论上就是应该和中断配合使用的，而此时并不是真的发生了中断到这里，所以我们得假装发生了中断才行，怎么假装呢？</p><p>其实就把栈做做工作就好了:</p><ul><li>中断发生时，CPU 会自动帮我们做如下的压栈操作。</li><li>中断返回时，CPU 又会帮我们把压栈的这些值返序赋值给响应的寄存器。</li></ul><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/%E4%B8%AD%E6%96%AD%E4%B8%8E%E5%8E%8B%E6%A0%88%E6%93%8D%E4%BD%9C.png"></p><p>去掉错误码，刚好是五个参数，所以我们在代码中模仿 CPU 进行了五次压栈操作，这样在执行 iretd 指令时，硬件会按顺序将刚刚压入栈中的数据，分别赋值给 SS、ESP、EFLAGS、CS、EIP 这几个寄存器，这就感觉像是正确返回了一样，让其误以为这是通过中断进来的。</p><ul><li>压入栈的 CS 和 EIP 就表示中断发生前代码所处的位置，这样中断返回后好继续去那里执行。</li><li>压入栈的 SS 和 ESP 表示中断发生前的栈的位置，这样中断返回后才好恢复原来的栈。</li></ul><p>其中，特权级的转换，就体现在 CS 和 SS 寄存器的值里，都是细节！</p><p>拿 CS 举例，给它赋的值是，0000000fh，用二进制表示为： <code>0000000000001111</code></p><p>最后两位 11 表示特权级为 3，即用户态。而我们刚刚说了，CS 寄存器里的特权级，表示 CPL，即当前处理器特权级。</p><p><strong>所以经过 iretd 返回之后，CS 的值就变成了它，而当前处理器特权级，也就变成了用户态特权级。</strong></p><h4 id="除了改变特权级之外"><a href="#除了改变特权级之外" class="headerlink" title="除了改变特权级之外"></a>除了改变特权级之外</h4><p>刚刚我们关注段寄存器，只关注了特权级的部分，除了改变了特权级之外，还做了什么事情呢，我们再详细看看。</p><p>刚刚说了 CS 寄存器为 <code>0000000000001111</code>，最后两位表示用户态的含义。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_5.png"></p><p>那继续解读，倒数第三位 TI 表示，前面的描述符索引，是从 GDT 还是 LDT 中取，1 表示 LDT，也就是从局部描述符表中取，表示从局部描述符表中取到代码段描述符。</p><p>在进程调度初始化中， 0 号 LDT 作为当前的 LDT 索引，记录在了 CPU 的 lldt 寄存器中。</p><p>而整个 GDT 与 LDT 表的设计，目前是这个样子</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_11.png"></p><p>所以，一目了然。</p><p>再看这行代码，把 EIP 寄存器赋值为了那行标号的地址。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">define move_to_user_mode() \</span></span><br><span class="line"><span class="bash">_asm &#123; \</span></span><br><span class="line"><span class="bash">   ...</span></span><br><span class="line">    _asm push offset l1 \</span><br><span class="line">    _asm iretd /* 执行中断返回指令*/ \</span><br><span class="line">_asm l1: mov eax,17h \</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里刚好设置的是下面标号 l1 的位置，所以 iretd 之后 CPU 就乖乖去那里执行了。</p><p>所以其实从效果上看，就是顺序往下执行，只不过利用了 iretd 做了些特权级转换等工作。</p><p>同理，这里的栈段 ss 和数据段 ds，都被赋值为了 17h，大家可以展开二进制算一下，他们又是什么特权级，对应的描述符又是谁。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>所以其实，最终效果上看就是按顺序执行了我们所写的指令，通过模拟中断返回实现了特权级的翻转，也就是从内核态变为了用户态，顺便设置了栈段、代码段和数据段的基地址。</p><p>好了，我们兜兜转转终于把这个 mov_to_user_mode 讲完了，特权级这块的检查细节非常繁琐，为了理解操作系统，我们只需要暂且记住如下一句话就好了：</p><p><strong>数据访问只能高特权级访问低特权级，代码跳转只能同特权级跳转，要想实现特权级转换，可以通过中断和中断返回来实现。</strong></p><details><summary>由此，表明需要内核态来完成的工作已经全部安排妥当</summary><ul><li>对全局描述符表、中断描述符表、页表等关键内存结构进行设置</li><li>以及对 CPU 特殊寄存器如 cr0 和 cr3 的设置</li><li>对外设如硬盘、键盘、定时器的设置等</li></ul></details><p>接下来只需要在用户态进行工作即可了</p><h3 id="如果让你来设计进程调度"><a href="#如果让你来设计进程调度" class="headerlink" title="如果让你来设计进程调度"></a>如果让你来设计进程调度</h3><p>创建新进程的过程，是一个很能体现操作系统设计的地方。在研究fork实现代码前，我们先头脑风暴一下，如果自己设计进程调度，我们会怎么弄。</p><p>进程调度本质是什么？很简单，假如有三段代码被加载到内存中。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_12.png"></p><p>进程调度就是让 CPU 一会去程序 1 的位置处运行一段时间，一会去程序 2 的位置处运行一段时间。</p><h4 id="整体流程设计"><a href="#整体流程设计" class="headerlink" title="整体流程设计"></a>整体流程设计</h4><ul><li>方案1 <ul><li>程序 1 的代码里，每隔几行就写一段代码，主动放弃自己的执行权，跳转到程序 2 的地方运行。</li><li>然后程序 2 也是如此。</li><li>这种依靠程序自己的办法肯定不靠谱。</li></ul></li><li>方案2<ul><li>由一个不受任何程序控制的，第三方的不可抗力，每隔一段时间就中断一下 CPU 的运行，</li><li>然后跳转到一个特殊的程序那里，这个程序通过某种方式获取到 CPU 下一个要运行的程序的地址，然后跳转过去。</li></ul></li></ul><p>每隔一段时间就中断 CPU 的不可抗力，就是由定时器触发的<strong>时钟中断</strong>，这个定时器和时钟中断，在进程调度初始化的<code>sched_init</code>中已经搞定了。</p><p>而那个特殊的程序，就是具体的<strong>进程调度函数</strong>了。</p><p>好了，整个流程就这样处理完了，那么应该设计什么样的数据结构，来支持这个流程呢？不妨假设这个结构叫 tast_struct。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">struct task_struct &#123;</span><br><span class="line">    ?</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>换句话说，你总得有一个结构来记录各个进程的信息，比如它上一次执行到哪里了，要不 CPU 就算决定好了要跳转到你这个进程上运行，具体跳到哪一行运行，总得有个地方存吧？</p><h4 id="上下文环境"><a href="#上下文环境" class="headerlink" title="上下文环境"></a>上下文环境</h4><p>每个程序最终的本质就是执行指令。这个过程会涉及<strong>寄存器，内存和外设端口</strong>。</p><p>内存还有可能设计成相互错开的，互不干扰，比如进程 1 你就用 0<del>1K 的内存空间，进程 2 就用 1K</del>2K 的内存空间，咱谁也别影响谁。</p><p>虽然有点浪费空间，而且对程序员十分不友好，但起码还是能实现的。</p><p>不过寄存器一共就那么点，肯定做不到互不干扰，可能一个进程就把寄存器全用上了，那其他进程咋整。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_13.png"></p><p>比如程序 1 刚刚往 eax 写入一个值，准备用，这时切换到进程 2 了，又往 eax 里写入了一个值。那么之后再切回进程 1 的时候，就出错了。</p><p>所以最稳妥的做法就是</p><details><summary>每次切换进程时，都把当前这些寄存器的值存到一个地方，以便之后切换回来的时候恢复</summary><p>每个进程的结构 task_struct 里面，有一个叫 tss 的结构，存储的就是 CPU 这些寄存器的信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">struct task_struct &#123;</span><br><span class="line">    ...</span><br><span class="line">    struct tss_struct tss;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct tss_struct &#123;</span><br><span class="line">    long    back_link;  /* 16 high bits zero */</span><br><span class="line">    long    esp0;</span><br><span class="line">    long    ss0;        /* 16 high bits zero */</span><br><span class="line">    long    esp1;</span><br><span class="line">    long    ss1;        /* 16 high bits zero */</span><br><span class="line">    long    esp2;</span><br><span class="line">    long    ss2;        /* 16 high bits zero */</span><br><span class="line">    long    cr3;</span><br><span class="line">    long    eip;</span><br><span class="line">    long    eflags;</span><br><span class="line">    long    eax,ecx,edx,ebx;</span><br><span class="line">    long    esp;</span><br><span class="line">    long    ebp;</span><br><span class="line">    long    esi;</span><br><span class="line">    long    edi;</span><br><span class="line">    long    es;     /* 16 high bits zero */</span><br><span class="line">    long    cs;     /* 16 high bits zero */</span><br><span class="line">    long    ss;     /* 16 high bits zero */</span><br><span class="line">    long    ds;     /* 16 high bits zero */</span><br><span class="line">    long    fs;     /* 16 high bits zero */</span><br><span class="line">    long    gs;     /* 16 high bits zero */</span><br><span class="line">    long    ldt;        /* 16 high bits zero */</span><br><span class="line">    long    trace_bitmap;   /* bits: trace 0, bitmap 16-31 */</span><br><span class="line">    struct i387_struct i387;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></details><p>这里提个细节，你发现 tss 结构里还有个 cr3 不？它表示 cr3 寄存器里存的值，而 cr3 寄存器是指向页目录表首地址的。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_14.png"></p><p>那么指向不同的页目录表，整个页表结构就是完全不同的一套，那么线性地址到物理地址的映射关系就有能力做到不同。</p><p>也就是说，在我们刚刚假设的理想情况下，不同程序用不同的内存地址可以做到内存互不干扰。</p><p>但是有了这个 cr3 字段，就完全可以无需由各个进程自己保证不和其他进程使用的内存冲突，因为只要建立不同的映射关系即可，由操作系统来建立不同的页目录表并替换 cr3 寄存器即可。</p><p>这也可以理解为，保存了<strong>内存映射的上下文信息</strong>。</p><p>当然 Linux 0.11 并不是通过替换 cr3 寄存器来实现内存互不干扰的，它的实现更为简单，这是后话了。</p><h4 id="运行时间信息"><a href="#运行时间信息" class="headerlink" title="运行时间信息"></a>运行时间信息</h4><p>如何判断一个进程该让出 CPU 了，切换到下一个进程呢？ 总不能是每次时钟中断时都切换一次吧？一来这样不灵活，二来这完全依赖时钟中断的频率，有点危险。</p><p>所以一个好的办法就是，给进程一个属性，叫<strong>剩余时间片</strong>，每次时钟中断来了之后都 -1，如果减到 0 了，就触发切换进程的操作。</p><p>在 Linux 0.11 里，这个属性就是 counter。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct task_struct &#123;</span><br><span class="line">    ...</span><br><span class="line">    long counter;</span><br><span class="line">    ...</span><br><span class="line">    struct tss_struct tss;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而他的用法也非常简单，就是每次中断都判断一下是否到 0 了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void do_timer(long cpl) &#123;</span><br><span class="line">    ...</span><br><span class="line">    // 当前线程还有剩余时间片，直接返回</span><br><span class="line">    if ((--current-&gt;counter)&gt;0) return;</span><br><span class="line">    // 若没有剩余时间片，调度</span><br><span class="line">    schedule();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果还没到 0，就直接返回，相当于这次时钟中断什么也没做，仅仅是给当前进程的时间片属性做了 -1 操作。</p><p>如果已经到 0 了，就触发<strong>进程调度</strong>，选择下一个进程并使 CPU 跳转到那里运行。 进程调度的逻辑就是在 schedule 函数里，怎么调，我们先不管。</p><h4 id="优先级"><a href="#优先级" class="headerlink" title="优先级"></a>优先级</h4><p>上面那个 counter 一开始的时候该是多少呢？而且随着 counter 不断递减，减到 0 时，下一轮回中这个 counter 应该赋予什么值呢？</p><p>其实这俩问题都是一个问题，就是 <strong>counter 的初始化</strong>问题，也需要有一个属性来记录这个值。</p><p>往宏观想一下，这个值越大，那么 counter 就越大，那么每次轮到这个进程时，它在 CPU 中运行的时间就越长，也就是这个进程比其他进程得到了更多 CPU 运行的时间。</p><p>那我们可以把这个值称为<strong>优先级</strong>，是不是很形象。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">struct task_struct &#123;</span><br><span class="line">...</span><br><span class="line">long counter;</span><br><span class="line">long priority;</span><br><span class="line">...</span><br><span class="line">struct tss_struct tss;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>每次一个进程初始化时，都把 counter 赋值为这个 priority，而且当 counter 减为 0 时，下一次分配时间片，也赋值为这个。</p><p>其实叫啥都行，反正就是这么用的，就叫优先级吧。</p><h4 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h4><p>其实我们有了上面那三个信息，就已经可以完成进程的调度了。</p><p>甚至如果你的操作系统让所有进程都得到同样的运行时间，连 counter 和 priority 都不用记录，就操作系统自己定一个固定值一直递减，减到 0 了就随机切一个新进程。 这样就仅仅维护好寄存器的上下文信息 tss 就好了。</p><p>但我们总要不断优化以适应不同场景的用户需求的，很简单的一个场景，一个进程中有一个读取硬盘的操作，发起读请求后，要等好久才能得到硬盘的中断信号。 </p><ul><li>那这个时间其实该进程再占用着 CPU 也没用，此时就可以选择主动放弃 CPU 执行权，然后再把自己的状态标记为等待中。 </li><li>意思是告诉进程调度的代码，先别调度我，因为我还在等硬盘的中断，现在轮到我了也没用，把机会给别人吧。</li></ul><p>那这个状态可以记录一个属性了，叫 state，记录了此时进程的状态。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">struct task_struct &#123;</span><br><span class="line">    long state;</span><br><span class="line">    long counter;</span><br><span class="line">    long priority;</span><br><span class="line">    ...</span><br><span class="line">    struct tss_struct tss;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而这个进程的状态在 Linux 0.11 里有这么五种。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#define TASK_RUNNING          0</span><br><span class="line">#define TASK_INTERRUPTIBLE    1</span><br><span class="line">#define TASK_UNINTERRUPTIBLE  2</span><br><span class="line">#define TASK_ZOMBIE           3</span><br><span class="line">#define TASK_STOPPED          4</span><br></pre></td></tr></table></figure><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>好了，目前我们这几个字段，就已经可以完成简单的进程调度任务了：</p><ul><li>有表示状态的 state</li><li>表示剩余时间片的 counter</li><li>表示优先级的 priority</li><li>和表示上下文信息的 tss</li></ul><p>其他字段我们需要用到的时候再说记住这四个字段就可以了</p><details><summary>看一下 Linux 0.11 中进程结构的全部，心里先有个数，具体干嘛的先不管</summary><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">struct task_struct &#123;</span><br><span class="line">/* these are hardcoded - don&#x27;t touch */</span><br><span class="line">    long state; /* -1 unrunnable, 0 runnable, &gt;0 stopped */</span><br><span class="line">    long counter;</span><br><span class="line">    long priority;</span><br><span class="line">    long signal;</span><br><span class="line">    struct sigaction sigaction[32];</span><br><span class="line">    long blocked;   /* bitmap of masked signals */</span><br><span class="line">/* various fields */</span><br><span class="line">    int exit_code;</span><br><span class="line">    unsigned long start_code,end_code,end_data,brk,start_stack;</span><br><span class="line">    long pid,father,pgrp,session,leader;</span><br><span class="line">    unsigned short uid,euid,suid;</span><br><span class="line">    unsigned short gid,egid,sgid;</span><br><span class="line">    long alarm;</span><br><span class="line">    long utime,stime,cutime,cstime,start_time;</span><br><span class="line">    unsigned short used_math;</span><br><span class="line">/* file system info */</span><br><span class="line">    int tty;        /* -1 if no tty, so it must be signed */</span><br><span class="line">    unsigned short umask;</span><br><span class="line">    struct m_inode * pwd;</span><br><span class="line">    struct m_inode * root;</span><br><span class="line">    struct m_inode * executable;</span><br><span class="line">    unsigned long close_on_exec;</span><br><span class="line">    struct file * filp[NR_OPEN];</span><br><span class="line">/* ldt for this task 0 - zero 1 - cs 2 - ds&amp;ss */</span><br><span class="line">    struct desc_struct ldt[3];</span><br><span class="line">/* tss for this task */</span><br><span class="line">    struct tss_struct tss;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></details><p>由此，我们知道了进程调度：</p><ul><li>开始，要从一次定时器滴答来触发，通过时钟中断处理函数走到进程调度函数，</li><li>然后去进程的结构 task_struct 中取出所需的数据，</li><li>进行策略计算，并挑选出下一个可以得到 CPU 运行的进程，跳转过去。</li></ul><h3 id="从一次定时器滴答来看进程调度"><a href="#从一次定时器滴答来看进程调度" class="headerlink" title="从一次定时器滴答来看进程调度"></a>从一次定时器滴答来看进程调度</h3><h4 id="时钟中断"><a href="#时钟中断" class="headerlink" title="时钟中断"></a>时钟中断</h4><p>我们在进程调度初始化时，开启了定时器，这个定时器每隔一段时间就会向CPU发起一个中断信号。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_15.png"></p><p>这个间隔时间被设置为 10 ms，也就是 100 Hz。发起的中断叫时钟中断，其中断向量号被设置为了 0x20。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#define HZ 100</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">set_intr_gate(0x20, &amp;timer_interrupt);</span><br></pre></td></tr></table></figure><p>这样，当时钟中断，也就是 0x20 号中断来临时，CPU 会查找中断向量表中 0x20 处的函数地址，即中断处理函数，并跳转过去执行。</p><h4 id="时钟中断处理函数"><a href="#时钟中断处理函数" class="headerlink" title="时钟中断处理函数"></a>时钟中断处理函数</h4><details><summary>这个中断处理函数就是 timer_interrupt，是用汇编语言写的</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">_timer_interrupt:</span><br><span class="line">    ...</span><br><span class="line">    // 增加系统滴答数</span><br><span class="line">    incl _jiffies</span><br><span class="line">    ...</span><br><span class="line">    // 调用函数 do_timer</span><br><span class="line">    call _do_timer</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></details><p>这个函数做了两件事:</p><ul><li>一个是将系统滴答数这个变量 jiffies 加一</li><li>一个是调用了另一个函数 do_timer</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">void do_timer(long cpl) &#123;</span><br><span class="line">    ...</span><br><span class="line">    // 当前线程还有剩余时间片，直接返回</span><br><span class="line">    if ((--current-&gt;counter)&gt;0) return;</span><br><span class="line">    // 若没有剩余时间片，调度</span><br><span class="line">    schedule();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>do_timer 最重要的部分就是上面这段代码，非常简单:</p><ul><li>首先将当先进程的时间片 -1，然后判断：</li><li>如果时间片仍然大于零，则什么都不做直接返回。</li><li>如果时间片已经为零，则调用 schedule()，很明显，这就是进行进程调度的主干。</li></ul><h4 id="进程选择"><a href="#进程选择" class="headerlink" title="进程选择"></a>进程选择</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">void schedule(void) &#123;</span><br><span class="line">    int i, next, c;</span><br><span class="line">    struct task_struct ** p;</span><br><span class="line">    ...</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        c = -1;</span><br><span class="line">        next = 0;</span><br><span class="line">        i = NR_TASKS;</span><br><span class="line">        p = &amp;task[NR_TASKS];</span><br><span class="line">        while (--i) &#123;</span><br><span class="line">            if (!*--p)</span><br><span class="line">                continue;</span><br><span class="line">            if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)</span><br><span class="line">                c = (*p)-&gt;counter, next = i;</span><br><span class="line">        &#125;</span><br><span class="line">        if (c) break;</span><br><span class="line">        for(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span><br><span class="line">            if (*p)</span><br><span class="line">                (*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; 1) +</span><br><span class="line">                        (*p)-&gt;priority;</span><br><span class="line">    &#125;</span><br><span class="line">    switch_to(next);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>做个不严谨的简化</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void schedule(void) &#123;</span><br><span class="line">    int next = get_max_counter_and_runnable_thread();</span><br><span class="line">    refresh_all_thread_counter();</span><br><span class="line">    switch_to(next);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很简答，这个函数就做了三件事：</p><ol><li>拿到剩余时间片（counter的值）最大且在 runnable 状态（state = 0）的进程号 next。<br><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_16.png"></li><li>如果所有 runnable 进程时间片都为 0，则将所有进程（注意不仅仅是 runnable 的进程）的 counter 重新赋值（counter = counter/2 + priority），然后再次执行步骤 1。</li><li>最后拿到了一个进程号 next，调用了 switch_to(next) 这个方法，就切换到了这个进程去执行了。</li></ol><h4 id="进程切换"><a href="#进程切换" class="headerlink" title="进程切换"></a>进程切换</h4><details><summary>看 switch_to 方法，是用内联汇编语句写的</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#define switch_to(n) &#123;\</span><br><span class="line">struct &#123;long a,b;&#125; __tmp; \</span><br><span class="line">__asm__(&quot;cmpl %%ecx,_current\n\t&quot; \</span><br><span class="line">    &quot;je 1f\n\t&quot; \</span><br><span class="line">    &quot;movw %%dx,%1\n\t&quot; \</span><br><span class="line">    &quot;xchgl %%ecx,_current\n\t&quot; \</span><br><span class="line">    &quot;ljmp %0\n\t&quot; \</span><br><span class="line">    &quot;cmpl %%ecx,_last_task_used_math\n\t&quot; \</span><br><span class="line">    &quot;jne 1f\n\t&quot; \</span><br><span class="line">    &quot;clts\n&quot; \</span><br><span class="line">    &quot;1:&quot; \</span><br><span class="line">    ::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \</span><br><span class="line">    &quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>看不懂没关系，其实主要就干了一件事，就是 ljmp 到新进程的 tss 段处。 啥意思？</p><p>CPU 规定，如果 ljmp 指令后面跟的是一个 tss 段，那么，会由硬件将当前各个寄存器的值保存在当前进程的 tss 中，并将新进程的 tss 信息加载到各个寄存器。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/_posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/Linux%E5%86%85%E6%A0%B8%E5%AE%8C%E5%85%A8%E6%B3%A8%E9%87%8AV5.0-Ljmp.png" alt="图片来源Linux内核完全注释V5.0"></p><p>简单说就是，<strong>保存当前进程上下文，恢复下一个进程的上下文，跳过去！</strong></p><h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p>罪魁祸首的，就是那个每 10ms 触发一次的定时器滴答。</p><p>而这个滴答将会给 CPU 产生一个时钟中断信号。</p><p>而这个中断信号会使 CPU 查找中断向量表，找到操作系统写好的一个时钟中断处理函数 do_timer。</p><p>do_timer 会首先将当前进程的 counter 变量 -1，如果 counter 此时仍然大于 0，则就此结束。</p><p>但如果 counter = 0 了，就开始进行进程的调度。</p><p>进程调度就是找到所有处于 RUNNABLE 状态的进程，并找到一个 counter 值最大的进程，把它丢进 switch_to 函数的入参里。</p><p>switch_to 这个终极函数，会保存当前进程上下文，恢复要跳转到的这个进程的上下文，同时使得 CPU 跳转到这个进程的偏移地址处。</p><p>接着，这个进程就舒舒服服地运行了起来，等待着下一次时钟中断的来临。</p><h3 id="回到主流程，通过fork看系统调用流程"><a href="#回到主流程，通过fork看系统调用流程" class="headerlink" title="回到主流程，通过fork看系统调用流程"></a>回到主流程，通过fork看系统调用流程</h3><h4 id="fork函数"><a href="#fork函数" class="headerlink" title="fork函数"></a>fork函数</h4><p>自此，我们通过自己设计了一遍进程调度，又看了一次 Linux 0.11 的进程调度的全过程。了解了进程调度具体实现，接下来，回到我们的主流程中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...    </span><br><span class="line">    move_to_user_mode();</span><br><span class="line">    if (!fork()) &#123;</span><br><span class="line">        init();</span><br><span class="line">    &#125;</span><br><span class="line">    for(;;) pause();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><details><summary>这个 fork 函数干了啥?</summary><p>这个 fork 函数稍稍绕了点，我们看如下代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">static _inline _syscall0(int,fork)</span><br><span class="line"></span><br><span class="line">#define _syscall0(type,name) \</span><br><span class="line">type name(void) \</span><br><span class="line">&#123; \</span><br><span class="line">long __res; \</span><br><span class="line">__asm__ volatile (&quot;int $0x80&quot; \</span><br><span class="line">    : &quot;=a&quot; (__res) \</span><br><span class="line">    : &quot;0&quot; (__NR_##name)); \</span><br><span class="line">if (__res &gt;= 0) \</span><br><span class="line">    return (type) __res; \</span><br><span class="line">errno = -__res; \</span><br><span class="line">return -1; \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>别急，我把它变成稍稍能看得懂的样子，就是这样。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#define _syscall0(type,name) \</span><br><span class="line">type name(void) \</span><br><span class="line">&#123; \</span><br><span class="line">    volatile long __res; \</span><br><span class="line">    _asm &#123; \</span><br><span class="line">        _asm mov eax,__NR_##name \</span><br><span class="line">        _asm int 80h \</span><br><span class="line">        _asm mov __res,eax \</span><br><span class="line">    &#125; \</span><br><span class="line">    if (__res &gt;= 0) \</span><br><span class="line">        return (type) __res; \</span><br><span class="line">    errno = -__res; \</span><br><span class="line">    return -1; \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以，把宏定义都展开，其实就相当于<strong>定义了一个函数</strong>，仅此而已。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">int fork(void) &#123;</span><br><span class="line">     volatile long __res;</span><br><span class="line">    _asm &#123;</span><br><span class="line">        _asm mov eax,__NR_fork</span><br><span class="line">        _asm int 80h</span><br><span class="line">        _asm mov __res,eax</span><br><span class="line">    &#125;</span><br><span class="line">    if (__res &gt;= 0)</span><br><span class="line">        return (void) __res;</span><br><span class="line">    errno = -__res;</span><br><span class="line">    return -1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>关键指令就是一个 0x80 号软中断的触发，<code>int 80h</code>,还记得 0x80 号中断的处理函数么, 进程调度初始化 <code>sched_init</code>中设置的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set_system_gate(0x80, &amp;system_call);</span><br></pre></td></tr></table></figure><p>其中还有一个 eax 寄存器里的参数是 <code>__NR_fork</code>，这也是个宏定义，值是 2。</p><p>看这个 system_call 的汇编代码，我们发现这么一行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_system_call:</span><br><span class="line">    ...</span><br><span class="line">    call [_sys_call_table + eax*4]</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>这个值就用上了，eax 寄存器里的值是 2，所以这个就是在这个 sys_call_table 表里找下标 2 位置处的函数，然后跳转过去。</p><p>那我们接着看 sys_call_table 是个啥，其实就是各种函数指针组成的一个数组，说白了就是个系统调用函数表。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">fn_ptr sys_call_table[] = &#123; sys_setup, sys_exit, sys_fork, sys_read,</span><br><span class="line">  sys_write, sys_open, sys_close, sys_waitpid, sys_creat, sys_link,</span><br><span class="line">  sys_unlink, sys_execve, sys_chdir, sys_time, sys_mknod, sys_chmod,</span><br><span class="line">  sys_chown, sys_break, sys_stat, sys_lseek, sys_getpid, sys_mount,</span><br><span class="line">  sys_umount, sys_setuid, sys_getuid, sys_stime, sys_ptrace, sys_alarm,</span><br><span class="line">  sys_fstat, sys_pause, sys_utime, sys_stty, sys_gtty, sys_access,</span><br><span class="line">  sys_nice, sys_ftime, sys_sync, sys_kill, sys_rename, sys_mkdir,</span><br><span class="line">  sys_rmdir, sys_dup, sys_pipe, sys_times, sys_prof, sys_brk, sys_setgid,</span><br><span class="line">  sys_getgid, sys_signal, sys_geteuid, sys_getegid, sys_acct, sys_phys,</span><br><span class="line">  sys_lock, sys_ioctl, sys_fcntl, sys_mpx, sys_setpgid, sys_ulimit,</span><br><span class="line">  sys_uname, sys_umask, sys_chroot, sys_ustat, sys_dup2, sys_getppid,</span><br><span class="line">  sys_getpgrp, sys_setsid, sys_sigaction, sys_sgetmask, sys_ssetmask,</span><br><span class="line">  sys_setreuid, sys_setregid</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>那下标 2 位置处是啥？从第零项开始数，第二项就是 sys_fork 函数！</p><p>至此，我们终于找到了 fork 函数，通过系统调用这个中断，最终走到内核层面的函数是什么，就是 sys_fork。</p><h4 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h4><p>由此，我们也可以看出，操作系统 <strong>通过系统调用，提供给用户态可用的功能，都暴露在 sys_call_table</strong> 里了：</p><ul><li>系统调用统一通过 int 0x80 中断来进入，具体调用这个表里的哪个功能函数，就由 eax 寄存器传过来，这里的值是个数组索引的下标，通过这个下标就可以找到在 sys_call_table 这个数组里的具体函数。</li><li>同时也可以看出，用户进程调用内核的功能，可以直接通过写一句 int 0x80 汇编指令，并且给 eax 赋值，当然这样就比较麻烦。</li><li>所以也可以直接调用 fork 这样的包装好的方法，而这个方法里本质也是 int 0x80 以及 eax 赋值而已。</li></ul><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_17.png"></p><details><summary>一些扩展内容，系统调用的参数传递</summary><p>刚刚定义 fork 的系统调用模板函数时，用的是 syscall0，其实这个表示参数个数为 0，也就是 sys_fork 函数并不需要任何参数。</p><p>所以其实，在 unistd.h 头文件里，还定义了 syscall0 ~ syscall3 一共四个宏。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#define _syscall0(type,name)</span><br><span class="line">#define _syscall1(type,name,atype,a)</span><br><span class="line">#define _syscall2(type,name,atype,a,btype,b)</span><br><span class="line">#define _syscall3(type,name,atype,a,btype,b,ctype,c)</span><br></pre></td></tr></table></figure><p>看都能看出来，其实 syscall1 就表示有一个参数，syscall2 就表示有两个参数。</p><p>那这些参数放在哪里了呢？总得有个约定的地方吧？</p><p>我们看一个今后要讲的重点函数，<code>execve</code>，是一个通常和 fork 在一起配合的变身函数，在之后的进程 1 创建进程 2 的过程中，就是这样玩的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void init(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    if (!(pid=fork())) &#123;</span><br><span class="line">        ...</span><br><span class="line">        execve(&quot;/bin/sh&quot;,argv_rc,envp_rc);</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然我们的重点不是研究这个函数的作用，仅仅把它当做研究 syscall3 的一个例子，因为它的宏定义就是 syscall3。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">execve(&quot;/bin/sh&quot;,argv_rc,envp_rc);</span><br><span class="line"></span><br><span class="line">_syscall3(int,execve,const char *,file,char **,argv,char **,envp)</span><br><span class="line"></span><br><span class="line">#define _syscall3(type,name,atype,a,btype,b,ctype,c) \</span><br><span class="line">type name(atype a,btype b,ctype c) &#123; \</span><br><span class="line">    volatile long __res; \</span><br><span class="line">    _asm &#123; \</span><br><span class="line">        _asm mov eax,__NR_##name \</span><br><span class="line">        _asm mov ebx,a \</span><br><span class="line">        _asm mov ecx,b \</span><br><span class="line">        _asm mov edx,c \</span><br><span class="line">        _asm int 80h \</span><br><span class="line">        _asm mov __res,eax\</span><br><span class="line">    &#125; \</span><br><span class="line">    if (__res &gt;= 0) \</span><br><span class="line">        return (type) __res; \</span><br><span class="line">    errno = -__res; \</span><br><span class="line">    return -1; \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看出，<strong>参数 a 被放在了 ebx 寄存器，参数 b 被放在了 ecx 寄存器，参数 c 被放在了 edx 寄存器</strong>。</p><p>我们再打开 system_call 的代码，刚刚我们只看了它的关键一行，就是去系统调用表里找函数，我们再看看全貌。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">_system_call:</span><br><span class="line">    cmpl $nr_system_calls-1,%eax</span><br><span class="line">    ja bad_sys_call</span><br><span class="line">    push %ds</span><br><span class="line">    push %es</span><br><span class="line">    push %fs</span><br><span class="line">    pushl %edx</span><br><span class="line">    pushl %ecx      # push %ebx,%ecx,%edx as parameters</span><br><span class="line">    pushl %ebx      # to the system call</span><br><span class="line">    movl $0x10,%edx     # set up ds,es to kernel space</span><br><span class="line">    mov %dx,%ds</span><br><span class="line">    mov %dx,%es</span><br><span class="line">    movl $0x17,%edx     # fs points to local data space</span><br><span class="line">    mov %dx,%fs</span><br><span class="line">    call _sys_call_table(,%eax,4)</span><br><span class="line">    pushl %eax</span><br><span class="line">    movl _current,%eax</span><br><span class="line">    cmpl $0,state(%eax)     # state</span><br><span class="line">    jne reschedule</span><br><span class="line">    cmpl $0,counter(%eax)       # counter</span><br><span class="line">    je reschedule</span><br><span class="line">ret_from_sys_call:</span><br><span class="line">    movl _current,%eax      # task[0] cannot have signals</span><br><span class="line">    cmpl _task,%eax</span><br><span class="line">    je 3f</span><br><span class="line">    cmpw $0x0f,CS(%esp)     # was old code segment supervisor ?</span><br><span class="line">    jne 3f</span><br><span class="line">    cmpw $0x17,OLDSS(%esp)      # was stack segment = 0x17 ?</span><br><span class="line">    jne 3f</span><br><span class="line">    movl signal(%eax),%ebx</span><br><span class="line">    movl blocked(%eax),%ecx</span><br><span class="line">    notl %ecx</span><br><span class="line">    andl %ebx,%ecx</span><br><span class="line">    bsfl %ecx,%ecx</span><br><span class="line">    je 3f</span><br><span class="line">    btrl %ecx,%ebx</span><br><span class="line">    movl %ebx,signal(%eax)</span><br><span class="line">    incl %ecx</span><br><span class="line">    pushl %ecx</span><br><span class="line">    call _do_signal</span><br><span class="line">    popl %eax</span><br><span class="line">3:  popl %eax</span><br><span class="line">    popl %ebx</span><br><span class="line">    popl %ecx</span><br><span class="line">    popl %edx</span><br><span class="line">    pop %fs</span><br><span class="line">    pop %es</span><br><span class="line">    pop %ds</span><br><span class="line">    iret</span><br></pre></td></tr></table></figure><p>我们先只关注压栈的情况，触发了中断后，CPU 会自动帮我们做如下压栈操作</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/%E4%B8%AD%E6%96%AD%E4%B8%8E%E5%8E%8B%E6%A0%88%E6%93%8D%E4%BD%9C.png"></p><p>因为 system_call 是通过 int 80h 这个软中断进来的，所以也属于中断的一种，具体说是属于特权级发生变化的，且没有错误码情况的中断，所以在这之前栈已经被压了 SS、ESP、EFLAGS、CS、EIP 这些值。</p><p>接下来 system_call 又压入了一些值，具体说来有 ds、es、fs、edx、ecx、ebx、eax。</p><p>如果你看源码费劲，得不出我上述结论，那你可以看 system_call.s 上面的注释，Linus 作者已经很贴心地给你写出了此时的堆栈状态。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Stack layout in &#x27;ret_from_system_call&#x27;:</span><br><span class="line"> *</span><br><span class="line"> *   0(%esp) - %eax</span><br><span class="line"> *   4(%esp) - %ebx</span><br><span class="line"> *   8(%esp) - %ecx</span><br><span class="line"> *   C(%esp) - %edx</span><br><span class="line"> *  10(%esp) - %fs</span><br><span class="line"> *  14(%esp) - %es</span><br><span class="line"> *  18(%esp) - %ds</span><br><span class="line"> *  1C(%esp) - %eip</span><br><span class="line"> *  20(%esp) - %cs</span><br><span class="line"> *  24(%esp) - %eflags</span><br><span class="line"> *  28(%esp) - %oldesp</span><br><span class="line"> *  2C(%esp) - %oldss</span><br><span class="line"> */</span><br></pre></td></tr></table></figure><p>看，就是 CPU 中断压入的 5 个值，加上 system_call 手动压入的 7 个值。</p><p>所以之后，中断处理程序如果有需要的话，就可以从这里取出它想要的值，包括 CPU 压入的那五个值，或者 system_call 手动压入的 7 个值。</p><p>比如 sys_execve 这个中断处理函数，一开始就取走了位于栈顶 0x1C 位置处的 EIP 的值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EIP = 0x1C</span><br><span class="line">_sys_execve:</span><br><span class="line">    lea EIP(%esp),%eax</span><br><span class="line">    pushl %eax</span><br><span class="line">    call _do_execve</span><br><span class="line">    addl $4,%esp</span><br><span class="line">    ret</span><br></pre></td></tr></table></figure><p>随后在 <code>do_execve</code> 函数中，又通过 C 语言函数调用的约定，取走了 <code>filename，argv，envp</code> 等参数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int do_execve(</span><br><span class="line">        unsigned long * eip,</span><br><span class="line">        long tmp,</span><br><span class="line">        char * filename,</span><br><span class="line">        char ** argv,</span><br><span class="line">        char ** envp) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体这个函数的详细流程和作用，将在后续文章中讲到。</p></details><h3 id="fork中进程槽位申请和基本信息的复制"><a href="#fork中进程槽位申请和基本信息的复制" class="headerlink" title="fork中进程槽位申请和基本信息的复制"></a>fork中进程槽位申请和基本信息的复制</h3><p>fork 触发系统调用中断，最终调用到了 sys_fork 函数，这个函数具体做了什么？</p><p>还是个汇编代码，但我们要关注的地方不多。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">_sys_fork:</span><br><span class="line">    call _find_empty_process</span><br><span class="line">    testl %eax,%eax</span><br><span class="line">    js 1f</span><br><span class="line">    push %gs</span><br><span class="line">    pushl %esi</span><br><span class="line">    pushl %edi</span><br><span class="line">    pushl %ebp</span><br><span class="line">    pushl %eax</span><br><span class="line">    call _copy_process</span><br><span class="line">    addl $20,%esp</span><br><span class="line">1:  ret</span><br></pre></td></tr></table></figure><p>其实就是调用了两个函数。我们先从方法名直接翻译一下，猜猜意思。</p><ul><li>先是 find_empty_process，就是找到空闲的进程槽位。</li><li>然后 copy_process，就是复制进程。</li></ul><p>在进程调度初始化<code>sched_init</code>函数中，我们设置了一个存储进程的数据结构 task[64] 数组。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_10.png"></p><p>就是先在这个数组中找一个空闲的位置，准备存一个新的进程的结构 task_struct</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">struct task_struct &#123;</span><br><span class="line">    long state;</span><br><span class="line">    long counter;</span><br><span class="line">    long priority;</span><br><span class="line">    ...</span><br><span class="line">    struct tss_struct tss;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个结构各个字段具体赋什么值呢？</p><p>通过 copy_process 这个名字我们知道，就是复制原来的进程，也就是当前进程。</p><p>当前只有一个进程，就是数组中位置 0 处的 init_task.init，也就是零号进程，那自然就复制它咯。</p><h4 id="find-empty-process"><a href="#find-empty-process" class="headerlink" title="find_empty_process"></a>find_empty_process</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">long last_pid = 0;</span><br><span class="line"></span><br><span class="line">int find_empty_process(void) &#123;</span><br><span class="line">    int i;</span><br><span class="line">    repeat:</span><br><span class="line">        if ((++last_pid)&lt;0) last_pid=1;</span><br><span class="line">        for(i=0 ; i&lt;64 ; i++)</span><br><span class="line">            if (task[i] &amp;&amp; task[i]-&gt;pid == last_pid) goto repeat;</span><br><span class="line">    for(i=1 ; i&lt;64; i++)</span><br><span class="line">        if (!task[i])</span><br><span class="line">            return i;</span><br><span class="line">    return -EAGAIN;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一共三步，很简单:</p><ol><li>判断 ++last_pid 是不是小于零了，小于零说明已经超过 long 的最大值了，重新赋值为 1，起到一个保护作用，这没什么好说的。</li><li>一个 for 循环，看看刚刚的 last_pid 在所有 task[] 数组中，是否已经被某进程占用了。如果被占用了，那就重复执行，再次加一，然后再次判断，直到找到一个 pid 号没有被任何进程用为止。</li><li>又是个 for 循环，刚刚已经找到一个可用的 pid 号了，那这一步就是再次遍历这个 task[] 试图找到一个空闲项，找到了就返回素组索引下标。</li></ol><p>最终，<strong>这个方法就返回 task[] 数组的索引，表示找到了一个空闲项</strong>，之后就开始往这里塞一个新的进程吧。</p><p>由于我们现在只有 0 号进程，且 task[] 除了 0 号索引位置，其他地方都是空的，所以这个方法运行完，<strong>last_pid 就是 1，也就是新进程被分配的 pid 就是 1</strong>，然后即将要加入的 task[] 数组的索引位置，也是 1。</p><p>好的，那我们接下来就看，怎么构造这个进程结构，塞到这个 1 索引位置的 task[] 中？</p><h4 id="copy-process"><a href="#copy-process" class="headerlink" title="copy_process"></a>copy_process</h4><details><summary>先看看源码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">int copy_process(int nr,long ebp,long edi,long esi,long gs,long none,</span><br><span class="line">        long ebx,long ecx,long edx,</span><br><span class="line">        long fs,long es,long ds,</span><br><span class="line">        long eip,long cs,long eflags,long esp,long ss)</span><br><span class="line">&#123;</span><br><span class="line">    struct task_struct *p;</span><br><span class="line">    int i;</span><br><span class="line">    struct file *f;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    p = (struct task_struct *) get_free_page();</span><br><span class="line">    if (!p)</span><br><span class="line">        return -EAGAIN;</span><br><span class="line">    task[nr] = p;</span><br><span class="line">    *p = *current;  /* NOTE! this doesn&#x27;t copy the supervisor stack */</span><br><span class="line">    p-&gt;state = TASK_UNINTERRUPTIBLE;</span><br><span class="line">    p-&gt;pid = last_pid;</span><br><span class="line">    p-&gt;father = current-&gt;pid;</span><br><span class="line">    p-&gt;counter = p-&gt;priority;</span><br><span class="line">    p-&gt;signal = 0;</span><br><span class="line">    p-&gt;alarm = 0;</span><br><span class="line">    p-&gt;leader = 0;      /* process leadership doesn&#x27;t inherit */</span><br><span class="line">    p-&gt;utime = p-&gt;stime = 0;</span><br><span class="line">    p-&gt;cutime = p-&gt;cstime = 0;</span><br><span class="line">    p-&gt;start_time = jiffies;</span><br><span class="line">    p-&gt;tss.back_link = 0;</span><br><span class="line">    p-&gt;tss.esp0 = PAGE_SIZE + (long) p;</span><br><span class="line">    p-&gt;tss.ss0 = 0x10;</span><br><span class="line">    p-&gt;tss.eip = eip;</span><br><span class="line">    p-&gt;tss.eflags = eflags;</span><br><span class="line">    p-&gt;tss.eax = 0;</span><br><span class="line">    p-&gt;tss.ecx = ecx;</span><br><span class="line">    p-&gt;tss.edx = edx;</span><br><span class="line">    p-&gt;tss.ebx = ebx;</span><br><span class="line">    p-&gt;tss.esp = esp;</span><br><span class="line">    p-&gt;tss.ebp = ebp;</span><br><span class="line">    p-&gt;tss.esi = esi;</span><br><span class="line">    p-&gt;tss.edi = edi;</span><br><span class="line">    p-&gt;tss.es = es &amp; 0xffff;</span><br><span class="line">    p-&gt;tss.cs = cs &amp; 0xffff;</span><br><span class="line">    p-&gt;tss.ss = ss &amp; 0xffff;</span><br><span class="line">    p-&gt;tss.ds = ds &amp; 0xffff;</span><br><span class="line">    p-&gt;tss.fs = fs &amp; 0xffff;</span><br><span class="line">    p-&gt;tss.gs = gs &amp; 0xffff;</span><br><span class="line">    p-&gt;tss.ldt = _LDT(nr);</span><br><span class="line">    p-&gt;tss.trace_bitmap = 0x80000000;</span><br><span class="line">    if (last_task_used_math == current)</span><br><span class="line">        __asm__(&quot;clts ; fnsave %0&quot;::&quot;m&quot; (p-&gt;tss.i387));</span><br><span class="line">    if (copy_mem(nr,p)) &#123;</span><br><span class="line">        task[nr] = NULL;</span><br><span class="line">        free_page((long) p);</span><br><span class="line">        return -EAGAIN;</span><br><span class="line">    &#125;</span><br><span class="line">    for (i=0; i&lt;NR_OPEN;i++)</span><br><span class="line">        if (f=p-&gt;filp[i])</span><br><span class="line">            f-&gt;f_count++;</span><br><span class="line">    if (current-&gt;pwd)</span><br><span class="line">        current-&gt;pwd-&gt;i_count++;</span><br><span class="line">    if (current-&gt;root)</span><br><span class="line">        current-&gt;root-&gt;i_count++;</span><br><span class="line">    if (current-&gt;executable)</span><br><span class="line">        current-&gt;executable-&gt;i_count++;</span><br><span class="line">    set_tss_desc(gdt+(nr&lt;&lt;1)+FIRST_TSS_ENTRY,&amp;(p-&gt;tss));</span><br><span class="line">    set_ldt_desc(gdt+(nr&lt;&lt;1)+FIRST_LDT_ENTRY,&amp;(p-&gt;ldt));</span><br><span class="line">    p-&gt;state = TASK_RUNNING;    /* do this last, just in case */</span><br><span class="line">    return last_pid;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>大部分都是 tss 结构的复制，以及一些无关紧要的分支，进行部分简化。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">int copy_process(int nr, ...) &#123;</span><br><span class="line">    struct task_struct p = </span><br><span class="line">        (struct task_struct *) get_free_page();</span><br><span class="line">    task[nr] = p;</span><br><span class="line">    *p = *current;</span><br><span class="line"></span><br><span class="line">    p-&gt;state = TASK_UNINTERRUPTIBLE;</span><br><span class="line">    p-&gt;pid = last_pid;</span><br><span class="line">    p-&gt;counter = p-&gt;priority;</span><br><span class="line">    ..</span><br><span class="line">    p-&gt;tss.edx = edx;</span><br><span class="line">    p-&gt;tss.ebx = ebx;</span><br><span class="line">    p-&gt;tss.esp = esp;</span><br><span class="line">    ...</span><br><span class="line">    copy_mem(nr,p);</span><br><span class="line">    ...</span><br><span class="line">    set_tss_desc(gdt+(nr&lt;&lt;1)+FIRST_TSS_ENTRY,&amp;(p-&gt;tss));</span><br><span class="line">    set_ldt_desc(gdt+(nr&lt;&lt;1)+FIRST_LDT_ENTRY,&amp;(p-&gt;ldt));</span><br><span class="line">    p-&gt;state = TASK_RUNNING;</span><br><span class="line">    return last_pid;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数本来就是 fork 的难点了，所以我们慢慢来。</p><ol><li>首先 get_free_page 会在主内存末端申请一个空闲页面<br> <img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_18.png"><ul><li>就是遍历 mem_map[] 这个数组，找出值为零的项，就表示找到了空闲的一页内存。 </li><li>然后把该项置为 1，表示该页已经被使用。</li><li>最后，算出这个页的内存起始地址，返回。</li></ul></li><li>拿到的这个内存起始地址，给 task_struct 结构的 p。<ul><li>自此，一个进程结构 task_struct 就在内存中有了一块空间，但此时还没有赋值具体的字段。</li></ul></li><li>将这个 p 记录在进程管理结构 task[] 中</li><li>然后下一句 *p = *current 很简单，<strong>就是把当前进程，也就是 0 号进程的 task_struct 的全部值都复制给即将创建的进程 p</strong>，目前它们两者就完全一样了。<ul><li>嗯，这就附上值了，就完全复制之前的进程的 task_struct 而已，很粗暴，最后的内存布局效果就是这样。<br><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_19.png"></li></ul></li><li>进程 1 和进程 0 目前是完全复制的关系，但有一些值是需要个性化处理的，下面的代码就是把这些不一样的值覆盖掉<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">int copy_process(int nr, ...) &#123;</span><br><span class="line"> ...</span><br><span class="line"> p-&gt;state = TASK_UNINTERRUPTIBLE;</span><br><span class="line"> p-&gt;pid = last_pid;</span><br><span class="line"> p-&gt;counter = p-&gt;priority;</span><br><span class="line"> ..</span><br><span class="line"> p-&gt;tss.edx = edx;</span><br><span class="line"> p-&gt;tss.ebx = ebx;</span><br><span class="line"> p-&gt;tss.esp = esp;</span><br><span class="line"> ...</span><br><span class="line"> p-&gt;tss.esp0 = PAGE_SIZE + (long) p;</span><br><span class="line"> p-&gt;tss.ss0 = 0x10;</span><br><span class="line"> ...</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li></ol><ul><li>不一样的值，一部分是 state，pid，counter 这种<strong>进程的元信息</strong>，另一部分是 tss 里面保存的各种寄存器的信息，即<strong>上下文</strong>。</li><li>这里有两个寄存器的值的赋值有些特殊，就是 ss0 和 esp0，这个表示 0 特权级也就是内核态时的 ss:esp 的指向。 根据代码我们得知，其含义是将代码在内核态时使用的堆栈栈顶指针指向进程 task_struct 所在的 4K 内存页的最顶端，而且之后的每个进程都是这样被设置的。<br><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_20.png"></li></ul><p>好了，进程槽位的申请，以及基本信息的复制，就讲完了。</p><p><strong>就是内存中找个地方存一个 task_struct 结构的东东，并添加到 task[] 数组里的空闲位置处，这个东东的具体字段赋值的大部分都是复制原来进程的</strong>。</p><p>接下来将是进程页表和段表的复制，这将会决定进程之间的内存规划问题，很是精彩，也是 fork 真正的难点所在。</p><h3 id="fork中进程内存规划的问题-页表和段表的复制"><a href="#fork中进程内存规划的问题-页表和段表的复制" class="headerlink" title="fork中进程内存规划的问题-页表和段表的复制"></a>fork中进程内存规划的问题-页表和段表的复制</h3><p>完成进程槽位申请和基本信息复制后，我们基本已经完成了fork函数的一般，接下来我们展开看看另一半，即copy_mem函数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int copy_process(int nr, ...) &#123;</span><br><span class="line">    ...</span><br><span class="line">    copy_mem(nr,p);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这将会决定进程之间的内存规划问题，十分精彩。</p><p>整个函数不长，我们还是试着先直译一下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">int copy_mem(int nr,struct task_struct * p) &#123;</span><br><span class="line">    // 局部描述符表 LDT 赋值</span><br><span class="line">    unsigned long old_data_base,new_data_base,data_limit;</span><br><span class="line">    unsigned long old_code_base,new_code_base,code_limit;</span><br><span class="line">    code_limit = get_limit(0x0f);</span><br><span class="line">    data_limit = get_limit(0x17);</span><br><span class="line">    new_code_base = nr * 0x4000000;</span><br><span class="line">    new_data_base = nr * 0x4000000;</span><br><span class="line">    set_base(p-&gt;ldt[1],new_code_base);</span><br><span class="line">    set_base(p-&gt;ldt[2],new_data_base);</span><br><span class="line">    // 拷贝页表</span><br><span class="line">    old_code_base = get_base(current-&gt;ldt[1]);</span><br><span class="line">    old_data_base = get_base(current-&gt;ldt[2]);</span><br><span class="line">    copy_page_tables(old_data_base,new_data_base,data_limit);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实就是<strong>新进程 LDT 表项的赋值，以及页表的拷贝</strong>。</p><h4 id="LDT-的赋值"><a href="#LDT-的赋值" class="headerlink" title="LDT 的赋值"></a>LDT 的赋值</h4><details><summary>我们先回顾一下LDT表项的含义</summary><p>程序员给出的逻辑地址最终转化为物理地址要经过这几步骤</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_21.png"></p><p>而我们已经开启了分页，那么分页机制的具体转化是这样的。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_22.png"></p><p>因为有了页表的存在，所以多了<strong>线性地址空间</strong>的概念，即经过分段机制转化后，分页机制转化前的地址。</p><p>不考虑段限长的话，32 位的 CPU 线性地址空间应为 4G。现在只有四个页目录表，也就是将前 16M 的线性地址空间，与 16M 的物理地址空间一一对应起来了。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_23.png"></p><p>把这个图和全局描述符表 GDT 联系起来，这个线性地址空间，就是经过分段机制（段可能是 GDT 也可能是 LDT）后的地址，是这样对应的。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_24.png"></p></details><p>我们给进程 0 准备的 LDT 的代码段和数据段，段基址都是 0，段限长是 640K。<br>给进程 1，也就是我们现在正在 fork 的这个进程，其代码段和数据段还没有设置。</p><p>所以第一步，局部描述符表 LDT 的赋值，就是给上图中那两个还未设置的代码段和数据段赋值。</p><ul><li>其中段限长，就是取自进程 0 设置好的段限长，也就是 640K。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int copy_mem(int nr,struct task_struct * p) &#123;</span><br><span class="line">  ...</span><br><span class="line">  code_limit = get_limit(0x0f);</span><br><span class="line">  data_limit = get_limit(0x17);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>而段基址有点意思，是取决于当前是几号进程，也就是 nr 的值。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int copy_mem(int nr,struct task_struct * p) &#123;</span><br><span class="line">  ...</span><br><span class="line">  new_code_base = nr * 0x4000000;</span><br><span class="line">  new_data_base = nr * 0x4000000;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>这里的 0x4000000 等于 64M。</p><p>也就是说，今后每个进程通过段基址的手段，分别在线性地址空间中占用 64M 的空间（暂不考虑段限长），且紧挨着。</p><p>接着就把 LDT 设置进了 LDT 表里。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int copy_mem(int nr,struct task_struct * p) &#123;</span><br><span class="line">    ...</span><br><span class="line">    set_base(p-&gt;ldt[1],new_code_base);</span><br><span class="line">    set_base(p-&gt;ldt[2],new_data_base);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最终效果如图</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_25.png"></p><p>经过以上的步骤，就通过分段的方式，将进程映射到了相互隔离的线性地址空间里，这就是<strong>段式管理</strong>。</p><p>当然，Linux 0.11 不但是分段管理，也开启了分页管理，最终形成段页式的管理方式。这就涉及到下面要说的，页表的复制。</p><h4 id="页表的复制"><a href="#页表的复制" class="headerlink" title="页表的复制"></a>页表的复制</h4><p>讲完段表的赋值，接下来就是页表的复制了，这也是 copy_mem 函数里的最后一行代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int copy_mem(int nr,struct task_struct * p) &#123;</span><br><span class="line">    ...</span><br><span class="line">    // old=0, new=64M, limit=640K</span><br><span class="line">    copy_page_tables(old_data_base,new_data_base,data_limit)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原来进程 0 有<strong>一个页目录表和四个页表</strong>，将线性地址空间的 0-16M 原封不动映射到了物理地址空间的 0-16M。</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_23.png"></p><p>那么新诞生的这个进程 2，也需要一套映射关系的页表，那我们看看这些页表是怎么建立的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> *  Well, here is one of the most complicated functions in mm. It</span><br><span class="line"> * copies a range of linerar addresses by copying only the pages.</span><br><span class="line"> * Let&#x27;s hope this is bug-free, &#x27;cause this one I don&#x27;t want to debug :-)</span><br><span class="line"> */</span><br><span class="line">int copy_page_tables(unsigned long from,unsigned long to,long size)</span><br><span class="line">&#123;</span><br><span class="line">    unsigned long * from_page_table;</span><br><span class="line">    unsigned long * to_page_table;</span><br><span class="line">    unsigned long this_page;</span><br><span class="line">    unsigned long * from_dir, * to_dir;</span><br><span class="line">    unsigned long nr;</span><br><span class="line"></span><br><span class="line">    from_dir = (unsigned long *) ((from&gt;&gt;20) &amp; 0xffc);</span><br><span class="line">    to_dir = (unsigned long *) ((to&gt;&gt;20) &amp; 0xffc);</span><br><span class="line">    size = ((unsigned) (size+0x3fffff)) &gt;&gt; 22;</span><br><span class="line">    for( ; size--&gt;0 ; from_dir++,to_dir++) &#123;</span><br><span class="line">        if (!(1 &amp; *from_dir))</span><br><span class="line">            continue;</span><br><span class="line">        from_page_table = (unsigned long *) (0xfffff000 &amp; *from_dir);</span><br><span class="line">        to_page_table = (unsigned long *) get_free_page()</span><br><span class="line">        *to_dir = ((unsigned long) to_page_table) | 7;</span><br><span class="line">        nr = (from==0)?0xA0:1024;</span><br><span class="line">        for ( ; nr-- &gt; 0 ; from_page_table++,to_page_table++) &#123;</span><br><span class="line">            this_page = *from_page_table;</span><br><span class="line">            if (!(1 &amp; this_page))</span><br><span class="line">                continue;</span><br><span class="line">            this_page &amp;= ~2;</span><br><span class="line">            *to_page_table = this_page;</span><br><span class="line">            if (this_page &gt; LOW_MEM) &#123;</span><br><span class="line">                *from_page_table = this_page;</span><br><span class="line">                this_page -= LOW_MEM;</span><br><span class="line">                this_page &gt;&gt;= 12;</span><br><span class="line">                mem_map[this_page]++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    invalidate();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先不讲这个函数，我们先看看注释，注释是 Linus 自己写的，他说：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;这部分是内存管理中最复杂的代码，希望这段代码没有错误（bug-free），因为我实在不想调试它！&quot;</span><br></pre></td></tr></table></figure><p>回归正题，这个函数要完成什么事情呢？</p><p>你想，现在进程 0 的线性地址空间是 0 - 64M，进程 1 的线性地址空间是 64M - 128M。</p><p><strong>我们现在要造一个进程 1 的页表，使得进程 1 和进程 0 最终被映射到的物理空间都是 0 - 64M，这样进程 1 才能顺利运行起来。</strong></p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_26.png"></p><p>总之，最终的效果就是：</p><ul><li>假设现在正在运行进程 0，代码中给出一个虚拟地址 0x03，由于进程 0 的 LDT 中代码段基址是 0，所以线性地址也是 0x03，最终由进程 0 页表映射到物理地址 0x03 处。</li><li>假设现在正在运行进程 1，代码中给出一个虚拟地址 0x03，由于进程 1 的 LDT 中代码段基址是 64M，所以线性地址是 64M + 3，最终由进程 1 页表映射到物理地址也同样是 0x03 处。</li></ul><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_27.png"></p><p><strong>即，进程 0 和进程 1 目前共同映射物理内存的前 640K 的空间。</strong></p><p>至于如何将不同地址通过不同页表映射到相同物理地址空间，很简单，举个刚刚的例子。</p><ul><li>刚刚的进程 1 的线性地址 64M + 0x03 用二进制表示是： 0000010000_0000000000_000000000011</li><li>刚刚的进程 0 的线性地址 0x03 用二进制表示是： 0000000000_0000000000_000000000011</li></ul><p>根据分页机制的转化规则，前 10 位表示页目录项，中间 10 位表示页表项，后 12 位表页内偏移。</p><ul><li>进程 1 要找的是页目录项 16 中的第 0 号页表</li><li>进程 0 要找的是页目录项 0 中的第 0 号页表</li></ul><p>那只要让这俩最终找到的两个页表里的数据一模一样即可。</p><p>由于理解起来非常简单，但代码中的计算就非常绕，所以我们就不细致分析代码了，只要理解其最终的作用就好。</p><h4 id="将新老进程页表修改为只读"><a href="#将新老进程页表修改为只读" class="headerlink" title="将新老进程页表修改为只读"></a>将新老进程页表修改为只读</h4><p>还记得页表的结构吧？</p><p><img src="/2022/06/14/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%89%E6%AD%A5%E4%B9%8B%E4%B8%80%E4%B8%AA%E6%96%B0%E8%BF%9B%E7%A8%8B%E7%9A%84%E8%AF%9E%E7%94%9F/img_28.png"></p><p>其中 RW 位表示读写状态</p><ul><li>0 表示只读（或可执行）</li><li>1表示可读写（或可执行）。 </li><li>当然，在内核态也就是 0 特权级时，这个标志位是没用的。</li></ul><p>那我们看下面的代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">int copy_page_tables(unsigned long from,unsigned long to,long size) &#123;</span><br><span class="line">    ...</span><br><span class="line">    for( ; size--&gt;0 ; from_dir++,to_dir++) &#123;</span><br><span class="line">        ...</span><br><span class="line">        for ( ; nr-- &gt; 0 ; from_page_table++,to_page_table++) &#123;</span><br><span class="line">            ...</span><br><span class="line">            this_page &amp;= ~2;</span><br><span class="line">            ...</span><br><span class="line">            if (this_page &gt; LOW_MEM) &#123;</span><br><span class="line">                *from_page_table = this_page;</span><br><span class="line">                ...</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>~2 表示取反，2 用二进制表示是 10，取反就是 01，其目的是把 this_page 也就是当前的页表的 RW 位置零，也就是是<strong>把该页变成只读</strong>。</p><p>而 *from_page_table = this_page 表示又把<strong>源页表也变成只读</strong>。</p><p>也就是说，<strong>经过 fork 创建出的新进程，其页表项都是只读的，而且导致源进程的页表项也变成了只读</strong>。</p><p>这个就是写时复制的基础：</p><ul><li>新老进程一开始共享同一个物理内存空间，如果只有读，那就相安无事</li><li>但如果任何一方有写操作，由于页面是只读的，将触发缺页中断，然后就会分配一块新的物理内存给产生写操作的那个进程，此时这一块内存就不再共享了。</li></ul><h4 id="copy-process总结"><a href="#copy-process总结" class="headerlink" title="copy_process总结"></a>copy_process总结</h4><ol><li>封不动复制了一下 task_struct</li><li>LDT 的复制和改造，使得进程 0 和进程 1 分别映射到了不同的线性地址空间</li><li>页表的复制，使得进程 0 和进程 1 又从不同的线性地址空间，被映射到了相同的物理地址空间</li><li>将新老进程的页表都变成只读状态，为后面写时复制的缺页中断做准备</li></ol>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统第二步之大战前期的初始化工作</title>
      <link href="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/"/>
      <url>/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h3 id="大道至简-二十几行代码完成操作系统"><a href="#大道至简-二十几行代码完成操作系统" class="headerlink" title="大道至简 二十几行代码完成操作系统"></a>大道至简 二十几行代码完成操作系统</h3><p>在第一部分，我们完成了进入 main 方法前的苦力工作，我们的程序终于跳到第一个由 c 语言写的，也是操作系统的全部代码骨架的地方，就是 main.c 文件里的 main 方法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ROOT_DEV = ORIG_ROOT_DEV;</span><br><span class="line">    drive_info = DRIVE_INFO;</span><br><span class="line">    memory_end = (1&lt;&lt;20) + (EXT_MEM_K&lt;&lt;10);</span><br><span class="line">    memory_end &amp;= 0xfffff000;</span><br><span class="line">    if (memory_end &gt; 16*1024*1024)</span><br><span class="line">    memory_end = 16*1024*1024;</span><br><span class="line">    if (memory_end &gt; 12*1024*1024)</span><br><span class="line">    buffer_memory_end = 4*1024*1024;</span><br><span class="line">    else if (memory_end &gt; 6*1024*1024)</span><br><span class="line">    buffer_memory_end = 2*1024*1024;</span><br><span class="line">    else</span><br><span class="line">    buffer_memory_end = 1*1024*1024;</span><br><span class="line">    main_memory_start = buffer_memory_end;</span><br><span class="line"></span><br><span class="line">    mem_init(main_memory_start,memory_end);</span><br><span class="line">    trap_init();</span><br><span class="line">    blk_dev_init();</span><br><span class="line">    chr_dev_init();</span><br><span class="line">    tty_init();</span><br><span class="line">    time_init();</span><br><span class="line">    sched_init();</span><br><span class="line">    buffer_init(buffer_memory_end);</span><br><span class="line">    hd_init();</span><br><span class="line">    floppy_init();</span><br><span class="line"></span><br><span class="line">    sti();</span><br><span class="line">    move_to_user_mode();</span><br><span class="line">    if (!fork()) &#123;</span><br><span class="line">        init();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    for(;;) pause();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>数一数看，总共也就 20 几行代码。</p><p>但这的确是操作系统启动流程的全部秘密了，我用空格将这个代码分成了几个部分。</p><h4 id="第一部分-一些参数的取值和计算。"><a href="#第一部分-一些参数的取值和计算。" class="headerlink" title="第一部分 一些参数的取值和计算。"></a>第一部分 一些参数的取值和计算。</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ROOT_DEV = ORIG_ROOT_DEV;</span><br><span class="line">    drive_info = DRIVE_INFO;</span><br><span class="line">    memory_end = (1&lt;&lt;20) + (EXT_MEM_K&lt;&lt;10);</span><br><span class="line">    memory_end &amp;= 0xfffff000;</span><br><span class="line">    if (memory_end &gt; 16*1024*1024)</span><br><span class="line">        memory_end = 16*1024*1024;</span><br><span class="line">    if (memory_end &gt; 12*1024*1024)</span><br><span class="line">        buffer_memory_end = 4*1024*1024;</span><br><span class="line">    else if (memory_end &gt; 6*1024*1024)</span><br><span class="line">        buffer_memory_end = 2*1024*1024;</span><br><span class="line">    else</span><br><span class="line">        buffer_memory_end = 1*1024*1024;</span><br><span class="line">    main_memory_start = buffer_memory_end;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>包括<strong>根设备 ROOT_DEV</strong>，之前在汇编语言中获取的各个设备的<strong>参数信息 drive_info</strong>，以及通过计算得到的<strong>内存边界</strong></p><ul><li>main_memory_start</li><li>main_memory_end</li><li>buffer_memory_start</li><li>buffer_memory_end</li></ul><p>从哪获得之前的设备参数信息呢？</p><p>如果你前面看了，那一定还记得这个表，都是由 setup.s 这个汇编程序调用 BIOS 中断获取的各个设备的信息，并保存在约定好的内存地址 0x90000 处，现在这不就来取了么。</p><table><thead><tr><th>内存地址</th><th>长度(字节)</th><th>名称</th></tr></thead><tbody><tr><td>0x90000</td><td>2</td><td>光标位置</td></tr><tr><td>0x90002</td><td>2</td><td>扩展内存数</td></tr><tr><td>0x90004</td><td>2</td><td>显示页面</td></tr><tr><td>0x90006</td><td>1</td><td>显示模式</td></tr><tr><td>0x90007</td><td>1</td><td>字符列数</td></tr><tr><td>0x90008</td><td>2</td><td>未知</td></tr><tr><td>0x9000A</td><td>1</td><td>显示内存</td></tr><tr><td>0x9000B</td><td>1</td><td>显示状态</td></tr><tr><td>0x9000C</td><td>2</td><td>显卡特性参数</td></tr><tr><td>0x9000E</td><td>1</td><td>屏幕行数</td></tr><tr><td>0x9000F</td><td>1</td><td>屏幕列数</td></tr><tr><td>0x90080</td><td>16</td><td>硬盘1参数表</td></tr><tr><td>0x90090</td><td>16</td><td>硬盘2参数表</td></tr><tr><td>0x901FC</td><td>2</td><td>根设备号</td></tr></tbody></table><h4 id="第二部分-各种初始化-init-操作。"><a href="#第二部分-各种初始化-init-操作。" class="headerlink" title="第二部分 各种初始化 init 操作。"></a>第二部分 各种初始化 init 操作。</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    mem_init(main_memory_start,memory_end);</span><br><span class="line">    trap_init();</span><br><span class="line">    blk_dev_init();</span><br><span class="line">    chr_dev_init();</span><br><span class="line">    tty_init();</span><br><span class="line">    time_init();</span><br><span class="line">    sched_init();</span><br><span class="line">    buffer_init(buffer_memory_end);</span><br><span class="line">    hd_init();</span><br><span class="line">    floppy_init();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>包括<strong>内存初始化 mem_init</strong>，<strong>中断初始化 trap_init</strong>、<strong>进程调度初始化 sched_init</strong> 等等。</p><p>我们知道学操作系统知识的时候，其实就分成这么几块来学的，看来在操作系统源码上看，也确实是这么划分的，那我们之后照着源码慢慢品，就好了。</p><h4 id="第三部分-切换到用户态模式，并在一个新的进程中做一个最终的初始化-init。"><a href="#第三部分-切换到用户态模式，并在一个新的进程中做一个最终的初始化-init。" class="headerlink" title="第三部分 切换到用户态模式，并在一个新的进程中做一个最终的初始化 init。"></a>第三部分 切换到用户态模式，并在一个新的进程中做一个最终的初始化 init。</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    sti();</span><br><span class="line">    move_to_user_mode();</span><br><span class="line">    if (!fork()) &#123;</span><br><span class="line">        init();</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 init 函数里会创建出一个进程，设置终端的标准 IO，并且再创建出一个执行 shell 程序的进程用来接受用户的命令，到这里其实就出现了我们熟悉的画面（下面是 bochs 启动 Linux 0.11 后的画面）。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img.png"></p><h4 id="第四部分-死循环"><a href="#第四部分-死循环" class="headerlink" title="第四部分 死循环"></a>第四部分 死循环</h4><p>如果没有任何任务可以运行，操作系统会一直陷入这个死循环无法自拔。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    for(;;) pause();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>OK，不要细品每一句话，我们本回就是要你有个整体印象，之后会细细讲这里的每一个部分。</p><h4 id="回顾-已完成工作"><a href="#回顾-已完成工作" class="headerlink" title="回顾 已完成工作"></a>回顾 已完成工作</h4><p>这里再放上目前的内存布局图。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_1.png"></p><p>这个图大家一定要牢记在心，操作系统说白了就是在内存中放置各种的数据结构，来实现“管理”的功能。</p><p>所以之后我们的学习过程，主心骨其实就是看看，操作系统在经过一番折腾后，又在内存中建立了什么数据结构，而这些数据结构后面又是如何用到的。</p><p>比如进程管理，就是在内存中建立好多复杂的数据结构用来记录进程的信息，再配合上进程调度的小算法，完成了进程这个强大的功能。</p><p>为了让大家目前心里有个底，我们把前面的工作再再再再在这里做一个回顾，用一张图表示就是：</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_2.png"></p><p>看到了吧，我们已经把 boot 文件夹下的三个汇编文件的全部代码都一行一行品读过了，其主要功能就是三张表的设置：</p><ul><li>全局描述符表</li><li>中断描述符表</li><li>页表</li></ul><p>同时还设置了各种段寄存器，栈顶指针。</p><p>并且，还为后续的程序提供了设备信息，保存在 0x90000 处往后的几个位置上。</p><p>最后，一个华丽的跳转，将程序跳转到了 main.c 文件里的 main 函数中。</p><h3 id="管理内存前先划分出三个边界值"><a href="#管理内存前先划分出三个边界值" class="headerlink" title="管理内存前先划分出三个边界值"></a>管理内存前先划分出三个边界值</h3><p>还是把 main 的全部代码都先写出来，很少</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line"></span><br><span class="line">    ROOT_DEV = ORIG_ROOT_DEV;</span><br><span class="line">    drive_info = DRIVE_INFO;</span><br><span class="line">    memory_end = (1&lt;&lt;20) + (EXT_MEM_K&lt;&lt;10);</span><br><span class="line">    memory_end &amp;= 0xfffff000;</span><br><span class="line">    if (memory_end &gt; 16*1024*1024)</span><br><span class="line">        memory_end = 16*1024*1024;</span><br><span class="line">    if (memory_end &gt; 12*1024*1024) </span><br><span class="line">        buffer_memory_end = 4*1024*1024;</span><br><span class="line">    else if (memory_end &gt; 6*1024*1024)</span><br><span class="line">        buffer_memory_end = 2*1024*1024;</span><br><span class="line">    else</span><br><span class="line">        buffer_memory_end = 1*1024*1024;</span><br><span class="line">    main_memory_start = buffer_memory_end;</span><br><span class="line"></span><br><span class="line">    mem_init(main_memory_start,memory_end);</span><br><span class="line">    trap_init();</span><br><span class="line">    blk_dev_init();</span><br><span class="line">    chr_dev_init();</span><br><span class="line">    tty_init();</span><br><span class="line">    time_init();</span><br><span class="line">    sched_init();</span><br><span class="line">    buffer_init(buffer_memory_end);</span><br><span class="line">    hd_init();</span><br><span class="line">    floppy_init();</span><br><span class="line"></span><br><span class="line">    sti();</span><br><span class="line">    move_to_user_mode();</span><br><span class="line">    if (!fork()) &#123;      /* we count on this going ok */</span><br><span class="line">        init();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for(;;) pause();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们今天就看这第一小段。</p><p>首先，ROOT_DEV 为系统的根文件设备号，drive_info 为之前 setup.s 程序获取并存储在内存 0x90000 处的设备信息，我们先不管这俩，等之后用到了再说。</p><p>我们看后面这一坨很影响整体画风的一段代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    memory_end = (1&lt;&lt;20) + (EXT_MEM_K&lt;&lt;10);</span><br><span class="line">    memory_end &amp;= 0xfffff000;</span><br><span class="line">    if (memory_end &gt; 16*1024*1024)</span><br><span class="line">        memory_end = 16*1024*1024;</span><br><span class="line">    if (memory_end &gt; 12*1024*1024) </span><br><span class="line">        buffer_memory_end = 4*1024*1024;</span><br><span class="line">    else if (memory_end &gt; 6*1024*1024)</span><br><span class="line">        buffer_memory_end = 2*1024*1024;</span><br><span class="line">    else</span><br><span class="line">        buffer_memory_end = 1*1024*1024;</span><br><span class="line">    main_memory_start = buffer_memory_end;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一坨代码和后面规规整整的 xxx_init 平级的位置，要是我们这么写代码，肯定被老板批评，被同事鄙视了。但 Linus 写的，就是经典，学就完事了。</p><p>这一坨代码虽然很乱，但仔细看就知道它只是为了计算出三个变量罢了。</p><ul><li>main_memory_start</li><li>memory_end</li><li>buffer_memory_end</li></ul><p>而观察最后一行代码发现，其实两个变量是相等的，所以其实仅仅计算出了两个变量。</p><ul><li>main_memory_start</li><li>memory_end</li></ul><p>然后再具体分析这个逻辑，其实就是一堆 if else 判断而已，判断的标准都是 memory_end 也就是内存最大值的大小，而这个内存最大值由第一行代码可以看出，是等于 1M + 扩展内存大小。</p><p>那 ok 了，其实就只是<strong>针对不同的内存大小，设置不同的边界值</strong>罢了，为了理解它，我们完全没必要考虑这么周全，就假设总内存一共就 8M 大小吧。</p><p>那么如果内存为 8M 大小，memory_end 就是 8 * 1024 * 1024，也就只会走倒数第二个分支，那么 buffer_memory_end 就为 2 * 1024 * 1024， 那么 main_memory_start<br>也为 2 * 1024 * 1024</p><p>那这些值有什么用呢？一张图就给你说明白了。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_3.png"></p><p>你看，其实就是定了三个箭头所指向的地址的三个边界变量。</p><h3 id="主内存区初始化-用一张大表管理内存-mem-init"><a href="#主内存区初始化-用一张大表管理内存-mem-init" class="headerlink" title="主内存区初始化 - 用一张大表管理内存 - mem_init"></a>主内存区初始化 - 用一张大表管理内存 - mem_init</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    mem_init(main_memory_start, memory_end);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>进入 mem_init 函数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#define LOW_MEM 0x100000</span><br><span class="line">#define PAGING_MEMORY (15*1024*1024)</span><br><span class="line">#define PAGING_PAGES (PAGING_MEMORY&gt;&gt;12)</span><br><span class="line">#define MAP_NR(addr) (((addr)-LOW_MEM)&gt;&gt;12)</span><br><span class="line">#define USED 100</span><br><span class="line"></span><br><span class="line">static long HIGH_MEMORY = 0;</span><br><span class="line">static unsigned char mem_map[PAGING_PAGES] = &#123; 0, &#125;;</span><br><span class="line"></span><br><span class="line">// start_mem = 2 * 1024 * 1024</span><br><span class="line">// end_mem = 8 * 1024 * 1024</span><br><span class="line">void mem_init(long start_mem, long end_mem)</span><br><span class="line">&#123;</span><br><span class="line">    int i;</span><br><span class="line">    HIGH_MEMORY = end_mem;</span><br><span class="line">    for (i=0 ; i&lt;PAGING_PAGES ; i++)</span><br><span class="line">        mem_map[i] = USED;</span><br><span class="line">    i = MAP_NR(start_mem);</span><br><span class="line">    end_mem -= start_mem;</span><br><span class="line">    end_mem &gt;&gt;= 12;</span><br><span class="line">    while (end_mem--&gt;0)</span><br><span class="line">        mem_map[i++]=0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发现也没几行，而且并没有更深的方法调用，看来是个好欺负的方法。</p><p>仔细一看这个方法，其实折腾来折腾去，就是给一个 <strong>mem_map</strong> 数组的各个位置上赋了值，而且显示全部赋值为 USED 也就是 100，然后对其中一部分又赋值为了 0。</p><p>是不是很简单？就是<strong>准备了一个表，记录了哪些内存被占用了，哪些内存没被占用</strong>。这就是所谓的“管理”，并没有那么神乎其神。</p><p>那接下来自然有两个问题，每个元素表示占用和未占用，这个表示的范围是多大？初始化时哪些地方是占用的，哪些地方又是未占用的？</p><p>还是一张图就看明白了，我们仍然假设内存总共只有 8M。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_4.png"></p><p>可以看出，初始化完成后，其实就是 mem_map 这个数组的每个元素都代表一个 4K 内存是否空闲（准确说是使用次数）。</p><p>4K 内存通常叫做 1 页内存，而这种管理方式叫<strong>分页管理</strong>，就是把内存分成一页一页（4K）的单位去管理。</p><p>1M 以下的内存这个数组干脆没有记录，这里的内存是无需管理的，或者换个说法是无权管理的，也就是没有权利申请和释放，因为这个区域是内核代码所在的地方，不能被“污染”。</p><p>1M 到 2M 这个区间是<strong>缓冲区</strong>，2M 是缓冲区的末端，缓冲区的开始在哪里之后再说，这些地方不是主内存区域，因此直接标记为 USED，产生的效果就是无法再被分配了。</p><p>2M 以上的空间是<strong>主内存区域</strong>，而主内存目前没有任何程序申请，所以初始化时统统都是零，未来等着应用程序去申请和释放这里的内存资源。</p><h4 id="通过-get-free-page-申请空闲内存页"><a href="#通过-get-free-page-申请空闲内存页" class="headerlink" title="通过 get_free_page() 申请空闲内存页"></a>通过 get_free_page() 申请空闲内存页</h4><p>在 memory.c 文件中有个函数 get_free_page()，用于在主内存区中申请一页空闲内存页，并返回物理内存页的起始地址</p><p>比如我们在 fork 子进程的时候，会调用 <strong>copy_process</strong> 函数来复制进程的结构信息，其中有一个步骤就是要<strong>申请一页内存</strong>，用于存放进程结构信息 task_struct。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">int copy_process(...) &#123;</span><br><span class="line">    struct task_struct *p;</span><br><span class="line">    ...</span><br><span class="line">    p = (struct task_struct *) get_free_page();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们看 get_free_page 的具体实现，是内联汇编代码，看不懂不要紧，注意它里面就有 mem_map 结构的使用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">unsigned long get_free_page(void) &#123;</span><br><span class="line">    register unsigned long __res asm(&quot;ax&quot;);</span><br><span class="line">    __asm__(</span><br><span class="line">        &quot;std ; repne ; scasb\n\t&quot;</span><br><span class="line">        &quot;jne 1f\n\t&quot;</span><br><span class="line">        &quot;movb $1,1(%%edi)\n\t&quot;</span><br><span class="line">        &quot;sall $12,%%ecx\n\t&quot;</span><br><span class="line">        &quot;addl %2,%%ecx\n\t&quot;</span><br><span class="line">        &quot;movl %%ecx,%%edx\n\t&quot;</span><br><span class="line">        &quot;movl $1024,%%ecx\n\t&quot;</span><br><span class="line">        &quot;leal 4092(%%edx),%%edi\n\t&quot;</span><br><span class="line">        &quot;rep ; stosl\n\t&quot;</span><br><span class="line">        &quot;movl %%edx,%%eax\n&quot;</span><br><span class="line">        &quot;1:&quot;</span><br><span class="line">        :&quot;=a&quot; (__res)</span><br><span class="line">        :&quot;0&quot; (0),&quot;i&quot; (LOW_MEM),&quot;c&quot; (PAGING_PAGES),</span><br><span class="line">        &quot;D&quot; (mem_map + PAGING_PAGES-1)</span><br><span class="line">        :&quot;di&quot;,&quot;cx&quot;,&quot;dx&quot;);</span><br><span class="line">    return __res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就是选择 mem_map 中首个空闲页面，并标记为已使用。</p><p>之后的内存申请与释放等骚操作，统统是跟着张大表 mem_map 打交道而已。</p><h3 id="中断初始化-键盘是什么时候开始生效的-trap-init"><a href="#中断初始化-键盘是什么时候开始生效的-trap-init" class="headerlink" title="中断初始化 - 键盘是什么时候开始生效的 - trap_init"></a>中断初始化 - 键盘是什么时候开始生效的 - trap_init</h3><p>当你的计算机刚刚启动时，你按下键盘是不生效的，但是过了一段时间后，再按下键盘就有效果了。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/_posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_5.png" alt="img_5.png"></p><p>那我们今天就来刨根问底一下，<strong>到底过了多久之后，按下键盘才有效果呢</strong>？</p><p>当然首先你得知道，按下键盘后会触发中断，CPU 收到你的键盘中断后，根据中断号，寻找由操作系统写好的键盘中断处理程序。</p><p>这个中断处理程序会把你的键盘码放入一个队列中，由相应的用户程序或内核程序读取，并显示在控制台，或者其他用途，这就代表你的键盘生效了。</p><p>不过放宽心，我们不展开讲这个中断处理程序以及用户程序读取键盘码后的处理细节，我们把关注点放在，究竟是“<strong>什么时候</strong>”，按下键盘才会有这个效果。</p><h4 id="trap-init"><a href="#trap-init" class="headerlink" title="trap_init()"></a>trap_init()</h4><p>进入内核的 main 函数后不久，有这样一行代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    trap_init();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看到这个方法的全部代码后，你可能会会心一笑，也可能一脸懵逼。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">void trap_init(void) &#123;</span><br><span class="line">    int i;</span><br><span class="line">    set_trap_gate(0,&amp;divide_error);</span><br><span class="line">    set_trap_gate(1,&amp;debug);</span><br><span class="line">    set_trap_gate(2,&amp;nmi);</span><br><span class="line">    set_system_gate(3,&amp;int3);   /* int3-5 can be called from all */</span><br><span class="line">    set_system_gate(4,&amp;overflow);</span><br><span class="line">    set_system_gate(5,&amp;bounds);</span><br><span class="line">    set_trap_gate(6,&amp;invalid_op);</span><br><span class="line">    set_trap_gate(7,&amp;device_not_available);</span><br><span class="line">    set_trap_gate(8,&amp;double_fault);</span><br><span class="line">    set_trap_gate(9,&amp;coprocessor_segment_overrun);</span><br><span class="line">    set_trap_gate(10,&amp;invalid_TSS);</span><br><span class="line">    set_trap_gate(11,&amp;segment_not_present);</span><br><span class="line">    set_trap_gate(12,&amp;stack_segment);</span><br><span class="line">    set_trap_gate(13,&amp;general_protection);</span><br><span class="line">    set_trap_gate(14,&amp;page_fault);</span><br><span class="line">    set_trap_gate(15,&amp;reserved);</span><br><span class="line">    set_trap_gate(16,&amp;coprocessor_error);</span><br><span class="line">    for (i=17;i&lt;48;i++)</span><br><span class="line">        set_trap_gate(i,&amp;reserved);</span><br><span class="line">    set_trap_gate(45,&amp;irq13);</span><br><span class="line">    set_trap_gate(39,&amp;parallel_interrupt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>给他简化一下, 把相同功能的去掉。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void trap_init(void) &#123;</span><br><span class="line">    int i;</span><br><span class="line">    // set 了一堆 trap_gate</span><br><span class="line">    set_trap_gate(0, &amp;divide_error);</span><br><span class="line">    ... </span><br><span class="line">    // 又 set 了一堆 system_gate</span><br><span class="line">    set_system_gate(45, &amp;bounds);</span><br><span class="line">    ...</span><br><span class="line">    // 又又批量 set 了一堆 trap_gate</span><br><span class="line">    for (i=17;i&lt;48;i++)</span><br><span class="line">        set_trap_gate(i, &amp;reserved);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="set-trap-gate-amp-set-system-gate"><a href="#set-trap-gate-amp-set-system-gate" class="headerlink" title="set_trap_gate &amp; set_system_gate"></a>set_trap_gate &amp; set_system_gate</h4><p>首先我们看 set_trap_gate 和 set_system_gate 这俩货，发现了这么几个宏定义。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#define _set_gate(gate_addr,type,dpl,addr) \</span><br><span class="line">__asm__ (&quot;movw %%dx,%%ax\n\t&quot; \</span><br><span class="line">    &quot;movw %0,%%dx\n\t&quot; \</span><br><span class="line">    &quot;movl %%eax,%1\n\t&quot; \</span><br><span class="line">    &quot;movl %%edx,%2&quot; \</span><br><span class="line">    : \</span><br><span class="line">    : &quot;i&quot; ((short) (0x8000+(dpl&lt;&lt;13)+(type&lt;&lt;8))), \</span><br><span class="line">    &quot;o&quot; (*((char *) (gate_addr))), \</span><br><span class="line">    &quot;o&quot; (*(4+(char *) (gate_addr))), \</span><br><span class="line">    &quot;d&quot; ((char *) (addr)),&quot;a&quot; (0x00080000))</span><br><span class="line"></span><br><span class="line">#define set_trap_gate(n,addr) \</span><br><span class="line">    _set_gate(&amp;idt[n],15,0,addr)</span><br><span class="line"></span><br><span class="line">#define set_system_gate(n,addr) \</span><br><span class="line">    _set_gate(&amp;idt[n],15,3,addr)</span><br></pre></td></tr></table></figure><p>不过这俩都是最终指向了相同的另一个宏定义 _set_gate，说明是有共性的。</p><p>啥共性呢？我直接说吧，那段你完全看不懂的代码，是将汇编语言嵌入到 c 语言了，最终的效果就是</p><p><strong>在中断描述符表中插入了一个中断描述符</strong>。</p><p>中断描述符表还记得吧，英文叫 idt。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_6.png"></p><p>这段代码就是往这个 idt 表里一项一项地写东西，其对应的中断号就是第一个参数，中断处理程序就是第二个参数。</p><p>产生的效果就是，之后如果来一个中断后，CPU 根据其中断号，就可以到这个中断描述符表 idt 中找到对应的中断处理程序了。</p><p>比如这个。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set_trap_gate(0,&amp;divide_error);</span><br></pre></td></tr></table></figure><p>就是设置 0 号中断，对应的中断处理程序是 divide_error。</p><p>等 CPU 执行了一条除零指令的时候，会从硬件层面发起一个 0 号异常中断，然后执行由我们操作系统定义的 divide_error 也就是除法异常处理程序，执行完之后再返回。</p><p>再比如这个。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set_system_gate(5,&amp;overflow);</span><br></pre></td></tr></table></figure><p>就是设置 5 号中断，对应的中断处理程序是 overflow，是边界出错中断。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TIPS：这个 system 与 trap 的区别仅仅在于，设置的中断描述符的特权级不同，前者是 0（内核态），后者是 3（用户态），这块展开将会是非常严谨的、绕口的、复杂的特权级相关的知识，不明白的话先不用管，就理解为都是设置一个中断号和中断处理程序的对应关系就好了。</span><br></pre></td></tr></table></figure><p>再往后看，批量操作这里。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void trap_init(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    for (i=17;i&lt;48;i++)</span><br><span class="line">        set_trap_gate(i,&amp;reserved);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>17 到 48 号中断都批量设置为了 reserved 函数，这是暂时的，后面各个硬件初始化时要重新设置好这些中断，把暂时的这个给覆盖掉，此时你留个印象。</p><p>所以整段代码执行下来，内存中那个 idt 的位置会变成如下的样子。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_7.png"></p><p>好了，我们看到了设置中断号与中断处理程序对应的地方，那这行代码过去后，键盘好使了么？</p><p><strong>NO</strong></p><p>键盘产生的中断的中断号是 0x21，此时这个中断号还仅仅对应着一个临时的中断处理程序 &amp;reserved，我们接着往后看。</p><h4 id="键盘中断设置"><a href="#键盘中断设置" class="headerlink" title="键盘中断设置"></a>键盘中断设置</h4><p>在这行代码往后几行，还有这么一行代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    trap_init();</span><br><span class="line">    ...</span><br><span class="line">    tty_init();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void tty_init(void) &#123;</span><br><span class="line">    rs_init();</span><br><span class="line">    con_init();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void con_init(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    set_trap_gate(0x21,&amp;keyboard_interrupt);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意到 trap_init 后有个 tty_init，最后根据调用链，会调用到一行添加 0x21 号中断处理程序的代码，就是刚刚熟悉的 set_trap_gate。</p><p>而后面的 keyboard_interrupt 根据名字也可以猜出，就是键盘的中断处理程序嘛！</p><p>就是从这一行代码开始，我们的键盘生效了！</p><h4 id="启用中断"><a href="#启用中断" class="headerlink" title="启用中断"></a>启用中断</h4><p>不过还有点小问题，不过不重要，就是我们现在的中断处于<strong>禁用状态</strong>，不论是键盘中断还是其他中断，通通都不好使。</p><p>而 main 方法继续往下读，还有一行这个东西。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    trap_init();</span><br><span class="line">    ...</span><br><span class="line">    tty_init();</span><br><span class="line">    ...</span><br><span class="line">    sti();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>sti 最终会对应一个同名的汇编指令 sti，表示允许中断。所以这行代码之后，键盘才真正开始生效！</p><h3 id="块设备请求项的初始化-读取块设备与内存缓冲区之间的桥梁-blk-dev-init"><a href="#块设备请求项的初始化-读取块设备与内存缓冲区之间的桥梁-blk-dev-init" class="headerlink" title="块设备请求项的初始化 - 读取块设备与内存缓冲区之间的桥梁 - blk_dev_init"></a>块设备请求项的初始化 - 读取块设备与内存缓冲区之间的桥梁 - blk_dev_init</h3><p>读取硬盘数据到内存中，是操作系统的一个基础功能。</p><p>读取硬盘需要有块设备驱动程序，而以文件的方式来读取则还有要再上面包一层文件系统。</p><p>把读出来的数据放到内存，就涉及到内存中缓冲区的管理。</p><p>上面说的每一件事，都是一个十分庞大的体系，先不展开叙述，先梳理读取块设备与内存缓冲区之间的桥梁，<strong>块设备请求项</strong>的初始化工作。</p><h4 id="初始化-request-32"><a href="#初始化-request-32" class="headerlink" title="初始化 request[32]"></a>初始化 request[32]</h4><p>进入内核的 main 函数后不久，有这样一行代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    blk_dev_init();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看到这个方法的全部代码后，你可能会会心一笑，也可能一脸懵逼。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void blk_dev_init(void) &#123;</span><br><span class="line">    int i;</span><br><span class="line">    for (i=0; i&lt;32; i++) &#123;</span><br><span class="line">        request[i].dev = -1;</span><br><span class="line">        request[i].next = NULL;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就是给 request 这个数组的前 32 个元素的两个变量 dev 和 next 附上值，看这俩值 -1 和 NULL 也可以大概猜出，这是没有任何作用时的初始化值。</p><h4 id="request-32-结构"><a href="#request-32-结构" class="headerlink" title="request[32] 结构"></a>request[32] 结构</h4><p>我们看下 request 结构体。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> * Ok, this is an expanded form so that we can use the same</span><br><span class="line"> * request for paging requests when that is implemented. In</span><br><span class="line"> * paging, &#x27;bh&#x27; is NULL, and &#x27;waiting&#x27; is used to wait for</span><br><span class="line"> * read/write completion.</span><br><span class="line"> */</span><br><span class="line">struct request &#123;</span><br><span class="line">    int dev;        /* -1 if no request */</span><br><span class="line">    int cmd;        /* READ or WRITE */</span><br><span class="line">    int errors;</span><br><span class="line">    unsigned long sector;</span><br><span class="line">    unsigned long nr_sectors;</span><br><span class="line">    char * buffer;</span><br><span class="line">    struct task_struct * waiting;</span><br><span class="line">    struct buffer_head * bh;</span><br><span class="line">    struct request * next;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>哎哟，这就有点头大了，刚刚的函数虽然很短，但看到这个结构体我们知道了，重点在这呢。</p><p>这也侧面说明了，学习操作系统，其实把遇到的重要数据结构牢记心中，就已经成功一半了。比如主内存管理结构 mem_map，知道它的数据结构是什么样子，其功能也基本就懂了。</p><p>收，继续说这个 request 结构，这个结构就代表了一次读盘请求，其中：</p><ul><li>dev 表示设备号，-1 就表示空闲。</li><li>cmd 表示命令，其实就是 READ 还是 WRITE，也就表示本次操作是读还是写。</li><li>errors 表示操作时产生的错误次数。</li><li>sector 表示起始扇区。</li><li>nr_sectors 表示扇区数。</li><li>buffer 表示数据缓冲区，也就是读盘之后的数据放在内存中的什么位置。</li><li>waiting 是个 task_struct 结构，这可以表示一个进程，也就表示是哪个进程发起了这个请求。</li><li>bh 是缓冲区头指针，这个后面讲完缓冲区就懂了，因为这个 request 是需要与缓冲区挂钩的。</li><li>next 指向了下一个请求项。</li></ul><p>这里有的变量看不懂没关系，不过我们倒是可以基于现有的重点参数猜测一下，比如读请求时，cmd 就是 READ，sector 和 nr_sectors 这俩就定位了所要读取的块设备（可以简单先理解为硬盘）的哪几个扇区，buffer<br>就定位了这些数据读完之后放在内存的什么位置。</p><p>这就够啦，想想看，这四个参数是不是就能完整描述了一个读取硬盘的需求了？而且完全没有歧义，就像下面这样。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_8.png"></p><p>而其他的参数，肯定是为了更好地配合操作系统进行读写块设备操作嘛，为了把多个读写块设备请求很好地组织起来。</p><p>这个组织不但要有这个数据结构中 hb 和 next 等变量的配合，还要有后面的电梯调度算法的配合，仅此而已，先点到为止。</p><p>总之，我们这里就先明白，这个 request 结构可以完整描述一个读盘操作。然后那个 request 数组就是把它们都放在一起，并且它们又通过 next 指针串成链表。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_9.png"></p><h4 id="如何使用-request-32-结构-数据读盘"><a href="#如何使用-request-32-结构-数据读盘" class="headerlink" title="如何使用 request[32] 结构 - 数据读盘"></a>如何使用 request[32] 结构 - 数据读盘</h4><p>简单展望一下，后面读盘的全流程中，是怎么用到刚刚初始化的这个 request[32] 结构的。</p><p>读操作的系统调用函数是 sys_read，源代码很长，简化一下，仅仅保留读取普通文件的分支，就是如下的样子。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int sys_read(unsigned int fd,char * buf,int count) &#123;</span><br><span class="line">    struct file * file = current-&gt;filp[fd];</span><br><span class="line">    struct m_inode * inode = file-&gt;f_inode;</span><br><span class="line">    // 校验 buf 区域的内存限制</span><br><span class="line">    verify_area(buf,count);</span><br><span class="line">    // 仅关注目录文件或普通文件</span><br><span class="line">    return file_read(inode,file,buf,count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看，入参 fd 是文件描述符，通过它可以找到一个文件的 inode，进而找到这个文件在硬盘中的位置。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_10.png"></p><p>另两个入参 buf 就是要复制到的内存中的位置，count 就是要复制多少个字节，很好理解。</p><p>钻到 file_read 函数里继续看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">int file_read(struct m_inode * inode, struct file * filp, char * buf, int count) &#123;</span><br><span class="line">    int left,chars,nr;</span><br><span class="line">    struct buffer_head * bh;</span><br><span class="line">    left = count;</span><br><span class="line">    while (left) &#123;</span><br><span class="line">        if (nr = bmap(inode,(filp-&gt;f_pos)/BLOCK_SIZE)) &#123;</span><br><span class="line">            if (!(bh=bread(inode-&gt;i_dev,nr)))</span><br><span class="line">                break;</span><br><span class="line">        &#125; else</span><br><span class="line">            bh = NULL;</span><br><span class="line">        nr = filp-&gt;f_pos % BLOCK_SIZE;</span><br><span class="line">        chars = MIN( BLOCK_SIZE-nr , left );</span><br><span class="line">        filp-&gt;f_pos += chars;</span><br><span class="line">        left -= chars;</span><br><span class="line">        if (bh) &#123;</span><br><span class="line">            char * p = nr + bh-&gt;b_data;</span><br><span class="line">            while (chars--&gt;0)</span><br><span class="line">                put_fs_byte(*(p++),buf++);</span><br><span class="line">            brelse(bh);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            while (chars--&gt;0)</span><br><span class="line">                put_fs_byte(0,buf++);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    inode-&gt;i_atime = CURRENT_TIME;</span><br><span class="line">    return (count-left)?(count-left):-ERROR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>整体看，就是一个 while 循环，每次读入一个块的数据，直到入参所要求的大小全部读完为止。</p><p>直接看 bread 那一行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">int file_read(struct m_inode * inode, struct file * filp, char * buf, int count) &#123;</span><br><span class="line">    ...</span><br><span class="line">    while (left) &#123;</span><br><span class="line">        ...</span><br><span class="line">        if (!(bh=bread(inode-&gt;i_dev,nr)))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数就是去读某一个设备的某一个数据块号的内容，展开进去看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">struct buffer_head * bread(int dev,int block) &#123;</span><br><span class="line">    struct buffer_head * bh = getblk(dev,block);</span><br><span class="line">    if (bh-&gt;b_uptodate)</span><br><span class="line">        return bh;</span><br><span class="line">    ll_rw_block(READ,bh);</span><br><span class="line">    wait_on_buffer(bh);</span><br><span class="line">    if (bh-&gt;b_uptodate)</span><br><span class="line">        return bh;</span><br><span class="line">    brelse(bh);</span><br><span class="line">    return NULL;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 getblk 先申请了一个内存中的缓冲块，然后 ll_rw_block 负责把数据读入这个缓冲块，进去继续看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">void ll_rw_block(int rw, struct buffer_head * bh) &#123;</span><br><span class="line">    ...</span><br><span class="line">    make_request(major,rw,bh);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">static void make_request(int major,int rw, struct buffer_head * bh) &#123;</span><br><span class="line">    ...</span><br><span class="line">if (rw == READ)</span><br><span class="line">        req = request+NR_REQUEST;</span><br><span class="line">    else</span><br><span class="line">        req = request+((NR_REQUEST*2)/3);</span><br><span class="line">/* find an empty request */</span><br><span class="line">    while (--req &gt;= request)</span><br><span class="line">        if (req-&gt;dev&lt;0)</span><br><span class="line">            break;</span><br><span class="line">    ...</span><br><span class="line">/* fill up the request-info, and add it to the queue */</span><br><span class="line">    req-&gt;dev = bh-&gt;b_dev;</span><br><span class="line">    req-&gt;cmd = rw;</span><br><span class="line">    req-&gt;errors=0;</span><br><span class="line">    req-&gt;sector = bh-&gt;b_blocknr&lt;&lt;1;</span><br><span class="line">    req-&gt;nr_sectors = 2;</span><br><span class="line">    req-&gt;buffer = bh-&gt;b_data;</span><br><span class="line">    req-&gt;waiting = NULL;</span><br><span class="line">    req-&gt;bh = bh;</span><br><span class="line">    req-&gt;next = NULL;</span><br><span class="line">    add_request(major+blk_dev,req);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看，这里就用到了刚刚说的结构咯。</p><p>具体说来，就是该函数会往刚刚的设备的请求项链表 request[32] 中添加一个请求项，只要 request[32] 中有未处理的请求项存在，都会陆续地被处理，直到设备的请求项链表是空为止。</p><p>具体怎么读盘，就是与硬盘 IO 端口进行交互的过程了，可以继续往里跟，直到看到一个 hd_out 函数为止，本讲不展开了。</p><p>具体读盘操作，后面会有详细的章节展开讲解，目前你只需要知道，我们在 main 函数的 init 系列函数中，通过 blk_dev_init 为后面的块设备访问，提前建立了一个数据结构，作为访问块设备和内存缓冲区之间的桥梁，就可以了。</p><h3 id="控制台初始化-为什么屏幕上就会有输出-tty-init"><a href="#控制台初始化-为什么屏幕上就会有输出-tty-init" class="headerlink" title="控制台初始化 - 为什么屏幕上就会有输出 - tty_init"></a>控制台初始化 - 为什么屏幕上就会有输出 - tty_init</h3><p>继内存管理结构 mem_map 和中断描述符表 idt 建立好之后，我们又在内存中倒腾出一个新的数据结构 request。</p><p>这是块<strong>设备驱动程序</strong>与<strong>内存缓冲区</strong>的桥梁，通过它可以完整地表示一个块设备读写操作要做的事。</p><h4 id="串口中断与显示模式"><a href="#串口中断与显示模式" class="headerlink" title="串口中断与显示模式"></a>串口中断与显示模式</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    blk_dev_init();</span><br><span class="line">    chr_dev_init();</span><br><span class="line">    tty_init();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方法执行完成之后，我们将会具备键盘输入到显示器输出字符这个最常用的功能。</p><p>打开这个函数后我有点慌。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void tty_init(void)</span><br><span class="line">&#123;</span><br><span class="line">    rs_init();</span><br><span class="line">    con_init();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看来这个方法已经多到需要拆成两个子方法了。</p><p>打开第一个方法，还好。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void rs_init(void)</span><br><span class="line">&#123;</span><br><span class="line">    set_intr_gate(0x24,rs1_interrupt);</span><br><span class="line">    set_intr_gate(0x23,rs2_interrupt);</span><br><span class="line">    init(tty_table[1].read_q.data);</span><br><span class="line">    init(tty_table[2].read_q.data);</span><br><span class="line">    outb(inb_p(0x21)&amp;0xE7,0x21);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方法是串口中断的开启，以及设置对应的中断处理程序，串口在我们现在的 PC 机上已经很少用到了，所以这个直接忽略。</p><p>看第二个方法，这是重点。代码非常长，有点吓人，我先把大体框架写出。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void con_init(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    if (ORIG_VIDEO_MODE == 7) &#123;</span><br><span class="line">        ...</span><br><span class="line">        if ((ORIG_VIDEO_EGA_BX &amp; 0xff) != 0x10) &#123;...&#125;</span><br><span class="line">        else &#123;...&#125;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        ...</span><br><span class="line">        if ((ORIG_VIDEO_EGA_BX &amp; 0xff) != 0x10) &#123;...&#125;</span><br><span class="line">        else &#123;...&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看出，非常多的 if else。</p><p>这是为了应对不同的显示模式，来分配不同的变量值，那如果我们仅仅找出一个显示模式，这些分支就可以只看一个了。</p><h4 id="一个字符是如何显示在屏幕上的呢"><a href="#一个字符是如何显示在屏幕上的呢" class="headerlink" title="一个字符是如何显示在屏幕上的呢"></a>一个字符是如何显示在屏幕上的呢</h4><p>如果你可以随意操作内存和 CPU 等设备，你如何操作才能使得你的显示器上，显示一个字符‘a’呢？</p><p>我们先看一张图。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_11.png"></p><p>内存中有这样一部分区域，是和显存映射的。啥意思，就是你往上图的这些内存区域中写数据，相当于写在了显存中。而往显存中写数据，就相当于在屏幕上输出文本了。</p><p>没错，就是这么简单。</p><p>如果我们写这一行汇编语句。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mov [0xB8000],&#x27;h&#x27;</span><br></pre></td></tr></table></figure><p>后面那个 h 相当于汇编编辑器帮我们转换成 ASCII 码的二进制数值，当然我们也可以直接写。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mov [0xB8000],0x68</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其实就是往内存中 0xB8000 这个位置写了一个值，只要一写，屏幕上就会是这样。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_12.png"></p><p>简单吧，具体说来，这片内存是<strong>每两个字节表示一个显示在屏幕上的字符，第一个是字符的编码，第二个是字符的颜色</strong>，那我们先不管颜色，如果多写几个字符就像这样。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mov [0xB8000],&#x27;h&#x27;</span><br><span class="line">mov [0xB8002],&#x27;e&#x27;</span><br><span class="line">mov [0xB8004],&#x27;l&#x27;</span><br><span class="line">mov [0xB8006],&#x27;l&#x27;</span><br><span class="line">mov [0xB8008],&#x27;o&#x27;</span><br></pre></td></tr></table></figure><p>此时屏幕上就会是这样。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_13.png"></p><p>是不是贼简单？那我们回过头看刚刚的代码，我们就假设显示模式是我们现在的这种文本模式，那条件分支就可以去掉好多。</p><p>代码可以简化成这个样子。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#define ORIG_X          (*(unsigned char *)0x90000)</span><br><span class="line">#define ORIG_Y          (*(unsigned char *)0x90001)</span><br><span class="line">void con_init(void) &#123;</span><br><span class="line">    register unsigned char a;</span><br><span class="line">    // 第一部分 获取显示模式相关信息</span><br><span class="line">    video_num_columns = (((*(unsigned short *)0x90006) &amp; 0xff00) &gt;&gt; 8);</span><br><span class="line">    video_size_row = video_num_columns * 2;</span><br><span class="line">    video_num_lines = 25;</span><br><span class="line">    video_page = (*(unsigned short *)0x90004);</span><br><span class="line">    video_erase_char = 0x0720;</span><br><span class="line">    // 第二部分 显存映射的内存区域 </span><br><span class="line">    video_mem_start = 0xb8000;</span><br><span class="line">    video_port_reg  = 0x3d4;</span><br><span class="line">    video_port_val  = 0x3d5;</span><br><span class="line">    video_mem_end = 0xba000;</span><br><span class="line">    // 第三部分 滚动屏幕操作时的信息</span><br><span class="line">    origin  = video_mem_start;</span><br><span class="line">    scr_end = video_mem_start + video_num_lines * video_size_row;</span><br><span class="line">    top = 0;</span><br><span class="line">    bottom  = video_num_lines;</span><br><span class="line">    // 第四部分 定位光标并开启键盘中断</span><br><span class="line">    gotoxy(ORIG_X, ORIG_Y);</span><br><span class="line">    set_trap_gate(0x21,&amp;keyboard_interrupt);</span><br><span class="line">    outb_p(inb_p(0x21)&amp;0xfd,0x21);</span><br><span class="line">    a=inb_p(0x61);</span><br><span class="line">    outb_p(a|0x80,0x61);</span><br><span class="line">    outb(a,0x61);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先还记不记得之前汇编语言的时候做的工作，存了好多以后要用的数据在内存中。</p><table><thead><tr><th>内存地址</th><th>长度(字节)</th><th>名称</th></tr></thead><tbody><tr><td>0x90000</td><td>2</td><td>光标位置</td></tr><tr><td>0x90002</td><td>2</td><td>扩展内存数</td></tr><tr><td>0x90004</td><td>2</td><td>显示页面</td></tr><tr><td>0x90006</td><td>1</td><td>显示模式</td></tr><tr><td>0x90007</td><td>1</td><td>字符列数</td></tr><tr><td>0x90008</td><td>2</td><td>未知</td></tr><tr><td>0x9000A</td><td>1</td><td>显示内存</td></tr><tr><td>0x9000B</td><td>1</td><td>显示状态</td></tr><tr><td>0x9000C</td><td>2</td><td>显卡特性参数</td></tr><tr><td>0x9000E</td><td>1</td><td>屏幕行数</td></tr><tr><td>0x9000F</td><td>1</td><td>屏幕列数</td></tr><tr><td>0x90080</td><td>16</td><td>硬盘1参数表</td></tr><tr><td>0x90090</td><td>16</td><td>硬盘2参数表</td></tr><tr><td>0x901FC</td><td>2</td><td>根设备号</td></tr></tbody></table><p>所以：</p><ol><li>第一部分获取 0x90006 地址处的数据，就是获取显示模式等相关信息。</li><li>第二部分就是显存映射的内存地址范围，我们现在假设是 CGA 类型的文本模式，所以映射的内存是从 0xB8000 到 0xBA000。</li><li>第三部分是设置一些滚动屏幕时需要的参数，定义顶行和底行是哪里，这里顶行就是第一行，底行就是最后一行，很合理。</li><li>第四部分是把光标定位到之前保存的光标位置处（取内存地址 0x90000 处的数据），然后设置并开启键盘中断。</li></ol><h4 id="键盘敲击如何显示在屏幕上"><a href="#键盘敲击如何显示在屏幕上" class="headerlink" title="键盘敲击如何显示在屏幕上"></a>键盘敲击如何显示在屏幕上</h4><p>开启键盘中断后，键盘上敲击一个按键后就会触发中断，中断程序就会读键盘码转换成 ASCII 码，然后写到光标处的内存地址，也就相当于往显存写，于是这个键盘敲击的字符就显示在了屏幕上。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_14.png"></p><p>这一切具体是怎么做到的呢？我们先看看我们干了什么。</p><ol><li>我们现在根据已有信息已经可以实现往屏幕上的任意位置写字符了，而且还能指定颜色。</li><li>并且，我们也能接受键盘中断，根据键盘码中断处理程序就可以得知哪个键按下了。</li></ol><p>有了这俩功能，那我们想干嘛还不是为所欲为？</p><p>好，接下来我们看看代码是怎么处理的，很简单。一切的起点，就是第四步的 gotoxy 函数，定位当前光标。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#define ORIG_X          (*(unsigned char *)0x90000)</span><br><span class="line">#define ORIG_Y          (*(unsigned char *)0x90001)</span><br><span class="line">void con_init(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    // 第四部分 定位光标并开启键盘中断</span><br><span class="line">    gotoxy(ORIG_X, ORIG_Y);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里面干嘛了呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">static inline void gotoxy(unsigned int new_x,unsigned int new_y) &#123;</span><br><span class="line">   ...</span><br><span class="line">   x = new_x;</span><br><span class="line">   y = new_y;</span><br><span class="line">   pos = origin + y*video_size_row + (x&lt;&lt;1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就是给 x y pos 这三个参数附上了值。</p><p>其中 x 表示光标在哪一列，y 表示光标在哪一行，pos 表示根据列号和行号计算出来的内存指针，也就是往这个 pos 指向的地址处写数据，就相当于往控制台的 x 列 y 行处写入字符了，简单吧？</p><p>然后，当你按下键盘后，触发键盘中断，之后的程序调用链是这样的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">_keyboard_interrupt:</span><br><span class="line">    ...</span><br><span class="line">    call _do_tty_interrupt</span><br><span class="line">    ...</span><br><span class="line">    </span><br><span class="line">void do_tty_interrupt(int tty) &#123;</span><br><span class="line">   copy_to_cooked(tty_table+tty);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void copy_to_cooked(struct tty_struct * tty) &#123;</span><br><span class="line">    ...</span><br><span class="line">    tty-&gt;write(tty);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 控制台时 tty 的 write 为 con_write 函数</span><br><span class="line">void con_write(struct tty_struct * tty) &#123;</span><br><span class="line">    ...</span><br><span class="line">    __asm__(&quot;movb _attr,%%ah\n\t&quot;</span><br><span class="line">      &quot;movw %%ax,%1\n\t&quot;</span><br><span class="line">      ::&quot;a&quot; (c),&quot;m&quot; (*(short *)pos)</span><br><span class="line">      :&quot;ax&quot;);</span><br><span class="line">     pos += 2;</span><br><span class="line">     x++;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>前面的过程不用管，我们看最后一个函数 con_write 中的关键代码。</p><p><strong>asm</strong> 内联汇编，就是把键盘输入的字符 c 写入 pos 指针指向的内存，相当于往屏幕输出了。</p><p>之后两行 pos+=2 和 x++，就是调整所谓的光标。</p><p>你看，写入一个字符，最底层，其实就是往内存的某处写个数据，然后顺便调整一下光标。</p><p>由此我们也可以看出，<strong>光标的本质，其实就是这里的 x y pos 这仨变量</strong>而已。</p><h5 id="换行效果"><a href="#换行效果" class="headerlink" title="换行效果"></a>换行效果</h5><p>当发现光标位置处于某一行的结尾时（这个应该很好算吧，我们都知道屏幕上一共有几行几列了），就把光标计算出一个新值，让其处于下一行的开头。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_15.png"></p><p>就一个小计算公式即可搞定，仍然在 con_write 源码处有体现，就是判断列号 x 是否大于了总列数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">void con_write(struct tty_struct * tty) &#123;</span><br><span class="line">    ...</span><br><span class="line">    if (x&gt;=video_num_columns) &#123;</span><br><span class="line">        x -= video_num_columns;</span><br><span class="line">        pos -= video_size_row;</span><br><span class="line">        lf();</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">static void lf(void) &#123;</span><br><span class="line">   if (y+1&lt;bottom) &#123;</span><br><span class="line">      y++;</span><br><span class="line">      pos += video_size_row;</span><br><span class="line">      return;</span><br><span class="line">   &#125;</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="滚屏"><a href="#滚屏" class="headerlink" title="滚屏"></a>滚屏</h5><p>无非就是当检测到光标已经出现在最后一行最后一列了，那就把每一行的字符，都复制到它上一行，其实就是算好哪些内存地址上的值，拷贝到哪些内存地址，就好了。</p><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>所以，有了这个初始化工作，我们就可以利用这些信息，弄几个小算法，实现各种我们常见控制台的操作。</p><p>或者换句话说，我们见惯不怪的控制台，回车、换行、删除、滚屏、清屏等操作，其实底层都要实现相应的代码的。</p><p>所以 console.c 中的其他方法就是做这个事的，我们就不展开每一个功能的方法体了，简单看看有哪些方法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 定位光标的</span><br><span class="line">static inline void gotoxy(unsigned int new_x, unsigned int new_y)&#123;&#125;</span><br><span class="line">// 滚屏，即内容向上滚动一行</span><br><span class="line">static void scrup(void)&#123;&#125;</span><br><span class="line">// 光标同列位置下移一行</span><br><span class="line">static void lf(int currcons)&#123;&#125;</span><br><span class="line">// 光标回到第一列</span><br><span class="line">static void cr(void)&#123;&#125;</span><br><span class="line">...</span><br><span class="line">// 删除一行</span><br><span class="line">static void delete_line(void)&#123;&#125;</span><br></pre></td></tr></table></figure><p>整个 console.c 就讲完了，要知道这个文件可是整个内核中代码量最大的文件，可是功能特别单一，也都很简单，主要是处理键盘各种不同的按键，需要写好多 switch case 等语句，十分麻烦，我们这里就完全没必要去展开了，就是个苦力活。</p><p>到这里，我们就正式讲完了 tty_init 的作用。</p><p>在此之后，内核代码就可以用它来方便地在控制台输出字符啦！这在之后内核想要在启动过程中告诉用户一些信息，以及后面内核完全建立起来之后，由用户用 shell 进行操作时手动输入命令，都是可以用到这里的代码的！</p><h3 id="时间初始化-操作系统如何获取当前时间"><a href="#时间初始化-操作系统如何获取当前时间" class="headerlink" title="时间初始化 操作系统如何获取当前时间"></a>时间初始化 操作系统如何获取当前时间</h3><p>过初始化控制台的 tty_init 操作，内核代码可以很方便地在控制台输出字符啦，同时支持用户键盘操作和换行和滚屏等友好设计。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    tty_init();</span><br><span class="line">    time_init();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们继续往下看下一个初始化的倒霉鬼，time_init。</p><p>为什么操作系统在启动之后，可以显示出当前时间呢？难道操作系统在电脑关机后，依然不停地在某处运行着，勤勤恳恳数着秒表么？</p><p>当然不是，那我们今天就打开这个 time_init 函数一探究竟。</p><p>打开这个函数后我又是很开心，因为很短，且没有更深入的方法调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#define CMOS_READ(addr) (&#123; \</span><br><span class="line">    outb_p(0x80|addr,0x70); \</span><br><span class="line">    inb_p(0x71); \</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">#define BCD_TO_BIN(val) ((val)=((val)&amp;15) + ((val)&gt;&gt;4)*10)</span><br><span class="line"></span><br><span class="line">static void time_init(void) &#123;</span><br><span class="line">    struct tm time;</span><br><span class="line">    do &#123;</span><br><span class="line">        time.tm_sec = CMOS_READ(0);</span><br><span class="line">        time.tm_min = CMOS_READ(2);</span><br><span class="line">        time.tm_hour = CMOS_READ(4);</span><br><span class="line">        time.tm_mday = CMOS_READ(7);</span><br><span class="line">        time.tm_mon = CMOS_READ(8);</span><br><span class="line">        time.tm_year = CMOS_READ(9);</span><br><span class="line">    &#125; while (time.tm_sec != CMOS_READ(0));</span><br><span class="line">    BCD_TO_BIN(time.tm_sec);</span><br><span class="line">    BCD_TO_BIN(time.tm_min);</span><br><span class="line">    BCD_TO_BIN(time.tm_hour);</span><br><span class="line">    BCD_TO_BIN(time.tm_mday);</span><br><span class="line">    BCD_TO_BIN(time.tm_mon);</span><br><span class="line">    BCD_TO_BIN(time.tm_year);</span><br><span class="line">    time.tm_mon--;</span><br><span class="line">    startup_time = kernel_mktime(&amp;time);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>梦想的代码呀！ 那主要就是对 CMOS_READ 和 BCD_TO_BIN 都是啥意思展开讲一下就明白了了。</p><h4 id="CMOS-READ"><a href="#CMOS-READ" class="headerlink" title="CMOS_READ"></a>CMOS_READ</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#define CMOS_READ(addr) (&#123; \</span><br><span class="line">    outb_p(0x80|addr,0x70); \</span><br><span class="line">    inb_p(0x71); \</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>就是对一个端口先 out 写一下，再 in 读一下。</p><p>这是 CPU 与外设交互的一个基本玩法，CPU 与外设打交道基本是通过端口，往某些端口写值来表示要这个外设干嘛，然后从另一些端口读值来接受外设的反馈。</p><p>至于这个外设内部是怎么实现的，对使用它的操作系统而言，是个黑盒，无需关心。那对于我们程序员来说，就更不用关心了。</p><p>对 CMOS 这个外设的交互讲起来可能没感觉，我们看看与硬盘的交互。</p><p>最常见的就是读硬盘了，我们看硬盘的端口表。</p><table><thead><tr><th>端口</th><th>读</th><th>写</th></tr></thead><tbody><tr><td>0x1F0</td><td>数据寄存器</td><td>数据寄存器</td></tr><tr><td>0x1F1</td><td>错误寄存器</td><td>特征寄存器</td></tr><tr><td>0x1F2</td><td>扇区计数寄存器</td><td>扇区计数寄存器</td></tr><tr><td>0x1F3</td><td>扇区号寄存器或 LBA 块地址 0~7</td><td>扇区号或 LBA 块地址 0~7</td></tr><tr><td>0x1F4</td><td>磁道数低 8 位或 LBA 块地址 8~15</td><td>磁道数低 8 位或 LBA 块地址 8~15</td></tr><tr><td>0x1F5</td><td>磁道数高 8 位或 LBA 块地址 16~23</td><td>磁道数高 8 位或 LBA 块地址 16~23</td></tr><tr><td>0x1F6</td><td>驱动器/磁头或 LBA 块地址 24~27</td><td>驱动器/磁头或 LBA 块地址 24~27</td></tr><tr><td>0x1F7</td><td>命令寄存器或状态寄存器</td><td>命令寄存器</td></tr></tbody></table><p>那读硬盘就是，往除了第一个以外的后面几个端口写数据，告诉要读硬盘的哪个扇区，读多少。然后再从 0x1F0 端口一个字节一个字节的读数据。这就完成了一次硬盘读操作。</p><p>如果觉得不够具体，那来个具体的版本。</p><ol><li>在 0x1F2 写入要读取的扇区数</li><li>在 0x1F3 ~ 0x1F6 这四个端口写入计算好的起始 LBA 地址</li><li>在 0x1F7 处写入读命令的指令号</li><li>不断检测 0x1F7 （此时已成为状态寄存器的含义）的忙位</li><li>如果第四步骤为不忙，则开始不断从 0x1F0 处读取数据到内存指定位置，直到读完</li></ol><p>看，是不是对 CPU 最底层是如何与外设打交道有点感觉了？是不是也不难？就是按照人家的操作手册，然后无脑按照要求读写端口就行了。</p><p>当然，读取硬盘的这个无脑循环，可以 <strong>CPU</strong> 直接读取并做写入内存的操作，这样就会占用 CPU 的计算资源。</p><p>也可以交给 <strong>DMA</strong> 设备去读，解放 CPU，但和硬盘的交互，通通都是按照硬件手册上的端口说明，来操作的，实际上也是做了一层封装。</p><p>好了，我们已经学会了和一个外设打交道的基本玩法了。</p><p>那我们代码中要打交道的是哪个外设呢？就是 <strong>CMOS</strong>。</p><p>它是主板上的一个可读写的 RAM 芯片，你在开机时长按某个键就可以进入设置它的页面。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_16.png"></p><p>那我们的代码，其实就是与它打交道，获取它的一些数据而已。</p><p>我们回过头看代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">static void time_init(void) &#123;</span><br><span class="line">    struct tm time;</span><br><span class="line">    do &#123;</span><br><span class="line">        time.tm_sec = CMOS_READ(0);</span><br><span class="line">        time.tm_min = CMOS_READ(2);</span><br><span class="line">        time.tm_hour = CMOS_READ(4);</span><br><span class="line">        time.tm_mday = CMOS_READ(7);</span><br><span class="line">        time.tm_mon = CMOS_READ(8);</span><br><span class="line">        time.tm_year = CMOS_READ(9);</span><br><span class="line">    &#125; while (time.tm_sec != CMOS_READ(0));</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>前面几个赋值语句 CMOS_READ 就是<strong>通过读写 CMOS 上的指定端口，依次获取年月日时分秒</strong>等信息。具体咋操作代码上也写了，也是按照 CMOS 手册要求的读写指定端口就行了，我们就不展开了。</p><p>所以你看，其实操作系统程序，也是要依靠与一个外部设备打交道，来获取这些信息的，并不是它自己有什么魔力。操作系统最大的魅力，就在于它借力完成了一项伟大的事，借 CPU 的力，借硬盘的力，借内存的力，以及现在借 CMOS 的力。</p><p>至于 CMOS 又是如何知道时间的，这个就不在我们讨论范围了。</p><h4 id="BCD-TO-BIN"><a href="#BCD-TO-BIN" class="headerlink" title="BCD_TO_BIN"></a>BCD_TO_BIN</h4><p>就是 BCD 转换成 BIN，因为从 CMOS 上获取的这些年月日都是 BCD 码值，需要转换成存储在我们变量上的二进制数值，所以需要一个小算法来转换一下，没什么意思。</p><h4 id="kernel-mktime"><a href="#kernel-mktime" class="headerlink" title="kernel_mktime"></a>kernel_mktime</h4><p>就是根据刚刚的那些时分秒数据，计算从 <strong>1970 年 1 月 1 日 0 时</strong>起到开机当时经过的秒数，作为开机时间，存储在 <strong>startup_time</strong> 这个变量里。</p><p>想研究可以仔细看看这段代码，不过我觉得这种细节不必看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">startup_time = kernel_mktime(&amp;time);</span><br><span class="line"></span><br><span class="line">// kernel/mktime.c</span><br><span class="line">long kernel_mktime(struct tm * tm)</span><br><span class="line">&#123;</span><br><span class="line">    long res;</span><br><span class="line">    int year;</span><br><span class="line">    year = tm-&gt;tm_year - 70;</span><br><span class="line">    res = YEAR*year + DAY*((year+1)/4);</span><br><span class="line">    res += month[tm-&gt;tm_mon];</span><br><span class="line">    if (tm-&gt;tm_mon&gt;1 &amp;&amp; ((year+2)%4))</span><br><span class="line">        res -= DAY;</span><br><span class="line">    res += DAY*(tm-&gt;tm_mday-1);</span><br><span class="line">    res += HOUR*tm-&gt;tm_hour;</span><br><span class="line">    res += MINUTE*tm-&gt;tm_min;</span><br><span class="line">    res += tm-&gt;tm_sec;</span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>所以今天其实就是，计算出了一个 startup_time 变量而已，至于这个变量今后会被谁用，怎么用，那就是后话了。</p><p>相信你逐渐也体会到了，此时操作系统好多地方都是用外设要求的方式去询问，比如硬盘信息、显示模式，以及今天的开机时间的获取等。</p><p>所以至少到目前来说，你还不应该感觉操作系统有多么的“高端”，很多时候都是繁琐地，读人家的硬件手册，获取到想要的的信息，拿来给自己用，或者对其进行各种设置。</p><p>但你一定要耐得住寂寞，真正体现操作系统的强大设计之处，还得接着往下读。</p><h3 id="进程调度初始化"><a href="#进程调度初始化" class="headerlink" title="进程调度初始化"></a>进程调度初始化</h3><p>我们继续往下看，大名鼎鼎的进程调度初始化，shed_init，这方法可了不起，因为它就是多进程的基石！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    sched_init();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>终于来到了兴奋的时刻，是不是很激动？不过先别激动，这里只是进程调度的初始化，也就是为进程调度所需要用到的数据结构做个准备，真正的进程调度还需要调度算法、时钟中断等机制的配合。</p><p>当然，对于理解操作系统，流程和数据结构最为重要了，而这一段作为整个流程的起点，以及建立数据结构的地方，就显得格外重要了。</p><p>我们进入这个方法，一点点往后看。</p><h4 id="初始化了下-TSS-和-LDT-线程0"><a href="#初始化了下-TSS-和-LDT-线程0" class="headerlink" title="初始化了下 TSS 和 LDT (线程0)"></a>初始化了下 TSS 和 LDT (线程0)</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void sched_init(void) &#123;</span><br><span class="line">    set_tss_desc(gdt+4, &amp;(init_task.task.tss));</span><br><span class="line">    set_ldt_desc(gdt+5, &amp;(init_task.task.ldt));</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>两行代码初始化了下 TSS 和 LDT。</p><p>先别急问这俩结构是啥。还记得之前讲的全局描述符表 gdt 么？它在内存的这个位置，并且被设置成了这个样子。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_17.png"></p><p>说回这两行代码，其实就是往后又加了两项，分别是 TSS 和 LDT。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_18.png"></p><p>好，那再说说这俩结构是干嘛的，不过本篇先简单理解，后面会详细讲到。</p><p><strong>TSS 叫任务状态段，就是保存和恢复进程的上下文的</strong>，所谓上下文，其实就是各个寄存器的信息而已，这样进程切换的时候，才能做到保存和恢复上下文，继续执行。</p><p>由它的数据结构你应该可以看出点意思。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">struct tss_struct&#123;</span><br><span class="line">    long back_link;</span><br><span class="line">    long esp0;</span><br><span class="line">    long ss0;</span><br><span class="line">    long esp1;</span><br><span class="line">    long ss1;</span><br><span class="line">    long esp2;</span><br><span class="line">    long ss2;</span><br><span class="line">    long cr3;</span><br><span class="line">    long eip;</span><br><span class="line">    long eflags;</span><br><span class="line">    long eax, ecx, edx, ebx;</span><br><span class="line">    long esp;</span><br><span class="line">    long ebp;</span><br><span class="line">    long esi;</span><br><span class="line">    long edi;</span><br><span class="line">    long es;</span><br><span class="line">    long cs;</span><br><span class="line">    long ss;</span><br><span class="line">    long ds;</span><br><span class="line">    long fs;</span><br><span class="line">    long gs;</span><br><span class="line">    long ldt;</span><br><span class="line">    long trace_bitmap;</span><br><span class="line">    struct i387_struct i387;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>而 <strong>LDT 叫局部描述符表，是与 GDT 全局描述符表相对应的</strong>，内核态的代码用 GDT 里的数据段和代码段，而用户进程的代码用每个用户进程自己的 LDT 里得数据段和代码段。</p><p>先不管它，我这里放一张超纲的图，你先找找感觉。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_19.png"></p><p>我们接着往下看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">struct desc_struct &#123;</span><br><span class="line">    unsigned long a,b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct task_struct * task[64] = &#123;&amp;(init_task.task), &#125;;</span><br><span class="line"></span><br><span class="line">void sched_init(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    int i;</span><br><span class="line">    struct desc_struct * p;</span><br><span class="line">        p = gdt+6;</span><br><span class="line">    for(i=1;i&lt;64;i++) &#123;</span><br><span class="line">        task[i] = NULL;</span><br><span class="line">        p-&gt;a=p-&gt;b=0;</span><br><span class="line">        p++;</span><br><span class="line">        p-&gt;a=p-&gt;b=0;</span><br><span class="line">        p++;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码有个循环，干了两件事。</p><p>一个是给一个长度为 64，结构为 task_struct 的数组 task 附上初始值。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_20.png"></p><p>这个 task_struct 结构就是代表<strong>每一个进程的信息</strong>，这可是个<strong>相当相当重要</strong>的结构了，把它放在心里。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">struct task_struct &#123;</span><br><span class="line">/* these are hardcoded - don&#x27;t touch */</span><br><span class="line">    long state; /* -1 unrunnable, 0 runnable, &gt;0 stopped */</span><br><span class="line">    long counter;</span><br><span class="line">    long priority;</span><br><span class="line">    long signal;</span><br><span class="line">    struct sigaction sigaction[32];</span><br><span class="line">    long blocked; /* bitmap of masked signals */</span><br><span class="line">  /* various fields */</span><br><span class="line">    int exit_code;</span><br><span class="line">    unsigned long start_code,end_code,end_data,brk,start_stack;</span><br><span class="line">    long pid,father,pgrp,session,leader;</span><br><span class="line">    unsigned short uid,euid,suid;</span><br><span class="line">    unsigned short gid,egid,sgid;</span><br><span class="line">    long alarm;</span><br><span class="line">    long utime,stime,cutime,cstime,start_time;</span><br><span class="line">    unsigned short used_math;</span><br><span class="line">  /* file system info */</span><br><span class="line">    int tty;  /* -1 if no tty, so it must be signed */</span><br><span class="line">    unsigned short umask;</span><br><span class="line">    struct m_inode * pwd;</span><br><span class="line">    struct m_inode * root;</span><br><span class="line">    struct m_inode * executable;</span><br><span class="line">    unsigned long close_on_exec;</span><br><span class="line">    struct file * filp[NR_OPEN];</span><br><span class="line">  /* ldt for this task 0 - zero 1 - cs 2 - ds&amp;ss */</span><br><span class="line">    struct desc_struct ldt[3];</span><br><span class="line">  /* tss for this task */</span><br><span class="line">    struct tss_struct tss;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个循环做的另一件事，是给 gdt 剩下的位置填充上 0，也就是把剩下留给 TSS 和 LDT 的描述符都先附上空值。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_21.png"></p><p>往后展望一下的话，就是以后每创建一个新进程，就会在后面添加一组 TSS 和 LDT 表示这个进程的任务状态段以及局部描述符表信息。</p><p>还记得刚刚的超纲图吧，未来整个内存的规划就是这样的，不过你先不用理解得很细。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_22.png"></p><p>那为什么一开始就先有了一组 TSS 和 LDT 呢？现在也没创建进程呀。错了，现在虽然我们还没有建立起进程调度的机制，但我们正在运行的代码就是会作为<strong>未来的一个进程的指令流</strong>。</p><p>也就是当未来进程调度机制一建立起来，正在执行的代码就会化身成为<strong>进程 0</strong> 的代码。所以我们需要提前把这些未来会作为进程 0 的信息写好。</p><p>如果你觉得很疑惑，别急，等后面整个进程调度机制建立起来，并且让你亲眼看到进程 0 以及进程 1 的创建，以及它们后面因为进程调度机制而切换，你就明白这一切的意义了。</p><h4 id="ltr-amp-lldt"><a href="#ltr-amp-lldt" class="headerlink" title="ltr &amp; lldt"></a>ltr &amp; lldt</h4><p>好，收回来，初始化了一组 TSS 和 LDT 后，再往下看两行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#define ltr(n) __asm__(&quot;ltr %%ax&quot;::&quot;a&quot; (_TSS(n)))</span><br><span class="line">#define lldt(n) __asm__(&quot;lldt %%ax&quot;::&quot;a&quot; (_LDT(n)))</span><br><span class="line"></span><br><span class="line">void sched_init(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    ltr(0);</span><br><span class="line">    lldt(0);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这又涉及到之前的知识咯。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">还记得 lidt 和 lgdt 指令么？一个是给 idtr 寄存器赋值，以告诉 CPU 中断描述符表 idt 在内存的位置；一个是给 gdtr 寄存器赋值，以告诉 CPU 全局描述符表 gdt 在内存的位置。</span><br></pre></td></tr></table></figure><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_23.png"></p><p>那这两行和刚刚的类似:</p><ul><li>ltr 是给 tr 寄存器赋值，以告诉 CPU 任务状态段 TSS 在内存的位置；</li><li>lldt 一个是给 ldt 寄存器赋值，以告诉 CPU 局部描述符 LDT 在内存的位置。</li></ul><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_24.png"></p><p>这样，CPU 之后就能通过 tr 寄存器找到当前进程的任务状态段信息，也就是上下文信息，以及通过 ldt 寄存器找到当前进程在用的局部描述符表信息。</p><h4 id="可编程定时器与中断"><a href="#可编程定时器与中断" class="headerlink" title="可编程定时器与中断"></a>可编程定时器与中断</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">void sched_init(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    outb_p(0x36,0x43);      /* binary, mode 3, LSB/MSB, ch 0 */</span><br><span class="line">    outb_p(LATCH &amp; 0xff , 0x40);    /* LSB */</span><br><span class="line">    outb(LATCH &gt;&gt; 8 , 0x40);    /* MSB */</span><br><span class="line">    set_intr_gate(0x20,&amp;timer_interrupt);</span><br><span class="line">    outb(inb_p(0x21)&amp;~0x01,0x21);</span><br><span class="line">    set_system_gate(0x80,&amp;system_call);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>四行端口读写代码，两行设置中断代码。</p><p>端口读写我们已经很熟悉了，就是 CPU 与外设交互的一种方式，之前讲硬盘读写以及 CMOS 读写时，已经接触过了。</p><p>而这次交互的外设是一个<strong>可编程定时器的芯片</strong>(内含晶振的、被称作时钟发生器的元件)，这四行代码就开启了这个定时器，之后这个定时器变会<strong>持续的、以一定频率的向 CPU 发出中断信号</strong>。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_25.png"></p><p>而这段代码中设置的两个中断:</p><ul><li>第一个就是<strong>时钟中断，中断号为 0x20，中断处理程序为 timer_interrupt</strong>。那么每次定时器向 CPU 发出中断后，便会执行这个函数。<ul><li>这个定时器的触发，以及时钟中断函数的设置，是操作系统主导进程调度的一个关键！没有他们这样的外部信号不断触发中断，操作系统就没有办法作为进程管理的主人，通过强制的手段收回进程的 CPU 执行权限。</li></ul></li><li>第二个设置的中断叫<strong>系统调用 system_call，中断号是 0x80</strong>，这个中断又是个<strong>非常非常非常非常非常非常非常重要</strong>的中断，所有用户态程序想要调用内核提供的方法，都需要基于这个系统调用来进行。<ul><li>比如 Java 程序员写一个 read，底层会执行汇编指令 int 0x80，这就会触发系统调用这个中断，最终调用到 Linux 里的 sys_read 方法。</li></ul></li></ul><p>所以你看这一章的内容，偷偷设置了影响进程和影响用户程序调用系统方法的两个重量级中断处理函数，不简单呀~</p><p>到目前为止，中断已经设置了不少了，我们现在看看所设置好的中断有哪些。</p><table><thead><tr><th>中断号</th><th>中断处理函数</th></tr></thead><tbody><tr><td>0 ~ 0x10</td><td>trap_init 里设置的一堆</td></tr><tr><td>0x20</td><td>timer_interrupt</td></tr><tr><td>0x21</td><td>keyboard_interrupt</td></tr><tr><td>0x80</td><td>system_call</td></tr></tbody></table><ul><li>其中 0-0x10 这 17 个中断是 trap_init 里初始化设置的，是一些基本的中断，比如除零异常等。</li><li>在控制台初始化 con_init 里设置了 0x21 键盘中断， 这样按下键盘就有反应了。</li><li>0x20 时钟中断，并且开启定时器。</li><li>最后又偷偷设置了一个极为重要的 0x80 系统调用中断。</li></ul><p>找到些感觉没，有没有越来越发现，操作系统有点靠中断驱动的意思，各个模块不断初始化各种中断处理函数，并且开启指定的外设开关，让操作系统自己慢慢“活”了起来，逐渐通过中断忙碌于各种事情中，无法自拔。</p><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>回顾一下我们今天，就三件事。</p><ul><li>第一，我们往全局描述符表写了两个结构，TSS 和 LDT，作为未来进程 0 的任务状态段和局部描述符表信息。</li></ul><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_26.png"></p><ul><li>第二，我们初始化了一个结构为 task_struct  的数组，未来这里会存放所有进程的信息，并且我们给数组的第一个位置附上了 init_task.init 这个具体值，也是作为未来进程 0 的信息。</li></ul><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_27.png"></p><ul><li>第三，设置了时钟中断 0x20 和系统调用 0x80，一个作为进程调度的起点，一个作为用户程序调用操作系统功能的桥梁，非常之重要。</li></ul><p>后面，我们将会逐渐看到，这些重要的事情，是如何紧密且精妙地结合在一起，发挥出奇妙的作用。</p><h3 id="缓冲区初始化-主内存外的另一个内存管理神器"><a href="#缓冲区初始化-主内存外的另一个内存管理神器" class="headerlink" title="缓冲区初始化 主内存外的另一个内存管理神器"></a>缓冲区初始化 主内存外的另一个内存管理神器</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ...</span><br><span class="line">    mem_init(main_memory_start, memory_end);</span><br><span class="line">    ...</span><br><span class="line">    buffer_init(buffer_memory_end);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在管理内存之初，我们划分出了三个边界值，对主内存和缓冲区进行了区分</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_28.png"></p><p>并通过 mem_init 完成了主内存区初始化， 设置好了内存管理结构 mam_map</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_29.png"></p><p>至此，我们完成了主内存区的管理，而缓冲区是如何管理和分配的，就要看 buffer_init 了。</p><p>我们还是采用之前的方式，就假设内存只有 8M，把一些不相干的分支去掉，方便理解。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">extern int end;</span><br><span class="line">struct buffer_head * start_buffer = (struct buffer_head *) &amp;end;</span><br><span class="line"></span><br><span class="line">void buffer_init(long buffer_end) &#123;</span><br><span class="line">    struct buffer_head * h = start_buffer;</span><br><span class="line">    void * b = (void *) buffer_end;</span><br><span class="line">    while ( (b -= 1024) &gt;= ((void *) (h+1)) ) &#123;</span><br><span class="line">        h-&gt;b_dev = 0;</span><br><span class="line">        h-&gt;b_dirt = 0;</span><br><span class="line">        h-&gt;b_count = 0;</span><br><span class="line">        h-&gt;b_lock = 0;</span><br><span class="line">        h-&gt;b_uptodate = 0;</span><br><span class="line">        h-&gt;b_wait = NULL;</span><br><span class="line">        h-&gt;b_next = NULL;</span><br><span class="line">        h-&gt;b_prev = NULL;</span><br><span class="line">        h-&gt;b_data = (char *) b;</span><br><span class="line">        h-&gt;b_prev_free = h-1;</span><br><span class="line">        h-&gt;b_next_free = h+1;</span><br><span class="line">        h++;</span><br><span class="line">    &#125;</span><br><span class="line">    h--;</span><br><span class="line">    free_list = start_buffer;</span><br><span class="line">    free_list-&gt;b_prev_free = h;</span><br><span class="line">    h-&gt;b_next_free = free_list;</span><br><span class="line">    for (int i=0;i&lt;307;i++)</span><br><span class="line">        hash_table[i]=NULL;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然很长，但其实就造了<strong>两个数据结构</strong>而已。</p><h4 id="通过链接器-ld-获取缓冲区开始位置"><a href="#通过链接器-ld-获取缓冲区开始位置" class="headerlink" title="通过链接器 ld 获取缓冲区开始位置"></a>通过链接器 ld 获取缓冲区开始位置</h4><p>不过别急，我们先看这一行代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">extern int end;</span><br><span class="line">void buffer_init(long buffer_end) &#123;</span><br><span class="line">    struct buffer_head * start_buffer = (struct buffer_head *) &amp;end;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有个外部变量 <strong>end</strong>，而我们的缓冲区开始位置 <strong>start_buffer</strong> 就等于这个变量的内存地址。</p><p>这个外部变量 end 并不是操作系统代码写就的，而是由<strong>链接器 ld</strong> 在链接整个程序时设置的一个外部变量，帮我们计算好了整个内核代码的末尾地址。</p><p>那在这之前的是内核代码区域肯定不能用，在这之后的，就给 buffer 用了。所以我们的内存分布图可以更精确一点了。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_30.png"></p><p>你看，之前的疑惑解决了吧？很好理解嘛，内核程序和缓冲区的划分，肯定有个分界线，这个分界线就是 end 变量的值。</p><p>这个值定多少合适呢？</p><p>像主内存和缓冲区的分界线，就直接代码里写死了，就是上图中的 2M。</p><p>可是内核程序占多大内存在写的时候完全不知道，就算知道了如果改动一点代码也会变化，所以就由程序编译链接时由链接器程序帮我们把这个内核代码末端的地址计算出来，作为一个外部变量 end 我们拿来即用，就方便多了。</p><h4 id="两个内存管理结构"><a href="#两个内存管理结构" class="headerlink" title="两个内存管理结构"></a>两个内存管理结构</h4><p>好，回过头我们再看看，<strong>整段代码创造了哪两个管理结构</strong>？</p><p>我们先看这段结构。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">void buffer_init(long buffer_end) &#123;</span><br><span class="line">    struct buffer_head * h = start_buffer;</span><br><span class="line">    void * b = (void *) buffer_end;</span><br><span class="line">    while ( (b -= 1024) &gt;= ((void *) (h+1)) ) &#123;</span><br><span class="line">        ...</span><br><span class="line">        h-&gt;b_data = (char *) b;</span><br><span class="line">        h-&gt;b_prev_free = h-1;</span><br><span class="line">        h-&gt;b_next_free = h+1;</span><br><span class="line">        h++;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就俩变量。</p><ul><li>一个是 buffer_head 结构的 h，代表缓冲头，其指针值是 start_buffer，刚刚我们计算过了，就是图中的内核代码末端地址 end，也就是缓冲区开头。</li><li>一个是 b，代表缓冲块，指针值是 buffer_end，也就是图中的 2M，就是缓冲区结尾。</li></ul><p>缓冲区结尾的 b 每次循环 -1024，也就是一页的值，缓冲区结尾的 h 每次循环 +1（一个 buffer_head 大小的内存），直到碰一块为止。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_31.png"></p><p>可以看到，其实这个 b 就代表缓冲块，h 代表缓冲头，一个从上往下，一个从下往上。</p><p>而且这个过程中，h 被附上了属性值，其中比较关键的是这个 buffer 所表示的数据部分 b_data，也就是指向了上面的缓冲块 b。</p><p>还有这个 buffer 的前后空闲 buffer 的指针 b_prev_free 和 b_next_free。</p><p>那画成图就是如下这样。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_32.png"></p><p>当缓冲头 h 的所有 next 和 prev 指针都指向彼此时，就构成了一个双向链表。继续看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void buffer_init(long buffer_end) &#123;</span><br><span class="line">...</span><br><span class="line">free_list = start_buffer;</span><br><span class="line">free_list-&gt;b_prev_free = h;</span><br><span class="line">h-&gt;b_next_free = free_list;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这三行代码，结合刚刚的双向链表 h，我画出图，你就懂了。</p><p><img src="/2022/05/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E6%AD%A5%E4%B9%8B%E5%A4%A7%E6%88%98%E5%89%8D%E6%9C%9F%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E4%BD%9C/img_33.png"></p><p>看，free_list 指向了缓冲头双向链表的第一个结构，然后就可以顺着这个结构，从双向链表中遍历到任何一个缓冲头结构了，而通过缓冲头又可以找到这个缓冲头对应的缓冲块。</p><p>简单说，<strong>缓冲头就是具体缓冲块的管理结构，而 free_list 开头的双向链表又是缓冲头的管理结构</strong>，整个管理体系就这样建立起来了。</p><p>现在，从 free_list 开始遍历，就可以找到这里的所有内容了。</p><h4 id="通过-哈希表-双向链表-进一步优化查询"><a href="#通过-哈希表-双向链表-进一步优化查询" class="headerlink" title="通过 哈希表 + 双向链表 进一步优化查询"></a>通过 哈希表 + 双向链表 进一步优化查询</h4><p>不过，还有最后一个事，能帮助更好管理，往下看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">void buffer_init(long buffer_end) &#123;</span><br><span class="line">    ...</span><br><span class="line">    for (i=0;i&lt;307;i++)</span><br><span class="line">        hash_table[i]=NULL;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个 307 大小的 <strong>hash_table</strong> 数组，这是干嘛的呢？</p><p>其实这段代码在 <strong>buffer.c</strong> 中，而 buffer.c 是在 <strong>fs</strong> 包下的，也就是<strong>文件系统</strong>包下的。所以它今后是为文件系统而服务，具体是内核程序如果需要访问块设备中的数据，就都需要经过缓冲区来间接地操作。</p><p>也就是说，读取块设备的数据（硬盘中的数据），需要先读到缓冲区中，如果缓冲区已有了，就不用从块设备读取了，直接取走。</p><p>那怎么知道缓冲区已经有了要读取的块设备中的数据呢？从双向链表从头遍历当然可以，但是这效率可太低了。所以需要一个 hashmap 的结构方便快速查找，这就是 hash_table 这个数组的作用。</p><p>现在只是初始化这个 hash_table，还并没有哪个地方用到了它，所以我就先简单剧透下。</p><p>之后当要读取某个块设备上的数据时，首先要搜索相应的缓冲块，是下面这个函数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#define _hashfn(dev,block) (((unsigned)(dev^block))%307)</span><br><span class="line">#define hash(dev,block) hash_table[_hashfn(dev,block)]</span><br><span class="line"></span><br><span class="line">// 搜索合适的缓冲块 </span><br><span class="line">struct buffer_head * getblk(int dev,int block) &#123;</span><br><span class="line">    ...</span><br><span class="line">    struct buffer_head bh = get_hash_table(dev,block)；</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct buffer_head * get_hash_table(int dev, int block) &#123;</span><br><span class="line">    ...    </span><br><span class="line">    find_buffer(dev,block);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">static struct buffer_head * find_buffer(int dev, int block) &#123; </span><br><span class="line">    ...     </span><br><span class="line">    hash(dev,block);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一路跟下来发现，就是通过</p><figure class="highlight plaintext"><figcaption><span>% 307``` 即 ```(设备号^逻辑块号) Mod 307``` 找到在 hash_table 里的索引下标，接下来就和 Java 里的 HashMap 类似，如果哈希冲突就形成链表，画成图就是这样。</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![](./操作系统第二步之大战前期的初始化工作/img_34.png)</span><br><span class="line"></span><br><span class="line">**哈希表 + 双向链表**，如果刷算法题多了，很容易想到这可以实现 **LRU 算法**，没错，之后的缓冲区使用和弃用，正是这个算法发挥了作用。</span><br><span class="line"></span><br><span class="line">也就是之后在讲通过文件系统来读取硬盘文件时，都需要使用和弃用这个缓冲区里的内容，缓冲区即是用户进程的内存和硬盘之间的桥梁。</span><br><span class="line"></span><br><span class="line">### 硬盘初始化 - hd_init</span><br><span class="line"></span><br><span class="line">至此，我们只剩下了最后两个初始化函数</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>void main(void) {<br>    …<br>    mem_init(main_memory_start,memory_end);<br>    trap_init();<br>    blk_dev_init();<br>    chr_dev_init();<br>    tty_init();<br>    time_init();<br>    sched_init();<br>    buffer_init(buffer_memory_end);<br>    hd_init(); //本节重点<br>    floppy_init();</p><pre><code>sti();move_to_user_mode();if (!fork()) &#123;init();&#125;for(;;) pause();</code></pre><p>}</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">floppy_init 是软盘初始化，现在软盘几乎都被淘汰了，计算机中也没有软盘驱动器了，所以这个我们完全可以不看。</span><br><span class="line"></span><br><span class="line">我们直接看 hd_init 硬盘初始化干了什么？</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>void hd_init(void) {<br>    blk_dev[3].request_fn = do_hd_request;<br>    set_intr_gate(0x2E,&amp;hd_interrupt);<br>    outb_p(inb_p(0x21)&amp;0xfb,0x21);<br>    outb(inb_p(0xA1)&amp;0xbf,0xA1);<br>}</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">就这？一共就四行代码。</span><br><span class="line"></span><br><span class="line">没错，初始化嘛，往往都比较简单，尤其是对硬件设备的初始化，大体都是：</span><br><span class="line">1. 往某些 IO 端口上读写一些数据，表示开启它；</span><br><span class="line">2. 然后再向中断向量表中添加一个中断，使得 CPU 能够响应这个硬件设备的动作；</span><br><span class="line">3. 最后再初始化一些数据结构来管理。不过像是内存管理可能结构复杂些，外设的管理，相对就简单很多了。</span><br><span class="line"></span><br><span class="line">#### blk_dev[3]</span><br><span class="line"></span><br><span class="line">看第一行代码：</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>void hd_init(void) {<br>    blk_dev[3].request_fn = do_hd_request;<br>    …<br>}</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">我们把 blk_dev 数组索引 3 位置处的块设备管理结构 blk_dev_struct 的 request_fn 赋值为了 do_hd_request，这是啥意思呢？</span><br><span class="line"></span><br><span class="line">因为有很多块设备，所以 Linux 0.11 内核用了一个 blk_dev[] 来进行管理，每一个索引表示一个块设备。</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>struct blk_dev_struct blk_dev[NR_BLK_DEV] = {<br>    { NULL, NULL },     /* no_dev <em>/<br>    { NULL, NULL },     /</em> dev mem <em>/<br>    { NULL, NULL },     /</em> dev fd <em>/<br>    { NULL, NULL },     /</em> dev hd <em>/<br>    { NULL, NULL },     /</em> dev ttyx <em>/<br>    { NULL, NULL },     /</em> dev tty <em>/<br>    { NULL, NULL }      /</em> dev lp */<br>};</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">你看，索引为 3 这个位置，就表示给硬盘 hd 这个块设备留的位置。</span><br><span class="line"></span><br><span class="line">那么每个块设备执行读写请求都有自己的函数实现，在上层看来都是一个统一函数 request_fn 即可，具体实现各有不同，对于硬盘来说，这个实现就是 do_hd_request 函数。</span><br><span class="line"></span><br><span class="line">是不是有点像接口？这其实就是**多态**思想在 C 语言的体现嘛~ 用 Java 程序员熟悉的话就是，父类引用 request_fn 指向子类对象 do_hd_request 的感觉咯。</span><br><span class="line"></span><br><span class="line">#### 设置中断 </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>void hd_init(void) {<br>    …<br>    set_intr_gate(0x2E,&amp;hd_interrupt);<br>    …<br>}</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">对于中断我们已经很熟悉了，这里就是又设置了一个新的中断，中断号是 0x2E，中断处理函数是 hd_interrupt，也就是说硬盘发生读写时，硬盘会发出中断信号给 CPU，之后 CPU 便会陷入中断处理程序，也就是执行 hd_interrupt 函数。</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>_hd_interrupt:<br>    …<br>    xchgl _do_hd,%edx<br>    …</p><p>// 如果是读盘操作，这个 do_hd 是 read_intr<br>static void read_intr(void) {<br>    …<br>    do_hd_request();<br>    …<br>}</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">好了，又多了一个中断，那我们再次梳理下目前开启的中断都有哪些。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">| 中断号 | 中断处理函数           |</span><br><span class="line">| ---- |------------------|</span><br><span class="line">| 0 ~ 0x10 | trap_init 里设置的一堆 |</span><br><span class="line">| 0x20 | timer_interrupt  |</span><br><span class="line">| 0x21 | keyboard_interrupt |</span><br><span class="line">| 0x2E | hd_interrupt |</span><br><span class="line">| 0x80 | system_call | </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>看到最后，你会发现操作系统就是一个靠中断驱动的死循环而已，如果不发生任何中断，操作系统会一直在一个死循环里等待。换句话说，让操作系统工作的唯一方式，就是触发中断。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### 允许硬盘控制器发送中断请求信号</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>void hd_init(void) {<br>    …<br>    outb_p(inb_p(0x21)&amp;0xfb,0x21);<br>    outb(inb_p(0xA1)&amp;0xbf,0xA1);<br>}</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">就是往几个 IO 端口上读写，其作用是**允许硬盘控制器发送中断请求信号**，仅此而已。我们向来是不深入硬件细节，知道往这个端口里写上这些数据，导致硬盘开启了中断，即可。</span><br><span class="line"></span><br><span class="line">#### 拓展</span><br><span class="line"></span><br><span class="line">hd.c 里还有很多读写硬盘的方法，这个在之后文件系统用到他们时，自然会讲起，这里就抛个引子，看看读硬盘最最底层的操作流程，是怎样的。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">| 端口     | 读                        | 写      |</span><br><span class="line">|--------|--------------------------|--------|</span><br><span class="line">| 0x1F0  | 数据寄存器                   | 数据寄存器  |</span><br><span class="line">| 0x1F1  | 错误寄存器                   | 特征寄存器 |</span><br><span class="line">| 0x1F2  | 扇区计数寄存器                 | 扇区计数寄存器 | </span><br><span class="line">| 0x1F3  | 扇区号寄存器或 LBA 块地址 0~7      | 扇区号或 LBA 块地址 0~7 |</span><br><span class="line">| 0x1F4  | 磁道数低 8 位或 LBA 块地址 8~15   | 磁道数低 8 位或 LBA 块地址 8~15 |</span><br><span class="line">| 0x1F5  | 磁道数高 8 位或 LBA 块地址 16~23 | 磁道数高 8 位或 LBA 块地址 16~23 |</span><br><span class="line">| 0x1F6  | 驱动器/磁头或 LBA 块地址 24~27    | 驱动器/磁头或 LBA 块地址 24~27 |</span><br><span class="line">| 0x1F7  | 命令寄存器或状态寄存器              | 命令寄存器 |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">那读硬盘就是，往除了第一个以外的后面几个端口写数据，告诉要读硬盘的哪个扇区，读多少。然后再从 0x1F0 端口一个字节一个字节的读数据。这就完成了一次硬盘读操作。</span><br><span class="line"></span><br><span class="line">如果觉得不够具体，那来个具体的版本。</span><br><span class="line"></span><br><span class="line">1. 在 0x1F2 写入要读取的扇区数</span><br><span class="line">2. 在 0x1F3 ~ 0x1F6 这四个端口写入计算好的起始 LBA 地址</span><br><span class="line">3. 在 0x1F7 处写入读命令的指令号</span><br><span class="line">4. 不断检测 0x1F7 （此时已成为状态寄存器的含义）的忙位</span><br><span class="line">5. 如果第四步骤为不忙，则开始不断从 0x1F0 处读取数据到内存指定位置，直到读完</span><br><span class="line"></span><br><span class="line">而操作系统的代码，也是这样写的，我们一睹为快一下，不用理解细节。</span><br></pre></td></tr></table></figure><p>static void hd_out(unsigned int drive,unsigned int nsect,unsigned int sect,<br>        unsigned int head,unsigned int cyl,unsigned int cmd,<br>        void (*intr_addr)(void)) {<br>    …<br>    do_hd = intr_addr;<br>    outb_p(hd_info[drive].ctl,HD_CMD);<br>    port = 0x1f0;<br>    outb_p(hd_info[drive].wpcom&gt;&gt;2,++port);<br>    outb_p(nsect,++port);<br>    outb_p(sect,++port);<br>    outb_p(cyl,++port);<br>    outb_p(cyl&gt;&gt;8,++port);<br>    outb_p(0xA0|(drive&lt;&lt;4)|head,++port);<br>    outb(cmd,++port);<br>}</p><pre><code>看，那些 outb_p 方法，转换成汇编语言，就是 out 指令，往指定的硬盘 IO 端口上写数据，达到我们想要的读或者写的目的。是不是很 low？但我们由用户层写的各种 read\write 函数，即便是经过系统调用、文件系统、缓冲区管理等等过程，但只要是读写硬盘，最终都要调用到这个最底层的函数，殊途同归，逃不掉的！### 总结[大战前期的初始化工作](https://mp.weixin.qq.com/s/Hf9B1ww1wFxiUDkWb0obeQ)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统第一步之进入内核前的苦力活</title>
      <link href="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/"/>
      <url>/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/</url>
      
        <content type="html"><![CDATA[<p>本系列转自<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0MjE3NDE0Ng==&action=getalbum&album_id=2123743679373688834&scene=173&from_msgid=2247499734&from_itemidx=1&count=3&nolastread=1#wechat_redirect">操作系统源码系列</a></p><p>会以一个读小说的心态，从开机启动后的代码执行顺序，阅读和赏析 Linux 0.11 全部核心代码，了解操作系统的技术细节和设计思想。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_0.png"></p><h3 id="最开始的两行代码-加载启动区"><a href="#最开始的两行代码-加载启动区" class="headerlink" title="最开始的两行代码-加载启动区"></a>最开始的两行代码-加载启动区</h3><p>在<a href="#">Post not found: 操作系统/操作系统第一步之按下开机键</a> 一文中， 我们简单介绍了操作系统启动区加载的过程，回顾一下：</p><ul><li>按下开机键，CPU 将 PC 寄存器的值强制初始化为 0xffff0，这个位置是 BIOS 程序的入口地址（一跳）</li><li>该入口地址处是一个跳转指令，跳转到 0xfe05b 位置，开始执行（二跳）</li><li>执行了一些硬件检测工作后，最后一步将启动区内容加载到内存 0x7c00，并跳转到这里（三跳）</li><li>启动区代码主要是加载操作系统内核，并跳转到加载处（四跳）</li></ul><p>当你按下开机键的那一刻，在主板上提前写死的固件程序 BIOS 会将硬盘中启动区的 512 字节的数据，原封不动复制到内存中的 0x7c00 这个位置，并跳转到那个位置进行执行。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img.png"></p><p>启动区的定义非常简单，只要硬盘中的 0 盘 0 道 1 扇区的 512 个字节的最后两个字节分别是 0x55 和 0xaa，那么 BIOS 就会认为它是个启动区。</p><p>所以对于我们理解操作系统而言，此时的 BIOS 仅仅就是个代码搬运工，把 512 字节的二进制数据从硬盘搬运到了内存中而已。</p><p><strong>所以作为操作系统的开发人员，仅仅需要把操作系统最开始的那段代码，编译并存储在硬盘的 0 盘 0 道 1 扇区即可</strong>。</p><p>之后 BIOS 会帮我们把它放到内存里，并且跳过去执行。</p><p>而 Linux-0.11 的最开始的代码，就是这个用汇编语言写的 bootsect.s，位于 boot 文件夹下。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_1.png"></p><p>通过编译，这个 bootsect.s 会被编译成二进制文件，存放在启动区的第一扇区。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_2.png"></p><p>随后就会如刚刚所说，由 BIOS 搬运到内存的 0x7c00 这个位置，而 CPU 也会从这个位置开始，不断往后一条一条语句无脑地执行下去。</p><p>那我们的梦幻之旅，就从这个文件的第一行代码开始啦！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mov ax,0x07c0</span><br><span class="line">mov ds,ax</span><br></pre></td></tr></table></figure><p>这段代码是用汇编语言写的，含义是<strong>把 0x07c0 这个值复制到 ax 寄存器里，再将 ax 寄存器里的值复制到 ds 寄存器</strong>里。</p><details><summary>立即数不能直接赋给段寄存器</summary><p>因为CPU的设计里面一次指令只能读写内存一次的流程设计。</p><p>立即数直接赋值给段寄存器的话，相当于读一次内存，一次内存流程了，再写一次内存，二次内存流程了。</p></details><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_3.png"></p><p>那其实这一番折腾的结果就是:</p><details><summary>让 ds 这个寄存器里的值变成了 0x07c0</summary><p>ds 是一个 16 位的段寄存器，具体表示数据段寄存器，在内存寻址时充当段基址的作用。</p><p>啥意思呢？就是当我们之后用汇编语言写一个内存地址时，实际上仅仅是写了偏移地址，比如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mov ax, [0x0001]</span><br></pre></td></tr></table></figure><p>实际上相当于</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mov ax, [ds:0x0001]</span><br></pre></td></tr></table></figure><p>ds 是默认加上的，表示在 ds 这个段基址处，往后再偏移 0x0001 单位，将这个位置的内存数据，复制到 ax 寄存器中。</p><p>这个 ds 被赋值为了 0x07c0，由于 x86 为了让自己在 16 位这个实模式下能访问到 20 位的地址线这个历史因素（不了解这个的就先别纠结为啥了），所以段基址要先左移四位。</p><p>那 0x07c0 左移四位就是 0x7c00，那这就刚好和这段代码被 BIOS 加载到的内存地址 0x7c00 一样了。</p></details><p>也就是说，之后再写的代码，里面访问的数据的内存地址，都先默认加上 0x7c00，再去内存中寻址。</p><p>为啥统一加上 0x7c00 这个数呢？这很好解释，BIOS 规定死了把操作系统代码加载到内存 0x7c00，那么里面的各种数据自然就全都被偏移了这么多，所以把数据段寄存器 ds<br>设置为这个值，方便了以后通过这种基址的方式访问内存里的数据。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_4.png"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>BIOS 将操作系统代码（启动区）加载到内存 0x7c00，然后通过 mov 指令将默认的数据段寄存器（ds 寄存器）的值改为 0x07c0 方便以后的基址寻址方式。</p><h3 id="自己给自己挪个地儿-移动启动区代码段"><a href="#自己给自己挪个地儿-移动启动区代码段" class="headerlink" title="自己给自己挪个地儿-移动启动区代码段"></a>自己给自己挪个地儿-移动启动区代码段</h3><h4 id="寄存器赋值"><a href="#寄存器赋值" class="headerlink" title="寄存器赋值"></a>寄存器赋值</h4><p>接下来我们带着这两行代码，继续往下看几行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mov ax,0x07c0</span><br><span class="line">mov ds,ax</span><br><span class="line">mov ax,0x9000</span><br><span class="line">mov es,ax</span><br><span class="line">mov cx,#256</span><br><span class="line">sub si,si</span><br><span class="line">sub di,di</span><br><span class="line">rep movw</span><br></pre></td></tr></table></figure><p>此时 ds 寄存器的值已经是 0x07c0 了，然后又通过同样的方式将 es 寄存器的值变成 0x9000，接着又把 cx 寄存器的值变成<br>256（代码里确实是用十进制表示的，与其他地方有些不一致，不过无所谓）。</p><figure class="highlight plaintext"><figcaption><span>si,si```表示```si</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">经过这些指令后，以下几个寄存器分别被附上了指定的值，我们梳理一下</span><br><span class="line"></span><br><span class="line">* 数据段寄存器： ds = 0x07c0</span><br><span class="line">* 附加段寄存器： es = 0x9000</span><br><span class="line">* 普通寄存器： cx = 256</span><br><span class="line">* 源变址： si = 0</span><br><span class="line">* 目的变址： di = 0</span><br><span class="line"></span><br><span class="line">![](./操作系统第一步之进入内核前的苦力活/img_5.png)</span><br><span class="line"></span><br><span class="line">#### 复制启动区</span><br><span class="line"></span><br><span class="line">干嘛要给这些毫不相干的寄存器附上值呢？其实就是为下一条指令服务的，就是</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>rep movw</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">其中 **rep 表示重复执行后面的指令**。</span><br><span class="line"></span><br><span class="line">而后面的指令 **movw 表示复制一个字**（word 16位），那其实就是不断重复地复制一个字。</span><br><span class="line"></span><br><span class="line">那下面自然就有三连问：</span><br><span class="line"></span><br><span class="line">**重复执行多少次呢？** 是 cx 寄存器中的值，也就是 256 次。</span><br><span class="line"></span><br><span class="line">**从哪复制到哪呢？** 是从 ds:si 处复制到 es:di 处。</span><br><span class="line"></span><br><span class="line">**一次复制多少呢？** 刚刚说过了，复制一个字，16 位，也就是两个字节。</span><br><span class="line"></span><br><span class="line">上面是直译，那把这段话翻译成更人话的方式讲出来就是，**将内存地址 0x7c00 处开始往后的 512 字节的数据，原封不动复制到 0x90000 处**。</span><br><span class="line"></span><br><span class="line">![](./操作系统第一步之进入内核前的苦力活/img_6.png)</span><br><span class="line"></span><br><span class="line">没错，就是这么折腾了一下。现在，操作系统最开头的代码，已经被挪到了 **0x90000** 这个位置了。</span><br><span class="line"></span><br><span class="line">#### 跳转到新的地址</span><br><span class="line"></span><br><span class="line">再往后是一个**跳转**指令。</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">jmpi go,0x9000</span><br><span class="line">go: </span><br><span class="line">  mov ax,cs</span><br><span class="line">  mov ds,ax</span><br></pre></td></tr></table></figure><p><strong>jmpi 是一个段间跳转指令，表示跳转到 0x9000:go 处执行</strong>。</p><p>还记得上一讲说的 <strong>段基址 : 偏移地址</strong> 这种格式的内存地址要如何计算吧？段基址仍然要先左移四位，因此结论就是跳转到 <strong>0x90000 + go</strong> 这个内存地址处执行。</p><p>再说 go，go 就是一个<strong>标签</strong>，最终编译成机器码的时候会被翻译成一个值，这个值就是 go 这个<strong>标签在文件内的偏移地址</strong>。</p><p>这个偏移地址再加上 0x90000，就刚好是 go 标签后面那段代码 <code>mov ax,cs</code> 此时所在的内存地址了。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_7.png"></p><p>那假如 mov ax,cx 这行代码位于最终编译好后的二进制文件的 0x08 处，那 go 就等于 0x08，而最终 CPU 跳转到的地址就是 0x90008 处。</p><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>到此为止，其实就是<strong>一段 512 字节的代码和数据，从硬盘的启动区先是被移动到了内存 0x7c00 处，然后又立刻被移动到 0x90000 处，并且跳转到此处往后再稍稍偏移 go<br>这个标签所代表的偏移地址处</strong>，也就是 mov ax,cs 这行指令的位置。</p><h3 id="做好最最基础的准备工作-内存规划"><a href="#做好最最基础的准备工作-内存规划" class="headerlink" title="做好最最基础的准备工作-内存规划"></a>做好最最基础的准备工作-内存规划</h3><h4 id="寄存器赋值-1"><a href="#寄存器赋值-1" class="headerlink" title="寄存器赋值"></a>寄存器赋值</h4><p>操作系统的代码最开头的 512 字节的数据，从硬盘的启动区先是被移动到了内存 0x7c00 处，然后又立刻被移动到 0x90000 处，并且跳转到此处往后再稍稍偏移 go 这个标签所代表的偏移地址处。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_8.png"></p><p>那我们接下来，就继续把我们的目光放在 go 这个标签的位置，跟着 CPU 的步伐往后看。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">go: mov ax,cs</span><br><span class="line">    mov ds,ax</span><br><span class="line">    mov es,ax</span><br><span class="line">    mov ss,ax</span><br><span class="line">    mov sp,#0xFF00</span><br></pre></td></tr></table></figure><p>这段代码的直接意思很容易理解，就是</p><ul><li>cs 寄存器的值分别复制给 ds、es 和 ss 寄存器，</li><li>把 0xFF00 给了 sp 寄存器。</li></ul><details><summary>CPU寄存器图</summary><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_9.png"></p></details><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cs 寄存器表示代码段寄存器，CPU 当前正在执行的代码在内存中的位置，就是由 cs:ip 这组寄存器配合指向的，其中 cs 是基址，ip 是偏移地址。</span><br></pre></td></tr></table></figure><ul><li><p>之前执行过一个段间跳转指令<code>jmpi go,0x9000</code>, 所以现在<strong>cs寄存器里的值就是0x9000，ip 寄存器里的值是 go 这个标签的偏移地址</strong>。</p></li><li><p>ds 为数据段寄存器，之前我们说过了，当时它被复制为 0x07c0，是因为之前的代码在 0x7c00 处，现在代码已经被挪到了 0x90000 处，所以现在自然又改赋值为 0x9000 了。</p></li><li><p>es 是扩展段寄存器，仅仅是个扩展，不是主角，先不用理它。</p></li><li><p>ss 为<strong>栈段寄存器</strong>，后面要配合栈基址寄存器 sp 来表示此时的栈顶地址。而此时 sp 寄存器被赋值为了 0xFF00 了，所以<strong>目前的栈顶地址就是 ss:sp 所指向的地址<br>0x9FF00 处</strong>。<br><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/_posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_11.png" alt="实模式下的内存分布图"></p><ul><li>回顾一下实模式下的内存分布图，栈顶位置被赋值为了0x9FF00，几乎是基本内存距离代码段最远的位置，所以栈向下发展就很难撞见代码，也就比较安全。<br><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_10.png"></li><li>这也是为什么给栈顶地址设置为这个值的原因，其实只需要离代码的位置远远的即可。</li></ul></li></ul><h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><p>其实到这里，操作系统的一些最最最最基础的准备工作，就做好了。都做了些啥事呢？</p><ol><li>代码从硬盘移到内存，又从内存挪了个地方，放在了 0x90000 处</li><li>数据段寄存器 ds 和代码段寄存器 cs 此时都被设置为了 0x9000，也就为跳转代码和访问内存数据，奠定了同一个内存的基址地址，方便了跳转和内存访问，因为仅仅需要指定偏移地址即可了。</li><li>栈顶地址被设置为了 0x9FF00，具体表现为栈段寄存器 ss 为 0x9000，栈基址寄存器 sp 为 0xFF00。栈是向下发展的，这个栈顶地址 0x9FF00 要远远大于此时代码所在的位置<br>0x90000，也就比较安全。</li></ol><p>拔高一下，这一部分其实就是把<strong>代码段寄存器 cs，数据段寄存器 ds，栈段寄存器 ss 和栈基址寄存器 sp</strong> 分别设置好了值，方便后续使用。</p><p>再拔高一下，其实操作系统在做的事情，就是给如何访问代码，如何访问数据，如何访问栈进行了一下<strong>内存的初步规划</strong>。其中访问代码和访问数据的规划方式就是设置了一个<strong>基址</strong>而已，访问栈就是把**<br>栈顶指针**指向了一个远离代码位置的地方而已。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_12.png"></p><h4 id="扩展阅读-三种段寄存器的作用"><a href="#扩展阅读-三种段寄存器的作用" class="headerlink" title="扩展阅读-三种段寄存器的作用"></a>扩展阅读-三种段寄存器的作用</h4><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_13.png"></p><ul><li>CS 是代码段寄存器，就是执行代码的时候带着这里存的基地址。</li><li>DS 是数据段寄存器，就是访问数据的时候带着这里的基地址。</li><li>SS 是栈段寄存器，就是访问栈时带着这里的基地址。</li></ul><h3 id="把自己在硬盘里的其他部分也放到内存来"><a href="#把自己在硬盘里的其他部分也放到内存来" class="headerlink" title="把自己在硬盘里的其他部分也放到内存来"></a>把自己在硬盘里的其他部分也放到内存来</h3><p>至此，短短几句代码，操作系统已经完成了最最基础的准备工作，也即初步做了一次内存规划， 从 CPU 的角度看，访问内存其实也就是三块地方而已</p><ul><li>数据段</li><li>代码段</li><li>栈</li></ul><p>内存规划中：</p><ul><li>将数据段寄存器 ds 和代码段寄存器 cs 设置为了 0x9000，方便代码的跳转与数据的访问。</li><li>将栈顶地址 ss:sp 设置在了离代码的位置 0x90000 足够遥远的 0x9FF00，保证栈向下发展不会轻易撞见代码的位置。</li></ul><h4 id="读取操作系统的全部代码"><a href="#读取操作系统的全部代码" class="headerlink" title="读取操作系统的全部代码"></a>读取操作系统的全部代码</h4><p>做好这些基础工作后，接下来就又该新的一翻折腾了，我们接着往下看。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">load_setup:</span><br><span class="line">mov dx,#0x0000      ; drive 0, head 0</span><br><span class="line">mov cx,#0x0002      ; sector 2, track 0</span><br><span class="line">mov bx,#0x0200      ; address = 512, in 0x9000</span><br><span class="line">mov ax,#0x0200+4    ; service 2, nr of sectors</span><br><span class="line">int 0x13            ; read it</span><br><span class="line">jnc ok_load_setup       ; ok - continue</span><br><span class="line">mov dx,#0x0000</span><br><span class="line">mov ax,#0x0000      ; reset the diskette</span><br><span class="line">int 0x13</span><br><span class="line">jmp load_setup</span><br><span class="line"></span><br><span class="line">ok_load_setup:</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这里有两个 int<br>指令我们还没见过，<a href="https://mp.weixin.qq.com/s?__biz=Mzk0MjE3NDE0Ng==&mid=2247498208&idx=1&sn=b784f8b4e627ebd1bfb9810d194fdb80&chksm=c2c5834df5b20a5bdee331002bfc61c90eb468da325bf67abeef780c303a9f51c8543e1a5981&scene=21#wechat_redirect">这个 int 是汇编指令，可不是高级语言的整型变量哟</a></p><p>int 0x13 表示<strong>发起 0x13 号中断</strong>，这条指令上面给 dx、cx、bx、ax 赋值都是作为这个中断程序的参数。</p><p>这个中断发起后，CPU 会<strong>通过这个中断号，去寻找对应的中断处理程序的入口地址，并跳转过去执行</strong>，逻辑上就相当于执行了一个函数。</p><p>而 0x13 号中断的处理程序是 BIOS 提前给我们写好的，是<strong>读取磁盘</strong>的相关功能的函数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">之后真正进入操作系统内核后，中断处理程序是需要我们自己去重新写的</span><br></pre></td></tr></table></figure><p>本段代码的注释已经写的很明确了，直接说最终的作用吧，就是<strong>将硬盘的第 2 个扇区开始，把数据加载到内存 0x90200 处，共加载 4 个扇区</strong>，图示其实就是这样。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_14.png"></p><p>如果复制成功，就跳转到 ok_load_setup 这个标签，如果失败，则会不断重复执行这段代码，也就是重试。</p><p>直接看成功后跳转的 ok_load_setup 这个标签后的代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ok_load_setup:</span><br><span class="line">    ...</span><br><span class="line">    mov ax,#0x1000</span><br><span class="line">    mov es,ax       ; segment of 0x10000</span><br><span class="line">    call read_it</span><br><span class="line">    ...</span><br><span class="line">    jmpi 0,0x9020</span><br></pre></td></tr></table></figure><p>这段代码省略了很多非主逻辑的代码，比如在屏幕上输出 Loading system … 这个字符串等。</p><p>剩下的主要代码就都写在这里了，就这么几行，其作用是<strong>把从硬盘第 6 个扇区开始往后的 240 个扇区，加载到内存 0x10000 处</strong>，和之前的从硬盘捣腾到内存是一个道理。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_15.png"></p><p>至此，整个操作系统的<strong>全部代码</strong>，就已经全部从硬盘中，被搬迁到内存来了。</p><p>然后又通过一个熟悉的段间跳转指令 jmpi 0,0x9020，跳转到 <strong>0x90200</strong> 处，就是硬盘第二个扇区开始处的内容。</p><h4 id="整个操作系统的编译过程"><a href="#整个操作系统的编译过程" class="headerlink" title="整个操作系统的编译过程"></a>整个操作系统的编译过程</h4><p>在分析硬盘第二个分区前，我们先简单看下炒作系统整个编译过程，就是通过 Makefile 和 build.c 配合完成的，最终会：</p><ol><li>把 bootsect.s 编译成 bootsect 放在硬盘的 1 扇区。</li><li>把 setup.s 编译成 setup 放在硬盘的 2~5 扇区。</li><li>把剩下的全部代码（head.s 作为开头）编译成 system 放在硬盘的随后 240 个扇区。</li></ol><p>所以整个路径就是这样的：</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_16.png"></p><p>所以，我们即将跳转到的内存中的 0x90200 处的代码，就是从硬盘第二个扇区开始处加载到内存的。</p><p>第二个扇区的最开始处，那也就是 setup.s 文件的第一行代码咯。</p><p>在<strong>操作系统刚刚开始建立的时候，那是完全自己安排前前后后的关系</strong><br>，一个字节都不能偏，就是这么强耦合，需要小心翼翼，需要大脑时刻保持清醒，规划好自己写的代码被编译并存储在硬盘的哪个位置，而随后又会被加载到内存的哪个位置，不能错乱。</p><h3 id="Setup加载-进入保护模式前的内存重规划"><a href="#Setup加载-进入保护模式前的内存重规划" class="headerlink" title="Setup加载-进入保护模式前的内存重规划"></a>Setup加载-进入保护模式前的内存重规划</h3><p>至此，操作系统已经完成了各种从硬盘到内存的加载，以及内存到内存的复制， 整个 bootsect.s 的使命就完成了，也是我们品读完的第一个操作系统源码文件。</p><h4 id="内存、硬盘、显卡等临时数据覆盖bootsect内容"><a href="#内存、硬盘、显卡等临时数据覆盖bootsect内容" class="headerlink" title="内存、硬盘、显卡等临时数据覆盖bootsect内容"></a>内存、硬盘、显卡等临时数据覆盖bootsect内容</h4><p>之后便跳转到了 0x90200 这个位置开始执行，这个位置处的代码就是位于 setup.s 的开头，我们接着来看。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">start:</span><br><span class="line">    mov ax,#0x9000  ; this is done in bootsect already, but...</span><br><span class="line">    mov ds,ax</span><br><span class="line">    mov ah,#0x03    ; read cursor pos</span><br><span class="line">    xor bh,bh</span><br><span class="line">    int 0x10        ; save it in known place, con_init fetches</span><br><span class="line">    mov [0],dx      ; it from 0x90000.</span><br></pre></td></tr></table></figure><p>又有个 int 0x10 指令, 它也是触发 BIOS 提供的<strong>显示服务中断</strong>处理程序，而 <strong>ah</strong> 寄存器被赋值为 0x03 表示显示服务里具体的<strong>读取光标位置功能</strong></p><p>这个 int 0x10 中断程序执行完毕并返回时，<strong>dx 寄存器里的值表示光标的位置</strong>，具体说来其高八位 dh 存储了行号，低八位 dl 存储了列号。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_17.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">计算机在加电自检后会自动初始化到文字模式，在这种模式下，一屏幕可以显示 25 行，每行 80 个字符，也就是 80 列。</span><br></pre></td></tr></table></figure><p>那下一步 mov [0],dx 就是把这个光标位置存储在 [0] 这个内存地址处。</p><p>注意，前面我们说过，这个内存地址仅仅是偏移地址，还需要加上 ds 这个寄存器里存储的段基址，最终的内存地址是在 0x90000 处，这里存放着光标的位置，以便之后在初始化控制台的时候用到。</p><p>所以从这里也可以看出，这和我们平时调用一个方法没什么区别，只不过这里的寄存器的用法相当于入参和返回值，这里的 0x10 中断号相当于方法名。</p><details><summary>再接下来的几行代码，也是调用一个 BIOS 中断获取点什么信息，然后存储在内存中某个位置</summary><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">比如获取内存信息。</span><br><span class="line">; Get memory size (extended mem, kB)</span><br><span class="line">    mov ah,#0x88</span><br><span class="line">    int 0x15</span><br><span class="line">    mov [2],ax</span><br><span class="line">获取显卡显示模式。</span><br><span class="line">; Get video-card data:</span><br><span class="line">    mov ah,#0x0f</span><br><span class="line">    int 0x10</span><br><span class="line">    mov [4],bx      ; bh = display page</span><br><span class="line">    mov [6],ax      ; al = video mode, ah = window width</span><br><span class="line">检查显示方式并取参数</span><br><span class="line">; check for EGA/VGA and some config parameters</span><br><span class="line">    mov ah,#0x12</span><br><span class="line">    mov bl,#0x10</span><br><span class="line">    int 0x10</span><br><span class="line">    mov [8],ax</span><br><span class="line">    mov [10],bx</span><br><span class="line">    mov [12],cx</span><br><span class="line">获取第一块硬盘的信息。</span><br><span class="line">; Get hd0 data</span><br><span class="line">    mov ax,#0x0000</span><br><span class="line">    mov ds,ax</span><br><span class="line">    lds si,[4*0x41]</span><br><span class="line">    mov ax,#INITSEG</span><br><span class="line">    mov es,ax</span><br><span class="line">    mov di,#0x0080</span><br><span class="line">    mov cx,#0x10</span><br><span class="line">    rep</span><br><span class="line">    movsb</span><br><span class="line">获取第二块硬盘的信息。</span><br><span class="line">; Get hd1 data</span><br><span class="line">    mov ax,#0x0000</span><br><span class="line">    mov ds,ax</span><br><span class="line">    lds si,[4*0x46]</span><br><span class="line">    mov ax,#INITSEG</span><br><span class="line">    mov es,ax</span><br><span class="line">    mov di,#0x0090</span><br><span class="line">    mov cx,#0x10</span><br><span class="line">    rep</span><br><span class="line">    movsb</span><br></pre></td></tr></table></figure></details><p>我们就没必要细琢磨了，对操作系统的理解作用不大，只需要知道最终存储在内存中的信息是什么，在什么位置，就好了，之后会用到他们的</p><table><thead><tr><th>内存地址</th><th>长度(字节)</th><th>名称</th></tr></thead><tbody><tr><td>0x90000</td><td>2</td><td>光标位置</td></tr><tr><td>0x90002</td><td>2</td><td>扩展内存数</td></tr><tr><td>0x90004</td><td>2</td><td>显示页面</td></tr><tr><td>0x90006</td><td>1</td><td>显示模式</td></tr><tr><td>0x90007</td><td>1</td><td>字符列数</td></tr><tr><td>0x90008</td><td>2</td><td>未知</td></tr><tr><td>0x9000A</td><td>1</td><td>显示内存</td></tr><tr><td>0x9000B</td><td>1</td><td>显示状态</td></tr><tr><td>0x9000C</td><td>2</td><td>显卡特性参数</td></tr><tr><td>0x9000E</td><td>1</td><td>屏幕行数</td></tr><tr><td>0x9000F</td><td>1</td><td>屏幕列数</td></tr><tr><td>0x90080</td><td>16</td><td>硬盘1参数表</td></tr><tr><td>0x90090</td><td>16</td><td>硬盘2参数表</td></tr><tr><td>0x901FC</td><td>2</td><td>根设备号</td></tr></tbody></table><p>由于之后很快就会用 c 语言进行编程，虽然汇编和 c 语言也可以用变量的形式进行传递数据，但这需要编译器在链接时做一些额外的工作，所以这么多数据更方便的还是<strong>双方共同约定一个内存地址</strong><br>，我往这里存，你从这里取，就完事了。这恐怕是最最原始和直观的变量传递的方式了。</p><h4 id="关闭中断"><a href="#关闭中断" class="headerlink" title="关闭中断"></a>关闭中断</h4><p>把这些信息存储好之后，操作系统又要做什么呢？我们继续往下看。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cli         ; no interrupts allowed ;</span><br></pre></td></tr></table></figure><p>就一行 cli，表示关闭中断的意思。</p><p>因为后面我们要把原本是 BIOS 写好的中断向量表给覆盖掉，也就是给破坏掉了，写上我们自己的中断向量表，所以这个时候是不允许中断进来的。</p><h4 id="System模块移动"><a href="#System模块移动" class="headerlink" title="System模块移动"></a>System模块移动</h4><p>继续看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">; first we move the system to it&#x27;s rightful place</span><br><span class="line">    mov ax,#0x0000</span><br><span class="line">    cld         ; &#x27;direction&#x27;=0, movs moves forward</span><br><span class="line">do_move:</span><br><span class="line">    mov es,ax       ; destination segment</span><br><span class="line">    add ax,#0x1000</span><br><span class="line">    cmp ax,#0x9000</span><br><span class="line">    jz  end_move</span><br><span class="line">    mov ds,ax       ; source segment</span><br><span class="line">    sub di,di</span><br><span class="line">    sub si,si</span><br><span class="line">    mov cx,#0x8000</span><br><span class="line">    rep movsw</span><br><span class="line">    jmp do_move</span><br><span class="line">; then we load the segment descriptors</span><br><span class="line">end_move:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>看到后面那个 rep movsw 熟不熟悉, 同前面的原理一样，也是做了个内存复制操作，最终的结果是，把内存地址 0x10000 处开始往后一直到 0x90000 的内容，统统复制到内存的最开始的 0<br>位置，大概就是这么个效果。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_18.png"></p><h4 id="Setup加载总结-新的内存布局"><a href="#Setup加载总结-新的内存布局" class="headerlink" title="Setup加载总结-新的内存布局"></a>Setup加载总结-新的内存布局</h4><p>由于之前的各种加载和复制，导致内存看起来很乱，是时候进行一波取舍和整理了，我们重新梳理一下此时的内存布局。</p><ul><li>栈顶地址仍然是 0x9FF00 没有改变。</li><li>0x90000 开始往上的位置，原来是 bootsect 和 setup 程序的代码，现 bootsect 的一部分代码在已经被操作系统为了记录内存、硬盘、显卡等一些临时存放的数据给覆盖了一部分。</li><li>内存最开始的 <strong>0 到 0x80000 这 512K 被 system 模块给占用</strong>了，之前讲过，这个 system 模块就是除了 bootsect 和 setup<br>之外的全部程序链接在一起的结果，可以理解为<strong>操作系统的全部</strong>。</li></ul><p>那么现在的内存布局就是这个样子。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_19.png"></p><p>好了，记住上面的图就好了，这回是不是又重新清晰起来了？<strong>之前的什么 0x7c00，已经是过去式了</strong>，赶紧忘掉它，向前看！</p><p>接下来，就要进行有点技术含量的工作了，那就是<strong>模式的转换</strong>，需要<strong>从现在的 16 位的实模式转变为之后 32 位的保护模式</strong>，这是一项大工程！</p><h3 id="先解决段寄存器的历史包袱问题-进入保护模式前的新寻址方式准备"><a href="#先解决段寄存器的历史包袱问题-进入保护模式前的新寻址方式准备" class="headerlink" title="先解决段寄存器的历史包袱问题-进入保护模式前的新寻址方式准备"></a>先解决段寄存器的历史包袱问题-进入保护模式前的新寻址方式准备</h3><h4 id="当前内存地址回顾"><a href="#当前内存地址回顾" class="headerlink" title="当前内存地址回顾"></a>当前内存地址回顾</h4><p>经过Setup模块执行，操作系统内存被重新划分，并且之后的很长一段时间内存布局相对稳定，目前它长这样：</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_20.png"></p><p>0 地址开始处存放着操作系统的全部代码吗，也就是 system 模块，0x90000 位置处往后的几十个字节存放着一些设备的信息，方便以后使用。</p><table><thead><tr><th>内存地址</th><th>长度(字节)</th><th>名称</th></tr></thead><tbody><tr><td>0x90000</td><td>2</td><td>光标位置</td></tr><tr><td>0x90002</td><td>2</td><td>扩展内存数</td></tr><tr><td>0x90004</td><td>2</td><td>显示页面</td></tr><tr><td>0x90006</td><td>1</td><td>显示模式</td></tr><tr><td>0x90007</td><td>1</td><td>字符列数</td></tr><tr><td>0x90008</td><td>2</td><td>未知</td></tr><tr><td>0x9000A</td><td>1</td><td>显示内存</td></tr><tr><td>0x9000B</td><td>1</td><td>显示状态</td></tr><tr><td>0x9000C</td><td>2</td><td>显卡特性参数</td></tr><tr><td>0x9000E</td><td>1</td><td>屏幕行数</td></tr><tr><td>0x9000F</td><td>1</td><td>屏幕列数</td></tr><tr><td>0x90080</td><td>16</td><td>硬盘1参数表</td></tr><tr><td>0x90090</td><td>16</td><td>硬盘2参数表</td></tr><tr><td>0x901FC</td><td>2</td><td>根设备号</td></tr></tbody></table><p>是不是十分清晰？不过别高兴得太早，清爽的内存布局，是方便后续操作系统的大显身手！</p><p>接下来就要进行真正的第一项大工程了，那就是模式的转换，需要从现在的 16 位的实模式转变为之后 32 位的保护模式。</p><h4 id="保护模式下的物理地址"><a href="#保护模式下的物理地址" class="headerlink" title="保护模式下的物理地址"></a>保护模式下的物理地址</h4><p>每次讲这里都十分的麻烦，因为这是 <strong>x86 的历史包袱</strong>问题，现在的 CPU 几乎都是支持 32 位模式甚至 64 位模式了，很少有还仅仅停留在 16 位的实模式下的 CPU。</p><p>所以我们要<strong>为了这个历史包袱，写一段模式转换的代码</strong>，如果 Intel CPU 被重新设计而不用考虑兼容性，那么今天的代码将会减少很多甚至不复存在。</p><p>关于实模式和保护模式的区别，可以参考文档<a href="https://zhuanlan.zhihu.com/p/352843177">实模式和保护模式区别及寻址方式</a></p><p>继续看 setup.s 文件中的代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lidt  idt_48      ; load idt with 0,0</span><br><span class="line">lgdt  gdt_48      ; load gdt with whatever appropriate</span><br><span class="line"></span><br><span class="line">idt_48:</span><br><span class="line">    .word   0     ; idt limit=0</span><br><span class="line">    .word   0,0   ; idt base=0L</span><br></pre></td></tr></table></figure><p>上来就是两行看不懂的指令，要理解这两条指令，就涉及到实模式和保护模式的第一个区别了。</p><p>目前，我们还处于实模式下，这个模式的CPU计算物理地址的方式为： <strong>段基址左移四位，再加上偏移地址</strong>。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_21.png"></p><p>当 CPU 切换到保护模式后，同样的代码，内存地址的计算方式还<strong>不一样</strong>。</p><p>刚刚那个 ds 寄存器里存储的值，在实模式下叫做<strong>段基址</strong>，在保护模式下叫<strong>段选择子</strong>。</p><p><strong>段选择子里存储着段描述符的索引</strong>。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_22.png"></p><p>通过段描述符索引，可以从 <strong>全局描述符表 gdt</strong> 中找到一个段描述符，段描述符里存储着段基址。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_23.png"></p><p>段基址取出来，再和偏移地址相加，就得到了物理地址，整个过程如下。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_24.png"></p><p>总结一下就是： <strong>段寄存器（比如 ds、ss、cs）里存储的是段选择子，段选择子去全局描述符表中寻找段描述符，从中取出段基址</strong>。</p><h4 id="全局描述符gdt-amp-gdtr-寄存器"><a href="#全局描述符gdt-amp-gdtr-寄存器" class="headerlink" title="全局描述符gdt &amp; gdtr 寄存器"></a>全局描述符gdt &amp; gdtr 寄存器</h4><p>那问题自然就出来了，全局描述符表（gdt）长什么样？它在哪？怎么让 CPU 知道它在哪？</p><p>先说说它在哪？ 在内存中呗。</p><p>那么怎么告诉 CPU 全局描述符表（gdt）在内存中的什么位置呢？</p><p>答案是由操作系统把这个位置信息存储在一个叫 gdtr 的寄存器中。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_25.png"></p><p>怎么存呢？就是刚刚那条指令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lgdt    gdt_48</span><br></pre></td></tr></table></figure><p>其中 <strong>lgdt</strong> 就表示把<strong>后面的值（gdt_48）放在 gdtr 寄存器</strong>中，gdt_48 标签，我们看看它长什么样。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gdt_48:</span><br><span class="line">    .word   0x800       ; gdt limit=2048, 256 GDT entries</span><br><span class="line">    .word   512+gdt,0x9 ; gdt base = 0X9xxxx</span><br></pre></td></tr></table></figure><p>可以看到这个标签位置处表示一个 48 位的数据，其中高 32 位存储着的正是全局描述符表 gdt 的内存地址</p><p><strong>0x90200 + gdt</strong></p><p>gdt 是个标签，表示在本文件内的偏移量，而本文件是 setup.s，编译后是放在 0x90200 这个内存地址的，还记得吧？所以要加上 0x90200 这个值。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_26.png"></p><p>那 gdt 这个标签处，就是全局描述符表在内存中的真正数据了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">gdt:</span><br><span class="line">    .word   0,0,0,0     ; dummy</span><br><span class="line"></span><br><span class="line">    .word   0x07FF      ; 8Mb - limit=2047 (2048*4096=8Mb)</span><br><span class="line">    .word   0x0000      ; base address=0</span><br><span class="line">    .word   0x9A00      ; code read/exec</span><br><span class="line">    .word   0x00C0      ; granularity=4096, 386</span><br><span class="line"></span><br><span class="line">    .word   0x07FF      ; 8Mb - limit=2047 (2048*4096=8Mb)</span><br><span class="line">    .word   0x0000      ; base address=0</span><br><span class="line">    .word   0x9200      ; data read/write</span><br><span class="line">    .word   0x00C0      ; granularity=4096, 386</span><br></pre></td></tr></table></figure><p>具体细节不用关心，跟我看重点。</p><p>根据刚刚的段描述符格式。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_27.png"></p><p>可以看出目前全局描述符表有三个段描述符，第一个为空，第二个是代码段描述符（type=code），第三个是数据段描述符（type=data）。</p><p>第二个和第三个段描述符的段基址都是 0，也就是之后在逻辑地址转换物理地址的时候，通过段选择子查找到无论是代码段还是数据段，取出的段基址都是<br>0，那么物理地址将直接等于程序员给出的逻辑地址（准确说是逻辑地址中的偏移地址）。先记住这点就好。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_28.png"></p><p>具体段描述符的细节还有很多，就不展开了，比如这里的高 22 位就表示它是代码段还是数据段。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_29.png"></p><h4 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h4><p>整体而言，操作系统设置了个全局描述符表 gdt，为后面切换到保护模式后，能去那里寻找到段描述符，然后拼凑成最终的物理地址，就这个作用。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_31.png"></p><p>我们看看目前的内存布局:</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_30.png"></p><p>这里我把 idtr 寄存器也画出来了，这个是中断描述符表，其原理和全局描述符表一样。</p><ul><li>全局描述符表是让段选择子去里面寻找段描述符用的，</li><li>而中断描述符表是用来在发生中断时，CPU 拿着中断号去中断描述符表中寻找中断处理程序的地址，找到后就跳到相应的中断程序中去执行，具体我们后面遇到了再说。</li></ul><p>当然，还有很多段描述符，作用不仅仅是转换成最终的物理地址，不过这是后话了。</p><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><p>段描述符结构和详细说明如下(Intel 手册)</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_34.png"></p><p>保护模式下逻辑地址到线性地址（不开启分页时就是物理地址）的转化</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_35.png"></p><h3 id="六行代码进入保护模式"><a href="#六行代码进入保护模式" class="headerlink" title="六行代码进入保护模式"></a>六行代码进入保护模式</h3><p>自此，我们解决了向前兼容(X86)实模式寻址的历史包袱问题, 但这知识进入保护模式前准备工作中的其中一个。</p><h4 id="打开A20地址线"><a href="#打开A20地址线" class="headerlink" title="打开A20地址线"></a>打开A20地址线</h4><p>我们接着往下看，代码仍然是 setup.s 中的:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mov al,#0xD1        ; command write</span><br><span class="line">out #0x64,al</span><br><span class="line">mov al,#0xDF        ; A20 on</span><br><span class="line">out #0x60,al</span><br></pre></td></tr></table></figure><p>这段代码的意思是，<strong>打开 A20 地址线</strong>。</p><details><summary>到底什么是 A20 地址线呢</summary><p>简单理解，这一步就是为了突破地址信号线 20 位的宽度，变成 32 位可用。这是由于 8086 CPU 只有 20 位的地址线，所以如果程序给出 21<br>位的内存地址数据，那多出的一位就被忽略了，比如如果经过计算得出一个内存地址为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 0000 00000000 00000000</span><br></pre></td></tr></table></figure><p>那实际上内存地址相当于 0，因为高位的那个 1 被忽略了，地方不够。</p><p>当 CPU 到了 32 位时代之后，由于要考虑<strong>兼容性</strong>，还必须保持一个只能用 20 位地址线的模式，所以如果你不手动开启的话，即使地址线已经有 32 位了，仍然会限制只能使用其中的 20 位。</p><p>具体可参考文档<a href="http://www.techbulo.com/703.html">A20 地址线问题全面解析</a></p></details><h4 id="中断重定义"><a href="#中断重定义" class="headerlink" title="中断重定义"></a>中断重定义</h4><p>接下来的一段代码，你完全完全不用看，但为了防止你一直记挂在心上，我给你截出来说道说道，这样以后我说完全不用看的代码时，你就真的可以放宽心完全不看了。</p><details><summary>就是这一大坨，还有 Linus 自己的注释</summary><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">; well, that went ok, I hope. Now we have to reprogram the interrupts :-(</span><br><span class="line">; we put them right after the intel-reserved hardware interrupts, at</span><br><span class="line">; int 0x20-0x2F. There they won&#x27;t mess up anything. Sadly IBM really</span><br><span class="line">; messed this up with the original PC, and they haven&#x27;t been able to</span><br><span class="line">; rectify it afterwards. Thus the bios puts interrupts at 0x08-0x0f,</span><br><span class="line">; which is used for the internal hardware interrupts as well. We just</span><br><span class="line">; have to reprogram the 8259&#x27;s, and it isn&#x27;t fun.</span><br><span class="line"></span><br><span class="line">    mov al,#0x11        ; initialization sequence</span><br><span class="line">    out #0x20,al        ; send it to 8259A-1</span><br><span class="line">    .word   0x00eb,0x00eb       ; jmp $+2, jmp $+2</span><br><span class="line">    out #0xA0,al        ; and to 8259A-2</span><br><span class="line">    .word   0x00eb,0x00eb</span><br><span class="line">    mov al,#0x20        ; start of hardware int&#x27;s (0x20)</span><br><span class="line">    out #0x21,al</span><br><span class="line">    .word   0x00eb,0x00eb</span><br><span class="line">    mov al,#0x28        ; start of hardware int&#x27;s 2 (0x28)</span><br><span class="line">    out #0xA1,al</span><br><span class="line">    .word   0x00eb,0x00eb</span><br><span class="line">    mov al,#0x04        ; 8259-1 is master</span><br><span class="line">    out #0x21,al</span><br><span class="line">    .word   0x00eb,0x00eb</span><br><span class="line">    mov al,#0x02        ; 8259-2 is slave</span><br><span class="line">    out #0xA1,al</span><br><span class="line">    .word   0x00eb,0x00eb</span><br><span class="line">    mov al,#0x01        ; 8086 mode for both</span><br><span class="line">    out #0x21,al</span><br><span class="line">    .word   0x00eb,0x00eb</span><br><span class="line">    out #0xA1,al</span><br><span class="line">    .word   0x00eb,0x00eb</span><br><span class="line">    mov al,#0xFF        ; mask off all interrupts for now</span><br><span class="line">    out #0x21,al</span><br><span class="line">    .word   0x00eb,0x00eb</span><br><span class="line">    out #0xA1,al</span><br></pre></td></tr></table></figure></details><p>这里是对<strong>可编程中断控制器 8259 芯片</strong>进行的编程。</p><p>因为中断号是不能冲突的， Intel 把 0 到 0x19 号中断都作为<strong>保留中断</strong>，比如 0 号中断就规定为<strong>除零异常</strong>，软件自定义的中断都应该放在这之后，但是 IBM 在原 PC<br>机中搞砸了，跟保留中断号发生了冲突，以后也没有纠正过来，所以我们得重新对其进行编程，不得不做，却又一点意思也没有。</p><p>所以我们也不必在意，只要知道重新编程之后，8259 这个芯片的引脚与中断号的对应关系，变成了如下的样子就好。</p><table><thead><tr><th>PIC请求号</th><th>中断号</th><th>用途</th></tr></thead><tbody><tr><td>IRQ0</td><td>0x20</td><td>时钟中断</td></tr><tr><td>IRQ1</td><td>0x21</td><td>键盘中断</td></tr><tr><td>IRQ2</td><td>0x22</td><td>接连从芯片</td></tr><tr><td>IRQ3</td><td>0x23</td><td>串口2</td></tr><tr><td>IRQ4</td><td>0x24</td><td>串口1</td></tr><tr><td>IRQ5</td><td>0x25</td><td>并口2</td></tr><tr><td>IRQ6</td><td>0x26</td><td>软盘驱动器</td></tr><tr><td>IRQ7</td><td>0x27</td><td>并口1</td></tr><tr><td>IRQ8</td><td>0x28</td><td>实时钟中断</td></tr><tr><td>IRQ9</td><td>0x29</td><td>保留</td></tr><tr><td>IRQ10</td><td>0x2a</td><td>保留</td></tr><tr><td>IRQ11</td><td>0x2b</td><td>保留</td></tr><tr><td>IRQ12</td><td>0x2c</td><td>鼠标中断</td></tr><tr><td>IRQ13</td><td>0x2d</td><td>数学协处理器</td></tr><tr><td>IRQ14</td><td>0x2e</td><td>硬盘中断</td></tr><tr><td>IRQ15</td><td>0x2f</td><td>保留</td></tr></tbody></table><h4 id="模式切换"><a href="#模式切换" class="headerlink" title="模式切换"></a>模式切换</h4><p>好了，接下来的一步，就是真正切换模式的一步了，从代码上看就两行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov ax,#0x0001  ; protected mode (PE) bit</span><br><span class="line">lmsw ax      ; This is it;</span><br><span class="line">jmpi 0,8     ; jmp offset 0 of segment 8 (cs)</span><br></pre></td></tr></table></figure><p>前两行，将 cr0 这个寄存器的位 0 置 1，模式就从实模式切换到保护模式了。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_32.png"></p><p>所以真正的模式切换十分简单，重要的是之前做的准备工作。</p><h4 id="跳转到System"><a href="#跳转到System" class="headerlink" title="跳转到System"></a>跳转到System</h4><p>再往后，又是一个段间跳转指令 jmpi，后面的 8 表示 cs（代码段寄存器）的值，0 表示偏移地址。</p><p>请注意，此时已经是保护模式了，之前也说过，保护模式下内存寻址方式变了，段寄存器里的值被当做段选择子。</p><p>回顾下段选择子的模样。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_33.png"></p><p>8 用二进制表示就是<code>00000,0000,0000,1000</code></p><p>对照上面段选择子的结构，可以知道<strong>描述符索引值是 1，也就是要去全局描述符表（gdt）中找第一项段描述符</strong>。</p><p>还记得全局描述符的具体内容吗？</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_28.png"></p><ul><li>第 0 项是空值，</li><li>第一项被表示为代码段描述符，是个可读可执行的段，</li><li>第二项为数据段描述符，是个可读可写段</li></ul><p>不过他们的段基址都是 0。</p><p>这里取的就是这个代码段描述符，段基址是 0，偏移也是 0，那加一块就还是 0 咯，所以最终这个跳转指令，就是跳转到内存地址的 0 地址处，开始执行。</p><p>零地址处是什么呢？还是回顾之前的内存布局图。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_30.png"></p><p>就是操作系统全部代码的 system 这个大模块，system 模块怎么生成的呢？</p><p>由 Makefile 文件可知，是由 head.s 和 main.c 以及其余各模块的操作系统代码合并来的，可以理解为操作系统的全部核心代码编译后的结果。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tools/system: boot/head.o init/main.o \</span><br><span class="line">    $(ARCHIVES) $(DRIVERS) $(MATH) $(LIBS)</span><br><span class="line">    $(LD) $(LDFLAGS) boot/head.o init/main.o \</span><br><span class="line">    $(ARCHIVES) \</span><br><span class="line">    $(DRIVERS) \</span><br><span class="line">    $(MATH) \</span><br><span class="line">    $(LIBS) \</span><br><span class="line">    -o tools/system &gt; System.map</span><br></pre></td></tr></table></figure><p>所以，接下来，我们就要重点阅读 head.s 了。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_36.png"></p><p>这也是 boot 文件夹下的最后一个由汇编写就的源代码文件，而且是汇编写的令人头疼的代码。</p><p>head.s 这个文件仅仅是为了顺利进入由后面的 c 语言写就的 main.c 做的准备，所以咬咬牙看完这个之后，我们就终于可以进入 c 语言的世界了！也终于可以看到我们熟悉的 main 函数了！</p><p>在那里，操作系统真正秀操作的地方，才刚刚开始！</p><h3 id="重新设置一遍-idt-和-gdt-给描述符表挪个地儿"><a href="#重新设置一遍-idt-和-gdt-给描述符表挪个地儿" class="headerlink" title="重新设置一遍 idt 和 gdt - 给描述符表挪个地儿"></a>重新设置一遍 idt 和 gdt - 给描述符表挪个地儿</h3><p>至此，CPU 进入了 32 位保护模式，并且跳转到了 system 模块。</p><p>那接下来，我们就品品，正式进入 c 语言写的 main.c 之前的 head.s 究竟写了点啥？</p><p>head.s 文件很短，我们一点点品。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">_pg_dir:</span><br><span class="line">_startup_32:</span><br><span class="line">    mov eax,0x10</span><br><span class="line">    mov ds,ax</span><br><span class="line">    mov es,ax</span><br><span class="line">    mov fs,ax</span><br><span class="line">    mov gs,ax</span><br><span class="line">    lss esp,_stack_start</span><br></pre></td></tr></table></figure><p>注意到开头有个标号 <strong>_pg_dir</strong>。先留个心眼，这个表示<strong>页目录</strong>，之后在设置<strong>分页机制</strong>时，页目录会存放在这里，也会覆盖这里的代码。</p><p>再往下连续五个 mov 操作，分别给 <strong>ds、es、fs、gs 这几个段寄存器赋值为 0x10</strong>，根据段描述符结构解析，表示<strong>这几个段寄存器的值为指向全局描述符表中的第二个段描述符（数据段描述符）</strong>。</p><p>最后 lss 指令相当于让 ss:esp 这个<strong>栈顶指针指向了 _stack_start 这个标号的位置</strong>。还记得图里的那个原来的栈顶指针在哪里吧？往上翻一下，<strong>0x9FF00，现在要变咯</strong>。</p><p>这个 stack_start 标号定义在了很久之后才会讲到的 sched.c 里，我们这里拿出来分析一波。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">long user_stack[4096 &gt;&gt; 2];</span><br><span class="line"></span><br><span class="line">struct</span><br><span class="line">&#123;</span><br><span class="line">  long *a;</span><br><span class="line">  short b;</span><br><span class="line">&#125;</span><br><span class="line">stack_start = &#123;&amp;user_stack[4096 &gt;&gt; 2], 0x10&#125;;</span><br></pre></td></tr></table></figure><p>这啥意思呢？</p><p>首先，stack_start 结构中的高位 8 字节是 0x10，将会赋值给 ss 栈段寄存器，低位 16 字节是 user_stack 这个数组的最后一个元素的地址值，将其赋值给 esp 寄存器。</p><p>赋值给 ss 的 0x10 仍然按照保护模式下的段选择子去解读，其指向的是全局描述符表中的第二个段描述符（数据段描述符），段基址是 0。</p><p>赋值给 esp 寄存器的就是 user_stack 数组的最后一个元素的内存地址值，那最终的栈顶地址，也指向了这里（user_stack + 0），后面的压栈操作，就是往这个新的栈顶地址处压咯。</p><p>继续往下看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">call setup_idt ;设置中断描述符表</span><br><span class="line">call setup_gdt ;设置全局描述符表</span><br><span class="line">mov eax,10h</span><br><span class="line">mov ds,ax</span><br><span class="line">mov es,ax</span><br><span class="line">mov fs,ax</span><br><span class="line">mov gs,ax</span><br><span class="line">lss esp,_stack_start</span><br></pre></td></tr></table></figure><p>先设置了 idt 和 gdt，然后又重新执行了一遍刚刚执行过的代码。</p><p>为什么要重新设置这些段寄存器呢？ 因为上面修改了 gdt，所以要重新设置一遍以刷新才能生效。</p><p>那我们接下来就把目光放到设置 idt 和 gdt 上。</p><h4 id="设置中断描述符表"><a href="#设置中断描述符表" class="headerlink" title="设置中断描述符表"></a>设置中断描述符表</h4><details><summary>中断描述符表 idt 我们之前没设置过，所以这里设置具体的值，理所应当</summary><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">setup_idt:</span><br><span class="line">    lea edx,ignore_int</span><br><span class="line">    mov eax,00080000h</span><br><span class="line">    mov ax,dx</span><br><span class="line">    mov dx,8E00h</span><br><span class="line">    lea edi,_idt</span><br><span class="line">    mov ecx,256</span><br><span class="line">rp_sidt:</span><br><span class="line">    mov [edi],eax</span><br><span class="line">    mov [edi+4],edx</span><br><span class="line">    add edi,8</span><br><span class="line">    dec ecx</span><br><span class="line">    jne rp_sidt</span><br><span class="line">    lidt fword ptr idt_descr</span><br><span class="line">    ret</span><br><span class="line"></span><br><span class="line">idt_descr:</span><br><span class="line">    dw 256*8-1</span><br><span class="line">    dd _idt</span><br><span class="line"></span><br><span class="line">_idt:</span><br><span class="line">    DQ 256 dup(0)</span><br></pre></td></tr></table></figure></details><p>中断描述符表 idt 里面存储着一个个中断描述符，每一个中断号就对应着一个中断描述符，而中断描述符里面存储着主要是中断程序的地址，这样一个中断号过来后，CPU 就会自动寻找相应的中断程序，然后去执行它。</p><p>那这段程序的作用就是:</p><ul><li><strong>设置了 256 个中断描述符</strong>，</li><li>并且让每一个中断描述符中的中断程序例程都指向一个 <strong>ignore_int</strong> 的函数地址<ul><li>这个是个<strong>默认的中断处理程序</strong>，之后会逐渐被各个具体的中断程序所覆盖。</li><li>比如之后键盘模块会将自己的键盘中断处理程序，覆盖过去。</li></ul></li></ul><p>那现在，产生任何中断都会指向这个默认的函数 ignore_int，也就是说<strong>现在这个阶段你按键盘还不好使</strong>。</p><h4 id="设置全局描述符表"><a href="#设置全局描述符表" class="headerlink" title="设置全局描述符表"></a>设置全局描述符表</h4><p>设置中断描述符表 setup_idt 说完了，那接下来 setup_gdt 就同理了。</p><p>我们就直接看设置好后的新的全局描述符表长什么样吧？</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">_gdt:</span><br><span class="line">    DQ 0000000000000000h    ;/* NULL descriptor */</span><br><span class="line">    DQ 00c09a0000000fffh    ;/* 16Mb */</span><br><span class="line">    DQ 00c0920000000fffh    ;/* 16Mb */</span><br><span class="line">    DQ 0000000000000000h    ;/* TEMPORARY - don&#x27;t use */</span><br><span class="line">    DQ 252 dup(0)</span><br></pre></td></tr></table></figure><p>其实和我们原先设置好的 gdt 一模一样。</p><p>也是有<strong>代码段描述符和数据段描述符</strong>，然后第四项系统段描述符并没有用到，不用管。</p><p>最后还留了 252 项的空间，这些空间后面会用来放置<strong>任务状态段描述符 TSS 和局部描述符 LDT</strong>，这个后面再说。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_37.png"></p><p>为什么原来已经设置过一遍了，这里又要重新设置一遍?</p><p>你可千万别想有什么复杂的原因，就是因为原来设置的 gdt 是在 setup 程序中，之后这个地方要被缓冲区覆盖掉，所以这里重新设置在 head 程序中，这块内存区域之后就不会被其他程序用到并且覆盖了，就这么个事。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_38.png"></p><h4 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h4><p>总体而言，header.s 目前就是完成了寄存器位置的一个指向转换，并且给所有中断设置了一个默认的中断处理程序 ignore_int，然后全局描述符表仍然只有代码段描述符和数据段描述符。</p><h3 id="Intel-内存管理两板斧-分段和分页"><a href="#Intel-内存管理两板斧-分段和分页" class="headerlink" title="Intel 内存管理两板斧-分段和分页"></a>Intel 内存管理两板斧-分段和分页</h3><p>header.s 代码在重新设置gdt和idt后， 来到了这样一段代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">jmp after_page_tables</span><br><span class="line">...</span><br><span class="line">after_page_tables:</span><br><span class="line">    push 0</span><br><span class="line">    push 0</span><br><span class="line">    push 0</span><br><span class="line">    push L6</span><br><span class="line">    push _main</span><br><span class="line">    jmp setup_paging</span><br><span class="line">L6:</span><br><span class="line">    jmp L6</span><br></pre></td></tr></table></figure><p>那就是开启分页机制，并且跳转到 main 函数！</p><p>这可太令人兴奋了！开启分页后，配合着分段，就构成了内存管理的最最底层的机制。</p><p>而跳转到 main 函数，标志着我们正式进入 c 语言写的操作系统核心代码！如何跳转到之后用 c 语言写的 main.c 里的 main 函数，是个有趣的事，也包含在这段代码里。</p><p>不过我们先瞧瞧这<strong>分页机制</strong>是如何开启的，也就是 setup_paging 这个标签处的代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">setup_paging:</span><br><span class="line">    mov ecx,1024*5</span><br><span class="line">    xor eax,eax</span><br><span class="line">    xor edi,edi</span><br><span class="line">    pushf</span><br><span class="line">    cld</span><br><span class="line">    rep stosd</span><br><span class="line">    mov eax,_pg_dir</span><br><span class="line">    mov [eax],pg0+7</span><br><span class="line">    mov [eax+4],pg1+7</span><br><span class="line">    mov [eax+8],pg2+7</span><br><span class="line">    mov [eax+12],pg3+7</span><br><span class="line">    mov edi,pg3+4092</span><br><span class="line">    mov eax,00fff007h</span><br><span class="line">    std</span><br><span class="line">L3: stosd</span><br><span class="line">    sub eax,00001000h</span><br><span class="line">    jge L3</span><br><span class="line">    popf</span><br><span class="line">    xor eax,eax</span><br><span class="line">    mov cr3,eax</span><br><span class="line">    mov eax,cr0</span><br><span class="line">    or  eax,80000000h</span><br><span class="line">    mov cr0,eax</span><br><span class="line">    ret</span><br></pre></td></tr></table></figure><h4 id="分页机制"><a href="#分页机制" class="headerlink" title="分页机制"></a>分页机制</h4><p>首先要了解的就是，啥是分页机制？</p><p>还记不记得之前我们在代码中给出一个内存地址，在保护模式下要先经过分段机制的转换，才能最终变成物理地址，就是这样。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_39.png"></p><p>这是在没有开启分页机制的时候，只需要经过这一步转换即可得到最终的物理地址了，但是在开启了分页机制后，又会<strong>多一步转换</strong>。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_40.png"></p><p>也就是说：</p><ul><li>在没有开启分页机制时，由程序员给出的逻辑地址，需要先通过分段机制转换成物理地址。</li><li>但在开启分页机制后，逻辑地址仍然要先通过分段机制进行转换，只不过转换后不再是最终的物理地址，而是线性地址，然后再通过一次分页机制转换，得到最终的物理地址。</li></ul><p>分段机制我们已经清楚如何对地址进行变换了，那分页机制又是如何变换的呢？我们直接以一个例子来学习过程。</p><p>比如我们的线性地址（已经经过了分段机制的转换）是 <code>15M</code>, 二进制表示就是 <code>0000000011_0100000000_000000000000</code></p><p>我们看一下它的转换过程</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_41.png"></p><p>也就是说，CPU 在看到我们给出的内存地址后，首先把线性地址被拆分成</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">高 10 位：中间 10 位：后 12 位</span><br></pre></td></tr></table></figure><p>高 10 位负责在<strong>页目录表</strong>中找到一个<strong>页目录项</strong>，这个页目录项的值加上中间 10 位拼接后的地址去<strong>页表</strong>中去寻找一个<strong>页表项</strong>，这个页表项的值，再加上后 12 位偏移地址，就是最终的物理地址。</p><p>而这一切的操作，都由计算机的一个硬件叫 <strong>MMU</strong>，中文名字叫<strong>内存管理单元</strong>，有时也叫 PMMU，分页内存管理单元。由这个部件来负责将虚拟地址转换为物理地址。</p><p>所以整个过程我们不用操心，作为操作系统这个软件层，只需要提供好页目录表和页表即可，这种页表方案叫做<strong>二级页表</strong>，第一级叫<strong>页目录表 PDE</strong>，第二级叫<strong>页表 PTE</strong>。</p><p>他们的结构如下:</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_42.png"></p><p>之后再开启分页机制的开关。其实就是更改 cr0 寄存器中的一位即可（31 位），还记得我们开启保护模式么，也是改这个寄存器中的一位的值。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_43.png"></p><p>然后，MMU 就可以帮我们进行分页的转换了。此后指令中的内存地址（就是程序员提供的逻辑地址），就统统要先经过分段机制的转换，再通过分页机制的转换，才能最终变成物理地址。</p><p>所以这段代码，就是帮我们<strong>把页表和页目录表在内存中写好，之后开启 cr0 寄存器的分页开关</strong>，仅此而已，我们再把代码贴上来。</p><h4 id="分页内存结构"><a href="#分页内存结构" class="headerlink" title="分页内存结构"></a>分页内存结构</h4><p>我们先说这段代码最终产生的效果吧。</p><p>当时 linux-0.11 认为，总共可以使用的内存不会超过 <strong>16M</strong>，也即最大地址空间为 <strong>0xFFFFFF</strong>。</p><p>而按照当前的页目录表和页表这种机制:</p><ul><li>1 个页目录表最多包含 1024 个页目录项（也就是 1024 个页表），</li><li>1 个页表最多包含 1024 个页表项（也就是 1024 个页），</li><li>1 页为 4KB（因为有 12 位偏移地址）</li></ul><p>因此，16M 的地址空间可以用 1 个页目录表 + 4 个页表搞定。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">4（页表数）* 1024（页表项数） * 4KB（一页大小）= 16MB</span><br></pre></td></tr></table></figure><p>所以，上面这段代码就是，<strong>将页目录表放在内存地址的最开头</strong>，还记得上一讲开头让你留意的 _pg_dir 这个标签吧？</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_pg_dir:</span><br><span class="line">_startup_32:</span><br><span class="line">    mov eax,0x10</span><br><span class="line">    mov ds,ax</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p><strong>之后紧挨着这个页目录表，放置 4 个页表</strong>，代码里也有这四个页表的标签项。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.org 0x1000 pg0:</span><br><span class="line">.org 0x2000 pg1:</span><br><span class="line">.org 0x3000 pg2:</span><br><span class="line">.org 0x4000 pg3:</span><br><span class="line">.org 0x5000</span><br></pre></td></tr></table></figure><p>最终将页目录表和页表填写好数值，来覆盖整个 16MB 的内存。随后，开启分页机制。</p><p>此时内存中的页表相关的布局如下。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_44.png"></p><p>这些页目录表和页表放到了整个内存布局中最开头的位置，就是覆盖了开头的 system 代码了，不过被覆盖的 system 代码已经执行过了，所以无所谓。</p><p>同时，如 idt 和 gdt 一样，我们也需要通过一个寄存器告诉 CPU 我们把这些页表放在了哪里，就是这段代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xor eax,eax</span><br><span class="line">mov cr3,eax</span><br></pre></td></tr></table></figure><p>你看，我们相当于告诉 <strong>cr3 寄存器</strong>，<strong>0 地址处就是页目录表，再通过页目录表可以找到所有的页表</strong>，也就相当于 CPU 知道了分页机制的全貌了。</p><p>至此后，整个内存布局如下:</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_45.png"></p><h4 id="页表具体映射内存"><a href="#页表具体映射内存" class="headerlink" title="页表具体映射内存"></a>页表具体映射内存</h4><p>那么具体页表设置好后，映射的内存是怎样的情况呢？那就要看页表的具体数据了，就是这一坨代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">setup_paging:</span><br><span class="line">    ...</span><br><span class="line">    mov eax,_pg_dir</span><br><span class="line">    mov [eax],pg0+7</span><br><span class="line">    mov [eax+4],pg1+7</span><br><span class="line">    mov [eax+8],pg2+7</span><br><span class="line">    mov [eax+12],pg3+7</span><br><span class="line">    mov edi,pg3+4092</span><br><span class="line">    mov eax,00fff007h</span><br><span class="line">    std</span><br><span class="line">L3: stosd</span><br><span class="line">    sub eax, 1000h</span><br><span class="line">    jpe L3</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>很简单，对照刚刚的页目录表与页表结构看。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_42.png"></p><p>前五行表示，页目录表的前 4 个页目录项，分别指向 4 个页表。比如页目录项中的第一项 [eax] 被赋值为 pg0+7，也就是 0x00001007，根据页目录项的格式，表示页表地址为 0x1000，页属性为 0x07 表示改页存在、用户可读写。</p><p>后面几行表示，填充 4 个页表的每一项，一共 4*1024=4096 项，依次映射到内存的前 16MB 空间。</p><p>画出图就是这个样子，其实刚刚的图就是:</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_46.png"></p><p>看，最终的效果就是，经过这套分页机制，<strong>线性地址将恰好和最终转换的物理地址一样</strong>。</p><p>现在只有四个页目录项，也就是将前 16M 的线性地址空间，与 16M 的物理地址空间一一对应起来了。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_47.png"></p><p>好了，我们终于把这些杂七杂八的idt、gdt、页表都设置好了，并且也开启了保护模式，之后我们就要做好进入 main.c 的准备了，那里是个新世界！</p><h4 id="拓展-名词梳理"><a href="#拓展-名词梳理" class="headerlink" title="拓展 - 名词梳理"></a>拓展 - 名词梳理</h4><p>关于地址，我们已经出现了好多词了，包括<strong>逻辑地址</strong>、<strong>线性地址</strong>、<strong>物理地址</strong>，以及本文中没出现的，你可能在很多地方看到过的<strong>虚拟地址</strong>。</p><p>而这些地址后面加上空间两个字，似乎又成为了一个新词，比如<strong>线性地址空间</strong>、<strong>物理地址空间</strong>、<strong>虚拟地址空间</strong>等。</p><p>那就是时候展开一波讨论，将这块的内容梳理一番了，且听我说。</p><p>Intel 体系结构的内存管理可以分成两大部分，也就是标题中的两板斧，<strong>分段和分页</strong>。</p><ul><li><p><strong>分段机制</strong>： 在之前已经讨论过多次了，其目的是为了为每个程序或任务提供单独的代码段（cs）、数据段（ds）、栈段（ss），使其不会相互干扰。</p></li><li><p><strong>分页机制</strong>： 开机后分页机制默认是关闭状态，需要我们手动开启，并且设置好页目录表（PDE）和页表（PTE）。</p><ul><li>其目的在于可以按需使用物理内存，同时也可以在多任务时起到隔离的作用，这个在后面将多任务时将会有所体会。</li></ul></li></ul><p>在 Intel 的保护模式下，分段机制是没有开启和关闭一说的，它必须存在，而分页机制是可以选择开启或关闭的。所以如果有人和你说，它实现了一个没有分段机制的操作系统，那一定是个外行。</p><p>再说说那些地址：</p><ul><li><p>逻辑地址：我们程序员写代码时给出的地址叫逻辑地址，其中包含段选择子和偏移地址两部分。</p></li><li><p>线性地址：通过分段机制，将逻辑地址转换后的地址，叫做线性地址。而这个线性地址是有个范围的，这个范围就叫做线性地址空间，32 位模式下，线性地址空间就是 4G。</p></li><li><p>物理地址：就是真正在内存中的地址，它也是有范围的，叫做物理地址空间。那这个范围的大小，就取决于你的内存有多大了。</p></li><li><p>虚拟地址：如果没有开启分页机制，那么线性地址就和物理地址是一一对应的，可以理解为相等。如果开启了分页机制，那么线性地址将被视为虚拟地址，这个虚拟地址将会通过分页机制的转换，最终转换成物理地址。</p></li></ul><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_48.png"></p><h3 id="进入-main-c-之前的最后一哆嗦"><a href="#进入-main-c-之前的最后一哆嗦" class="headerlink" title="进入 main.c 之前的最后一哆嗦"></a>进入 main.c 之前的最后一哆嗦</h3><p>回到上节中开启分页机制的代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">jmp after_page_tables</span><br><span class="line">...</span><br><span class="line">after_page_tables:</span><br><span class="line">    push 0</span><br><span class="line">    push 0</span><br><span class="line">    push 0</span><br><span class="line">    push L6</span><br><span class="line">    push _main</span><br><span class="line">    jmp setup_paging</span><br><span class="line">L6:</span><br><span class="line">    jmp L6</span><br></pre></td></tr></table></figure><p>这里有个 push _main，把 main 函数的地址压栈了，那最终跳转到这个 main.c 里的 main 函数，一定和这个压栈有关。</p><p>压栈为什么和跳转到这里还能联系上呢？</p><p>五个 push 指令过去后，栈会变成这个样子。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_49.png"></p><p>然后注意，setup_paging 最后一个指令是 ret，也就是设置分页的代码的最后一个指令，形象地说它叫<strong>返回指令</strong>，但 CPU 可没有那么聪明，它并不知道该返回到哪里执行，只是很<strong>机械地把栈顶的元素值当做返回地址</strong>，跳转去那里执行。</p><p>再具体说是，把 esp 寄存器（栈顶地址）所指向的内存处的值，赋值给 eip 寄存器，而 cs:eip 就是 CPU 要执行的下一条指令的地址。而此时栈顶刚好是 main.c 里写的 main 函数的内存地址，是我们刚刚特意压入栈的，所以 CPU 就理所应当跳过来了。</p><details><summary>当然 Intel CPU 是设计了 call 和 ret 这一配对儿的指令，意为调用函数和返回</summary><p>关于 ret 指令，其实 Intel CPU 是配合 call 设计的，有关 call 和 ret 指令，即调用和返回指令，可以参考 Intel 手册。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Intel 1 Chapter 6.4 CALLING PROCEDURES USING CALL AND RET</span><br></pre></td></tr></table></figure><p>同时，可以看到系统还分为不改变段基址的 near call &amp; near ret, 以及改变段基址的 far call 和 far ret。</p><p>压栈和出栈的具体过程，上面文字写的清清楚楚，下面 Intel 手册还非常友好地放了张图。</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_52.png"></p><p>可以看到，我们本文就是左边的那一套，把 main 函数地址值当做 Calling EIP 压入栈，仿佛是执行了 call 指令调用了一个函数一样，但实际上这是我们通过骚操作代码伪造的假象，骗了 CPU。</p><p>然后 ret 的时候就把栈顶的那个 Calling EIP 也就是 main 函数地址弹出栈，存入 EIP 寄存器，这样 CPU 就相当于“返回”到了 main 函数开始执行。</p></details><p>至于其他压入栈的 L6 是用作当 main 函数返回时的跳转地址，但由于在操作系统层面的设计上，main 是绝对不会返回的，所以也就没用了。而其他的三个压栈的 0，本意是作为 main 函数的参数，但实际上似乎也没有用到，所以也不必关心。</p><p>总之，经过这一个小小的骚操作，程序终于跳转到 main.c 这个由 c 语言写就的主函数 main 里了！</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">void main(void) &#123;</span><br><span class="line">    ROOT_DEV = ORIG_ROOT_DEV;</span><br><span class="line">    drive_info = DRIVE_INFO;</span><br><span class="line">    memory_end = (1&lt;&lt;20) + (EXT_MEM_K&lt;&lt;10);</span><br><span class="line">    memory_end &amp;= 0xfffff000;</span><br><span class="line">    if (memory_end &gt; 16*1024*1024)</span><br><span class="line">        memory_end = 16*1024*1024;</span><br><span class="line">    if (memory_end &gt; 12*1024*1024) </span><br><span class="line">        buffer_memory_end = 4*1024*1024;</span><br><span class="line">    else if (memory_end &gt; 6*1024*1024)</span><br><span class="line">        buffer_memory_end = 2*1024*1024;</span><br><span class="line">    else</span><br><span class="line">        buffer_memory_end = 1*1024*1024;</span><br><span class="line">    main_memory_start = buffer_memory_end;</span><br><span class="line">    mem_init(main_memory_start,memory_end);</span><br><span class="line">    trap_init();</span><br><span class="line">    blk_dev_init();</span><br><span class="line">    chr_dev_init();</span><br><span class="line">    tty_init();</span><br><span class="line">    time_init();</span><br><span class="line">    sched_init();</span><br><span class="line">    buffer_init(buffer_memory_end);</span><br><span class="line">    hd_init();</span><br><span class="line">    floppy_init();</span><br><span class="line">    sti();</span><br><span class="line">    move_to_user_mode();</span><br><span class="line">    if (!fork()) &#123;</span><br><span class="line">        init();</span><br><span class="line">    &#125;</span><br><span class="line">    for(;;) pause();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>没错，这就是这个 main 函数的全部了。</p><p>而整个操作系统也会最终停留在最后一行死循环中，永不返回，直到关机。</p><h4 id="总结-5"><a href="#总结-5" class="headerlink" title="总结"></a>总结</h4><p>至此，系统正式完成了 main 函数的所有准备工作，并跳转到了 main 函数地址。</p><p>来看看系统都经历了什么？</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_50.png"></p><p>而经过这样的流程，内存被搞成了这个样子</p><p><img src="/2022/04/19/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E6%AD%A5%E4%B9%8B%E8%BF%9B%E5%85%A5%E5%86%85%E6%A0%B8%E5%89%8D%E7%9A%84%E8%8B%A6%E5%8A%9B%E6%B4%BB/img_51.png"></p><p>之后，main 方法就开始执行了，靠着我们辛辛苦苦建立起来的内存布局，向崭新的未来前进！</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统之按下开机键</title>
      <link href="/2022/04/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E6%8C%89%E4%B8%8B%E5%BC%80%E6%9C%BA%E9%94%AE/"/>
      <url>/2022/04/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E6%8C%89%E4%B8%8B%E5%BC%80%E6%9C%BA%E9%94%AE/</url>
      
        <content type="html"><![CDATA[<p>文档说明：转自<a href="https://mp.weixin.qq.com/s?__biz=Mzk0MjE3NDE0Ng==&mid=2247483867&idx=1&sn=76ece31324d32922a7cb9db129decd3f&chksm=c2c67b76f5b1f260bb459e12c029f8e6a7a813055811ab8ed794a3f36d0d7d50e66df27f4f0a&scene=21#wechat_redirect">全网最硬核讲解计算机的启动过程</a></p><p>我们按下开机键后究竟发生了什么？</p><p>当我们探寻这个问题的答案时，搜到的大多数是这样的描述：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BIOS 按照“启动顺序”，把控制权转交给排在第一位的存储设备：硬盘。</span><br><span class="line"></span><br><span class="line">然后在硬盘里寻找主引导记录的分区，这个分区告诉电脑操作系统在哪里，并把操作系统被加载到内存中，然后你就能看到经典的启动界面了，这个开机过程也就完成了。</span><br></pre></td></tr></table></figure><p>这种描述简直太魔幻了</p><ul><li>为什么是 BIOS 主导这一切？</li><li>怎么叫按照启动顺序？</li><li>这个分区咋就被加载到内存了?</li><li>又咋告诉电脑操作系统在哪里了？</li></ul><p><strong>前置知识</strong></p><ul><li>内存是存储数据的地方，给出一个地址信号，内存可以返回该地址所对应的数据。</li><li>CPU 的工作方式就是不断从内存中取出指令，并执行。</li><li>CPU 从内存的哪个地址取出指令，是由一个寄存器中的值决定的，这个值会不断进行 +1 操作，或者由某条跳转指令指定其值是多少。</li></ul><h3 id="为什么是BIOS主导"><a href="#为什么是BIOS主导" class="headerlink" title="为什么是BIOS主导"></a>为什么是BIOS主导</h3><p>都说开机后，BIOS 就开始运行自己的程序了，又硬件自检，又加载启动区的。</p><p>我就不服了，为什么开机后是执行 BIOS 里的程序？<br>为啥不是内存里的？<br>为啥不是硬盘里的？</p><p>好的，不要怀疑前置知识，CPU 的工作方式，就是不断从内存中取指令并执行，那为什么会说是执行 BIOS 里的程序呢？这就不得不说说内存映射了。</p><h3 id="内存映射"><a href="#内存映射" class="headerlink" title="内存映射"></a>内存映射</h3><p><strong>CPU 地址总线的宽度决定了可访问的内存空间的大小</strong></p><p>比如 16 位的 CPU 地址总线宽度为 20 位，地址范围是 1M。32 位的 CPU 地址总线宽度为 32 位，地址范围是 4G。你可以算算我们现在的 64 位机的地址范围。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">地址总线用来定位，数据总线用来传输。</span><br><span class="line">cpu的位宽 = 数据总线的位宽 = cpu内部通用寄存器的位宽 = 机器字长， 与地址总线位宽无关。</span><br></pre></td></tr></table></figure><p>可是，可访问的内存空间这么大，并不等于说全都给内存使用，也就是说寻址的对象不只有内存，还有一些外设也要通过地址总线的方式去访问，那怎么去访问这些外设呢？就是在地址范围中划出一片片的区域，这块给显存使用，那块给硬盘控制器使用，等等 。</p><p>这样说，其实就不符合我们的前置知识了，所以可以有一种不太正确的理解方式，那就是内存中的这块位置就是显存，那块位置就是硬盘控制器。我们在相应的位置上读取或者写入，就相当于在显存等外设的相应位置上读取或者写入，就好像这些外设的存储区域，被映射到了内存中的某一片区域一样。</p><p>这样我们就不用管那些外设啦，关注点仍然是一个简简单单的内存。 </p><p>这就是所谓的内存映射。</p><h3 id="实模式下的内存分布"><a href="#实模式下的内存分布" class="headerlink" title="实模式下的内存分布"></a>实模式下的内存分布</h3><p>刚刚说到内存中划分出了一片一片区域给各种外设，那么问题自然就来了，哪块区域，分给了哪块外设了呢？如果是规定，那应该有一张表比较好吧。</p><p>嗯没错，还真有，它就是实模式下的内存分布，笔者给它画了一张图：</p><p><img src="/2022/04/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E6%8C%89%E4%B8%8B%E5%BC%80%E6%9C%BA%E9%94%AE/img_1.png"></p><p>实模式之后再解释，现在简单理解就是计算机刚开机的时候只有 1M 的内存可用。</p><p>我们看到，内存被各种外设瓜分了，即映射在了内存中。</p><p>BIOS 更狠，不但其空间被映射到了内存 0xC0000 - 0xFFFFF 位置，其里面的程序还占用了开头的一些区域，比如把中断向量表写在了内存开始的位置，真所谓先到先得啊。</p><h3 id="为什么从BIOS的程序开始执行"><a href="#为什么从BIOS的程序开始执行" class="headerlink" title="为什么从BIOS的程序开始执行"></a>为什么从BIOS的程序开始执行</h3><p>现在我们知道 BIOS 里的信息被映射到了内存 0xC0000 - 0xFFFFF 位置，其中最为关键的系统 BIOS 被映射到了 0xF0000 - 0xFFFFF 位置。</p><p>CPU 开机就是执行了这块区域的代码，然后巴拉巴拉一顿操作就开机了，那咋不从头开始执行？</p><p>就是 CPU 从内存的哪个位置取出执行并执行呢？</p><p><strong>是 PC 寄存器中的地址值</strong></p><p>BIOS 程序的入口地址也就是开始地址是 0xFFFF0（人家就那么写的），也就是开机键一按下，一定有一个神奇的力量，将 pc 寄存器中的值变成 0xFFFF0，然后 CPU 就开始马不停蹄地跑了起来。</p><p><strong>在你开机的一瞬间，CPU 的 PC 寄存器被强制初始化为 0xFFFF0。</strong></p><p>如果再说具体些，CPU 将段基址寄存器 cs 初始化为 0xF000，将偏移地址寄存器 IP 初始化为 0xFFF0，根据<strong>实模式下的最终地址计算规则</strong>，将段基址左移 4 位，加上偏移地址，得到最终的物理地址也就是抽象出来的 PC 寄存器地址为 0xFFFF0。</p><p>至于怎么强制初始化的，我觉得就越过了前置知识的边界了，况且各个厂商的硬件实现也不一定相同，有很多办法，也很简单。讨论起来意义就不大了。</p><h3 id="BIOS里到底写了什么？"><a href="#BIOS里到底写了什么？" class="headerlink" title="BIOS里到底写了什么？"></a>BIOS里到底写了什么？</h3><p>我们现在知道了 BIOS 被映射到了内存的某个位置，并且开机一瞬间 CPU 强制将自己的 pc 寄存器初始化为 BIOS 程序的入口地址，从这里开始 CPU 马不停蹄地向前跑了起来。</p><p>那接下来的问题似乎也非常自然地就问出来了，那就是 BIOS 程序里到底写了啥？ 把 BIOS 程序里的二进制信息全贴出来也不合适，我们分析一些主要的。</p><p>我们首先还是来猜测，你看入口地址是 0xFFFF0，说明程序是从这执行的。</p><p>实模式下内存的下边界就是 0xFFFFF，也就是只剩下 16 个字节的空间可以写代码了，这够干啥的呢？</p><p>如果你有心的话应该能猜出，入口地址处可能是个跳转指令，跳到一个更大范围的空间去执行自己的任务。</p><p>没错就是这样，0xFFFF0 处存储的机器指令，翻译成汇编语言是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmp far f000:e05b</span><br></pre></td></tr></table></figure><p>意思是跳转到物理地址 0xfe05b 处开始执行（回忆下前面说的实模式下的地址计算方式）。</p><p>地址 0xfe05b 处开始，便是 BIOS 真正发挥作用的代码了，这块代码会检测一些外设信息，并初始化好硬件，建立中断向量表并填写中断例程。</p><p>这里的部分不要展开，这只是一段写死的程序而已，而且对理解开机启动过程无帮助，我们看后面精彩的部分，也就是 BIOS 的最后一项工作：<strong>加载启动区</strong>。</p><h3 id="0x7c00-是啥"><a href="#0x7c00-是啥" class="headerlink" title="0x7c00 是啥"></a>0x7c00 是啥</h3><p>该较真的地方就是要较真，我绝对不会让<strong>加载</strong>这种魔幻的词出现在这里，我们现在就来把它拆解成人话。</p><p>其实这个词也并不魔幻，加载在计算机领域就是指，<strong>把某设备上（比如硬盘）的程序复制到内存中的过程</strong>。</p><p>那加载启动区这个过程，翻译过来就是，<strong>BIOS 程序把启动区的内容复制到了内存中的某个区域</strong>。</p><p>好了，问题又自然出来了，启动区是哪里？被复制到了内存的哪个位置？然后呢？我们一个个来回答。</p><h4 id="什么是启动区呢"><a href="#什么是启动区呢" class="headerlink" title="什么是启动区呢"></a>什么是启动区呢</h4><p>即使你不知道，你也应该能够猜到，一定是符合某种特征的一块区域，于是人们把它就叫做启动区了，那要符合什么特征呢？</p><p>先不急，不知道你有没有过设置 BIOS 启动顺序的经历，通常有 U 盘启动、硬盘启动、软盘启动、光盘启动等等。</p><p>BIOS 会按照顺序，读取这些启动盘中位于<strong>0 盘 0 道 1 扇区</strong>的内容。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">至于磁盘格式的划分，本篇就不做讲解了，总之对于内存，我们给出一个数字地址就能获取到该地址的数据，而对于磁盘，我们需要给出磁头、柱面、扇区这三个信息才能定位某个位置的数据，都是描述位置的一种方式而已。</span><br></pre></td></tr></table></figure><p>接着说， 这 0 盘 0 道 1 扇区的内容一共有 512 个字节，<strong>如果末尾的两个字节分别是 0x55 和 0xaa，那么 BIOS 就会认为它是个启动区</strong>。 如果不是，那么按顺序继续向下个设备中寻找位于 0 盘 0 道 1 扇区的内容。如果最后发现都没找到符合条件的，那直接报出一个无启动区的错误。</p><h4 id="BIOS找到启动区后做什么？"><a href="#BIOS找到启动区后做什么？" class="headerlink" title="BIOS找到启动区后做什么？"></a>BIOS找到启动区后做什么？</h4><p>前面说过了是加载，<strong>就是把这 512 个字节的内容，一个比特都不少的全部复制到内存的 0x7c00 这个位置</strong>。</p><p>怎么复制的？ 当然是指令啦。</p><p>哪些指令呢？这里我只能简单说指令集中是有 in 和 out 的，用来将外设中的数据复制到内存，或者将内存中的数据复制到外设，用这两个指令，以及外设给我们提供的读取方式，就能做到这一点啦。</p><p>启动区内容此时已经被 BIOS 程序复制到了内存的 0x7c00 这个位置，然后呢？这个其实也不难猜测，启动区的内容就是我们自己写的代码了，复制到这里之后，就开始执行呗，之后我们的程序就接管了接下来的流程，BIOS 的使命也就结束啦。</p><p>所以复制完之后，接下来应该是一个跳转指令吧！没错，正是这样，PC 寄存器的值变为 0x7c00，指令开始从这里执行。</p><p>这样，我们就可以理解这句魔法语言了： </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BIOS 把控制权转交给排在第一位的存储设备。</span><br><span class="line"></span><br><span class="line">就是 BIOS 把启动区的 512 字节复制到内存的 0x7c00 位置，并且用一条跳转指令将 pc 寄存器的值指向 0x7c00。</span><br></pre></td></tr></table></figure><h4 id="为什么是-ox7c00"><a href="#为什么是-ox7c00" class="headerlink" title="为什么是 ox7c00"></a>为什么是 ox7c00</h4><p>现在似乎就剩下一个问题了，为什么非要是 0x7c00 呢？好问题，当然答案也很简单，那就是人家 BIOS 开发团队就是这样定的，之后也不好改了，不然不兼容。为什么不好改？</p><details><summary>我们看一个简单的启动区 512 字节的代码</summary><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">; hello-os</span><br><span class="line">; TAB=4</span><br><span class="line"></span><br><span class="line">  ORG  0x7c00   ;程序加载到内存的 0x7c00 这个位置</span><br><span class="line"></span><br><span class="line">;程序主体</span><br><span class="line"></span><br><span class="line">entry:</span><br><span class="line">  MOV  AX,0   ;初始化寄存器</span><br><span class="line">  MOV  SS,AX</span><br><span class="line">  MOV  SP,0x7c00</span><br><span class="line">  MOV  DS,AX   ;段寄存器初始化为 0</span><br><span class="line">  MOV  ES,AX</span><br><span class="line">  MOV  SI,msg</span><br><span class="line">putloop:</span><br><span class="line">  MOV  AL,[SI]</span><br><span class="line">  ADD  SI,1</span><br><span class="line">  CMP  AL,0   ;如果遇到 0 结尾的，就跳出循环不再打印新字符</span><br><span class="line">  JE  fin</span><br><span class="line">  MOV  AH,0x0e   ;指定文字</span><br><span class="line">  MOV  BX,15   ;指定颜色</span><br><span class="line">  INT  0x10   ;调用 BIOS 显示字符函数</span><br><span class="line">  JMP  putloop</span><br><span class="line">fin:</span><br><span class="line">  HLT</span><br><span class="line">  JMP  fin</span><br><span class="line">msg:</span><br><span class="line">  DB  0x0a,0x0a  ;换行、换行</span><br><span class="line">  DB  &quot;hello-os&quot;</span><br><span class="line">  DB  0x0a   ;换行</span><br><span class="line">  DB  0    ;0 结尾</span><br><span class="line"></span><br><span class="line">  RESB 0x7dfe-$   ;填充0到512字节</span><br><span class="line">  DB 0x55, 0xaa   ;可启动设备标识</span><br></pre></td></tr></table></figure></details><p>我们看第一行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ORG  0x7c00</span><br></pre></td></tr></table></figure><p>这个数字就是刚刚说的启动区加载位置，这行汇编代码简单说就表示把下面的地址统统加上 0x7c00。正因为 BIOS 将启动区的代码加载到了这里，因此有了一个偏移量，所以所有写启动区代码的人就需要在开头写死一个这样的代码，不然全都串位了。</p><p>然后正因为所有写操作系统的，启动区的第一行汇编代码都写死了这个数字，那 BIOS 开发者最初定的这个数字就不好改了，否则它得挨个联系各个操作系统的开发厂商，说唉我这个地址改一下哈，你们跟着改改。在公司推动另一个团队改个代码都得大费周折，想想看这样的推动得耗费多大人力。况且即使改了，之前的代码也都不兼容了，这不得被人们骂死啊。</p><p>再看最后一行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DB 0x55, 0xaa</span><br></pre></td></tr></table></figure><p>这也验证了我们之前说的这 512 字节的最后两个字节得是 0x55 0xaa，BIOS 才会认为它是一个启动区，才会去加载它，仅此而已。</p><p>回过头来说 0x7c00 这个值，它其实就是一个规定死的值，但还是会有人问，那必然有它的合理性吧。其实，我的解释也只能说是人家规定了这个值，后人们替他们解释这个合理性，并不是说当初人家就一定是这样想的，就好比我们做语文的阅读理解题一样。</p><p>第一个 BIOS 开发团队是 IBM PC 5150 BIOS，当时被认为的第一个操作系统是 DOS 1.0 操作系统，BIOS 团队就假设是为它服务的。但操作系统还没出，BIOS 团队假设其操作系统需要的最小内存为 32 KB。BIOS 希望自己所加载的启动区代码尽量靠后，这样比较“安全”，不至于过早的被其他程序覆盖掉。可是如果仅仅留 512 字节又感觉太悬了，还有一些栈空间需要预留，那扩大到 1 KB 吧。这样 32 KB 的末尾是 0x8000，减去 1KB(0x400) ，刚好等于 0x7c00。哇塞，太精准了，这可以是一种解释方式。</p><h3 id="启动区里的代码写了啥"><a href="#启动区里的代码写了啥" class="headerlink" title="启动区里的代码写了啥"></a>启动区里的代码写了啥</h3><p>启动区里的代码写了啥？就 512 字节就是全部操作系统内容了？</p><p>这是一个好问题，512 个字节确实干不了啥，现在的操作系统怎么也得按 M 为单位算吧，512 个字节远远不够呢，那是怎么回事呢？</p><p>其实我们可以按照之前的思路猜测，BIOS 用很少的代码就把 512 字节的启动区内容加载到了内存，并跳转过去开始执行。那按照这个套路，这 512 字节的启动区代码，是不是也可以把更多磁盘中存储的操作系统程序，加载到内存的某个位置，然后跳转过去呢？</p><p>没错，就是这个套路。<strong>所以 BIOS 负责加载了启动区，而启动区又负责加载真正的操作系统内核</strong>，这配合默契吧？</p><p>由于用于启动盘的磁盘是人家写操作系统的厂商制作的，俗称制作启动盘，所以他也肯定知道操作系统的核心代码存储在磁盘的哪个扇区，因此启动区就把这个扇区，以及之后的好多好多扇区（具体取决于操作系统有多大）都读到内存中，然后跳转到开始的程序开始的位置。跳转到哪里呢？这个就不像 0x7c00 这个数那么经典了，不同的操作系统肯定也不一样，也不用事先规定好，反正写操作系统的人给自己定一个就好了，别覆盖其他关键设备用到的区域就好。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>好了现在经过好几轮跳跳跳，终于跳到内核代码啦，我们来一起回顾一下：</p><ul><li>按下开机键，CPU 将 PC 寄存器的值强制初始化为 0xffff0，这个位置是 BIOS 程序的入口地址（一跳）</li><li>该入口地址处是一个跳转指令，跳转到 0xfe05b 位置，开始执行（二跳）</li><li>执行了一些硬件检测工作后，最后一步将启动区内容加载到内存 0x7c00，并跳转到这里（三跳）</li><li>启动区代码主要是加载操作系统内核，并跳转到加载处（四跳）</li></ul><p>经过这连续的四次跳跃，终于来到了操作系统的世界了。</p><p>剩下的内容，可以说是整个操作系统课程所讲述的原理： 分段、分页、建立中断、设备驱动、内存管理、进程管理、文件系统、用户态接口等等。</p><h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p><a href="https://blog.csdn.net/wwwlyj123321/article/details/99940786">cpu的位宽、操作系统的位宽和寻址能力的关系</a></p><p><img src="/2022/04/18/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E6%8C%89%E4%B8%8B%E5%BC%80%E6%9C%BA%E9%94%AE/img.png"></p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PPT与超级汽车系列之UML类图</title>
      <link href="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/"/>
      <url>/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<h3 id="什么是类图"><a href="#什么是类图" class="headerlink" title="什么是类图"></a>什么是类图</h3><p>类图(Class diagram)主要用于描述系统的结构化设计。类图也是最常用的UML图，用类图可以显示出类、接口以及它们之间的静态结构和关系。</p><h3 id="UML类图图示样例"><a href="#UML类图图示样例" class="headerlink" title="UML类图图示样例"></a>UML类图图示样例</h3><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img.png"></p><h3 id="UML类图模型元素"><a href="#UML类图模型元素" class="headerlink" title="UML类图模型元素"></a>UML类图模型元素</h3><p>在类图中一共包含了以下几种模型元素，分别是：类（Class）、接口（Interface）以及类之间的关系。</p><p>各种关系的强弱顺序：</p><p><strong>泛化 = 实现 &gt; 组合 &gt; 聚合 &gt; 关联 &gt; 依赖</strong></p><h4 id="类-Class"><a href="#类-Class" class="headerlink" title="类(Class)"></a>类(Class)</h4><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_2.png"></p><p>类图分三层: </p><ul><li>第一层显示类的名称，如果是抽象类，则就用斜体显示。</li><li>第二层是类的特性，通常就是字段和属性。</li><li>第三层是类的操作，通常是方法或行为。<ul><li>注意前面的符号，‘+’表示public，‘-’表示private，‘#’表示protected。”</li></ul></li></ul><p>示例如下：</p><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_1.png"></p><h4 id="接口-Interface"><a href="#接口-Interface" class="headerlink" title="接口(Interface)"></a>接口(Interface)</h4><p>与类图的区别主要是顶端有&lt;<interface>&gt;显示。第一行是接口名称，第二行是接口方法。</interface></p><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_4.png"></p><p>接口还有另一种表示方法，俗称棒棒糖表示法，比如图中的唐老鸭类就是实现了‘讲人话’的接口。”</p><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_5.png"></p><h4 id="类图中关系"><a href="#类图中关系" class="headerlink" title="类图中关系"></a>类图中关系</h4><p>在UML类图中，常见的有以下几种关系: 泛化（Generalization）, 实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)</p><h5 id="泛化-继承"><a href="#泛化-继承" class="headerlink" title="泛化-继承"></a>泛化-继承</h5><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_6.png"></p><p>【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。</p><p>例如：鸟是动物的一种，即有鸟的特性也有动物的共性。</p><p>【箭头指向】：带空心三角箭头的实线，箭头指向父类</p><h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_7.png"></p><p>【实现关系】：是一种类与接口的关系，表示类是接口所有特征和行为的实现.</p><p>【箭头指向】：带空心三角箭头的虚线，箭头指向接口</p><h5 id="关联"><a href="#关联" class="headerlink" title="关联"></a>关联</h5><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_8.png"></p><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_9.png"></p><p>【关联关系】：是一种拥有的关系，它使一个类知道另一个类的属性和方法；如：老师与学生，</p><p>丈夫与妻子关联可以是双向的，也可以是单向的。</p><p>双向的关联可以有两个箭头或者没有箭头，单向的关联有一个箭头。</p><p>【代码体现】：成员变量</p><p>【箭头及指向】：带普通箭头的实心线，指向被拥有者</p><h5 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h5><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_10.png"></p><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_11.png"></p><p>【聚合关系】：是整体与部分的关系，且部分可以离开整体而单独存在。</p><p>聚合表示一种弱的‘拥有’关系，体现的是A对象可以包含B对象，但B对象不是A对象的一部分。</p><p>如车和轮胎是整体和部分的关系，轮胎离开车仍然可以存在。</p><p>聚合关系是关联关系的一种，是强的关联关系；关联和聚合在语法上无法区分，必须考察具体的逻辑关系。</p><p>【代码体现】：成员变量</p><p>【箭头及指向】：带空心菱形的实心线，菱形指向整体</p><h5 id="组合"><a href="#组合" class="headerlink" title="组合"></a>组合</h5><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_12.png"></p><p>【组合关系】：是整体与部分的关系，但部分不能离开整体而单独存在。</p><p>一种强的‘拥有’关系，体现了严格的部分和整体的关系，部分和整体的生命周期一样。是关联关系的一种，是比聚合关系还要强的关系，部分和整体的生命周期一样。</p><p>如公司和部门是整体和部分的关系，没有公司就不存在部门。</p><p>它要求普通的聚合关系中代表整体的对象负责代表部分的对象的生命周期。</p><p>【代码体现】：成员变量</p><p>【箭头及指向】：带实心菱形的实线，菱形指向整体</p><h5 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h5><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_13.png"></p><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_14.png"></p><p>【依赖关系】：是一种使用的关系，即一个类的实现需要另一个类的协助，</p><p>所以要尽量不使用双向的互相依赖.</p><p>【代码表现】：局部变量、方法的参数或者对静态方法的调用</p><p>【箭头及指向】：带箭头的虚线，指向被使用者</p><h3 id="类图绘制要点"><a href="#类图绘制要点" class="headerlink" title="类图绘制要点"></a>类图绘制要点</h3><ol><li><p>类的操作是针对类自身的操作，而不是它去操作人家。比如书这个类有上架下架的操作，是书自己被上架下架，不能因为上架下架是管理员的动作而把它放在管理员的操作里。</p></li><li><p>两个相关联的类，需要在关联的类中加上被关联类的ID，并且箭头指向被关联类。可以理解为数据表中的外键。比如借书和书，借书需要用到书的信息，因此借书类需包含书的ID，箭头指向书。</p></li><li><p>由于业务复杂性，一个显示中的实体可能会被分为多个类，这是很正常的，类不是越少越好。类的设计取决于怎样让后台程序的操作更加简单。比如单看逻辑，借书类可以不存在，它的信息可以放在书这个类里。然而借还书和书的上架下架完全不是一回事，借书类对借书的操作更加方便，不需要去重复改动书这个类中的内容。此外，如果书和借书是1对多的关系，那就必须分为两个类。</p></li><li><p>类图中的规范问题，比如不同关系需要不同的箭头，可见性符号等。</p></li></ol><h3 id="类图分类"><a href="#类图分类" class="headerlink" title="类图分类"></a>类图分类</h3><p>软件在分析与设计两个阶段各自会绘制一套UML类图，而且是由分析师和设计师两个不同的角色绘制的。</p><p>一般情况下，分析师绘制的UML类图叫做“领域UML类图”，而设计师绘制的UML类图叫做“实现UML类图”。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这里要声明，这两个名词是并不是大家都认同的通用叫法。</span><br></pre></td></tr></table></figure><h4 id="领域UML类图"><a href="#领域UML类图" class="headerlink" title="领域UML类图"></a>领域UML类图</h4><p>产生于分析阶段，由系统分析师绘制，主要作用是描述业务实体的静态结构，包括业务实体、各个业务实体所具有的业务属性及业务操作、业务实体之间具有的关系。</p><p>虽然这个UML类图也叫“UML类图”，但是说实话，它和编程中的“类”实在是没啥关系，因为最后的系统中可能根本没有类和它们对应，而且很多最后系统中的类如控制类和界面类这套UML类图中也没有。也就是说这套图和具体技术无关，也不是画给程序员看的，它只是表达业务领域中的一个静态结构。</p><p><img src="/2022/04/12/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/PPT%E4%B8%8E%E8%B6%85%E7%BA%A7%E6%B1%BD%E8%BD%A6%E7%B3%BB%E5%88%97%E4%B9%8BUML%E7%B1%BB%E5%9B%BE/img_15.png"></p><p>这是一个选课系统的简单领域分析UML类图。可以看到，主要实体有教师、学生、课程和开课安排。每个实体标注了其在业务上具有的属性和方法。而且图中还标明了实体间的关系。</p><p>但是，最终系统中可能没有一个学生类和其对应。 因为最终系统中有哪些类、各个类有什么属性、方法依赖于所选择的平台和架构。例如，如果使用了Struts2，则会存在很多Action类，而使用了ASP.NETMVC，则会有很多Controller类等，所以，领域UML类图只于业务有关，和具体实现及编码等计算机技术无关。</p><h4 id="实现UML类图"><a href="#实现UML类图" class="headerlink" title="实现UML类图"></a>实现UML类图</h4><p>产生于设计阶段，由系统设计师绘制，其作用是描述系统的架构结构、指导程序员编码。它包括系统中所有有必要指明的实体类、控制类、界面类及与具体平台有关的所有技术性信息。</p><p>就像上面的领域UML类图，如果你把它交给程序员编码，我想程序员会疯掉，因为它没有提供任何编码的依据。假如我们使用的是.NET平台分层架构，并使用ASP.NETMVC，则设计师应该在实现UML类图中绘制出所有的实体类、数据访问类、业务逻辑类和界面类，界面类又分为视图类、控制器类等等，还要表示出IoC和Aop等信息，并明确指出各个类的属性、方法，不能有遗漏，因为最终程序员实现程序的依据就是实现UML类图。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>最后，我们总结一下要点：</p><ul><li>软件分析与设计是编码前的两个阶段，其中分析仅与业务有关，而与技术无关。设计以分析为基础，主要与具体技术有关。</li><li>分析阶段由分析师绘制领域UML类图，设计阶段由设计师绘制实现UML类图。</li><li>领域UML类图表示系统的静态领域结构，其中的类不与最终程序中的类对应；设计UML类图表示系统的技术架构，是程序员的编码依据，其中的类与系统中的类对应。</li><li>领域UML类图中类的属性与操作仅关注与业务相关的部分，实现UML类图中的属性与操作要包括最终需要实现的全部方法与操作。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一个注解搞定重试机制之spring-retry框架</title>
      <link href="/2022/04/11/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E4%B8%80%E4%B8%AA%E6%B3%A8%E8%A7%A3%E6%90%9E%E5%AE%9A%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6%E4%B9%8Bspring-retry%E6%A1%86%E6%9E%B6/"/>
      <url>/2022/04/11/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E4%B8%80%E4%B8%AA%E6%B3%A8%E8%A7%A3%E6%90%9E%E5%AE%9A%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6%E4%B9%8Bspring-retry%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在实际工作中，重处理是一个非常常见的场景，比如:</p><ul><li>发送消息失败。</li><li>调用远程服务失败。</li><li>争抢锁失败。</li></ul><p>这些错误可能是因为网络波动造成的，等待过后重处理就能成功。</p><p>通常来说，会用try/catch，while循环之类的语法来进行重处理，但是这样的做法缺乏统一性，并且不是很方便，要多写很多代码。</p><p>然而spring-retry却可以通过注解，在不入侵原有业务逻辑代码的方式下，优雅的实现重处理功能。</p><h3 id="Retryable是什么？"><a href="#Retryable是什么？" class="headerlink" title="@Retryable是什么？"></a>@Retryable是什么？</h3><p>spring系列的spring-retry是另一个实用程序模块，可以帮助我们以标准方式处理任何特定操作的重试。</p><p>在spring-retry中，所有配置都是基于简单注释的。</p><h3 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h3><h4 id="POM依赖"><a href="#POM依赖" class="headerlink" title="POM依赖"></a>POM依赖</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.2.5.RELEASE&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h4 id="启用-Retryable"><a href="#启用-Retryable" class="headerlink" title="启用@Retryable"></a>启用@Retryable</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@EnableRetry</span><br><span class="line">@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class&#125;)</span><br><span class="line">public class Application &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        ApplicationContext ctx = SpringApplication.run(Application.class, args);</span><br><span class="line">        // 针对404错误，抛出异常</span><br><span class="line">        DispatcherServlet dispatcherServlet = (DispatcherServlet) ctx.getBean(&quot;dispatcherServlet&quot;);</span><br><span class="line">        dispatcherServlet.setThrowExceptionIfNoHandlerFound(true);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="在方法上添加-Retryable"><a href="#在方法上添加-Retryable" class="headerlink" title="在方法上添加@Retryable"></a>在方法上添加@Retryable</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">@Slf4j</span><br><span class="line">@Service</span><br><span class="line">public class RetryServiceImpl implements IRetryService &#123;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * value：抛出指定异常才会重试</span><br><span class="line">     * include：和value一样，默认为空，当exclude也为空时，默认所有异常</span><br><span class="line">     * exclude：指定不处理的异常</span><br><span class="line">     * maxAttempts：最大重试次数，默认3次</span><br><span class="line">     * backoff：重试等待策略，默认使用@Backoff，@Backoff的value默认为1000L，我们设置为2000L；multiplier（指定延迟倍数）默认为0，表示固定暂停1秒后进行重试，如果把multiplier设置为1.5，则第一次重试为2秒，第二次为3秒，第三次为4.5秒。</span><br><span class="line">     */</span><br><span class="line">    @Override</span><br><span class="line">    @Retryable(value = IllegalStateException.class, maxAttempts = 3, backoff = @Backoff(delay = 2000, multiplier = 1.5))</span><br><span class="line">    public int retryTest(int code) throws Exception &#123;</span><br><span class="line">        log.info(&quot;请求方法执行，时间: &#123;&#125;&quot;, System.currentTimeMillis());</span><br><span class="line">        if (code == 0) &#123;</span><br><span class="line">            throw new IllegalStateException(&quot;情况不对头！&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        log.info(&quot;情况对头了！&quot;);</span><br><span class="line">        return 200;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单解释一下注解种几个参数的含义：</p><ul><li>value：抛出指定异常才会重试</li><li>include：和value一样，默认为空，当exclude也为空时，默认所有异常</li><li>exclude：指定不处理的异常</li><li>maxAttempts：最大重试次数，默认3次</li><li>backoff：重试等待策略，默认使用@Backoff，@Backoff的value默认为1000L，我们设置为2000L；multiplier（指定延迟倍数）默认为0，表示固定暂停1秒后进行重试，如果把multiplier设置为1.5，则第一次重试为2秒，第二次为3秒，第三次为4.5秒。</li></ul><p>当重试耗尽还是失败时，会出现什么情况呢？</p><p>当重试耗尽时，RetryOperations可以将控制传递给另一个回调，即RecoveryCallback。</p><p>Spring-Retry还提供了@Recover注解，用于@Retryable重试失败后处理方法。</p><p>如果不需要回调方法，可以直接不写回调方法，那么实现的效果是，重试次数完了后，如果还是没成功没符合业务判断，就抛出异常。</p><h4 id="Recover"><a href="#Recover" class="headerlink" title="@Recover"></a>@Recover</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@Recover</span><br><span class="line">public int recover(IllegalStateException e, int code) &#123;</span><br><span class="line">    log.info(&quot;回调方法执行&quot;);</span><br><span class="line">    return 400;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到传参里面写的是 Exception e，这个是作为回调的接头暗号（重试次数用完了，还是失败，我们抛出这个Exception e通知触发这个回调方法）。</p><p>对于@Recover注解的方法，需要特别注意的是：</p><ul><li>方法的返回值必须与@Retryable方法一致</li><li>方法的第一个参数，必须是Throwable类型的，建议是与@Retryable配置的异常一致，其他的参数，需要哪个参数，写进去就可以了（@Recover方法中有的）</li><li>该回调方法与重试方法写在同一个实现类里面</li></ul><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ul><li>由于是基于AOP实现，所以不支持类里自调用方法</li><li>如果重试失败需要给@Recover注解的方法做后续处理，那这个重试的方法不能有返回值，只能是void</li><li>方法内不能使用try catch，只能往外抛异常</li><li>@Recover注解来开启重试失败后调用的方法(注意,需跟重处理方法在同一个类中)，此注解注释的方法参数一定要是@Retryable抛出的异常，否则无法识别，可以在该方法中进行日志处理。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> 重试 </tag>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis消息队列发展历程</title>
      <link href="/2022/04/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Redis/Redis%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/"/>
      <url>/2022/04/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Redis/Redis%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>文档说明： 转自<a href="https://mp.weixin.qq.com/s/gCUT5TcCQRAxYkTJfTRjJw">阿里开发者-阿里巴巴官方技术号</a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Redis是目前最受欢迎的kv类数据库，当然它的功能越来越多，早已不限定在kv场景，消息队列就是Redis中一个重要的功能。</p><p>Redis从2010年发布1.0版本就具备一个消息队列的雏形，随着10多年的迭代，其消息队列的功能也越来越完善，作为一个全内存的消息队列，适合应用与要求高吞吐、低延时的场景。</p><p>我们来盘一下Redis消息队列功能的发展历程，历史版本有哪些不足，后续版本是如何来解决这些问题的。</p><p><img src="/2022/04/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Redis/Redis%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/img.png"></p><h2 id="Redis1-0-List"><a href="#Redis1-0-List" class="headerlink" title="Redis1.0 - List"></a>Redis1.0 - List</h2><p>从广义上来讲消息队列就是一个队列的数据结构。</p><p>生产者从队列一端放入消息，消费者从另一端读取消息，消息保证先入先出的顺序。</p><p>一个本地的list数据结构就是一个进程维度的消息队列，它可以让模块A写入消息，模块B消费消息，做到模块A/B的解耦与异步化。</p><p>但想要做到应用级别的解耦和异步还需要一个消息队列的服务。</p><h3 id="List的特性"><a href="#List的特性" class="headerlink" title="List的特性"></a>List的特性</h3><p>Redis 1.0发布时就具备了list数据结构，应用A可以通过lpush写入消息，应用B通过rpop从队列中读取消息，每个消息只会被读取一次，而且是按照lpush写入的顺序读到。同时Redis的接口是并发安全的，可以同时有多个生产者向一个list中生产消息，多个消费者从list中读取消息。</p><p>这里还有个问题，消费者要如何知道list中有消息了，需要不断轮询去查询吗。</p><p>轮询无法保证消息被及时的处理，会增加延时，而且当list为空时，大部分轮询的请求都是无效请求，这种方式大量浪费了系统资源。</p><p>好在Redis有<strong>brpop接口</strong>，该接口有一个参数是超时时间，如果list为空，那么Redis服务端不会立刻返回结果，它会等待list中有新数据后在返回或是等待最多一个超时时间后返回空。</p><p>通过brpop接口实现了<strong>长轮询</strong>，该效果等同于服务端推送，消费者能立刻感知到新的消息，而且通过设置合理的超时时间，使系统资源的消耗降到很低。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">基于list完成消息的生产和消费</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">生产者生产消息msg1</span></span><br><span class="line">lpush listA msg1</span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">消费者读取到消息msg1</span></span><br><span class="line">rpop listA</span><br><span class="line">&quot;msg1&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">消费者阻塞式读取listA，如果有数据立刻返回，否则最多等待10秒</span></span><br><span class="line">brpop listA 10 </span><br><span class="line">1) &quot;listA&quot;</span><br><span class="line">2) &quot;msg1&quot;</span><br></pre></td></tr></table></figure><p><img src="/2022/04/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Redis/Redis%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/img_1.png"></p><p>使用rpop或brpop这样接口消费消息会先从队列中删除消息，然后再由应用消费，如果应用应用在处理消息前异常宕机了，<strong>消息就丢失了</strong>。</p><p>但如果使用lindex这样的只读命令先读取消息处理完毕后在删除，又需要额外的机制来<strong>保证一条消息不会被其他消费者重复读到</strong>。</p><p>好在list有<strong>rpoplpush或brpoplpush</strong>这样的接口，可以原子性的从一个list中移除一个消息并加入另一个list。</p><p>应用程序可以<strong>通过2个list组和来完成消息的消费和确认功能</strong>，使用rpoplpush从list A中消费消息并移入list B，等消息处理完毕后在从list B中删除消息，如果在处理消息过程中应用异常宕机，恢复后应用可以重新从list B中读取未处理的消息并处理。</p><p><strong>这种方式为消息的消费增加了ack机制</strong>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">基于2个list完成消息消费和确认</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">从listA中读取消息并写入listB</span></span><br><span class="line">rpoplpush listA listB</span><br><span class="line">&quot;msg1&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">业务逻辑处理msg1完毕后，从listB中删除msg1，完成消息的确认</span></span><br><span class="line">lrem listB 1 msg1</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p><img src="/2022/04/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Redis/Redis%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/img_2.png"></p><h3 id="List的不足之处"><a href="#List的不足之处" class="headerlink" title="List的不足之处"></a>List的不足之处</h3><p>通过Redis 1.0就引入的list结构我们就能实现一个分布式的消息队列，满足一些简单的业务需求。</p><p>但list结构作为消息队列服务有一个很致命的问题，它<strong>没有广播功能，一个消息只能被消费一次</strong>。</p><p>而在大型系统中，通常一个消息会被下游多个应用同时订阅和消费，例如当用户完成一个订单的支付操作时，需要通知商家发货，要更新物流状态，可能还会提高用户的积分和等级，这些都是不同的下游子系统，他们全部会订阅支付完成的操作，而list一个消息只能被消费一次在这样复杂的大型系统面前就捉襟见肘了。</p><p>可能你会说那弄多个list，生产者向每个list中都投递消息，每个消费者处理自己的list不就行了吗。这样第一是性能不会太好，因为同一个消息需要被重复的投递，第二是这样的设计违反了生产者和消费者解耦的原则，这个设计下生产者需要知道下游有哪些消费者，如果业务发生变化，需要额外增加一个消费者，生产者的代码也需要修改。</p><h3 id="List总结"><a href="#List总结" class="headerlink" title="List总结"></a>List总结</h3><h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul><li>模型简单，和使用本地list基本相同，适配容易</li><li>通过brpop做到消息处理的实时性 </li><li>通过rpoplpush来联动2个list，可以做到消息先消费后确认，避免消费者应用异常情况下消息丢失</li></ul><h4 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h4><ul><li>消息只能被消费一次，缺乏广播机制</li></ul><h2 id="Redis2-0-Pub-Sub"><a href="#Redis2-0-Pub-Sub" class="headerlink" title="Redis2.0 - Pub/Sub"></a>Redis2.0 - Pub/Sub</h2><p>list作为消息队列应用场景受到限制很重要的原因在于没有广播，所以Redis 2.0中引入了一个新的数据结构 pubsub 。</p><p>pubsub虽然不能算作是list的替代品，但它确实能解决一些list不能解决的问题。</p><h3 id="pubsub特性"><a href="#pubsub特性" class="headerlink" title="pubsub特性"></a>pubsub特性</h3><p>pubsub引入一个概念叫channel，生产者通过publish接口投递消息时会指定channel，消费者通过subscribe接口订阅它关心的channel，调用subscribe后这条连接会进入一个特殊的状态，通常不能在发送其他请求，当有消息投递到这个channel时Redis服务端会立刻通过该连接将消息推送到消费者。</p><p>这里一个channel可以被多个应用订阅，消息会同时投递到每个订阅者，做到了消息的广播。</p><p>另一方面，消费者可以会订阅一批channel，例如一个用户订阅了浙江的新闻的推送，但浙江新闻还会进行细分，例如“浙江杭州xx”、“浙江温州xx”，这里订阅者不需要获取浙江的所有子类在挨个订阅，只需要调用psubscribe“浙江*”就能订阅所有以浙江开头的新闻推送了，这里psubscribe传入一个通配符表达的channel，Redis服务端按照规则推送所有匹配channel的消息给对应的客户端。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">基于pubsub完成channel的匹配和消息的广播</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">消费者1订阅channel1</span></span><br><span class="line">subscribe channel1</span><br><span class="line">1) &quot;subscribe&quot;</span><br><span class="line">2) &quot;channel1&quot;</span><br><span class="line">3) (integer) 1</span><br><span class="line"><span class="meta">#</span><span class="bash">收到消息推送</span></span><br><span class="line">1) &quot;message&quot;</span><br><span class="line">2) &quot;channel1&quot;</span><br><span class="line">3) &quot;msg1&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">消费者2订阅channel*</span></span><br><span class="line">psubscribe channel*</span><br><span class="line">1) &quot;psubscribe&quot;</span><br><span class="line">2) &quot;channel*&quot;</span><br><span class="line">3) (integer) 1</span><br><span class="line"><span class="meta">#</span><span class="bash">收到消息推送</span></span><br><span class="line">1) &quot;pmessage&quot;</span><br><span class="line">2) &quot;channel*&quot;</span><br><span class="line">3) &quot;channel1&quot;</span><br><span class="line">4) &quot;msg1&quot;</span><br><span class="line">1) &quot;pmessage&quot;</span><br><span class="line">2) &quot;channel*&quot;</span><br><span class="line">3) &quot;channel2&quot;</span><br><span class="line">4) &quot;msg2&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">生产者发布消息msg1和msg2</span></span><br><span class="line">publish channel1 msg1</span><br><span class="line">(integer) 2</span><br><span class="line">publish channel2 msg2</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p><img src="/2022/04/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Redis/Redis%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/img_3.png"></p><p>在Redfis 2.8时加入了<a href="https://blog.51cto.com/u_15346415/5188764">keyspace notifications功能</a></p><p>此时pubsub除了通知用户自定义消息，也可以通知系统内部消息。</p><p>keyspace notifications引入了2个特殊的channel分别是 <code>__keyevent@&lt;db&gt;__:&lt;event&gt;</code> 和 <code>__keyspace@&lt;db&gt;__:&lt;key&gt;</code>, 可以通过开启配置notify-keyspace-events使用</p><details><summary>notify-keyspace-events</summary>服务器配置的notify-keyspace-events选项决定了服务器所发送通知的类型：<p>可以设置的类型如下：</p><ul><li>想让服务器发送所有类型的键空间通知和键事件通知，可以将选项的值设置为AKE</li><li>想让服务器发送所有类型的键空间通知，可以将选项的值设置为AK</li><li>想让服务器发送所有类型的键事件通知，可以将选项的值设置为AE</li><li>想让服务器只发送和字符串键有关的键空间通知，可以将选项的值设置为K$</li><li>想让服务器只发送和列表键有关的键事件通知，可以将选项的值设置为El<br>备注：notify-keyspace-events选项的默认值为空，所以如果不设置上面的值，SUBSCRIBE命令不会有任何效果</li></ul></details><p><strong>键空间通知</strong></p><p>某个键执行了什么命令, 通过订阅__keyspace客户端可以收到目标key的增删改操作以及过期事件。</p><details><summary>键空间通知演示案例</summary><ol><li><p>先将notify-keyspace-events选项设置为“AKE”，表示服务器可以发送所有类型的键空间通知和键事件通知</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; CONFIG SET notify-keyspace-events AKE</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; CONFIG GET notify-keyspace-events</span><br><span class="line">1) &quot;notify-keyspace-events&quot;</span><br><span class="line">2) &quot;AKE&quot;</span><br></pre></td></tr></table></figure></li><li><p>使用下面命令开启对0号数据库中的message键的监视，可以获取其通知消息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SUBSCRIBE __keyspace@0__:message</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) &quot;subscribe&quot;</span><br><span class="line">2) &quot;__keyspace@0__:message&quot;</span><br><span class="line">3) (integer) 1</span><br></pre></td></tr></table></figure></li><li><p>我们在另一个客户端命令行先后用SET、EXPIRE、DEL三个命令对键message进行了操作</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">```shell</span><br><span class="line">127.0.0.1:6379&gt; set message HellowWorld</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; expire message 500</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; del message</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure></li><li><p>可以看到监听一端接收到了服务端发来的message键更改的通知</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SUBSCRIBE __keyspace@0__:message</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) &quot;subscribe&quot;</span><br><span class="line">2) &quot;__keyspace@0__:message&quot;</span><br><span class="line">3) (integer) 1</span><br><span class="line"></span><br><span class="line">1) &quot;message&quot;</span><br><span class="line">2) &quot;__keyspace@0__:message&quot;</span><br><span class="line">3) &quot;set&quot;</span><br><span class="line">4) &quot;message&quot;</span><br><span class="line">5) &quot;__keyspace@0__:message&quot;</span><br><span class="line">6) &quot;expire&quot;</span><br><span class="line">7) &quot;message&quot;</span><br><span class="line">8) &quot;__keyspace@0__:message&quot;</span><br><span class="line">9) &quot;del&quot;</span><br></pre></td></tr></table></figure></li></ol></details><p><strong>键事件通知</strong></p><p>某个命令被什么键执行了, 通过订阅__keyevent客户端可以收到某个具体命令调用的回调通知，</p><details><summary>键事件通知演示案例</summary>  <ol><li><p>先将notify-keyspace-events选项设置为“AKE”，表示服务器可以发送所有类型的键空间通知和键事件通知</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; CONFIG SET notify-keyspace-events AKE</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; CONFIG GET notify-keyspace-events</span><br><span class="line">1) &quot;notify-keyspace-events&quot;</span><br><span class="line">2) &quot;AKE&quot;</span><br></pre></td></tr></table></figure></li><li><p>下面代码展示了客户端如何获取0号数据库中所有执行DEL命令的键</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SUBSCRIBE __keyevent@0__:del</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) &quot;subscribe&quot;</span><br><span class="line">2) &quot;__keyevent@0__:del&quot;</span><br><span class="line">3) (integer) 1</span><br></pre></td></tr></table></figure></li><li><p>我们在另一个客户端命令行执行2次del命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; del key</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; del message</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure></li><li><p>可以看到监听一端接收到了服务端发来的del通知</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SUBSCRIBE __keyevent@0__:del</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) &quot;subscribe&quot;</span><br><span class="line">2) &quot;__keyevent@0__:del&quot;</span><br><span class="line">3) (integer) 1</span><br><span class="line"></span><br><span class="line">1) &quot;message&quot;</span><br><span class="line">2) &quot;__keyevent@0__:del&quot;</span><br><span class="line">3) &quot;key&quot;</span><br><span class="line">1) &quot;message&quot;</span><br><span class="line">2) &quot;__keyevent@0__:del&quot;</span><br><span class="line">3) &quot;message&quot;</span><br></pre></td></tr></table></figure></li></ol></details><h3 id="pubsub的不足之处"><a href="#pubsub的不足之处" class="headerlink" title="pubsub的不足之处"></a>pubsub的不足之处</h3><p>pubsub既能单播又能广播，还支持channel的简单正则匹配，功能上已经能满足大部分业务的需求，而且这个接口发布的时间很早，在2011年Redis 2.0发布时就已经具备，用户基础很广泛，所以现在很多业务都有用到这个功能。</p><p>但你要深入了解pubsub的原理后，是肯定不敢把它作为一个一致性要求较高，数据量较大系统的消息服务的。</p><p>首先，pubsub的消息数据是瞬时的，它在Redis服务端不做保存，publish发送到Redis的消息会立刻推送到所有当时subscribe连接的客户端，如果当时客户端因为网络问题断连，那么就会错过这条消息，当客户端重连后，它没法重新获取之前那条消息，甚至无法判断是否有消息丢失。</p><p>其次，pubsub中消费者获取消息是一个推送模型，这意味着Redis会按消息生产的速度给所有的消费者推送消息，不管消费者处理能力如何，如果消费者应用处理能力不足，消息就会在Redis的client buf中堆积，当堆积数据超过一个阈值后会断开这条连接，这意味着这些消息全部丢失了，在也找不回来了。如果同时有多个消费者的client buf堆积数据但又还没达到断开连接的阈值，那么Redis服务端的内存会膨胀，进程可能因为oom而被杀掉，这导致了整个服务中断。</p><h3 id="pubsub总结"><a href="#pubsub总结" class="headerlink" title="pubsub总结"></a>pubsub总结</h3><h4 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a>优势</h4><ul><li>消息具备广播能力</li><li>psubscribe能按字符串通配符匹配，给予了业务逻辑的灵活性</li><li>能订阅特定key或特定命令的系统消息<h4 id="不足-1"><a href="#不足-1" class="headerlink" title="不足"></a>不足</h4></li><li>Redis异常、客户端断连都会导致消息丢失</li><li>消息缺乏堆积能力，不能削峰填谷。推送的方式缺乏背压机制，没有考虑消费者处理能力，推送的消息超过消费者处理能力后可能导致消息丢失或服务异常。</li></ul><h2 id="Redis5-0-stream"><a href="#Redis5-0-stream" class="headerlink" title="Redis5.0 - stream"></a>Redis5.0 - stream</h2><p>消息丢失、消息服务不稳定的问题严重限制了pubsub的应用场景，所以Redis需要重新设计一套机制，来解决这些问题，这就有了后来的stream结构。</p><h3 id="stream特性"><a href="#stream特性" class="headerlink" title="stream特性"></a>stream特性</h3><p>一个稳定的消息服务需要具备几个要点：</p><ul><li>要保证消息不会丢失</li><li>至少被消费一次，</li><li>要具备削峰填谷的能力，来匹配生产者和消费者吞吐的差异。</li></ul><p>在2018年Redis 5.0加入了stream结构，这次考虑了list、pubsub在应用场景下的缺陷，对标kafka的模型重新设计全内存消息队列结构，从这时开始Redis消息队列功能算是能和主流消息队列产品pk一把了。</p><p><img src="/2022/04/08/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Redis/Redis%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/img_4.png"></p><p>stream的改进分为多个方面</p><p><strong>成本</strong>：</p><ul><li>存储message数据使用了listpack结构，这是一个紧凑型的数据结构，不同于list的双向链表每个节点都要额外占用2个指针的存储空间，这使得小msg情况下stream的空间利用率更高。</li></ul><p><strong>功能</strong>：</p><ul><li>stream引入了消费者组的概念，一个消费者组内可以有多个消费者，同一个组内的消费者共享一个消息位点（last_delivered_id），这使得消费者能够水平的扩容，可以在一个组内加入多个消费者来线性的提升吞吐，对于一个消费者组，每条msg只会被其中一个消费者获取和处理，这是pubsub的广播模型不具备的。</li><li>不同消费者组之前是相互隔离的，他们各自维护自己的位点，这使得一条msg能被多个不同的消费者组重复消费，做到了消息广播的能力。</li><li>stream中消费者采用拉取的方式，并能设置timeout在没有消息时阻塞，通过这种长轮询机制保证了消息的实时性，而且消费速率是和消费者自身吞吐相匹配。</li></ul><p><strong>消息不丢失</strong>：</p><ul><li>stream的数据会存储在aof和rdb文件中，这使Redis重启后能够恢复stream的数据。而pubsub的数据是瞬时的，Redis重启意味着消息全部丢失。</li><li>stream中每个消费者组会存储一个last_delivered_id来标识已经读取到的位点，客户端连接断开后重连还是能从该位点继续读取，消息不会丢失。</li><li>stream引入了ack机制保证消息至少被处理一次。<ul><li>考虑一种场景，如果消费者应用已经读取了消息，但还没来得及处理应用就宕机了，对于这种已经读取但没有ack的消息，stream会标示这条消息的状态为pending，等客户端重连后通过xpending命令可以重新读取到pengind状态的消息，继续处理。</li><li>如果这个应用永久宕机了，那么该消费者组内的其他消费者应用也能读取到这条消息，并通过xclaim命令将它归属到自己下面继续处理。</li></ul></li></ul><details><summary>基于stream完成消息的生产和消费，并确保异常状态下消息至少被消费一次</summary><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">创建mystream，并且创建一个consumergroup为mygroup</span></span><br><span class="line">XGROUP CREATE mystream mygroup $ MKSTREAM</span><br><span class="line">OK</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">写入一条消息，由redis自动生成消息id，消息的内容是一个kv数组，这里包含field1 value1 field2 value2</span></span><br><span class="line">XADD mystream * field1 value1 field2 value2</span><br><span class="line">&quot;1645517760385-0&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">消费者组mygroup中的消费者consumer1从mystream读取一条消息，&gt;表示读取一条该消费者组从未读取过的消息</span></span><br><span class="line">XREADGROUP GROUP mygroup consumer1 COUNT 1 STREAMS mystream &gt;</span><br><span class="line">1) 1) &quot;mystream&quot;</span><br><span class="line">   2) 1) 1) &quot;1645517760385-0&quot;</span><br><span class="line">         2) 1) &quot;field1&quot;</span><br><span class="line">            2) &quot;value1&quot;</span><br><span class="line">            3) &quot;field2&quot;</span><br><span class="line">            4) &quot;value2&quot;</span><br><span class="line">            </span><br><span class="line"><span class="meta">#</span><span class="bash">消费完成后ack确认消息</span></span><br><span class="line">xack mystream mygroup 1645517760385-0</span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">如果消费者应用在ack前异常宕机，恢复后重新获取未处理的消息id。</span></span><br><span class="line">XPENDING mystream mygroup - + 10 </span><br><span class="line">1) 1) &quot;1645517760385-0&quot;</span><br><span class="line">   2) &quot;consumer1&quot;</span><br><span class="line">   3) (integer) 305356</span><br><span class="line">   4) (integer) 1</span><br><span class="line">   </span><br><span class="line"><span class="meta"> #</span><span class="bash">如果consumer1永远宕机，其他消费者可以把pending状态的消息移动到自己名下后继续消费</span></span><br><span class="line"><span class="meta"> #</span><span class="bash">将消息id 1645517760385-0移动到consumer2下</span></span><br><span class="line"> XCLAIM mystream mygroup consumer2 0 1645517760385-0</span><br><span class="line"> 1) 1) &quot;1645517760385-0&quot;</span><br><span class="line">   2) 1) &quot;field1&quot;</span><br><span class="line">      2) &quot;value1&quot;</span><br><span class="line">      3) &quot;field2&quot;</span><br><span class="line">      4) &quot;value2&quot;</span><br></pre></td></tr></table></figure></details><p>Redis stream保证了消息至少被处理一次，但如果想做到每条消息仅被处理一次还需要应用逻辑的介入。</p><p>消息被重复处理要么是生产者重复投递，要么是消费者重复消费。</p><ul><li><p>对于生产者重复投递问题，Redis stream为每个消息都设置了一个唯一递增的id，通过参数可以让Redis自动生成id或者应用自己指定id，应用可以根据业务逻辑为每个msg生成id，当xadd超时后应用并不能确定消息是否投递成功，可以通过xread查询该id的消息是否存在，存在就说明已经投递成功，不存在则重新投递，而且stream限制了id必须递增，这意味了已经存在的消息重复投递会被拒绝。这套机制保证了每个消息可以仅被投递一次。</p></li><li><p>对于消费者重复消费的问题，考虑一个场景，消费者读取消息后业务处理完毕，但还没来得及ack就发生了异常，应用恢复后对于这条没有ack的消息进行了重复消费。这个问题因为ack和消费消息的业务逻辑发生在2个系统，没法做到事务性，需要业务来改造，保证消息处理的幂等性。</p></li></ul><h3 id="stream的不足"><a href="#stream的不足" class="headerlink" title="stream的不足"></a>stream的不足</h3><p>stream的模型做到了消息的高效分发，而且保证了消息至少被处理一次，通过应用逻辑的改造能做到消息仅被处理一次，它的能力对标kafka，但吞吐高于kafka，在高吞吐场景下成本比kafka低，那它又有哪些不足了。</p><p>首先消息队列很重要的一个功能就是削峰填谷，来匹配生产者和消费者吞吐的差异，生产者和消费者吞吐差异越大，持续时间越长，就意味着steam中需要堆积更多的消息，而Redis作为一个全内存的产品，<strong>数据堆积的成本比磁盘高</strong>。</p><p>其次stream通过ack机制保证了消息至少被消费一次，但这有个<strong>前提</strong>就是存储在Redis中的消息本身不会丢失。</p><ul><li>Redis数据的持久化依赖aof和rdb文件，aof落盘方式有几种，通过配置appendfsync决定，通常我们不会配置为always来让每条命令执行完后都做一次fsync，线上配置一般为everysec，每秒做一次fsync，而rdb是全量备份时生成，这意味了宕机恢复可能会丢掉最近一秒的数据。</li><li>另一方面线上生产环境的Redis都是高可用架构，当主节点宕机后通常不会走恢复逻辑，而是直接切换到备节点继续提供服务，而Redis的同步方式是异步同步，这意味着主节点上新写入的数据可能还没同步到备节点，在切换后这部分数据就丢失了。所以在<strong>故障恢复中Redis中的数据可能会丢失一部分</strong>，在这样的背景下无论stream的接口设计的多么完善，都不能保证消息至少被消费一次。</li></ul><h3 id="stream总结"><a href="#stream总结" class="headerlink" title="stream总结"></a>stream总结</h3><h4 id="优势-2"><a href="#优势-2" class="headerlink" title="优势"></a>优势</h4><ul><li>在成本、功能上做了很多改进，支持了紧凑的存储小消息、具备广播能力、消费者能水平扩容、具备背压机制</li><li>通过ack机制保证了Redis服务端<strong>正常情况下</strong>消息至少被处理一次的能力</li></ul><h4 id="不足-2"><a href="#不足-2" class="headerlink" title="不足"></a>不足</h4><ul><li>内存型消息队列，数据堆积成本高</li><li>Redis本身rpo&gt;0，故障恢复可能会丢数据，所以stream在Redis发生故障恢复后也<strong>不能保证</strong>消息至少被消费一次。</li></ul><h2 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h2><p>消息队列主要是为了解决3类问题，应用模块的解耦、消息的异步化、削峰填谷。</p><p>目前主流的消息队列都能满足这些需求，所以在实际选型时还会考虑一些特殊的功能是否满足，产品的性能如何，具体业务场景下的成本怎么样，开发的复杂度等。</p><p>Redis的消息队列功能并不是最全面的，它不希望做成一个大而全的产品，而是做一个小而美的产品，服务好一部分用户在某些场景下的需求。</p><p>目前用户选型Redis作为消息队列服务的原因，主要有Redis在相同成本下吞吐更高、Redis的延时更低、应用需要一个消息服务但又不想额外引入一堆依赖等。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AOP实现机制详解与字节码编排技术</title>
      <link href="/2022/04/07/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/AOP%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF/"/>
      <url>/2022/04/07/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/AOP%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<img src="/2022/04/07/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/AOP%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF/04/07/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/AOP%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF/%E5%AD%97%E8%8A%82%E7%A0%81%E5%A2%9E%E5%BC%BA.jpg" class><p>文章说明： 转载自<a href="https://blog.csdn.net/qq_32115439/article/details/78361596">Java-AOP(Hook)实现机制(JDK/cglib动态代理/ASM/Javassist/AspectJ)</a></p><h2 id="AOP的各种实现"><a href="#AOP的各种实现" class="headerlink" title="AOP的各种实现"></a>AOP的各种实现</h2><p>AOP就是面向切面编程，我们可以从几个层面来实现AOP。 </p><p>AOP实现时有三种方式：</p><ul><li>生成子类字节码</li><li>生成代理类字节码</li><li>直接修改原类的字节码。</li></ul><p><img src="/2022/04/07/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/AOP%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF/img.png"></p><p>在编译器修改源代码，在运行期字节码加载前修改字节码或字节码加载后动态创建代理类的字节码，以下是各种实现机制的比较。 </p><table><thead><tr><th>类别</th><th>机制</th><th>原理</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>静态AOP</td><td>静态织入</td><td>在编译期，切面直接以字节码的形式编译到目标字节码文件中。</td><td>对系统无性能影响。</td><td>灵活性不够。</td></tr><tr><td>动态AOP</td><td>动态代理</td><td>在运行期，目标类加载后，为接口动态生成代理类，将切面植入到代理类中。</td><td>相对于静态AOP更加灵活。</td><td>切入的关注点需要实现接口。对系统有一点性能影响。</td></tr><tr><td>动态字节码生成</td><td>在运行期，目标类加载后，动态构建字节码文件生成目标类的子类，将切面逻辑加入到子类中。</td><td>没有接口也可以织入。</td><td>扩展类的实例方法为final时，则无法进行织入。</td><td></td></tr><tr><td>自定义类加载器</td><td>在运行期，目标加载前，将切面逻辑加到目标字节码里。</td><td>可以对绝大部分类进行织入。</td><td>代码中如果使用了其他类加载器，则这些类将不会被织入。</td><td></td></tr><tr><td>字节码转换</td><td>在运行期，所有类加载器加载字节码前，前进行拦截。</td><td>可以对所有类进行织入。</td><td></td><td></td></tr></tbody></table><h2 id="AOP中的公民"><a href="#AOP中的公民" class="headerlink" title="AOP中的公民"></a>AOP中的公民</h2><ul><li>Joinpoint：拦截点，如某个业务方法。</li><li>Pointcut：Joinpoint的表达式，表示拦截哪些方法。一个Pointcut对应多个Joinpoint。</li><li>Advice:  要切入的逻辑。</li><li>Before Advice 在方法前切入。</li><li>After Advice 在方法后切入，抛出异常时也会切入。</li><li>After Returning Advice 在方法返回后切入，抛出异常则不会切入。</li><li>After Throwing Advice 在方法抛出异常时切入。</li><li>Around Advice 在方法执行前后切入，可以中断或忽略原有流程的执行。</li></ul><h3 id="公民之间的关系"><a href="#公民之间的关系" class="headerlink" title="公民之间的关系"></a>公民之间的关系</h3><p><img src="/2022/04/07/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/AOP%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF/img_1.png"></p><p>织入器通过在切面中定义pointcut来搜索目标（被代理类）的JoinPoint(切入点)，然后把要切入的逻辑（Advice）织入到目标对象里，生成代理类。</p><h2 id="AOP的实现机制"><a href="#AOP的实现机制" class="headerlink" title="AOP的实现机制"></a>AOP的实现机制</h2><h3 id="动态代理-JavaAgent"><a href="#动态代理-JavaAgent" class="headerlink" title="动态代理-JavaAgent"></a>动态代理-JavaAgent</h3><h3 id="动态字节码生成-Cglib"><a href="#动态字节码生成-Cglib" class="headerlink" title="动态字节码生成-Cglib"></a>动态字节码生成-Cglib</h3><p>使用动态字节码生成技术实现AOP原理是在运行期间目标字节码加载后，生成目标类的子类，将切面逻辑加入到子类中，所以<strong>使用Cglib实现AOP不需要基于接口</strong>。</p><p><img src="/2022/04/07/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/AOP%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%BC%96%E6%8E%92%E6%8A%80%E6%9C%AF/img_2.png"></p><p>Cglib是一个强大的,高性能的Code生成类库，它可以在运行期间扩展Java类和实现Java接口，它封装了<strong>Asm</strong>，所以使用Cglib前需要引入Asm的jar。</p><details><summary>使用CGLib实现AOP</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String[] args) &#123;   </span><br><span class="line">    byteCodeGe();   </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public static void byteCodeGe() &#123; </span><br><span class="line">//创建一个织入器 </span><br><span class="line">Enhancer enhancer = new Enhancer(); </span><br><span class="line">//设置父类 </span><br><span class="line">enhancer.setSuperclass(Business.class); </span><br><span class="line">//设置需要织入的逻辑 </span><br><span class="line">enhancer.setCallback(new LogIntercept()); </span><br><span class="line">//使用织入器创建子类 </span><br><span class="line">IBusiness2 newBusiness = (IBusiness2) enhancer.create(); </span><br><span class="line">newBusiness.doSomeThing2(); </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/**  </span><br><span class="line"> * 记录日志  </span><br><span class="line"> */   </span><br><span class="line">public static class LogIntercept implements MethodInterceptor &#123;   </span><br><span class="line">    @Override   </span><br><span class="line">    public Object intercept(Object target, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;   </span><br><span class="line">        //执行原有逻辑，注意这里是invokeSuper   </span><br><span class="line">        Object rev = proxy.invokeSuper(target, args);   </span><br><span class="line">        //执行织入的日志   </span><br><span class="line">        if (method.getName().equals(&quot;doSomeThing2&quot;)) &#123;   </span><br><span class="line">            System.out.println(&quot;记录日志&quot;);   </span><br><span class="line">        &#125;   </span><br><span class="line">        return rev;   </span><br><span class="line">    &#125;   </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure></details><h2 id="自定义类加载器-Javassist"><a href="#自定义类加载器-Javassist" class="headerlink" title="自定义类加载器-Javassist"></a>自定义类加载器-Javassist</h2>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 动态代理 </tag>
            
            <tag> AOP </tag>
            
            <tag> 字节码编排 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaAgent动态代理实现及原理详细分析</title>
      <link href="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/"/>
      <url>/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h2><p>代理模式是常用的java设计模式，他的特征是代理类与委托类有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。</p><p>代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供特定的服务。</p><p>简单的说就是，我们在访问实际对象时，是通过代理对象来访问的，代理模式就是在访问实际对象时引入一定程度的间接性，因为这种间接性，可以附加多种用途。</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img.png"></p><h2 id="静态代理"><a href="#静态代理" class="headerlink" title="静态代理"></a>静态代理</h2><p>由程序员创建或特定工具自动生成源代码，也就是在编译时就已经将接口，被代理类，代理类等确定下来。在程序运行之前，代理类的.class文件就已经生成。</p><h3 id="静态代理简单实现"><a href="#静态代理简单实现" class="headerlink" title="静态代理简单实现"></a>静态代理简单实现</h3><p>假设现在项目经理有一个需求：在项目现有所有类的方法前后打印日志。</p><p>你如何在不修改已有代码的前提下，完成这个需求？</p><ol><li>为现有的每一个类都编写一个对应的代理类，并且让它实现和目标类相同的接口（假设都有）</li></ol><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_1.png"></p><ol start="2"><li>在创建代理对象时，通过构造器塞入一个目标对象，然后在代理对象的方法内部调用目标对象同名方法，并在调用前后打印日志。也就是说，<strong>代理对象 = 增强代码 + 目标对象（原对象）</strong>。有了代理对象后，就不用原对象了</li></ol><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_2.png"></p><h3 id="静态代理的缺陷"><a href="#静态代理的缺陷" class="headerlink" title="静态代理的缺陷"></a>静态代理的缺陷</h3><p>程序员要手动为每一个目标类编写对应的代理类。</p><p>如果当前系统已经有成百上千个类，工作量太大了。</p><p>所以，现在我们的努力方向是：如何少写或者不写代理类，却能完成代理功能？</p><h2 id="复习对象创建"><a href="#复习对象创建" class="headerlink" title="复习对象创建"></a>复习对象创建</h2><p>对于很多初学JAVA的朋友而言，创建对象的过程大概如下图： </p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_3.png"></p><p>实际上，我们也可以换个角度来说</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_4.png"></p><p>所谓的Class对象，是Class类的实例，而Class类是描述所有类的，比如Person类，Student类<img src="https://pic1.zhimg.com/50/v2-c9bf695b1b9d2a0ae01cf92501492159_720w.jpg?source=1940ef5c" data-caption data-size="normal" data-rawwidth="563" data-rawheight="454" data-default-watermark-src="https://pic3.zhimg.com/50/v2-cbd87cbe037bde814221c7584cd60f4e_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="563" data-original="https://pica.zhimg.com/v2-c9bf695b1b9d2a0ae01cf92501492159_r.jpg?source=1940ef5c"></p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_5.png"></p><p>可以看出，要创建一个实例，最关键的就是<strong>得到对应的Class对象</strong>。</p><p>分析到这里，貌似有了思路：</p><p><strong>能否不写代理类，而直接得到代理Class对象，然后根据它创建代理实例（反射）。</strong></p><p>Class对象包含了一个类的所有信息，比如构造器、方法、字段等。如果我们不写代理类，这些信息从哪获取呢？</p><p>代理类和目标类理应<strong>实现同一组接口</strong>。</p><ul><li>之所以实现相同接口，是为了尽可能保证代理对象的内部结构和目标对象一致，这样我们对代理对象的操作最终都可以转移到目标对象身上，代理对象只需专注于增强代码的编写。</li></ul><p>还是上面这幅图：</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_6.png"></p><p>所以，可以这样说：接口拥有代理对象和目标对象共同的类信息。</p><p>所以，我们可以从接口那得到理应由代理类提供的信息。但是别忘了，接口是无法创建对象的，怎么办？</p><h2 id="JDK动态代理"><a href="#JDK动态代理" class="headerlink" title="JDK动态代理"></a>JDK动态代理</h2><p>代理类在程序运行时创建的代理方式被成为动态代理。 </p><p>在静态代理的例子中，代理类是自己定义好的，在程序运行之前就已经编译完成。</p><p>然而动态代理，代理类并不是在Java代码中定义的，而是在运行时根据我们在Java代码中的“指示”动态生成的。</p><p>相比于静态代理， 动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。</p><h3 id="JDK动态代理的简单实现"><a href="#JDK动态代理的简单实现" class="headerlink" title="JDK动态代理的简单实现"></a>JDK动态代理的简单实现</h3><p>JDK提供了java.lang.reflect.InvocationHandler接口和 java.lang.reflect.Proxy类，这两个类相互配合，入口是Proxy，所以我们先聊它。</p><p>Proxy有个静态方法：getProxyClass(ClassLoader, interfaces)，只要你给它传入类加载器和一组接口，它就给你返回代理Class对象。</p><p>用通俗的话说，getProxyClass()这个方法，会从你传入的接口Class中，“拷贝”类结构信息到一个新的Class对象中，但新的Class对象带有构造器，是可以创建对象的。</p><p>打个比方，一个大内太监（接口Class），空有一身武艺（类信息），但是无法传给后人。现在江湖上有个妙手神医（Proxy类），发明了克隆大法（getProxyClass），不仅能克隆太监的一身武艺，还保留了小DD（构造器）…</p><p>所以，一旦我们明确接口，完全可以通过接口的Class对象，创建一个代理Class，通过代理Class即可创建代理对象。</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_7.png"></p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_8.png" class title="静态代理"><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_9.png" class title="动态代理"><p>所以，按我理解，Proxy.getProxyClass()这个方法的本质就是：以Class造Class。</p><p>有了Class对象，就很好办了，具体看代码：</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_10.png"></p><p>完美。</p><p>根据代理Class的构造器创建对象时，需要传入InvocationHandler。每次调用代理对象的方法，最终都会调用InvocationHandler的invoke()方法：</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_11.png"></p><p>怎么做到的呢？</p><p>根据代理Class的构造器创建对象时，需要传入InvocationHandler。通过构造器传入一个引用，那么必然有个成员变量去接收。没错，代理对象的内部确实有个成员变量invocationHandler，而且代理对象的每个方法内部都会调用handler.invoke()！InvocationHandler对象成了代理对象和目标对象的桥梁，不像静态代理这么直接。</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_12.png"></p><p>大家仔细看上图右侧的动态代理，我在invocationHandler的invoke()方法中并没有写目标对象。因为一开始invocationHandler的invoke()里确实没有目标对象，需要我们手动new。</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_13.png"></p><p>但这种写法不够优雅，属于硬编码。我这次代理A对象，下次想代理B对象还要进来改invoke()方法，太差劲了。改进一下，让调用者把目标对象作为参数传进来：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProxyTest</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">CalculatorImpl target = <span class="keyword">new</span> CalculatorImpl();</span><br><span class="line">                <span class="comment">//传入目标对象</span></span><br><span class="line">                <span class="comment">//目的：1.根据它实现的接口生成代理对象 2.代理对象调用目标对象方法</span></span><br><span class="line">Calculator calculatorProxy = (Calculator) getProxy(target);</span><br><span class="line">calculatorProxy.add(<span class="number">1</span>, <span class="number">2</span>);</span><br><span class="line">calculatorProxy.subtract(<span class="number">2</span>, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Object <span class="title">getProxy</span><span class="params">(<span class="keyword">final</span> Object target)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">//参数1：随便找个类加载器给它， 参数2：目标对象实现的接口，让代理对象实现相同接口</span></span><br><span class="line">Class proxyClazz = Proxy.getProxyClass(target.getClass().getClassLoader(), target.getClass().getInterfaces());</span><br><span class="line">Constructor constructor = proxyClazz.getConstructor(InvocationHandler.class);</span><br><span class="line">Object proxy = constructor.newInstance(<span class="keyword">new</span> InvocationHandler() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">System.out.println(method.getName() + <span class="string">&quot;方法开始执行...&quot;</span>);</span><br><span class="line">Object result = method.invoke(target, args);</span><br><span class="line">System.out.println(result);</span><br><span class="line">System.out.println(method.getName() + <span class="string">&quot;方法执行结束...&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="keyword">return</span> proxy;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就非常灵活，非常优雅了。无论现在系统有多少类，只要你把实例传进来，getProxy()都能给你返回对应的代理对象。就这样，我们完美地跳过了代理类，直接创建了代理对象！</p><p>不过实际编程中，一般不用getProxyClass()，而是使用Proxy类的另一个静态方法：Proxy.newProxyInstance()，直接返回代理实例，连中间得到代理Class对象的过程都帮你隐藏：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProxyTest</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">CalculatorImpl target = <span class="keyword">new</span> CalculatorImpl();</span><br><span class="line">Calculator calculatorProxy = (Calculator) getProxy(target);</span><br><span class="line">calculatorProxy.add(<span class="number">1</span>, <span class="number">2</span>);</span><br><span class="line">calculatorProxy.subtract(<span class="number">2</span>, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Object <span class="title">getProxy</span><span class="params">(<span class="keyword">final</span> Object target)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">Object proxy = Proxy.newProxyInstance(</span><br><span class="line">target.getClass().getClassLoader(),<span class="comment">/*类加载器*/</span></span><br><span class="line">target.getClass().getInterfaces(),<span class="comment">/*让代理对象和目标对象实现相同接口*/</span></span><br><span class="line"><span class="keyword">new</span> InvocationHandler()&#123;<span class="comment">/*代理对象的方法最终都会被JVM导向它的invoke方法*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">System.out.println(method.getName() + <span class="string">&quot;方法开始执行...&quot;</span>);</span><br><span class="line">Object result = method.invoke(target, args);</span><br><span class="line">System.out.println(result);</span><br><span class="line">System.out.println(method.getName() + <span class="string">&quot;方法执行结束...&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">);</span><br><span class="line"><span class="keyword">return</span> proxy;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，我想应该能看懂动态代理了。</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_14.png"></p><p>最后讨论一下代理对象是什么类型。</p><p>首先，请区分两个概念：代理Class对象和代理对象。</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_15.png"></p><p>单从名字看，代理Class和Calculator的接口确实相去甚远，但是我们却能将代理对象赋值给接口类型：</p><p><img src="/2022/04/02/JAVA%E5%9F%BA%E7%A1%80/JAVA%E4%BB%A3%E7%90%86/JavaAgent%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%8E%9F%E7%90%86%E8%AF%A6%E7%BB%86%E5%88%86%E6%9E%90/img_16.png"></p><p>千万别觉得名字奇怪，就怀疑它不能用接口接收，只要实现该接口就是该类型。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">代理对象的本质就是：和目标对象实现相同接口的实例。代理Class可以叫任何名字，whatever，只要它实现某个接口，就能成为该接口类型。</span><br></pre></td></tr></table></figure><p>我写了一个MyProxy类，那么它的Class名字必然叫MyProxy。但这和能否赋值给接口没有任何关系。由于它实现了Serializable和Collection，所以myProxy（代理实例）同时是这两个接口的类型。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>j动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类中的方法。是因为所有被代理执行的方法，都是通过在InvocationHandler中的invoke方法调用的，所以我们只要在invoke方法中统一处理，就可以对所有被代理的方法进行相同的操作了。例如，这里的方法计时，所有的被代理对象执行的方法都会被计时，然而我只做了很少的代码量。</p><p>动态代理的过程，代理对象和被代理对象的关系不像静态代理那样一目了然，清晰明了。因为动态代理的过程中，我们并没有实际看到代理类，也没有很清晰地的看到代理类的具体样子，而且动态代理中被代理对象和代理对象是通过InvocationHandler来完成的代理过程的，其中具体是怎样操作的，为什么代理对象执行的方法都会通过InvocationHandler中的invoke方法来执行。</p><h3 id="JDK动态代理Proxy类源码分析"><a href="#JDK动态代理Proxy类源码分析" class="headerlink" title="JDK动态代理Proxy类源码分析"></a>JDK动态代理Proxy类源码分析</h3><h4 id="JDK动态代理创建出来的动态代理类"><a href="#JDK动态代理创建出来的动态代理类" class="headerlink" title="JDK动态代理创建出来的动态代理类"></a>JDK动态代理创建出来的动态代理类</h4><p>上面我们利用Proxy类的newProxyInstance方法创建了一个动态代理对象，查看该方法的源码，发现它只是封装了创建动态代理类的步骤：</p><details><summary>newProxyInstance</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">public static Object newProxyInstance(ClassLoader loader,</span><br><span class="line">                                          Class&lt;?&gt;[] interfaces,</span><br><span class="line">                                          InvocationHandler h)</span><br><span class="line">        throws IllegalArgumentException</span><br><span class="line">    &#123;</span><br><span class="line">        Objects.requireNonNull(h);</span><br><span class="line"></span><br><span class="line">        final Class&lt;?&gt;[] intfs = interfaces.clone();</span><br><span class="line">        final SecurityManager sm = System.getSecurityManager();</span><br><span class="line">        if (sm != null) &#123;</span><br><span class="line">            checkProxyAccess(Reflection.getCallerClass(), loader, intfs);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">         * Look up or generate the designated proxy class.</span><br><span class="line">         */</span><br><span class="line">        Class&lt;?&gt; cl = getProxyClass0(loader, intfs);</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">         * Invoke its constructor with the designated invocation handler.</span><br><span class="line">         */</span><br><span class="line">        try &#123;</span><br><span class="line">            if (sm != null) &#123;</span><br><span class="line">                checkNewProxyPermission(Reflection.getCallerClass(), cl);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams);</span><br><span class="line">            final InvocationHandler ih = h;</span><br><span class="line">            if (!Modifier.isPublic(cl.getModifiers())) &#123;</span><br><span class="line">                AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123;</span><br><span class="line">                    public Void run() &#123;</span><br><span class="line">                        cons.setAccessible(true);</span><br><span class="line">                        return null;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">            return cons.newInstance(new Object[]&#123;h&#125;);</span><br><span class="line">        &#125; catch (IllegalAccessException|InstantiationException e) &#123;</span><br><span class="line">            throw new InternalError(e.toString(), e);</span><br><span class="line">        &#125; catch (InvocationTargetException e) &#123;</span><br><span class="line">            Throwable t = e.getCause();</span><br><span class="line">            if (t instanceof RuntimeException) &#123;</span><br><span class="line">                throw (RuntimeException) t;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                throw new InternalError(t.toString(), t);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (NoSuchMethodException e) &#123;</span><br><span class="line">            throw new InternalError(e.toString(), e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></details><p>其实，我们最应该关注的是 <strong>Class&lt;?&gt; cl = getProxyClass0(loader, intfs)</strong>; 这句，这里产生了代理类，后面代码中的构造器也是通过这里产生的类来获得，可以看出，这个类的产生就是整个动态代理的关键，由于是动态生成的类文件，我这里不具体进入分析如何产生的这个类文件，只需要知道这个类文件时缓存在java虚拟机中的，我们可以</p><details><summary>通过方法将其打印到文件里面，一睹真容</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">byte[] classFile = ProxyGenerator.generateProxyClass(&quot;$Proxy0&quot;, Student.class.getInterfaces());</span><br><span class="line">String path = &quot;G:/javacode/javase/Test/bin/proxy/StuProxy.class&quot;;</span><br><span class="line">try(FileOutputStream fos = new FileOutputStream(path)) &#123;</span><br><span class="line">    fos.write(classFile);</span><br><span class="line">    fos.flush();</span><br><span class="line">    System.out.println(&quot;代理类class文件写入成功&quot;);</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">   System.out.println(&quot;写文件错误&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><details><summary>对这个class文件进行反编译，我们看看jdk为我们生成了什么样的内容</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Proxy;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.UndeclaredThrowableException;</span><br><span class="line"><span class="keyword">import</span> proxy.Person;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> $<span class="title">Proxy0</span> <span class="keyword">extends</span> <span class="title">Proxy</span> <span class="keyword">implements</span> <span class="title">Person</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Method m1;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Method m2;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Method m3;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Method m0;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  *注意这里是生成代理类的构造方法，方法参数为InvocationHandler类型，看到这，是不是就有点明白</span></span><br><span class="line"><span class="comment">  *为何代理对象调用方法都是执行InvocationHandler中的invoke方法，而InvocationHandler又持有一个</span></span><br><span class="line"><span class="comment">  *被代理对象的实例，不禁会想难道是....？ 没错，就是你想的那样。</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  *super(paramInvocationHandler)，是调用父类Proxy的构造方法。</span></span><br><span class="line"><span class="comment">  *父类持有：protected InvocationHandler h;</span></span><br><span class="line"><span class="comment">  *Proxy构造方法：</span></span><br><span class="line"><span class="comment">  *    protected Proxy(InvocationHandler h) &#123;</span></span><br><span class="line"><span class="comment">  *         Objects.requireNonNull(h);</span></span><br><span class="line"><span class="comment">  *         this.h = h;</span></span><br><span class="line"><span class="comment">  *     &#125;</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">public</span> $Proxy0(InvocationHandler paramInvocationHandler)</span><br><span class="line">    <span class="keyword">throws</span> </span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">super</span>(paramInvocationHandler);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//这个静态块本来是在最后的，我把它拿到前面来，方便描述</span></span><br><span class="line">   <span class="keyword">static</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">//看看这儿静态块儿里面有什么，是不是找到了giveMoney方法。请记住giveMoney通过反射得到的名字m3，其他的先不管</span></span><br><span class="line">      m1 = Class.forName(<span class="string">&quot;java.lang.Object&quot;</span>).getMethod(<span class="string">&quot;equals&quot;</span>, <span class="keyword">new</span> Class[] &#123; Class.forName(<span class="string">&quot;java.lang.Object&quot;</span>) &#125;);</span><br><span class="line">      m2 = Class.forName(<span class="string">&quot;java.lang.Object&quot;</span>).getMethod(<span class="string">&quot;toString&quot;</span>, <span class="keyword">new</span> Class[<span class="number">0</span>]);</span><br><span class="line">      m3 = Class.forName(<span class="string">&quot;proxy.Person&quot;</span>).getMethod(<span class="string">&quot;giveMoney&quot;</span>, <span class="keyword">new</span> Class[<span class="number">0</span>]);</span><br><span class="line">      m0 = Class.forName(<span class="string">&quot;java.lang.Object&quot;</span>).getMethod(<span class="string">&quot;hashCode&quot;</span>, <span class="keyword">new</span> Class[<span class="number">0</span>]);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (NoSuchMethodException localNoSuchMethodException)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchMethodError(localNoSuchMethodException.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (ClassNotFoundException localClassNotFoundException)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NoClassDefFoundError(localClassNotFoundException.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  *这里调用代理对象的giveMoney方法，直接就调用了InvocationHandler中的invoke方法，并把m3传了进去。</span></span><br><span class="line"><span class="comment">  *this.h.invoke(this, m3, null);这里简单，明了。</span></span><br><span class="line"><span class="comment">  *来，再想想，代理对象持有一个InvocationHandler对象，InvocationHandler对象持有一个被代理的对象，</span></span><br><span class="line"><span class="comment">  *再联系到InvacationHandler中的invoke方法。嗯，就是这样。</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">giveMoney</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> </span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">this</span>.h.invoke(<span class="keyword">this</span>, m3, <span class="keyword">null</span>);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (Error|RuntimeException localError)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">throw</span> localError;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (Throwable localThrowable)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> UndeclaredThrowableException(localThrowable);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//注意，这里为了节省篇幅，省去了toString，hashCode、equals方法的内容。原理和giveMoney方法一毛一样。</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>jdk为我们的生成了一个叫$Proxy0（这个名字后面的0是编号，有多个代理类会一次递增）的代理类，这个类文件时放在内存中的，我们在创建代理对象时，就是通过反射获得这个类的构造方法，然后创建的代理实例。通过对这个生成的代理类源码的查看，我们很容易能看出，动态代理实现的具体过程。</p><p>我们可以对InvocationHandler看做一个中介类，中介类持有一个被代理对象，在invoke方法中调用了被代理对象的相应方法。通过聚合方式持有被代理对象的引用，把外部对invoke的调用最终都转为对被代理对象的调用。</p><p>代理类调用自己方法时，通过自身持有的中介类对象来调用中介类对象的invoke方法，从而达到代理执行被代理对象的方法。也就是说，动态代理通过中介类实现了具体的代理功能。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>生成的代理类：$Proxy0 extends Proxy implements Person，我们看到代理类继承了Proxy类，所以也就决定了java动态代理只能对接口进行代理，Java的继承机制注定了这些动态代理类们无法实现对class的动态代理。</p><p>上面的动态代理的例子，其实就是AOP的一个简单实现了。</p><p>Spring的AOP实现其实也是用了Proxy和InvocationHandler这两个东西的。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 动态代理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库MySQL系列之分区分片分库分表</title>
      <link href="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
      <url>/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p>数据库的数据量达到一定程度之后，为避免带来系统性能上的瓶颈， 往往需要进行数据的处理，最常采用的手段总结起来：</p><ul><li>分区</li><li>分片</li><li>分库</li><li>分表</li></ul><h2 id="表分区"><a href="#表分区" class="headerlink" title="表分区"></a>表分区</h2><h3 id="什么是表分区"><a href="#什么是表分区" class="headerlink" title="什么是表分区"></a>什么是表分区</h3><p>MySQL 数据库中的数据是以文件的形势存在磁盘上的，默认放在 /var/lib/mysql/ 目录下面，</p><p>我们可以通过 show variables like ‘%datadir%’; 命令来查看：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img.png"></p><p>我们进入到这个目录下，就可以看到我们定义的所有数据库了，一个数据库就是一个文件夹，一个库中，有其对应的表的信息，如下：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_1.png"></p><p>在 MySQL 中，如果存储引擎是 MyISAM，那么在 data 目录下会看到 3 类文件：.frm、.myi、.myd，作用如下：</p><ol><li><code>*.frm</code>：这个是表定义，是描述表结构的文件。</li><li><code>*.myd</code>：这个是数据信息文件，是表的数据文件。</li><li><code>*.myi</code>：这个是索引信息文件。</li></ol><p>如果存储引擎是 InnoDB, 那么在 data 目录下会看到两类文件：.frm、.ibd，作用分别如下：</p><ol><li><code>*.frm</code>：表结构文件。</li><li><code>*.ibd</code>：表数据和索引的文件。 </li></ol><p>无论是哪种存储引擎，只要一张表的数据量过大，就会导致 <em>.myd、</em>.myi 以及 *.ibd 文件过大，数据的查找就会变的很慢。</p><p>为了解决这个问题，我们可以利用 MySQL 的分区功能，在物理上将这一张表对应的文件，分割成许多小块，如此，当我们查找一条数据时，就不用在某一个文件中进行整个遍历了，我们只需要知道这条数据位于哪一个数据块，然后在那一个数据块上查找就行了；另一方面，如果一张表的数据量太大，可能一个磁盘放不下，这个时候，通过表分区我们就可以把数据分配到不同的磁盘里面去。</p><p>MySQL 从 5.1 开始添加了对分区的支持，分区的过程是将一个表或索引分解为多个更小、更可管理的部分。对于开发者而言，分区后的表使用方式和不分区基本上还是一模一样，只不过在物理存储上，原本该表只有一个数据文件，现在变成了多个，每个分区都是独立的对象，可以独自处理，也可以作为一个更大对象的一部分进行处理。</p><p>需要注意的是，分区功能<strong>并不是在存储引擎层完成</strong>的，常见的存储引擎如 InnoDB、MyISAM、NDB 等都支持分区。但并不是所有的存储引擎都支持，如 CSV、FEDORATED、MERGE 等就不支持分区，因此在使用此分区功能前，应该对选择的存储引擎对分区的支持有所了解。</p><h3 id="表分区两种方式"><a href="#表分区两种方式" class="headerlink" title="表分区两种方式"></a>表分区两种方式</h3><p>不同于 MyCat 中既可以垂直切分又可以水平切分，MySQL 数据库支持的分区类型为水平分区，它<strong>不支持垂直分区</strong>。</p><h4 id="水平切分"><a href="#水平切分" class="headerlink" title="水平切分"></a>水平切分</h4><p>将同一个表的数据进行分块保存到不同的数据库中，来解决单表中数据量增长出现的压力。这些数据库中的表结构完全相同。</p><p>先来一张简单的示意图，大家感受一下什么是水平切分：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_2.png"></p><p>假设我的 DB 中有 table-1、table-2 以及 table-3 三张表，水平切分就是拿着我 40 米大刀，对准黑色的线条，砍一剑或者砍 N 剑！</p><p>砍完之后，将砍掉的部分放到另外一个数据库实例中，变成下面这样：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_3.png"></p><p>这样，原本放在一个 DB 中的 table 现在放在两个 DB 中了，观察之后我们发现：</p><ul><li>两个 DB 中表的个数都是完整的，就是原来 DB 中有几张表，现在还是几张。 </li><li>每张表中的数据是不完整的，数据被拆分到了不同的 DB 中去了。</li></ul><p>这就是数据库的水平切分，也可以理解为<strong>按照数据行进行切分</strong>，即按照表中某个字段的某种规则来将表数据分散到多个库之中，每个表中包含一部分数据，即<strong>水平切分不改变表结构</strong>。</p><p>表结构设计水平切分，常见的一些场景包括：</p><ul><li>比如在线电子商务网站，订单表数据量过大，按照年度、月度水平切分</li><li>Web 2.0网站注册用户、在线活跃用户过多，按照用户ID范围等方式，将相关用户以及该用户紧密关联的表做水平切分</li><li>例如论坛的置顶帖子，因为涉及到分页问题，每页都需要显示置顶贴，这种情况可以把置顶贴水平切分开来，避免取置顶帖子时从所有帖子的表中读取</li></ul><h4 id="垂直切分"><a href="#垂直切分" class="headerlink" title="垂直切分"></a>垂直切分</h4><p>是指按功能模块拆分，以解决表与表之间的io竞争。比如分为订单库、商品库、用户库…这种方式多个数据库之间的表结构不同。</p><p>先来一张简单的示意图，大家感受一下垂直切分：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_4.png"></p><p>所谓的垂直切分就是拿着我 40 米大刀，对准了黑色的线条砍。</p><p>砍完之后，将不同的表放到不同的数据库实例中去，变成下面这个样子：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_5.png"><br><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_6.png"><br><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_7.png"></p><p>这个时候我们发现如下几个特点：</p><ul><li>每一个数据库实例中的表的数量都是不完整的。</li><li>每一个数据库实例中表的数据是完整的。</li></ul><p>这就是垂直切分。</p><p>一般来说，垂直切分我们可以按照业务来划分，不同业务的表放到不同的数据库实例中。</p><p>表结构设计垂直切分，常见的一些场景包括：</p><ul><li><strong>大字段的垂直切分</strong>。单独将大字段建在另外的表中，提高基础表的访问性能，原则上在性能关键的应用中应当避免数据库的大字段</li><li><strong>按照使用用途垂直切分</strong>。例如企业物料属性，可以按照基本属性、销售属性、采购属性、生产制造属性、财务会计属性等用途垂直切分</li><li><strong>按照访问频率垂直切分</strong>。例如电子商务、Web 2.0系统中，如果用户属性设置非常多，可以将基本、使用频繁的属性和不常用的属性垂直切分开</li></ul><h4 id="MySQL-数据库支持的分区类型为水平分区。"><a href="#MySQL-数据库支持的分区类型为水平分区。" class="headerlink" title="MySQL 数据库支持的分区类型为水平分区。"></a>MySQL 数据库支持的分区类型为水平分区。</h4><p>MySQL 数据库的分区是<strong>局部分区索引</strong>，即一个分区中既存放了数据又存放了索引。</p><p>目前，MySQL数据库还不支持全局分区（数据存放在各个分区中，但是所有数据的索引放在一个对象中）。</p><h3 id="为什么需要表分区"><a href="#为什么需要表分区" class="headerlink" title="为什么需要表分区"></a>为什么需要表分区</h3><ul><li>可以让单表存储更多的数据。</li><li>分区表的数据更容易维护，可以通过清除整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。<br>另外，还可以对一个独立分区进行优化、检查、修复等操作。</li><li>部分查询能够从查询条件确定只落在少数分区上，查询速度会很快。</li><li>分区表的数据还可以分布在不同的物理设备上，从而高效利用多个硬件设备。</li><li>可以使用分区表来避免某些特殊瓶颈，例如 InnoDB 单个索引的互斥访问、ext3 文件系统的 inode 锁竞争。</li><li>可以备份和恢复单个分区。</li></ul><h4 id="分区的限制和缺点"><a href="#分区的限制和缺点" class="headerlink" title="分区的限制和缺点"></a>分区的限制和缺点</h4><ul><li>一个表最多只能有 1024 个分区。</li><li>如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来。</li><li>分区表无法使用外键约束。</li><li>NULL 值会使分区过滤无效。</li><li>所有分区必须使用相同的存储引擎。</li></ul><h3 id="分区实践"><a href="#分区实践" class="headerlink" title="分区实践"></a>分区实践</h3><p>说了这么多，来个例子看一下。</p><p>首先我们先来查看一下当前的 MySQL 是否支持分区。</p><p>在 MySQL5.6.1 之前可以通过命令 <code>show variables like &#39;%have_partitioning%&#39;</code> 来查看 MySQL 是否支持分区。如果 <code>have_partitioning</code> 的值为 <code>YES</code>，则表示支持分区。</p><p>从 MySQL5.6.1 开始，<code>have_partitioning</code> 参数已经被去掉了，而是用 <code>SHOW PLUGINS</code> 来代替。若有 <code>partition</code> 行且 <code>STATUS</code> 列的值为 <code>ACTIVE</code>，则表示支持分区，如下所示：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_8.png"></p><p>确认我们的 MySQL 支持分区后，我们就可以开始分区啦！</p><h4 id="RANGE-分区"><a href="#RANGE-分区" class="headerlink" title="RANGE 分区"></a>RANGE 分区</h4><p>RANGE 分区比较简单，就是根据某一个字段的值进行分区。 </p><p>不过这个字段有一个要求，就是<strong>必须是主键或者是联合主键中的某个字段</strong>。</p><p>例如根据 user 表的 id 进行分区：</p><ul><li>当 id 小于 100，数据插入 p0 分区；</li><li>当 id 大于等于 100 小于 200 的时候，插入 p1 分区；</li><li>如果 id 大于等于 200 则插入 p2 分区。</li></ul><p>上面的规则涉及到了 id 的所有范围了，如果没有第三条规则，那么插入一个 id 为 300 的记录时，就会报错。</p><p>建表 SQL 如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create  table  user(</span><br><span class="line">  id int primary key,</span><br><span class="line">  username varchar(255)</span><br><span class="line">)engine=innodb</span><br><span class="line">  partition by range(id)(</span><br><span class="line">     partition  p0  values  less  than(100),</span><br><span class="line">     partition  p1  values  less  than(200),</span><br><span class="line">     partition  p2  values  less  than maxvalue  </span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>表创建成功后，我们进入到 <code>/var/lib/mysql/test08</code> 文件夹中，来看刚刚创建的表文件：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_9.png"></p><p>可以看到，此时的数据文件分为好几个了。</p><p>在 <code>information_schema.partitions</code> 表中，我们可以查看分区的详细信息：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_10.png"></p><p>也可以自己写个 SQL 去查询：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from information_schema.partitions where table_schema=&#x27;test08&#x27; and table_name=&#x27;user&#x27;</span><br></pre></td></tr></table></figure><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_11.png"></p><p>每一行展示一个分区的信息，包括分区的方式、该区的范围、分区的字段、该区目前有几条记录等等。</p><p>RANGE 分区有一个比较典型的使用场景，就是按照日期对表进行分区，例如同一年注册的用户放在一个分区中，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">create  table  user(</span><br><span class="line">  id int,</span><br><span class="line">  username varchar(255),</span><br><span class="line">  password varchar(255),</span><br><span class="line">  createDate date,</span><br><span class="line">  primary key (id,createDate)</span><br><span class="line">)engine=innodb</span><br><span class="line">  partition by range(year(createDate))(</span><br><span class="line">     partition  p2022  values  less  than(2023),</span><br><span class="line">     partition  p2023  values  less  than(2024),</span><br><span class="line">     partition  p2024  values  less  than(2025)  </span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>注意，<code>createDate</code> 是联合主键的一员。如果 <code>createDate</code> 不是主键，只是一个普通字段，那么创建时就会抛出如下错误：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_12.png"></p><p>现在，如果我们要查询 2022 年注册的用户，系统就只会去搜索 p2022 这个分区，通过 explain 执行计划可以证实我们的想法：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_13.png"></p><p>如果想要删除 2022 年注册的用户，则只需要删除该分区即可：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table user drop partition p2022;</span><br></pre></td></tr></table></figure><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_14.png"></p><p>由上图可以看到，删除之后，数据就没了。</p><h4 id="LIST-分区"><a href="#LIST-分区" class="headerlink" title="LIST 分区"></a>LIST 分区</h4><p>LIST 分区和 RANGE 分区类似，区别在于 LIST 分区是基于列值匹配一个离散值集合中的某个值来进行选择，而非连续的。举个例子大家看下就明白了：</p><p>假设我有一个用户表，用户有性别，现在想按照性别将用户分开存储，男性存储在一个分区中，女性存储在一个分区中，SQL 如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">create  table  user(</span><br><span class="line">  id int,</span><br><span class="line">  username varchar(255),</span><br><span class="line">  password varchar(255),</span><br><span class="line">  gender int,</span><br><span class="line">  primary key(id, gender)</span><br><span class="line">)engine=innodb</span><br><span class="line">  partition by list(gender)(</span><br><span class="line">     partition  man  values  in  (1),</span><br><span class="line">     partition  woman  values  in  (0));</span><br></pre></td></tr></table></figure><p>这个表将来就两个分区，分别存储男性和女性，gender 的取值为 1 或者 0，gender 如果取其他值，执行就会出错，最终执行结果如下：</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_15.png"></p><p>这样分区之后，将来查询男性或者查询女性效率都会比较高，删除某一性别的用户时删除效率也高。</p><h4 id="HASH-分区"><a href="#HASH-分区" class="headerlink" title="HASH 分区"></a>HASH 分区</h4><p>HASH 分区的目的是将数据均匀地分布到预先定义的各个分区中，保证各分区的数据量大致都是一样的。</p><p>在 RANGE 和 LIST 分区中，必须明确指定一个给定的列值或列值集合应该保存在哪个分区中；而在 HASH 分区中，MySQL 自动完成这些工作，用户所要做的只是基于将要进行哈希分区的列指定一个表达式，并且分区的数量。</p><ul><li>使用 HASH 分区来分割一个表，要在 CREATE TABLE 语句上添加 PARTITION BY HASH (expr)，其中 expr 是一个<strong>字段或者是一个返回整数的表达式</strong>；</li><li>通过 PARTITIONS 属性指定分区的数量，如果没有指定，那么<strong>分区的数量默认为 1</strong>，</li><li>HASH 分区不能删除分区，所以<strong>不能使用 DROP PARTITION 操作进行分区删除</strong>操作。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create  table  user(</span><br><span class="line">  id int,</span><br><span class="line">  username varchar(255),</span><br><span class="line">  password varchar(255),</span><br><span class="line">  gender int,</span><br><span class="line">  primary key(id, gender)</span><br><span class="line">)engine=innodb partition by hash(id) partitions 4;</span><br></pre></td></tr></table></figure><h4 id="KEY-分区"><a href="#KEY-分区" class="headerlink" title="KEY 分区"></a>KEY 分区</h4><p>KEY 分区和 HASH 分区相似，但是 KEY 分区支持除 text 和 BLOB 之外的所有数据类型的分区，而 HASH 分区只支持数字分区。</p><p>KEY 分区不允许使用用户自定义的表达式进行分区，KEY 分区使用系统提供的 HASH 函数进行分区。</p><p>当表中存在主键或者唯一索引时，如果创建 KEY 分区时没有指定字段系统默认会<strong>首选主键列作为分区字段</strong>,如果不存在主键列会选择<strong>非空唯一索引列</strong>作为分区字段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create  table  user(</span><br><span class="line">  id int,</span><br><span class="line">  username varchar(255),</span><br><span class="line">  password varchar(255),</span><br><span class="line">  gender int,</span><br><span class="line">  primary key(id, gender)</span><br><span class="line">)engine=innodb partition by key(id) partitions 4;</span><br></pre></td></tr></table></figure><h4 id="COLUMNS-分区"><a href="#COLUMNS-分区" class="headerlink" title="COLUMNS 分区"></a>COLUMNS 分区</h4><p>COLUMN 分区是 5.5 开始引入的分区功能，只有 RANGE COLUMN 和 LIST COLUMN 这两种分区；支持整形、日期、字符串；这种分区方式和 RANGE、LIST 的分区方式非常的相似。</p><p>COLUMNS Vs RANGE Vs LIST 分区：</p><ul><li>针对日期字段的分区不需要再使用函数进行转换了。</li><li>COLUMN 分区支持多个字段作为分区键但是不支持表达式作为分区键。</li></ul><p>COLUMNS 支持的类型</p><ul><li>整形支持：tinyint、smallint、mediumint、int、bigint；不支持 decimal 和 float。</li><li>时间类型支持：date、datetime。</li><li>字符类型支持：char、varchar、binary、varbinary；不支持text、blob。</li></ul><p>举个例子看下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">create  table  user(</span><br><span class="line">  id int,</span><br><span class="line">  username varchar(255),</span><br><span class="line">  password varchar(255),</span><br><span class="line">  gender int,</span><br><span class="line">  createDate date,</span><br><span class="line">  primary key(id, createDate)</span><br><span class="line">)engine=innodb PARTITION BY RANGE COLUMNS(createDate) (</span><br><span class="line">    PARTITION p0 VALUES LESS THAN (&#x27;1990-01-01&#x27;),</span><br><span class="line">    PARTITION p1 VALUES LESS THAN (&#x27;2000-01-01&#x27;),</span><br><span class="line">    PARTITION p2 VALUES LESS THAN (&#x27;2010-01-01&#x27;),</span><br><span class="line">    PARTITION p3 VALUES LESS THAN (&#x27;2020-01-01&#x27;),</span><br><span class="line">    PARTITION p4 VALUES LESS THAN MAXVALUE</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>这是 RANGE COLUMNS，分区值是连续的。</p><p>再来看 LIST COLUMNS 分区，这个就类似于枚举了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">create  table  user(</span><br><span class="line">  id int,</span><br><span class="line">  username varchar(255),</span><br><span class="line">  password varchar(255),</span><br><span class="line">  gender int,</span><br><span class="line">  createDate date,</span><br><span class="line">  primary key(id, createDate)</span><br><span class="line">)engine=innodb PARTITION BY LIST COLUMNS(createDate) (</span><br><span class="line">    PARTITION p0 VALUES IN (&#x27;1990-01-01&#x27;),</span><br><span class="line">    PARTITION p1 VALUES IN (&#x27;2000-01-01&#x27;),</span><br><span class="line">    PARTITION p2 VALUES IN (&#x27;2010-01-01&#x27;),</span><br><span class="line">    PARTITION p3 VALUES IN (&#x27;2020-01-01&#x27;)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><h3 id="常见分区命令"><a href="#常见分区命令" class="headerlink" title="常见分区命令"></a>常见分区命令</h3><h4 id="添加分区"><a href="#添加分区" class="headerlink" title="添加分区"></a>添加分区</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter table user add partition (partition p3 values less than (4000)); -- range 分区</span><br><span class="line">alter table user add partition (partition p3 values in (40));  -- lists分区</span><br></pre></td></tr></table></figure><h4 id="删除表分区（会删除数据）"><a href="#删除表分区（会删除数据）" class="headerlink" title="删除表分区（会删除数据）"></a>删除表分区（会删除数据）</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table user drop partition p30;</span><br></pre></td></tr></table></figure><h4 id="除表的所有分区（不会丢失数据）："><a href="#除表的所有分区（不会丢失数据）：" class="headerlink" title="除表的所有分区（不会丢失数据）："></a>除表的所有分区（不会丢失数据）：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table user remove partitioning; </span><br></pre></td></tr></table></figure><h4 id="重新定义-range-分区表（不会丢失数据）："><a href="#重新定义-range-分区表（不会丢失数据）：" class="headerlink" title="重新定义 range 分区表（不会丢失数据）："></a>重新定义 range 分区表（不会丢失数据）：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter table user partition by range(salary)(</span><br><span class="line">partition p1 values less than (2000),</span><br><span class="line">partition p2 values less than (4000)); </span><br></pre></td></tr></table></figure><h4 id="重新定义-hash-分区表（不会丢失数据）："><a href="#重新定义-hash-分区表（不会丢失数据）：" class="headerlink" title="重新定义 hash 分区表（不会丢失数据）："></a>重新定义 hash 分区表（不会丢失数据）：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table user partition by hash(salary) partitions 7; </span><br></pre></td></tr></table></figure><h4 id="合并分区：把-2-个分区合并为一个，不会丢失数据："><a href="#合并分区：把-2-个分区合并为一个，不会丢失数据：" class="headerlink" title="合并分区：把 2 个分区合并为一个，不会丢失数据："></a>合并分区：把 2 个分区合并为一个，不会丢失数据：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table user  reorganize partition p1,p2 into (partition p1 values less than (1000));</span><br></pre></td></tr></table></figure><h2 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h2><p>分片是把数据库横向扩展（Scale Out）到多个物理节点上的一种有效的方式，其主要目的是为突破单节点数据库服务器的 I/O 能力限制，解决数据库扩展性问题。</p><p>Shard这个词的意思是“碎片”。</p><p>如果将一个数据库当作一块大玻璃，将这块玻璃打碎，那么每一小块都称为数据库的碎片（DatabaseShard）。</p><p>将整个数据库打碎的过程就叫做分片，可以翻译为分片。</p><p>形式上，分片可以简单定义为将大数据库分布到多个物理节点上的一个分区方案。</p><p>每一个分区包含数据库的某一部分，称为一个片，分区方式可以是任意的，并不局限于传统的水平分区和垂直分区。</p><p>一个分片可以包含多个表的内容甚至可以包含多个数据库实例中的内容。</p><p>每个分片被放置在一个数据库服务器上，一个数据库服务器可以处理一个或多个分片的数据。</p><p>系统中需要有服务器进行查询路由转发，负责将查询转发到包含该查询所访问数据的分片或分片集合节点上去执行。</p><h2 id="分表和分区"><a href="#分表和分区" class="headerlink" title="分表和分区"></a>分表和分区</h2><p>分表从表面意思说就是把一张表分成多个小表，分区则是把一张表的数据分成N多个区块，这些区块可以在同一个磁盘上，也可以在不同的磁盘上。</p><p>分表和分区的区别</p><ol><li>实现方式上</li></ol><p>  mysql的分表是真正的分表，一张表分成很多表后，每一个小表都是完正的一张表，都对应三个文件（MyISAM引擎：一个.MYD数据文件，.MYI索引文件，.frm表结构文件）。</p><ol start="2"><li>数据处理上</li></ol><p>  分表后数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面。分区则不存在分表的概念，分区只不过把存放数据的文件分成了许多小块，分区后的表还是一张表，数据处理还是由自己来完成。</p><ol start="3"><li>提高性能上</li></ol><p>  分表后，单表的并发能力提高了，磁盘I/O性能也提高了。分区突破了磁盘I/O瓶颈，想提高磁盘的读写能力，来增加mysql性能。</p><p>  在这一点上，分区和分表的测重点不同，分表重点是存取数据时，如何提高mysql并发能力上；而分区呢，如何突破磁盘的读写能力，从而达到提高mysql性能的目的。</p><ol start="4"><li>实现的难易度上</li></ol><p>  分表的方法有很多，用merge来分表，是最简单的一种方式。这种方式和分区难易度差不多，并且对程序代码来说可以做到透明的。如果是用其他分表方式就比分区麻烦了。分区实现是比较简单的，建立分区表，跟建平常的表没什么区别，并且对代码端来说是透明的。</p><p>分区的适用场景: </p><ol><li>一张表的查询速度已经慢到影响使用的时候。</li><li>表中的数据是分段的</li><li>对数据的操作往往只涉及一部分数据，而不是所有的数据</li></ol><p>分表的适用场景:</p><ol><li>一张表的查询速度已经慢到影响使用的时候。</li><li>当频繁插入或者联合查询时，速度变慢。</li><li>分表的实现需要业务结合实现和迁移，较为复杂。</li></ol><h2 id="分表与分库"><a href="#分表与分库" class="headerlink" title="分表与分库"></a>分表与分库</h2><p>分表能够解决单表数据量过大带来的查询效率下降的问题，但是，却无法给数据库的并发处理能力带来质的提升。</p><p>面对高并发的读写访问，当数据库master服务器无法承载写操作压力时，不管如何扩展slave服务器，此时都没有意义了。</p><p>因此，我们必须换一种思路，对数据库进行拆分，从而提高数据库写入能力，这就是所谓的分库。</p><p>与分表策略相似，分库可以采用通过一个关键字取模的方式，来对数据访问进行路由，如下图所示</p><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_16.png"></p><h2 id="分区与分片"><a href="#分区与分片" class="headerlink" title="分区与分片"></a>分区与分片</h2><p><img src="/2022/03/22/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%8C%BA%E5%88%86%E7%89%87%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/img_17.png"></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis初探之常见问题汇总</title>
      <link href="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
      <url>/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<p>拓展阅读: <a href="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/" title="高并发系统02之高并发三大利器之缓存">高并发系统02之高并发三大利器之缓存</a></p><h2 id="Redis-缓存使用优缺点总结"><a href="#Redis-缓存使用优缺点总结" class="headerlink" title="Redis 缓存使用优缺点总结"></a>Redis 缓存使用优缺点总结</h2><p>Redis 是完全开源免费的，是一个高性能的key-value类型的内存数据库。</p><p>整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。</p><p>因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li><p>速度快，因为数据存在内存中，读的速度是 110000 次 /s, 写的速度是 81000 次 /s；</p><ul><li>值得注意的是，该测试结果还是早些年旧机器上的测试结果。如果与今天的机器设备相比，预估可能是以下结果的两倍。</li></ul></li><li><p>支持丰富数据类型，支持string，list，set，sorted set，hash；</p></li><li><p>支持事务，操作都是原子性，对数据的更改要么全部执行，要么全部不执行，事务中任意命令执行失败，其余命令依然被执行。也就是说 Redis 事务不保证原子性，也不支持回滚；事务中的多条命令被一次性发送给服务器，服务器在执行命令期间，不会去执行其他客户端的命令请求。</p></li><li><p>丰富的特性：可用于缓存，消息（支持 publish/subscribe 通知），按key设置过期时间，过期后将会自动删除。</p><p> 具体<strong>淘汰策略</strong>有：</p><ul><li>volatile-lru：从已经设置过期时间的数据集中，挑选最近最少使用的数据淘汰 </li><li>volatile-ttl：从已经设置过期时间的数据集中，挑选即将要过期的数据淘汰 </li><li>volatile-random：从已经设置过期时间的数据集中，随机挑选数据淘汰</li><li>allkeys-lru：从所有的数据集中，挑选最近最少使用的数据淘汰 </li><li>allkeys-random：从所有的数据集中，随机挑选数据淘汰</li><li>no-enviction：禁止淘汰数据</li></ul><p> 具体<strong>过期键的策略</strong>有：</p><ul><li>定时删除（缓存过期时间到就删除，创建timer耗CPU）</li><li>惰性删除（获取的时候检查，不获取一直留在内存，对内存不友好）</li><li>定期删除（CPU和内存的折中方案）</li></ul></li><li><p>支持数据持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用；</p></li><li><p>支持数据的备份，即 master - slave 模式的数据备份。</p></li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在<strong>较小数据量的高性能操作和运算</strong>上。</p><h2 id="Redis-支持的数据类型"><a href="#Redis-支持的数据类型" class="headerlink" title="Redis 支持的数据类型"></a>Redis 支持的数据类型</h2><h3 id="基础数据类型"><a href="#基础数据类型" class="headerlink" title="基础数据类型"></a>基础数据类型</h3><p>Redis 支持 5 中数据类型：string（字符串），hash（哈希），list（列表），set（集合），zset（sorted set：有序集合）。</p><ul><li><p><strong>String</strong> key-value, 最基本的数据类型，二进制安全的字符串，最大存储数据512M</p></li><li><p><strong>List</strong> 简单的字符串列表，按插入顺序排序，可以左添加/右添加，最大存储数据量2^32-1。list 内的元素是可重复的。可以做消息队列或最新消息排行等功能。</p></li><li><p><strong>Hash</strong> String类型key-value集合映射表，适合存储对象，并且可以像数据库中一样只对某一项属性值进行存储、读取、修改等操作。最大存储数据量2^32-1。</p></li><li><p><strong>Set</strong> hash表实现，无序的字符串集合，不存在重复的元素，添加、删除、查找复杂度O（1），最大存储数据量2^32-1</p></li><li><p><strong>SortedSet</strong> 每个元素关联一个double类型分数，redis 通过分数来为集合中的成员进行从小到大的排序。zset 的元素是唯一的，但是分数（score）却可以重复，可用作排行榜等场景。</p></li></ul><h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><h4 id="布隆过滤器解决什么问题"><a href="#布隆过滤器解决什么问题" class="headerlink" title="布隆过滤器解决什么问题"></a>布隆过滤器解决什么问题</h4><p>大数据量集合，如何准确快速的判断某个数据是否在大数据量集合中，并且不占用内存？</p><h4 id="布隆过滤器怎么解决该问题"><a href="#布隆过滤器怎么解决该问题" class="headerlink" title="布隆过滤器怎么解决该问题"></a>布隆过滤器怎么解决该问题</h4><p>一种数据结构，是由一串很长的二进制向量组成，可以将其看成一个二进制数组。既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_2.png"></p><p>添加数据：自定义几个Hash函数，分别算出Key对应的各个值，将值的位置都置为1。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_1.png"></p><p>判断存在性：如果通过哈希函数算出来的值，对应的地方有0，则数据一定不存在；无法判断数据一定存在。</p><h4 id="布隆过滤器有什么优缺点"><a href="#布隆过滤器有什么优缺点" class="headerlink" title="布隆过滤器有什么优缺点"></a>布隆过滤器有什么优缺点</h4><ul><li>优点：内存占用极小，插入&amp;查询极快</li><li>缺点：无法判断数据一定存在；随着数据量增大，误判率增加；无法删除数据。</li></ul><h4 id="Redis如何实现布隆过滤器"><a href="#Redis如何实现布隆过滤器" class="headerlink" title="Redis如何实现布隆过滤器"></a>Redis如何实现布隆过滤器</h4><p>Redis本身支持bitmap数据结构，通过setbit和getbit即可实现一个Bloom Filter，具体实现参考文章：</p><p><a href="https://segmentfault.com/a/1190000017370384">基于Redis的BloomFilter实现</a></p><p><a href="https://blog.csdn.net/zwx900102/article/details/110307834?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-2&spm=1001.2101.3001.4242">如何利用一个支持元素删除的布隆过滤器来解决缓存穿透问题</a></p><h2 id="Redis-线程模型"><a href="#Redis-线程模型" class="headerlink" title="Redis 线程模型"></a>Redis 线程模型</h2><h3 id="为什么说Redis是单线程模型"><a href="#为什么说Redis是单线程模型" class="headerlink" title="为什么说Redis是单线程模型"></a>为什么说Redis是单线程模型</h3><p>Redis的单线程，其实是指执行Redis命令的<strong>核心模块是单线程</strong>的，也就是文件事件处理器，主要由四个部分组成：</p><ul><li>套接字</li><li>IO多路复用</li><li>文件事件分派器</li><li>事件处理器。</li></ul><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img.png"></p><h3 id="Redis为什么一开始要使用单线程"><a href="#Redis为什么一开始要使用单线程" class="headerlink" title="Redis为什么一开始要使用单线程"></a>Redis为什么一开始要使用单线程</h3><ul><li>使用非阻塞IO和多路复用IO<ul><li>使用IO多路复用机制同时监听多个文件描述符的可读和可写状态</li><li>绝大部分操作纯内存，在单线程模式下，处理的网络请求得到忽略</li></ul></li><li>可维护性高<ul><li>单线程不存在并发读写问题</li><li>无上下文切换，可以避免线程切换带来的开销</li></ul></li><li>Redis本身是基于内存的，数据都存放在内存中，单线程效率依旧高</li><li>普通 KV 存储<strong>瓶颈压根不在 CPU，而往往可能受到内存和网络I/O的制约</strong></li><li>可以通过开启多个Redis实例来利用多核</li></ul><p>Redis6.0其实已经支持多线程来提高性能了。</p><h3 id="Redis为什么要引入多线程"><a href="#Redis为什么要引入多线程" class="headerlink" title="Redis为什么要引入多线程"></a>Redis为什么要引入多线程</h3><p>Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。</p><p>对网络事件进行监听，分发给work thread进行处理，处理完以后将主动权交还给主线程，进行执行操作，当然后续还会有，执行后依然交由 work thread 进行响应数据的 socket write 操作。</p><p>大元素异步删除支持。</p><h2 id="Redis-高可用架构"><a href="#Redis-高可用架构" class="headerlink" title="Redis 高可用架构"></a>Redis 高可用架构</h2><h3 id="首先，保证数据不丢失-数据持久化"><a href="#首先，保证数据不丢失-数据持久化" class="headerlink" title="首先，保证数据不丢失-数据持久化"></a>首先，保证数据不丢失-数据持久化</h3><p>Redis 数据是存储在内存中的，为了保证 Redis 数据不丢失，那就要把数据从内存存储到磁盘上，以便在服务器重启后还能够从磁盘中恢复原有数据，这就是 Redis 的数据持久化。</p><p>Redis 数据持久化有三种方式： 1）AOF 日志（Append Only File，文件追加方式）：记录所有的操作命令，并以文本的形式追加到文件中。 2）RDB 快照（Redis<br>DataBase）：将某一个时刻的内存数据，以二进制的方式写入磁盘。 3）混合持久化方式：Redis 4.0 新增了混合持久化的方式，集成了 RDB 和 AOF 的优点。</p><p><a href="https://baijiahao.baidu.com/s?id=1662843885312435398">详解Redis持久化（RDB和AOF）</a></p><h4 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h4><p>Redis DataBase：采用的是内存快照的方式，它记录的是某一时刻的数据，而不是操作。</p><p>故障恢复时只需要直接把 RDB 文件读入内存即可实现快速恢复。</p><h5 id="快照的过程"><a href="#快照的过程" class="headerlink" title="快照的过程"></a>快照的过程</h5><ul><li> Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；</li><li> 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；</li><li> 当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。</li><li> 在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时（如执行一个写命令 ），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是执行fork一刻的内存数据。</li></ul><p>Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说<strong>任何时候RDB文件都是完整的</strong>。</p><p>这使得我们可以通过定时备份RDB文件来实现Redis数据库备份。</p><p>RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。</p><p>除了自动快照，还可以手动发送SAVE或BGSAVE命令让Redis执行快照。</p><ul><li>SAVE: 是由主进程进行快照操作，会阻塞住其他请求</li><li>BGSAVE: 会通过fork子进程进行快照操作。</li></ul><p>redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将一个记录一千万个字符串类型键、大小为1GB的快照文件载入到内存中需要花费20～30秒钟。 </p><p>通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。<strong>如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化</strong>。</p><h5 id="快照配置"><a href="#快照配置" class="headerlink" title="快照配置"></a>快照配置</h5><p>RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的所有数据进行快照并存储在硬盘上。</p><p>进行快照的条件可以由用户在配置文件中自定义，由两个参数构成：时间和改动的键的个数。</p><p>当在指定的时间内被更改的键的个数大于指定的数值时就会进行快照。</p><p>RDB是redis默认采用的持久化方式，在配置文件中已经预置了3个条件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 900 1      #900秒内有至少1个键被更改则进行快照</span><br><span class="line">save 300 10     #300秒内有至少10个键被更改则进行快照</span><br><span class="line">save 60 10000   #60秒内有至少10000个键被更改则进行快照</span><br></pre></td></tr></table></figure><p>可以存在多个条件，条件之间是”或”的关系，只要满足其中一个条件，就会进行快照。</p><p>如果想要禁用自动快照，只需要将所有的save参数删除即可。</p><p>Redis默认会将快照文件存储在当前目录(可CONFIG GET dir来查看)的dump.rdb文件中，可以通过配置dir和dbfilename两个参数分别指定快照文件的存储路径和文件名。</p><h5 id="快照优势与劣势"><a href="#快照优势与劣势" class="headerlink" title="快照优势与劣势"></a>快照优势与劣势</h5><p>优势：</p><ul><li>全量备份，适合做冷备；</li><li>fork子进程，让子进程执行磁盘 IO 操作，性能影响小；</li><li>相对于 AOF 持久化机制来说，恢复更快；</li><li>fork子进程生成快照时可以会暂停服务。</li></ul><p>劣势：</p><ul><li>如果想要在 Redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好；</li><li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li></ul><h4 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h4><p>Append Only File：采用的是“<strong>写后日志</strong>”的方式，Redis 先执行命令把数据写入内存，然后再记录日志到文件中。</p><p>AOF 日志记录的是操作命令，不是实际的数据，如果采用 AOF 方法做故障恢复时需要将全量日志都执行一遍。</p><h5 id="AOF-重写机制"><a href="#AOF-重写机制" class="headerlink" title="AOF 重写机制"></a>AOF 重写机制</h5><ul><li>解决AOF文件体积膨胀的问题，使用更小的体积来保存数据库状态</li><li>Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区</li><li>AOF缓冲区的内容会定期被写入和同步到AOF文件中，对现有的AOF文件的处理工作会正常进行，从创建子进程开始，服务器执行的所有写操作都会被记录到AOF重写缓冲区中；</li><li>当子进程完成对AOF文件重写之后，它会向父进程发送一个完成信号，父进程接到该完成信号之后，会调用一个信号处理函数，该函数完成以下工作：</li><li>将AOF重写缓存中的内容全部写入到新的AOF文件中；这个时候新的AOF文件所保存的数据库状态和服务器当前的数据库状态一致；</li><li>新的AOF文件进行改名，原子的覆盖原有的AOF文件；完成新旧两个AOF文件的替换。</li><li>在整个AOF后台重写过程中，只有最后的“主进程写入命令到AOF缓存”和“对新的AOF文件进行改名，覆盖原有的AOF文件。”<ul><li>这<strong>两个步骤（信号处理函数执行期间）会造成主进程阻塞</strong>，在其他时候，AOF后台重写都不会对主进程造成阻塞，这将AOF重写对性能造成的影响降到最低。</li></ul></li></ul><h5 id="AOF配置"><a href="#AOF配置" class="headerlink" title="AOF配置"></a>AOF配置</h5><p>默认情况下Redis没有开启AOF(append only file)方式的持久化，可以在redis.conf中通过appendonly参数开启：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure><p>在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相较RDB会慢一些</p><p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendfilename appendonly.aof</span><br></pre></td></tr></table></figure><p>配置redis自动重写AOF文件的条件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">auto-aof-rewrite-percentage 100  # 当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时的AOF文件大小为依据</span><br><span class="line"> </span><br><span class="line">auto-aof-rewrite-min-size 64mb   # 允许重写的最小AOF文件大小</span><br><span class="line">配置写入AOF文件后，要求系统刷新硬盘缓存的机制</span><br><span class="line"> </span><br><span class="line"># appendfsync always   # 每次执行写入都会执行同步，最安全也最慢</span><br><span class="line">appendfsync everysec   # 每秒执行一次同步操作</span><br><span class="line"></span><br><span class="line"># appendfsync no       # 不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次），最快也最不安全</span><br></pre></td></tr></table></figure><h5 id="“写后日志”"><a href="#“写后日志”" class="headerlink" title="“写后日志”"></a>“写后日志”</h5><h6 id="为什么使用写后日志"><a href="#为什么使用写后日志" class="headerlink" title="为什么使用写后日志"></a>为什么使用写后日志</h6><p>Redis 在写入日志之前，不对命令进行语法检查，所以只记录执行成功的命令，避免出现记录错误命令的情况，而且在命令执行后再写日志不会阻塞当前的写操作。</p><h6 id="写后日志有什么风险"><a href="#写后日志有什么风险" class="headerlink" title="写后日志有什么风险"></a>写后日志有什么风险</h6><ul><li>数据可能会丢失：如果 Redis 刚执行完命令，此时发生故障宕机，会导致这条命令存在丢失的风险。</li><li>可能阻塞其他操作：AOF 日志其实也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。</li></ul><h5 id="AOF优势"><a href="#AOF优势" class="headerlink" title="AOF优势"></a>AOF优势</h5><ul><li>数据安全，aof持久化，可以配置appendfsync属性，有always，每进行一次命令操作就记录到aof文件中一次。</li><li>通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题。</li><li>适合误删除紧急恢复-AOF机制的rewrite模式。AOF文件没被rewrite之前（文件过大时，会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）)</li><li>写QPS性能降低(每秒一次性能影响不高)</li></ul><h4 id="持久化机制如何选择"><a href="#持久化机制如何选择" class="headerlink" title="持久化机制如何选择"></a>持久化机制如何选择</h4><p>redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制。</p><p>用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</p><h3 id="其次，解决单点故障-复制副本"><a href="#其次，解决单点故障-复制副本" class="headerlink" title="其次，解决单点故障-复制副本"></a>其次，解决单点故障-复制副本</h3><p>为解决单点数据库问题，Redis会把数据复制多个副本部署到其他节点上。</p><p>通过复制，实现Redis的高可用性，实现对数据的冗余备份，保证数据和服务的高度可靠性。</p><p>Redis的主从结构可以采用一主多从或者级联结构，Redis主从复制可以根据是否是全量分为全量同步和增量同步。下图为级联结构。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_3.png"></p><h4 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h4><p>Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_4.png"></p><p>具体步骤如下：</p><ul><li> 从服务器连接主服务器，发送SYNC命令；</li><li> 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；</li><li> 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；</li><li> 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；</li><li> 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；</li><li> 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；</li></ul><p>完成上面几个步骤后就完成了从服务器数据初始化的所有操作，从服务器此时可以接收来自用户的读请求。</p><h4 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h4><p>Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。</p><p>增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。</p><p>增量同步功能组成部分</p><ol><li>主服务器的复制偏移量和从服务器的复制偏移量；<ul><li>主服务器每次向从服务器传播N个字节的数据时，就将自己的复制偏移量的值加N；</li><li>从服务器每次收到主服务器传播来的N个字节的数据时，就将自己的复制偏移量的值加上N。</li></ul></li><li>主服务器的复制积压缓冲区；<ul><li>由主服务器维护的一个固定长度队列，默认为1M，当主服务器进行命令传播时，它不仅会将写命令发送给所有从服务器，还会将写命令入队到复制积压缓冲区里面。</li></ul></li><li>服务器的运行ID。<ul><li>每个服务器在启动时随机生成运行ID（runid）。</li></ul></li></ol><p>Redis增量同步功能实现：</p><ol><li>从服务器向主服务器发送PSYNC命令，携带主服务器的runid和复制偏移量；</li><li>主服务器验证runid和自身runid是否一致，如不一致，则进行全量复制；</li><li>主服务器验证复制偏移量是否在积压缓冲区内，如不在，则进行全量复制；</li><li>如都验证通过，则主服务器将保持在积压区内的偏移量后的所有数据发送给从服务器，主从服务器再次回到一致状态。</li></ol><p>总结： </p><ol><li>只有当从服务器的携带的主服务器runid和offset都符合，Redis才会采用增量同步的策略，存在着很大的局限性；</li><li>因此从服务器重启、更换主服务器、以及断连时间过长，redis都会采用全量同步的策略。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">因为只要Slave启动，就会发送sync请求和主机全量同步，当多个同时出现的时候，可能会导致Master IO剧增宕机</span><br></pre></td></tr></table></figure><h4 id="主从同步注意事项"><a href="#主从同步注意事项" class="headerlink" title="主从同步注意事项"></a>主从同步注意事项</h4><ol><li>Redis使用异步复制。但从Redis 2.8开始，从服务器会周期性的应答从复制流中处理的数据量。<ul><li>主从服务器之间会定期进行通话，但是如果master上设置了密码，那么如果不给slave设置密码就会导致slave不能跟master进行任何操作，所以如果你的master服务器<br>上有密码，那么也需要给slave相应的设置一下密码（通过设置配置文件中的masterauth）</li></ul></li><li>一个主服务器可以有多个从服务器。<ul><li>一般slave服务器不能进行写操作，但是这不是死的，之所以这样是为了更容易的保证主和各个从之间数据的一致性，如果slave服务器上数据进行了修改， 那么要保证所有主从服务器都能一致，可能在结构上和处理逻辑上更为负责。不过你也可以通过配置文件让从服务器支持写操作。（所带来的影响还得自己承担）   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">从服务器默认只读模式，这个行为是由Redis.conf文件中的slave-read-only 参数控制的，可以在运行中通过CONFIG SET来启用或者禁用。</span><br><span class="line"></span><br><span class="line">只读的从服务器会拒绝所有写命令，所以对从服务器不会有误写操作。但这不表示可以把从服务器实例暴露在危险的网络环境下。</span><br><span class="line">因为像DEBUG或者CONFIG这样的管理命令还是可以运行的。不过你可以通过使用rename-command命令来为这些命令改名来增加安全性。</span><br><span class="line"></span><br><span class="line">你可能想知道为什么只读限制还可以被还原，使得从服务器还可以进行写操作。虽然当主从服务器进行重新同步或者从服务器重启后，</span><br><span class="line">这些写操作都会失效，还是有一些使用场景会想从服务器中写入临时数据的，但将来这个特性可能会被去掉。</span><br></pre></td></tr></table></figure></li><li>可以配置主服务器连接N个以上从服务器才允许对主服务器进行写操作。   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">因为Redis使用的是异步主从复制，</span><br><span class="line">没办法确保从服务器确实收到了要写入的数据，所以还是有一定的数据丢失的可能性。</span><br><span class="line"></span><br><span class="line">这一特性的工作原理如下：</span><br><span class="line">1）从服务器每秒钟ping一次主服务器，确认处理的复制流数量。</span><br><span class="line">2）主服务器记住每个从服务器最近一次ping的时间。</span><br><span class="line">3）用户可以配置最少要有N个服务器有小于M秒的确认延迟。</span><br><span class="line">4）如果有N个以上从服务器，并且确认延迟小于M秒，主服务器接受写操作。</span><br><span class="line"></span><br><span class="line">还可以把这看做是CAP原则（一致性，可用性，分区容错性）不严格的一致性实现，虽然不能百分百确保一致性，但至少保证了丢失的数据不会超过M秒内的数据量。</span><br><span class="line"></span><br><span class="line">如果条件不满足，主服务器会拒绝写操作并返回一个错误。</span><br><span class="line">1）min-slaves-to-write（最小从服务器数）</span><br><span class="line">2）min-slaves-max-lag（从服务器最大确认延迟）</span><br></pre></td></tr></table></figure></li></ul></li><li>从服务器也可以接受其他从服务器的连接。<ul><li>除了多个从服务器连接到一个主服务器之外，多个从服务器也可以连接到一个从服务器上，形成一个<br>图状结构。</li></ul></li><li>Redis主从复制不阻塞主服务器端。也就是说当若干个从服务器在进行初始同步时，主服务器仍然可以处理请求。</li><li>主从复制也不阻塞从服务器端。<ul><li>当从服务器进行初始同步时，它使用旧版本的数据来应对查询请求，假设你在redis.conf配置文件是这么配置的。</li><li>否则的话，你可以配置当复制流关闭时让从服务器给客户端返回一个错误。但是，当初始同步完成后，需要删除旧的数据集和加载新的数据集，在这个短暂的时间内，从服务器会阻塞连接进来的请求。</li></ul></li><li>主从复制可以用来增强扩展性，使用多个从服务器来处理只读的请求（比如，繁重的排序操作可以放到从服务器去做），也可以简单的用来做数据冗余。</li><li>使用主从复制可以为主服务器免除把数据写入磁盘的消耗：在主服务器的redis.conf文件中配置“避免保存”（注释掉所有“保存“命令），然后连接一个配置为“进行保存”的从服务器即可。<ul><li>这个配置要确保主服务器不会自动重启，主redis服务器一旦重启，因为主redis服务器数据为空，这时候通过主从同步可能导致从redis服务器上的数据也被清空。</li><li>全量同步过程中，master会将数据保存在rdb文件中然后发送给slave服务器，但是如果master上的磁盘空间有效怎么办呢？那么此时全部同步对于master来说将是一份十分有压力的操作了。此时可以通过<strong>无盘复制</strong>来达到目的，由master直接开启一个socket将rdb文件发送给slave服务器。（无盘复制一般应用在磁盘空间有限但是网络状态良好的情况下）</li><li>强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启。   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">设置节点A为主服务器，关闭持久化，节点B和C从节点A复制数据。</span><br><span class="line">这时出现了一个崩溃，但Redis具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。</span><br><span class="line">节点B和C从节点A进行复制，现在节点A是空的，所以节点B和C上的复制数据也会被删除。</span><br><span class="line">当在高可用系统中使用Redis Sentinel，关闭了主服务器的持久化，并且允许自动重启，这种情况是很危险的。</span><br><span class="line">比如主服务器可能在很短的时间就完成了重启，以至于Sentinel都无法检测到这次失败，那么上面说的这种失败的情况就发生了。</span><br><span class="line">    </span><br><span class="line">如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。</span><br></pre></td></tr></table></figure></li></ul></li><li>关于slave服务器上过期键的处理，由master服务器负责键的过期删除处理，然后将相关删除命令已数据同步的方式同步给slave服务器，slave服务器根据删除命令删除<br>本地的key。</li></ol><h3 id="最后，满足不同架构需求-多种架构模式"><a href="#最后，满足不同架构需求-多种架构模式" class="headerlink" title="最后，满足不同架构需求-多种架构模式"></a>最后，满足不同架构需求-多种架构模式</h3><p>为了满足开发市场需求，Redis 支持<strong>单机、主从、哨兵、集群</strong>多种架构模式。</p><h4 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h4><p>单机模式顾名思义就是安装一个 Redis，启动起来，业务调用即可。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_5.png"></p><p>一些简单的应用，并非必须保证高可用的情况下可以使用该模式。</p><p>优点：</p><ul><li>部署简单；</li><li>成本低，无备用节点；</li><li>高性能，单机不需要同步数据，数据天然一致性。</li></ul><p>缺点:</p><ul><li>可靠性保证不是很好，单节点有宕机的风险。</li><li>单机高性能受限于 CPU 的处理能力，Redis 是单线程的。</li></ul><p>单机 Redis 能够承载的 QPS（每秒查询速率）大概在几万左右。 取决于业务操作的复杂性，Lua 脚本复杂性就极高。假如是简单的 key value 查询那性能就会很高。</p><p>假设上千万、上亿用户同时访问 Redis，QPS 达到 10 万+。这些请求过来，单机 Redis 直接就挂了。系统的瓶颈就出现在 Redis 单机问题上，此时我们可以通过<strong>主从复制</strong>解决该问题，实现系统的高并发</p><h4 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h4><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_6.png"></p><p>Redis 的复制（Replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（Master），而通过复制创建出来的复制品则为从服务器（Slave）。 只要主从服务器之间的网络连接正常，主服务器就会将写入自己的数据同步更新给从服务器，从而保证主从服务器的数据相同。</p><p>数据的复制是单向的，只能由主节点到从节点，简单理解就是从节点只支持读操作，不允许写操作。主要是读高并发的场景下用主从架构。</p><p>主从模式需要考虑的问题是：当 Master 节点宕机，需要选举产生一个新的 Master 节点，从而保证服务的高可用性。</p><p>优点：</p><ul><li>Master/Slave 角色方便水平扩展，QPS 增加，增加 Slave 即可；</li><li>降低 Master 读压力，转交给 Slave 节点；</li><li>主节点宕机，从节点作为主节点的备份可以随时顶上继续提供服务；</li></ul><p>缺点： </p><ul><li>可靠性保证不是很好，主节点故障便无法提供写入服务；</li><li>没有解决主节点写的压力；</li><li>数据冗余（为了高并发、高可用和高性能，一般是允许有冗余存在的）；</li><li>一旦主节点宕机，从节点晋升成主节点，需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预；</li><li>主节点的写能力受到单机的限制；</li><li>主节点的存储能力受到单机的限制。</li></ul><h4 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h4><p>主从模式中，当主节点宕机之后，从节点是可以作为主节点顶上来继续提供服务，但是需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。</p><p>于是，在 Redis 2.8 版本开始，引入了哨兵（Sentinel）这个概念，在主从复制的基础上，哨兵实现了自动化故障恢复。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_7.png"></p><p>如图所示，哨兵模式由两部分组成，哨兵节点和数据节点：</p><ul><li>哨兵节点：哨兵节点是特殊的 Redis 节点，不存储数据；</li><li>数据节点：主节点和从节点都是数据节点。</li></ul><p>Redis Sentinel 是分布式系统中监控 Redis 主从服务器，并提供主服务器下线时自动故障转移功能的模式。</p><p>其中三个特性为：</p><ul><li>监控(Monitoring)：Sentinel 会不断地检查你的主服务器和从服务器是否运作正常；</li><li>提醒(Notification)：当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知；</li><li>自动故障迁移(Automatic failover)：当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。</li></ul><h5 id="Sentinel关键名词"><a href="#Sentinel关键名词" class="headerlink" title="Sentinel关键名词"></a>Sentinel关键名词</h5><p>####### 定时任务<br>Sentinel 内部有 3 个定时任务，分别是：</p><ul><li>每 1 秒每个 Sentinel 对其他 Sentinel 和 Redis 节点执行 PING 操作（监控），这是一个心跳检测，是失败判定的依据。</li><li>每 2 秒每个 Sentinel 通过 Master 节点的 channel 交换信息（Publish/Subscribe）；</li><li>每 10 秒每个 Sentinel 会对 Master 和 Slave 执行 INFO 命令，这个任务主要达到两个目的：<ul><li>发现 Slave 节点；</li><li>确认主从关系。</li></ul></li></ul><p>####### 主观下线<br>所谓主观下线（Subjectively Down， 简称 SDOWN）指的是单个 Sentinel 实例对服务器做出的下线判断，即单个 Sentinel 认为某个服务下线（有可能是接收不到订阅，之间的网络不通等等原因）。</p><p>主观下线就是说如果服务器在给定的毫秒数之内，没有返回 Sentinel 发送的 PING 命令的回复，或者返回一个错误，那么 Sentinel 会将这个服务器标记为主观下线（SDOWN）。</p><p>####### 客观下线<br>客观下线（Objectively Down， 简称 ODOWN）指的是多个 Sentinel 实例在对同一个服务器做出 SDOWN 判断，并且通过命令互相交流之后，得出的服务器下线判断，然后开启 failover。</p><p>只有在足够数量的 Sentinel 都将一个服务器标记为主观下线之后， 服务器才会被标记为客观下线（ODOWN）。</p><p>只有当 Master 被认定为客观下线时，才会发生故障迁移。</p><p>####### 仲裁<br>仲裁指的是配置文件中的 <code>quorum</code> 选项。</p><p>某个 Sentinel 先将 Master 节点标记为主观下线，然后会将这个判定通过 sentinel is-master-down-by-addr 命令询问其他 Sentinel 节点是否也同样认为该 addr 的 Master 节点要做主观下线。</p><p>最后当达成这一共识的 Sentinel 个数达到前面说的 <code>quorum</code> 设置的值时，该 Master 节点会被认定为客观下线并进行故障转移。</p><p><code>quorum</code> 的值一般设置为 Sentinel 个数的二分之一加 1，例如 3 个 Sentinel 就设置为 2。</p><h5 id="Sentinel工作原理"><a href="#Sentinel工作原理" class="headerlink" title="Sentinel工作原理"></a>Sentinel工作原理</h5><ol><li>每个 Sentinel 以每秒一次的频率向它所知的 Master，Slave 以及其他 Sentinel 节点发送一个 PING 命令；</li><li>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过配置文件 own-after-milliseconds 选项所指定的值，则这个实例会被 Sentinel 标记为主观下线；</li><li>如果一个 Master 被标记为主观下线，那么正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认 Master 是否真的进入主观下线状态；</li><li>当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 Master 的确进入了主观下线状态，则 Master 会被标记为客观下线；</li><li>如果 Master 处于 ODOWN 状态，则投票自动选出新的主节点。将剩余的从节点指向新的主节点继续进行数据复制；</li><li>在正常情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 INFO 命令；当 Master 被 Sentinel 标记为客观下线时，Sentinel 向已下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次；</li><li>若没有足够数量的 Sentinel 同意 Master 已经下线，Master 的客观下线状态就会被移除。若 Master 重新向 Sentinel 的 PING 命令返回有效回复，Master 的主观下线状态就会被移除。</li></ol><h5 id="哨兵模式的优缺点"><a href="#哨兵模式的优缺点" class="headerlink" title="哨兵模式的优缺点"></a>哨兵模式的优缺点</h5><h6 id="哨兵模式的优点"><a href="#哨兵模式的优点" class="headerlink" title="哨兵模式的优点"></a>哨兵模式的优点</h6><ul><li>哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都有；</li><li>主从可以自动切换，系统更健壮，可用性更高；</li><li>Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。</li></ul><h6 id="哨兵模式的缺点"><a href="#哨兵模式的缺点" class="headerlink" title="哨兵模式的缺点"></a>哨兵模式的缺点</h6><ul><li>主从切换需要时间，会丢失数据；</li><li>还是没有解决主节点写的压力；</li><li>主节点的写能力，存储能力受到单机的限制；</li><li>动态扩容困难复杂，对于集群，容量达到上限时在线扩容会变得很复杂。</li></ul><h4 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h4><p>假设上千万、上亿用户同时访问 Redis，QPS 达到 10 万+。这些请求过来，<strong>单机</strong> Redis 直接就挂了。系统的瓶颈就出现在 Redis 单机问题上，此时我们可以通过<strong>主从复制</strong>解决该问题，实现系统的高并发。</p><p>主从模式中，当主节点宕机之后，从节点是可以作为主节点顶上来继续提供服务，但是需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。于是，在 Redis 2.8 版本开始，引入了<strong>哨兵</strong>（Sentinel）这个概念，在<strong>主从复制</strong>的基础上，哨兵实现了<strong>自动化故障恢复</strong>。</p><p>哨兵模式中，单个节点的写能力，存储能力受到单机的限制，动态扩容困难复杂。于是，Redis 3.0 版本正式推出 <strong>Redis Cluster 集群</strong>模式，有效地解决了 Redis 分布式方面的需求。Redis Cluster 集群模式具有<strong>高可用、可扩展性、分布式、容错</strong>等特性。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_8.png"></p><p>Redis Cluster 采用无中心结构，<strong>每个节点都可以保存数据和整个集群状态</strong>，每个节点都和其他所有节点连接。</p><p>Cluster 一般由多个节点组成，节点数量至少为 6 个才能保证组成完整高可用的集群，其中三个为主节点，三个为从节点。</p><p>三个主节点会分配<strong>槽</strong>，处理客户端的命令请求，而从节点可用在主节点故障后，顶替主节点。</p><p>如上图所示，该集群中包含 6 个 Redis 节点，3 主 3 从，分别为 M1，M2，M3，S1，S2，S3。</p><p>除了主从 Redis 节点之间进行数据复制外，所有 Redis 节点之间采用 <strong>Gossip 协议</strong>进行通信，交换维护节点元数据信息。</p><p>总结下来就是：读请求分配给 Slave 节点，写请求分配给 Master，数据同步从 Master 到 Slave 节点。</p><h5 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h5><p>单机、主从、哨兵的模式数据都是存储在一个节点上，其他节点进行数据的复制。</p><p>而单个节点存储是存在上限的，集群模式就是把数据进行<strong>分片存储</strong>，当一个分片数据达到上限的时候，还可以分成多个分片。</p><p>Redis Cluster 采用<strong>虚拟哈希槽分区</strong>，所有的键根据哈希函数映射到 0 ~ 16383 整数槽内，计算公式：HASH_SLOT = CRC16(key) % 16384。</p><p>每一个节点负责维护一部分槽以及槽所映射的键值数据。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/img_9.png"></p><p>Redis Cluster 提供了灵活的节点扩容和缩容方案。在不影响集群对外服务的情况下，可以为集群添加节点进行扩容也可以下线部分节点进行缩容。</p><p>可以说，槽是 Redis Cluster 管理数据的基本单位，集群伸缩就是槽和数据在节点之间的移动。</p><p>简单的理解就是：扩容或缩容以后，槽需要重新分配，数据也需要重新迁移，但是服务不需要下线。</p><p>假如，这里有 3 个节点的集群环境如下：</p><ul><li>节点 A 哈希槽范围为 0 ~ 5500；</li><li>节点 B 哈希槽范围为 5501 ~ 11000；</li><li>节点 C 哈希槽范围为 11001 ~ 16383。</li></ul><p>此时，我们如果要存储数据，按照 Redis Cluster 哈希槽的算法，假设结果是： CRC16(key) % 16384 = 6782。 那么就会把这个 key 的存储分配到 B 节点。此时连接 A、B、C 任何一个节点获取 key，都会这样计算，最终通过 B 节点获取数据。</p><p>假如这时我们新增一个节点 D，Redis Cluster 会从各个节点中拿取一部分 Slot 到 D 上，比如会变成这样：</p><ul><li>节点 A 哈希槽范围为 1266 ~ 5500；</li><li>节点 B 哈希槽范围为 6827 ~ 11000；</li><li>节点 C 哈希槽范围为 12288 ~ 16383；</li><li>节点 D 哈希槽范围为 0 ~ 1265，5501 ~ 6826，11001 ~ 12287</li></ul><p>这种特性允许在集群中轻松地添加和删除节点。</p><p>同样的如果我想删除节点 D，只需要将节点 D 的哈希槽移动到其他节点，当节点是空时，便可完全将它从集群中移除。</p><h5 id="主从"><a href="#主从" class="headerlink" title="主从"></a>主从</h5><p>Redis Cluster 为了保证数据的高可用性，加入了主从模式，一个主节点对应一个或多个从节点，主节点提供数据存取，从节点复制主节点数据备份，当这个主节点挂掉后，就会通过这个主节点的从节点选取一个来充当主节点，从而保证集群的高可用。</p><p>回到刚才的例子中，集群有 A、B、C 三个主节点，如果这 3 个节点都没有对应的从节点，如果 B 挂掉了，则集群将无法继续，因为我们不再有办法为 5501 ~ 11000 范围内的哈希槽提供服务。</p><p>所以我们在创建集群的时候，一定要为每个主节点都添加对应的从节点。比如，集群包含主节点 A、B、C，以及从节点 A1、B1、C1，那么即使 B 挂掉系统也可以继续正确工作。</p><p>因为 B1 节点属于 B 节点的子节点，所以 Redis 集群将会选择 B1 节点作为新的主节点，集群将会继续正确地提供服务。当 B 重新开启后，它就会变成 B1 的从节点。但是请注意，如果节点 B 和 B1 同时挂掉，Redis Cluster 就无法继续正确地提供服务了。</p><h5 id="Redis-Cluster优缺点"><a href="#Redis-Cluster优缺点" class="headerlink" title="Redis Cluster优缺点"></a>Redis Cluster优缺点</h5><h6 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h6><ul><li>无中心架构；</li><li>可扩展性，数据按照 Slot 存储分布在多个节点，节点间数据共享，节点可动态添加或删除，可动态调整数据分布；</li><li>高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做备份数据副本。</li><li>实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升。</li></ul><h6 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h6><ul><li>数据通过异步复制，<strong>无法保证数据强一致性</strong>；</li><li>集群环境搭建复杂，不过基于 Docker 的搭建方案会相对简单。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis底层存储结构之用户数据结构存储模式详解</title>
      <link href="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/"/>
      <url>/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Redis作为目前已知速度最快的Key-Value数据库，本质上是一个数据结构服务器（data structures server），以高效的方式实现了多种现成的数据结构，研究它的数据结构和基于其上的算法，对于我们自己提升局部算法的编程水平有很重要的参考意义。</p><p>当我们提到Redis的“数据结构”，可能是在两个不同的层面来讨论它。</p><p>第一个层面，是从使用者的角度。比如：</p><ul><li>string</li><li>list</li><li>hash</li><li>set</li><li>sorted set</li></ul><p>这一层面也是Redis暴露给外部的调用接口。</p><p>第二个层面，是从内部实现的角度，属于更底层的实现。 比如：</p><ul><li>dict</li><li>sds</li><li>ziplist</li><li>quicklist</li><li>skiplist</li></ul><p>对于第一个层面的”数据结构“，<a href="http://redis.io/topics/data-types-intro">Redis官方文档</a>有详细介绍，我们在 <a href="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%88%9D%E6%8E%A2%E4%B9%8B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/" title="Redis初探之常见问题汇总">Redis初探之常见问题汇总</a> 也有简单的总结。</p><p>本文的重点在于讨论第二个层面：</p><ul><li>Redis数据结构的内部实现</li><li>以及这两个层面的数据结构之间的关系： Redis如何通过组合第二个层面的各种基础数据结构来实现第一个层面的更高层的数据结构。</li></ul><p>在讨论任何一个系统的内部实现的时候，我们都要先明确它的设计原则，这样我们才能更深刻地理解它为什么会进行如此设计的真正意图。</p><p>在本文接下来的讨论中，我们主要关注以下几点：</p><ul><li>存储效率（memory efficiency）。<ul><li>Redis是专用于存储数据的，它对于计算机资源的主要消耗就在于内存，因此节省内存是它非常非常重要的一个方面。</li><li>这意味着Redis一定是非常精细地考虑了<strong>压缩数据、减少内存碎片</strong>等问题。</li></ul></li><li>快速响应时间（fast response time）。<ul><li>与快速响应时间相对的，是高吞吐量（high throughput）。</li><li>Redis是用于提供在线访问的，对于单个请求的响应时间要求很高，因此，<strong>快速响应时间是比高吞吐量更重要的目标</strong>。</li><li>有时候，这两个目标是矛盾的。</li></ul></li><li>单线程（single-threaded）。<ul><li>Redis的性能瓶颈不在于CPU资源，而在于内存访问和网络IO。</li><li>而采用单线程的设计带来的好处是，极大简化了数据结构和算法的实现。</li><li>相反，Redis通过异步IO和pipelining等机制来实现高速的并发访问。</li><li>显然，单线程的设计，对于单个请求的快速响应时间也提出了更高的要求。</li></ul></li></ul><h2 id="Redis-Dict结构"><a href="#Redis-Dict结构" class="headerlink" title="Redis Dict结构"></a>Redis Dict结构</h2><p>dict是一个用于维护key和value映射关系的数据结构，与很多语言中的Map或dictionary类似。</p><ul><li>Redis的一个database中所有key到value的映射，就是使用一个dict来维护的。</li></ul><p>不过，这只是它在Redis中的一个用途而已，它在Redis中被使用的地方还有很多。</p><ul><li>比如，一个Redis hash结构，当它的field较多时，便会采用dict来存储。</li><li>再比如，Redis配合使用dict和skiplist来共同维护一个sorted set。</li></ul><p>这些细节我们后面再讨论，我们先集中精力讨论dict本身的实现。</p><h3 id="为什么要使用Dict"><a href="#为什么要使用Dict" class="headerlink" title="为什么要使用Dict"></a>为什么要使用Dict</h3><p>dict本质上是为了解决算法中的查找问题（Searching）。</p><p>一般查找问题的解法分为两个大类：</p><ul><li>一个是基于各种平衡树，</li><li>一个是基于哈希表。</li></ul><p>我们平常使用的各种Map或dictionary，大都是基于哈希表实现的。</p><p>在不要求数据有序存储，且能保持较低的哈希值冲突概率的前提下，基于哈希表的查找性能能做到非常高效，接近O(1)，而且实现简单。</p><p>在Redis中，dict也是一个<strong>基于哈希表</strong>的算法。</p><p>和传统的哈希算法类似，它采用某个<strong>哈希函数</strong>从key计算得到在哈希表中的位置，采用<strong>拉链法</strong>解决冲突，并在装载因子（load factor）超过预定值时自动扩展内存，引发<strong>重哈希</strong>（rehashing）。</p><p>Redis的dict实现最显著的一个特点，就在于它的重哈希。</p><p>它采用了一种称为<strong>增量式重哈希</strong>（incremental rehashing）的方法，在需要扩展内存时避免一次性对所有key进行重哈希，而是将重哈希操作分散到对于dict的各个增删改查的操作中去。</p><p>这种方法能做到<strong>每次只对一小部分key进行重哈希</strong>，而每次重哈希之间不影响dict的操作。</p><p>dict之所以这样设计，是为了<strong>避免重哈希期间单个请求的响应时间剧烈增加</strong>，这与前面提到的“快速响应时间”的设计原则是相符的。</p><h3 id="Dict的数据结构定义"><a href="#Dict的数据结构定义" class="headerlink" title="Dict的数据结构定义"></a>Dict的数据结构定义</h3><p>为了实现增量式重哈希（incremental rehashing），dict的数据结构里包含两个哈希表。</p><p>在重哈希期间，数据从第一个哈希表向第二个哈希表迁移。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_6.png"></p><p>其C代码定义如下(出自Redis源码dict.h)：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_7.png"></p><p>结合上面的代码和结构图，可以很清楚地看出dict的结构。</p><h4 id="一个指向dictType结构的指针（type）。"><a href="#一个指向dictType结构的指针（type）。" class="headerlink" title="一个指向dictType结构的指针（type）。"></a>一个指向dictType结构的指针（type）。</h4><ul><li>它通过自定义的方式使得dict的key和value能够存储任何类型的数据。</li><li>dictType结构包含若干函数指针，用于dict的调用者对涉及key和value的各种操作进行自定义。<ul><li>hashFunction，对key进行哈希值计算的哈希算法。</li><li>keyDup和valDup，分别定义key和value的拷贝函数，用于在需要的时候对key和value进行深拷贝，而不仅仅是传递对象指针。</li><li>keyCompare，定义两个key的比较操作，在根据key进行查找时会用到。 </li><li>keyDestructor和valDestructor，分别定义对key和value的析构函数。<h4 id="privdata。"><a href="#privdata。" class="headerlink" title="privdata。"></a>privdata。</h4>一个私有数据指针，由调用者在创建dict的时候传进来，在dictType的某些操作被调用时会传回给调用者。</li></ul></li></ul><h4 id="两个哈希表（ht-2-）。"><a href="#两个哈希表（ht-2-）。" class="headerlink" title="两个哈希表（ht[2]）。"></a>两个哈希表（ht[2]）。</h4><p>它定义一个哈希表的结构，由如下若干项组成:</p><ul><li>一个dictEntry指针数组（table）。<ul><li>key的哈希值最终映射到这个数组的某个位置上（对应一个bucket）。</li><li>如果多个key映射到同一个位置，就发生了冲突，那么就拉出一个dictEntry链表。</li><li>dictEntry结构中包含k, v和指向链表下一项的next指针。<ul><li>k是void指针，这意味着它可以指向任何类型。</li><li>v是个union，当它的值是uint64_t、int64_t或double类型时，就不再需要额外的存储，这有利于减少内存碎片。</li><li>当然，v也可以是void指针，以便能存储任何类型的数据。</li></ul></li></ul></li><li>size：标识dictEntry指针数组的长度。<ul><li>它总是2的指数。</li></ul></li><li>sizemask：用于将哈希值映射到table的位置索引。<ul><li>它的值等于(size-1)，比如7, 15, 31, 63，等等，也就是用二进制表示的各个bit全1的数字。每个key先经过hashFunction计算得到一个哈希值，然后计算(哈希值 &amp; sizemask)得到在table上的位置。相当于计算取余(哈希值 % size)。 </li></ul></li></ul><h4 id="used"><a href="#used" class="headerlink" title="used"></a>used</h4><p>记录dict中现有的数据个数，它与size的比值就是装载因子（load factor）。</p><p>这个比值越大，哈希值冲突概率越高。</p><ul><li><p>只有在重哈希的过程中，ht[0]和ht[1]才都有效。 而在平常情况下，只有ht[0]有效，ht[1]里面没有任何数据。</p></li><li><p>上图表示的就是重哈希进行到中间某一步时的情况。</p></li><li><p>当前重哈希索引（rehashidx）。</p><ul><li>如果rehashidx = -1，表示当前没有在重哈希过程中；</li><li>否则，表示当前正在进行重哈希，且它的值记录了当前重哈希进行到哪一步了。</li></ul></li><li><p>当前正在进行遍历的iterator的个数。这不是我们现在讨论的重点，暂时忽略。</p></li></ul><h3 id="Dict的CURD"><a href="#Dict的CURD" class="headerlink" title="Dict的CURD"></a>Dict的CURD</h3><h4 id="dictCreate"><a href="#dictCreate" class="headerlink" title="dictCreate"></a>dictCreate</h4><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_8.png"></p><p>dictCreate为dict的数据结构分配空间并为各个变量赋初值。</p><p>其中两个哈希表ht[0]和ht[1]起始都没有分配空间，table指针都赋为NULL。</p><p>这意味着要等第一个数据插入时才会真正分配空间。</p><h4 id="dictFind"><a href="#dictFind" class="headerlink" title="dictFind"></a>dictFind</h4><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_9.png"></p><p>上述dictFind的源码，根据dict当前是否正在重哈希，依次做了这么几件事：</p><ul><li>如果当前正在进行重哈希，那么将重哈希过程向前推进一步（即调用_dictRehashStep）。实际上，除了查找，插入和删除也都会触发这一动作。这就将重哈希过程分散到各个查找、插入和删除操作中去了，而不是集中在某一个操作中一次性做完。</li><li>计算key的哈希值（调用dictHashKey，里面的实现会调用前面提到的hashFunction）。</li><li>先在第一个哈希表ht[0]上进行查找。在table数组上定位到哈希值对应的位置（如前所述，通过哈希值与sizemask进行按位与），然后在对应的dictEntry链表上进行查找。查找的时候需要对key进行比较，这时候调用dictCompareKeys，它里面的实现会调用到前面提到的keyCompare。如果找到就返回该项。否则，进行下一步。</li><li>判断当前是否在重哈希，如果没有，那么在ht[0]上的查找结果就是最终结果（没找到，返回NULL）。否则，在ht[1]上进行查找（过程与上一步相同）。</li></ul><p>下面我们有必要看一下增量式重哈希的_dictRehashStep的实现。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_10.png"></p><p>dictRehash每次将重哈希至少向前推进n步（除非不到n步整个重哈希就结束了），每一步都将ht[0]上某一个bucket（即一个dictEntry链表）上的每一个dictEntry移动到ht[1]上，它在ht[1]上的新位置根据ht[1]的sizemask进行重新计算。rehashidx记录了当前尚未迁移（有待迁移）的ht[0]的bucket位置。</p><p>如果dictRehash被调用的时候，rehashidx指向的bucket里一个dictEntry也没有，那么它就没有可迁移的数据。这时它尝试在ht[0].table数组中不断向后遍历，直到找到下一个存有数据的bucket位置。如果一直找不到，则最多走n*10步，本次重哈希暂告结束。</p><p>最后，如果ht[0]上的数据都迁移到ht[1]上了（即d-&gt;ht[0].used == 0），那么整个重哈希结束，ht[0]变成ht[1]的内容，而ht[1]重置为空。</p><p>根据以上对于重哈希过程的分析，我们容易看出，本文前面的dict结构图中所展示的正是rehashidx=2时的情况，前面两个bucket（ht[0].table[0]和ht[0].table[1]）都已经迁移到ht[1]上去了。</p><h4 id="dictAdd-amp-dictReplace"><a href="#dictAdd-amp-dictReplace" class="headerlink" title="dictAdd &amp; dictReplace"></a>dictAdd &amp; dictReplace</h4><p>dictAdd插入新的一对key和value，如果key已经存在，则插入失败。</p><p>dictReplace也是插入一对key和value，不过在key存在的时候，它会更新value。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_11.png"></p><p>以上是dictAdd的关键实现代码。我们主要需要注意以下几点：</p><ul><li>它也会触发推进一步重哈希（_dictRehashStep）。</li><li>如果正在重哈希中，它会把数据插入到ht[1]；否则插入到ht[0]。</li><li>在对应的bucket中插入数据的时候，总是插入到dictEntry的头部。因为新数据接下来被访问的概率可能比较高，这样再次查找它时就比较次数较少。</li><li>_dictKeyIndex在dict中寻找插入位置。如果不在重哈希过程中，它只查找ht[0]；否则查找ht[0]和ht[1]。</li><li>_dictKeyIndex可能触发dict内存扩展（_dictExpandIfNeeded，它将哈希表长度扩展为原来两倍，具体请参考dict.c中源码）。</li></ul><p>dictReplace在dictAdd基础上实现，如下：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_12.png"></p><p>在key已经存在的情况下，dictReplace会同时调用dictAdd和dictFind，这其实相当于两次查找过程。这里Redis的代码不够优化。</p><h4 id="dictDelete"><a href="#dictDelete" class="headerlink" title="dictDelete"></a>dictDelete</h4><p>dictDelete的源码这里忽略，具体请参考dict.c。需要稍加注意的是：</p><p>dictDelete也会触发推进一步重哈希（_dictRehashStep）</p><p>如果当前不在重哈希过程中，它只在ht[0]中查找要删除的key；否则ht[0]和ht[1]它都要查找。</p><p>删除成功后会调用key和value的析构函数（keyDestructor和valDestructor）。</p><h2 id="Redis-SDS"><a href="#Redis-SDS" class="headerlink" title="Redis SDS"></a>Redis SDS</h2><p>不管在哪门编程语言当中，字符串都几乎是使用最多的数据结构。 sds正是在Redis中被广泛使用的字符串结构，它的全称是Simple Dynamic String。</p><p>与其它语言环境中出现的字符串相比，它具有如下显著的特点：</p><ul><li>可动态扩展内存。sds表示的字符串其内容可以修改，也可以追加。在很多语言中字符串会分为mutable和immutable两种，显然sds属于mutable类型的。</li><li>二进制安全（Binary Safe）。sds能存储任意二进制数据，而不仅仅是可打印字符。</li><li>与传统的C语言字符串类型兼容。</li></ul><p>看到这里，很多对Redis有所了解的同学可能已经产生了一个疑问：Redis已经对外暴露了一个字符串结构，叫做string，那这里所说的<strong>sds到底和string是什么关系呢</strong>？可能有人会猜：string是基于sds实现的。这个猜想已经非常接近事实，但在描述上还不太准确。有关string和sds之间关系的详细分析，我们放在后面再讲。现在为了方便讨论，让我们先暂时简单地认为，string的底层实现就是sds。</p><p>在讨论sds的具体实现之前，我们先站在Redis使用者的角度，来观察一下string所支持的一些主要操作。下面是一个操作示例：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_13.png"></p><p>以上这些操作都比较简单，我们简单解释一下：</p><ul><li>初始的字符串的值设为”tielei”。</li><li>第3步通过append命令对字符串进行了追加，变成了”tielei zhang”。</li><li>然后通过setbit命令将第53个bit设置成了1。bit的偏移量从左边开始算，从0开始。其中第48～55bit是中间的空格那个字符，它的ASCII码是0x20。将第53个bit设置成1之后，它的ASCII码变成了0x24，打印出来就是’$’。因此，现在字符串的值变成了”tielei$zhang”。</li><li>最后通过getrange取从倒数第5个字节到倒数第1个字节的内容，得到”zhang”。</li></ul><p>这些命令的实现，有一部分是和sds的实现有关的。下面我们开始详细讨论。</p><h3 id="SDS的数据结构定义"><a href="#SDS的数据结构定义" class="headerlink" title="SDS的数据结构定义"></a>SDS的数据结构定义</h3><p>我们知道，在C语言中，字符串是以’\0’字符结尾（NULL结束符）的字符数组来存储的，通常表达为字符指针的形式（char *）。它不允许字节0出现在字符串中间，因此，它不能用来存储任意的二进制数据。</p><p>我们可以在sds.h中找到sds的类型定义：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">typedef char *sds;</span><br></pre></td></tr></table></figure><p>肯定有人感到困惑了，竟然sds就等同于char *？我们前面提到过，sds和传统的C语言字符串保持类型兼容，因此它们的类型定义是一样的，都是char *。在有些情况下，需要传入一个C语言字符串的地方，也确实可以传入一个sds。</p><p>但是，sds和char *并不等同。sds是Binary Safe的，它可以存储任意二进制数据，不能像C语言字符串那样以字符’\0’来标识字符串的结束，因此它必然有个长度字段。但这个长度字段在哪里呢？</p><p>实际上sds还包含一个header结构：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_14.png"></p><p>sds一共有5种类型的header。之所以有5种，是为了能让不同长度的字符串可以使用不同大小的header。这样，短字符串就能使用较小的header，从而节省内存。</p><p>一个sds字符串的完整结构，由在<strong>内存地址上前后相邻</strong>的两部分组成：</p><ul><li>一个header。通常包含字符串的长度(len)、最大容量(alloc)和flags。sdshdr5有所不同。</li><li>一个字符数组。这个字符数组的长度等于最大容量+1。真正有效的字符串数据，其长度通常小于最大容量。在真正的字符串数据之后，是空余未用的字节（一般以字节0填充），允许在不重新分配内存的前提下让字符串数据向后做有限的扩展。在真正的字符串数据之后，还有一个NULL结束符，即ASCII码为0的’\0’字符。这是为了和传统C字符串兼容。之所以字符数组的长度比最大容量多1个字节，就是为了在字符串长度达到最大容量时仍然有1个字节存放NULL结束符。</li></ul><p>header的类型共有5种，在sds.h中有常量定义。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#define SDS_TYPE_5  0</span><br><span class="line">#define SDS_TYPE_8  1</span><br><span class="line">#define SDS_TYPE_16 2</span><br><span class="line">#define SDS_TYPE_32 3</span><br><span class="line">#define SDS_TYPE_64 4</span><br></pre></td></tr></table></figure><p>除了sdshdr5之外，其它4个header的结构都包含3个字段：</p><ul><li>len: 表示字符串的真正长度（不包含NULL结束符在内）。</li><li>alloc: 表示字符串的最大容量（不包含最后多余的那个字节）。</li><li>flags: 总是占用一个字节。其中的最低3个bit用来表示header的类型。</li></ul><p>sds的数据结构，我们有必要非常仔细地去解析它。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_15.png"></p><p>上图是sds的一个内部结构的例子。图中展示了两个sds字符串s1和s2的内存结构，一个使用sdshdr8类型的header，另一个使用sdshdr16类型的header。但它们都表达了同样的一个长度为6的字符串的值：”tielei”。下面我们结合代码，来解释每一部分的组成。</p><p>sds的字符指针（s1和s2）就是指向真正的数据（字符数组）开始的位置，而header位于内存地址较低的方向。</p><p>在sds.h中有一些跟解析header有关的宏定义：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_16.png"></p><p>其中SDS_HDR用来从sds字符串获得header起始位置的指针，比如SDS_HDR(8, s1)表示s1的header指针，SDS_HDR(16, s2)表示s2的header指针。</p><p>当然，使用SDS_HDR之前我们必须先知道到底是哪一种header，这样我们才知道SDS_HDR第1个参数应该传什么。由sds字符指针获得header类型的方法是，先向低地址方向偏移1个字节的位置，得到flags字段。比如，s1[-1]和s2[-1]分别获得了s1和s2的flags的值。然后取flags的最低3个bit得到header的类型。</p><ul><li>由于s1[-1] == 0x01 == SDS_TYPE_8，因此s1的header类型是sdshdr8。</li><li>由于s2[-1] == 0x02 == SDS_TYPE_16，因此s2的header类型是sdshdr16。</li></ul><p>有了header指针，就能很快定位到它的len和alloc字段：</p><ul><li>s1的header中，len的值为0x06，表示字符串数据长度为6；alloc的值为0x80，表示字符数组最大容量为128。</li><li>s2的header中，len的值为0x0006，表示字符串数据长度为6；alloc的值为0x03E8，表示字符数组最大容量为1000。（注意：图中是按小端地址构成）</li></ul><p>在各个header的类型定义中，还有几个需要我们注意的地方：</p><ul><li>在各个header的定义中使用了__attribute__ ((packed))，是为了让编译器以紧凑模式来分配内存。如果没有这个属性，编译器可能会为struct的字段做优化对齐，在其中填充空字节。那样的话，就不能保证header和sds的数据部分紧紧前后相邻，也不能按照固定向低地址方向偏移1个字节的方式来获取flags字段了。</li><li>在各个header的定义中最后有一个char buf[]。我们注意到这是一个没有指明长度的字符数组，这是C语言中定义字符数组的一种特殊写法，它在这里只是起到一个标记的作用，表示在flags字段后面就是一个字符数组。而程序在为header分配的内存的时候，它并不占用内存空间。如果计算sizeof(struct sdshdr16)的值，那么结果是5个字节，其中没有buf字段。</li><li>sdshdr5与其它几个header结构不同，它不包含alloc字段，而长度使用flags的高5位来存储。因此，它不能为字符串分配空余空间。如果字符串需要动态增长，那么它就必然要重新分配内存才行。所以说，这种类型的sds字符串更适合存储静态的短字符串（长度小于32）。</li></ul><p>至此，我们非常清楚地看到了：sds字符串的header，其实隐藏在真正的字符串数据的前面（低地址方向）。这样的一个定义，有如下几个好处：</p><ul><li>header和数据相邻，而不用分成两块内存空间来单独分配。这有利于减少内存碎片，提高存储效率（memory efficiency）。</li><li>虽然header有多个类型，但sds可以用统一的char *来表达。且它与传统的C语言字符串保持类型兼容。如果一个sds里面存储的是可打印字符串，那么我们可以直接把它传给C函数，比如使用strcmp比较字符串大小，或者使用printf进行打印。</li></ul><p>弄清了sds的数据结构，它的具体操作函数就比较好理解了。</p><h3 id="sds的一些基础函数"><a href="#sds的一些基础函数" class="headerlink" title="sds的一些基础函数"></a>sds的一些基础函数</h3><ul><li>sdslen(const sds s): 获取sds字符串长度。</li><li>sdssetlen(sds s, size_t newlen): 设置sds字符串长度。</li><li>sdsinclen(sds s, size_t inc): 增加sds字符串长度。</li><li>sdsalloc(const sds s): 获取sds字符串容量。</li><li>sdssetalloc(sds s, size_t newlen): 设置sds字符串容量。</li><li>sdsavail(const sds s): 获取sds字符串空余空间（即alloc - len）。</li><li>sdsHdrSize(char type): 根据header类型得到header大小。</li><li>sdsReqType(size_t string_size): 根据字符串数据长度计算所需要的header类型。</li></ul><p>这里我们挑选sdslen和sdsReqType的代码，察看一下。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_17.png"></p><p>sdslen先用s跟前面的分析类似:</p><ul><li>先用s[-1]向低地址方向偏移1个字节，得到flags；</li><li>然后与SDS_TYPE_MASK进行按位与，得到header类型；</li><li>然后根据不同的header类型，调用SDS_HDR得到header起始指针，进而获得len字段。</li></ul><p>通过sdsReqType的代码，很容易看到：</p><ul><li>长度在0和2^5-1之间，选用SDS_TYPE_5类型的header。</li><li>长度在2^5和2^8-1之间，选用SDS_TYPE_8类型的header。</li><li>长度在2^8和2^16-1之间，选用SDS_TYPE_16类型的header。</li><li>长度在2^16和2^32-1之间，选用SDS_TYPE_32类型的header。</li><li>长度大于2^32的，选用SDS_TYPE_64类型的header。能表示的最大长度为2^64-1。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注：sdsReqType的实现代码，直到3.2.0，它在长度边界值上都一直存在问题，直到3.2 branch上的commit 6032340才修复。</span><br></pre></td></tr></table></figure><h3 id="sds的CURD"><a href="#sds的CURD" class="headerlink" title="sds的CURD"></a>sds的CURD</h3><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_18.png"></p><h4 id="sdsnewlen-创建sds字符串"><a href="#sdsnewlen-创建sds字符串" class="headerlink" title="sdsnewlen 创建sds字符串"></a>sdsnewlen 创建sds字符串</h4><p>创建一个长度为initlen的sds字符串，并使用init指向的字符数组（任意二进制数据）来初始化数据。如果init为NULL，那么使用全0来初始化数据。</p><p>它的实现中，我们需要注意的是：</p><ul><li>如果要创建一个长度为0的空字符串，那么不使用SDS_TYPE_5类型的header，而是转而使用SDS_TYPE_8类型的header。这是因为创建的空字符串一般接下来的操作很可能是追加数据，但SDS_TYPE_5类型的sds字符串不适合追加数据（会引发内存重新分配）。</li><li>需要的内存空间一次性进行分配，其中包含三部分：header、数据、最后的多余字节（hdrlen+initlen+1）。</li><li>初始化的sds字符串数据最后会追加一个NULL结束符（s[initlen] = ‘\0’）。</li></ul><h4 id="sdsfree-释放内存"><a href="#sdsfree-释放内存" class="headerlink" title="sdsfree 释放内存"></a>sdsfree 释放内存</h4><p>需要注意的是：内存要整体释放，所以要先计算出header起始指针，把它传给s_free函数。</p><p>这个指针也正是在sdsnewlen中调用s_malloc返回的那个地址。</p><h4 id="sdscatlen-追加操作"><a href="#sdscatlen-追加操作" class="headerlink" title="sdscatlen 追加操作"></a>sdscatlen 追加操作</h4><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_19.png"></p><p>sdscatlen将t指向的长度为len的任意二进制数据追加到sds字符串s的后面。本文开头演示的string的append命令，内部就是调用sdscatlen来实现的。</p><p>在sdscatlen的实现中，先调用sdsMakeRoomFor来保证字符串s有足够的空间来追加长度为len的数据。sdsMakeRoomFor可能会分配新的内存，也可能不会。</p><p>sdsMakeRoomFor是sds实现中很重要的一个函数。关于它的实现代码，我们需要注意的是：</p><ul><li>如果原来字符串中的空余空间够用（avail &gt;= addlen），那么它什么也不做，直接返回。</li><li>如果需要分配空间，它会比实际请求的要多分配一些，以防备接下来继续追加。它在字符串已经比较长的情况下要至少多分配SDS_MAX_PREALLOC个字节，这个常量在sds.h中定义为(1024*1024)=1MB。</li><li>按分配后的空间大小，可能需要更换header类型（原来header的alloc字段太短，表达不了增加后的容量）。</li><li>如果需要更换header，那么整个字符串空间（包括header）都需要重新分配（s_malloc），并拷贝原来的数据到新的位置。</li><li>如果不需要更换header（原来的header够用），那么调用一个比较特殊的s_realloc，试图在原来的地址上重新分配空间。s_realloc的具体实现得看Redis编译的时候选用了哪个allocator（在Linux上默认使用jemalloc）。但不管是哪个realloc的实现，它所表达的含义基本是相同的：它尽量在原来分配好的地址位置重新分配，如果原来的地址位置有足够的空余空间完成重新分配，那么它返回的新地址与传入的旧地址相同；否则，它分配新的地址块，并进行数据搬迁。参见<a href="http://man.cx/realloc%E3%80%82">http://man.cx/realloc。</a></li></ul><p>从sdscatlen的函数接口，我们可以看到一种使用模式：<strong>调用它的时候，传入一个旧的sds变量，然后它返回一个新的sds变量</strong>。由于它的内部实现可能会造成地址变化，因此调用者在调用完之后，原来旧的变量就失效了，而都应该用新返回的变量来替换。不仅仅是sdscatlen函数，sds中的其它函数（比如sdscpy、sdstrim、sdsjoin等），还有Redis中其它一些能自动扩展内存的数据结构（如ziplist），也都是同样的使用模式。</p><h3 id="浅谈sds与string的关系"><a href="#浅谈sds与string的关系" class="headerlink" title="浅谈sds与string的关系"></a>浅谈sds与string的关系</h3><p>现在我们回过头来看看本文开头给出的string操作的例子：</p><ul><li>append操作使用sds的sdscatlen来实现。</li><li>setbit和getrange都是先根据key取到整个sds字符串，然后再从字符串选取或修改指定的部分。由于sds就是一个字符数组，所以对它的某一部分进行操作似乎都比较简单。</li></ul><p>但是，string除了支持这些操作之外，当它存储的值是个数字的时候，它还支持incr、decr等操作。 当string存储数字值的时候，它的内部存储就不是sds了。而且，这种情况下，setbit和getrange的实现也会有所不同。这些细节，我们放在后续robj的时候再进行系统地讨论。</p><h2 id="Redis-robj"><a href="#Redis-robj" class="headerlink" title="Redis robj"></a>Redis robj</h2><p>从Redis的使用者的角度来看，一个Redis节点包含多个database（非cluster模式下默认是16个，cluster模式下只能是1个），而一个database维护了从key space到object space的映射关系。这个映射关系的key是string类型，而value可以是多种数据类型，比如：string, list, hash等。我们可以看到，key的类型固定是string，而value可能的类型是多个。</p><p>而从Redis内部实现的角度来看，一个database内的这个映射关系是用一个dict来维护的。dict的key固定用一种数据结构来表达就够了，这就是动态字符串sds。而value则比较复杂，为了在同一个dict内能够存储不同类型的value，这就需要一个通用的数据结构，这个通用的数据结构就是robj（全名是redisObject）。</p><p>举个例子：</p><ul><li>如果value是一个list，那么它的内部存储结构是一个quicklist（quicklist的具体实现我们放在后面的文章讨论）；</li><li>如果value是一个string，那么它的内部存储结构一般情况下是一个sds。</li><li>当然实际情况更复杂一点，比如一个string类型的value，如果它的值是一个数字，那么Redis内部还会把它转成long型来存储，从而减小内存使用。</li></ul><p>一个robj既能表示一个sds，也能表示一个quicklist，甚至还能表示一个long型。</p><h3 id="robj的数据结构定义"><a href="#robj的数据结构定义" class="headerlink" title="robj的数据结构定义"></a>robj的数据结构定义</h3><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_20.png"></p><p>一个robj包含如下5个字段：</p><ul><li>type: 对象的数据类型。<ul><li>占4个bit。</li><li>可能的取值有5种：OBJ_STRING, OBJ_LIST, OBJ_SET, OBJ_ZSET, OBJ_HASH，分别对应Redis对外暴露的5种数据结构（即我们在第一篇文章中提到的第一个层面的5种数据结构）。</li></ul></li><li>encoding: 对象的内部表示方式（也可以称为编码）。<ul><li>占4个bit。</li><li>可能的取值有10种，即前面代码中的10个OBJ_ENCODING_XXX常量。</li></ul></li><li>lru: 做LRU替换算法用<ul><li>占24个bit。 </li><li>这个不是我们这里讨论的重点，暂时忽略。</li></ul></li><li>refcount: 引用计数。<ul><li>它允许robj对象在某些情况下被共享。</li></ul></li><li>ptr: 数据指针。 <ul><li>指向真正的数据。</li><li>比如，一个代表string的robj，它的ptr可能指向一个sds结构；一个代表list的robj，它的ptr可能指向一个quicklist。</li></ul></li></ul><p>对于同一个type，还可能对应不同的encoding，这说明同样的一个数据类型，可能存在不同的内部表示方式。而不同的内部表示，在内存占用和查找性能上会有所不同。</p><p>这里特别需要仔细察看的是encoding字段。对于同一个type，还可能对应不同的encoding，这说明同样的一个数据类型，可能存在不同的内部表示方式。而不同的内部表示，在内存占用和查找性能上会有所不同。</p><p>比如，当type = OBJ_STRING的时候，表示这个robj存储的是一个string，这时encoding可以是下面3种中的一种：</p><ul><li>OBJ_ENCODING_RAW: string采用原生的表示方式，即用sds来表示。</li><li>OBJ_ENCODING_INT: string采用数字的表示方式，实际上是一个long型。</li><li>OBJ_ENCODING_EMBSTR: string采用一种特殊的嵌入式的sds来表示。接下来我们会讨论到这个细节。</li></ul><p>再举一个例子：当type = OBJ_HASH的时候，表示这个robj存储的是一个hash，这时encoding可以是下面2种中的一种：</p><ul><li>OBJ_ENCODING_HT: hash采用一个dict来表示。</li><li>OBJ_ENCODING_ZIPLIST: hash采用一个ziplist来表示。</li></ul><p>前面代码段中出现的所有10种encoding，在这里我们先简单解释一下：</p><ul><li>OBJ_ENCODING_RAW: 最原生的表示方式。其实只有string类型才会用这个encoding值（表示成sds）。</li><li>OBJ_ENCODING_INT: 表示成数字。实际用long表示。</li><li>OBJ_ENCODING_HT: 表示成dict。</li><li>OBJ_ENCODING_ZIPMAP: 是个旧的表示方式，已不再用。在小于Redis 2.6的版本中才有。</li><li>OBJ_ENCODING_LINKEDLIST: 也是个旧的表示方式，已不再用。</li><li>OBJ_ENCODING_ZIPLIST: 表示成ziplist。</li><li>OBJ_ENCODING_INTSET: 表示成intset。用于set数据结构。</li><li>OBJ_ENCODING_SKIPLIST: 表示成skiplist。用于sorted set数据结构。</li><li>OBJ_ENCODING_EMBSTR: 表示成一种特殊的嵌入式的sds。</li><li>OBJ_ENCODING_QUICKLIST: 表示成quicklist。用于list数据结构。</li></ul><p>我们来总结一下robj的作用：</p><ul><li>为多种数据类型提供一种统一的表示方式。</li><li>允许同一类型的数据采用不同的内部表示，从而在某些情况下尽量节省内存。</li><li>支持对象共享和引用计数。当对象被共享的时候，只占用一份内存拷贝，进一步节省内存。</li></ul><h3 id="string-robj的编码过程"><a href="#string-robj的编码过程" class="headerlink" title="string robj的编码过程"></a>string robj的编码过程</h3><p>当我们执行Redis的set命令的时候，Redis首先将接收到的value值（string类型）表示成一个type = OBJ_STRING并且encoding = OBJ_ENCODING_RAW的robj对象，然后在存入内部存储之前先执行一个编码过程，试图将它表示成另一种更节省内存的encoding方式。这一过程的核心代码，是object.c中的tryObjectEncoding函数。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_21.png"></p><p>这段代码执行的操作比较复杂，我们有必要仔细看一下每一步的操作：</p><ul><li>第1步检查，检查type。确保只对string类型的对象进行操作。</li><li>第2步检查，检查encoding。sdsEncodedObject是定义在server.h中的一个宏，确保只对OBJ_ENCODING_RAW和OBJ_ENCODING_EMBSTR编码的string对象进行操作。这两种编码的string都采用sds来存储，可以尝试进一步编码处理。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define sdsEncodedObject(objptr) (objptr-&gt;encoding == OBJ_ENCODING_RAW </span><br></pre></td></tr></table></figure></li><li>第3步检查，检查refcount。引用计数大于1的共享对象，在多处被引用。由于编码过程结束后robj的对象指针可能会变化（我们在介绍sdscatlen函数的时候提到过类似这种接口使用模式），这样对于引用计数大于1的对象，就需要更新所有地方的引用，这不容易做到。因此，对于计数大于1的对象不做编码处理。</li><li>试图将字符串转成64位的long。64位的long所能表达的数据范围是-2^63到2^63-1，用十进制表达出来最长是20位数（包括负号）。这里判断小于等于21，似乎是写多了，实际判断小于等于20就够了（如果我算错了请一定告诉我哦）。string2l如果将字符串转成long转成功了，那么会返回1并且将转好的long存到value变量里。<ul><li>如果Redis的配置不要求运行LRU替换算法，且转成的long型数字的值又比较小（小于OBJ_SHARED_INTEGERS，在目前的实现中这个值是10000），那么会使用共享数字对象来表示。之所以这里的判断跟LRU有关，是因为LRU算法要求每个robj有不同的lru字段值，所以用了LRU就不能共享robj。shared.integers是一个长度为10000的数组，里面预存了10000个小的数字对象。这些小数字对象都是encoding = OBJ_ENCODING_INT的string robj对象。</li><li>如果前一步不能使用共享小对象来表示，那么将原来的robj编码成encoding = OBJ_ENCODING_INT，这时ptr字段直接存成这个long型的值。注意ptr字段本来是一个void *指针（即存储的是内存地址），因此在64位机器上有64位宽度，正好能存储一个64位的long型值。这样，除了robj本身之外，它就不再需要额外的内存空间来存储字符串值。</li></ul></li><li>接下来是对于那些不能转成64位long的字符串进行处理。最后再做两步处理：<ul><li>如果字符串长度足够小（小于等于OBJ_ENCODING_EMBSTR_SIZE_LIMIT，定义为44），那么调用createEmbeddedStringObject编码成encoding = OBJ_ENCODING_EMBSTR；<br><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_22.png"><br>createEmbeddedStringObject对sds重新分配内存，将robj和sds放在一个连续的内存块中分配，这样对于短字符串的存储有利于减少内存碎片。这个连续的内存块包含如下几部分：<ul><li>16个字节的robj结构。</li><li>3个字节的sdshdr8头。</li><li>最多44个字节的sds字符数组。 </li><li>1个NULL结束符。</li></ul>加起来一共不超过64字节（16+3+44+1），因此这样的一个短字符串可以完全分配在一个64字节长度的内存块中。</li><li>如果前面所有的编码尝试都没有成功（仍然是OBJ_ENCODING_RAW），且sds里空余字节过多，那么做最后一次努力，调用sds的sdsRemoveFreeSpace接口来释放空余字节。</li></ul></li></ul><h3 id="string-robj的解码过程"><a href="#string-robj的解码过程" class="headerlink" title="string robj的解码过程"></a>string robj的解码过程</h3><p>当我们需要获取字符串的值，比如执行get命令的时候，我们需要执行与前面讲的编码过程相反的操作——解码。</p><p>这一解码过程的核心代码，是object.c中的getDecodedObject函数。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_23.png"></p><p>这个过程比较简单，需要我们注意的点有：</p><ul><li><p>编码为OBJ_ENCODING_RAW和OBJ_ENCODING_EMBSTR的字符串robj对象，不做变化，原封不动返回。站在使用者的角度，这两种编码没有什么区别，内部都是封装的sds。</p></li><li><p>编码为数字的字符串robj对象，将long重新转为十进制字符串的形式，然后调用createStringObject转为sds的表示。注意：这里由long转成的sds字符串长度肯定不超过20，而根据createStringObject的实现，它们肯定会被编码成OBJ_ENCODING_EMBSTR的对象。createStringObject的代码如下：<br><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_24.png"></p></li></ul><h3 id="再谈sds与string的关系"><a href="#再谈sds与string的关系" class="headerlink" title="再谈sds与string的关系"></a>再谈sds与string的关系</h3><p>在SDS章节中，我们简单地提到了sds与string的关系；在本节介绍了robj的概念之后，我们重新总结一下sds与string的关系。</p><ul><li>确切地说，string在Redis中是用一个robj来表示的。</li><li>用来表示string的robj可能编码成3种内部表示：OBJ_ENCODING_RAW, OBJ_ENCODING_EMBSTR, OBJ_ENCODING_INT。其中前两种编码使用的是sds来存储，最后一种OBJ_ENCODING_INT编码直接把string存成了long型。</li><li>在对string进行incr, decr等操作的时候，如果它内部是OBJ_ENCODING_INT编码，那么可以直接进行加减操作；如果它内部是OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR编码，那么Redis会先试图把sds存储的字符串转成long型，如果能转成功，再进行加减操作。</li><li>对一个内部表示成long型的string执行append, setbit, getrange这些命令，针对的仍然是string的值（即十进制表示的字符串），而不是针对内部表示的long型进行操作。比如字符串”32”，如果按照字符数组来解释，它包含两个字符，它们的ASCII码分别是0x33和0x32。当我们执行命令setbit key 7 0的时候，相当于把字符0x33变成了0x32，这样字符串的值就变成了”22”。而如果将字符串”32”按照内部的64位long型来解释，那么它是0x0000000000000020，在这个基础上执行setbit位操作，结果就完全不对了。因此，在这些命令的实现中，会把long型先转成字符串再进行相应的操作。由于篇幅原因，这三个命令的实现代码这里就不详细介绍了，有兴趣的读者可以参考Redis源码：<ul><li>t_string.c中的appendCommand函数；</li><li>biops.c中的setbitCommand函数；</li><li>t_string.c中的getrangeCommand函数。</li></ul></li></ul><p>值得一提的是，append和setbit命令的实现中，都会最终调用到db.c中的dbUnshareStringValue函数，将string对象的内部编码转成OBJ_ENCODING_RAW的（只有这种编码的robj对象，其内部的sds 才能在后面自由追加新的内容），并解除可能存在的对象共享状态。这里面调用了前面提到的getDecodedObject。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_25.png"></p><h3 id="robj的引用计数操作"><a href="#robj的引用计数操作" class="headerlink" title="robj的引用计数操作"></a>robj的引用计数操作</h3><p>将robj的引用计数加1和减1的操作，定义在object.c中：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_26.png"></p><p>我们特别关注一下将引用计数减1的操作decrRefCount。如果只剩下最后一个引用了（refcount已经是1了），那么在decrRefCount被调用后，整个robj将被释放。</p><p>注意：<strong>Redis的del命令就依赖decrRefCount操作将value释放掉</strong>。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>我们很容易看出，robj所表示的就是Redis对外暴露的第一层面的数据结构：string, list, hash, set, sorted set，而每一种数据结构的底层实现所对应的是哪个（或哪些）第二层面的数据结构（dict, sds, ziplist, quicklist, skiplist, 等），则通过不同的encoding来区分。</p><p>可以说，robj是联结两个层面的数据结构的桥梁。</p><h2 id="Redis-ziplist"><a href="#Redis-ziplist" class="headerlink" title="Redis ziplist"></a>Redis ziplist</h2><p>我们首先介绍一个新的Redis内部数据结构——ziplist，然后在后半部分我们会讨论一下在robj, dict和ziplist的基础上，Redis对外暴露的hash结构是怎样构建起来的。</p><p>我们在讨论中还会涉及到两个Redis配置（在redis.conf中的ADVANCED CONFIG部分）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hash-max-ziplist-entries 512</span><br><span class="line">hash-max-ziplist-value 64</span><br></pre></td></tr></table></figure><p>后续会对这两个配置做详细的解释。</p><h3 id="什么是ziplist"><a href="#什么是ziplist" class="headerlink" title="什么是ziplist"></a>什么是ziplist</h3><p>Redis官方对于ziplist的定义是（出自ziplist.c的文件头部注释）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The ziplist is a specially encoded dually linked list that is designed to be very memory efficient. It stores both strings and integer values, where integers are encoded as actual integers instead of a series of characters. It allows push and pop operations on either side of the list in O(1) time.</span><br></pre></td></tr></table></figure><p>翻译一下就是说：ziplist是一个经过特殊编码的双向链表，它的设计目标就是为了提高存储效率。ziplist可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以O(1)的时间复杂度在表的两端提供push和pop操作。</p><p>实际上，ziplist充分体现了Redis对于存储效率的追求。一个普通的双向链表，链表中每一项都占用独立的一块内存，各项之间用地址指针（或引用）连接起来。这种方式会带来大量的内存碎片，而且地址指针也会占用额外的内存。而ziplist却是将表中每一项存放在前后连续的地址空间内，一个ziplist整体占用一大块内存。它是一个表（list），但其实不是一个链表（linked list）。</p><p>另外，ziplist为了在细节上节省内存，对于值的存储采用了变长的编码方式，大概意思是说，对于大的整数，就多用一些字节来存储，而对于小的整数，就少用一些字节来存储。我们接下来很快就会讨论到这些实现细节。</p><h3 id="ziplist的数据结构定义"><a href="#ziplist的数据结构定义" class="headerlink" title="ziplist的数据结构定义"></a>ziplist的数据结构定义</h3><p>ziplist的数据结构组成是ziplist要讨论的重点。实际上，ziplist还是稍微有点复杂的，它复杂的地方就在于它的数据结构定义。一旦理解了数据结构，它的一些操作也就比较容易理解了。</p><p>从宏观上看，ziplist的内存结构如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;zlbytes&gt;&lt;zltail&gt;&lt;zllen&gt;&lt;entry&gt;...&lt;entry&gt;&lt;zlend&gt;</span><br></pre></td></tr></table></figure><p>各个部分在内存上是前后相邻的，它们分别的含义如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;zlbytes&gt;: 32bit，表示ziplist占用的字节总数（也包括&lt;zlbytes&gt;本身占用的4个字节）。</span><br><span class="line"></span><br><span class="line">&lt;zltail&gt;: 32bit，表示ziplist表中最后一项（entry）在ziplist中的偏移字节数。&lt;zltail&gt;的存在，使得我们可以很方便地找到最后一项（不用遍历整个ziplist），从而可以在ziplist尾端快速地执行push或pop操作。</span><br><span class="line"></span><br><span class="line">&lt;zllen&gt;: 16bit， 表示ziplist中数据项（entry）的个数。zllen字段因为只有16bit，所以可以表达的最大值为2^16-1。这里需要特别注意的是，如果ziplist中数据项个数超过了16bit能表达的最大值，ziplist仍然可以来表示。那怎么表示呢？这里做了这样的规定：如果&lt;zllen&gt;小于等于2^16-2（也就是不等于2^16-1），那么&lt;zllen&gt;就表示ziplist中数据项的个数；否则，也就是&lt;zllen&gt;等于16bit全为1的情况，那么&lt;zllen&gt;就不表示数据项个数了，这时候要想知道ziplist中数据项总数，那么必须对ziplist从头到尾遍历各个数据项，才能计数出来。</span><br><span class="line"></span><br><span class="line">&lt;entry&gt;: 表示真正存放数据的数据项，长度不定。一个数据项（entry）也有它自己的内部结构，这个稍后再解释。</span><br><span class="line"></span><br><span class="line">&lt;zlend&gt;: ziplist最后1个字节，是一个结束标记，值固定等于255。</span><br></pre></td></tr></table></figure><p>上面的定义中还值得注意的一点是：<code>&lt;zlbytes&gt;, &lt;zltail&gt;,&lt;zllen&gt;</code>既然占据多个字节，那么在存储的时候就有大端（big endian）和小端（little endian）的区别。</p><p>ziplist采取的是<strong>小端模式</strong>来存储，这在下面我们介绍具体例子的时候还会再详细解释。</p><p>我们再来看一下每一个数据项<code>&lt;entry&gt;</code>的构成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;prevrawlen&gt;&lt;len&gt;&lt;data&gt;</span><br></pre></td></tr></table></figure><p>我们看到在真正的数据（<data>）前面，还有两个字段：</data></p><ul><li><code>&lt;prevrawlen&gt;</code>: 表示前一个数据项占用的总字节数。这个字段的用处是为了让ziplist能够从后向前遍历（从后一项的位置，只需向前偏移prevrawlen个字节，就找到了前一项）。这个字段采用变长编码。</li><li><code>&lt;len&gt;</code>: 表示当前数据项的数据长度（即<data>部分的长度）。也采用变长编码。</data></li></ul><p>那么<code>&lt;prevrawlen&gt;</code>和<code>&lt;len&gt;</code>是怎么进行变长编码的呢？各位读者打起精神了，我们终于讲到了ziplist的定义中最繁琐的地方了。</p><p>先说<code>&lt;prevrawlen&gt;</code>。它有两种可能，或者是1个字节，或者是5个字节：</p><ul><li>如果前一个数据项占用字节数小于254，那么<code>&lt;prevrawlen&gt;</code>就只用一个字节来表示，这个字节的值就是前一个数据项的占用字节数。</li><li>如果前一个数据项占用字节数大于等于254，那么<code>&lt;prevrawlen&gt;</code>就用5个字节来表示，其中第1个字节的值是254（作为这种情况的一个标记），而后面4个字节组成一个整型值，来真正存储前一个数据项的占用字节数。</li></ul><p>为什么没有255的情况呢？这是因为：255已经定义为ziplist结束标记<code>&lt;zlend&gt;</code>的值了。</p><p>在ziplist的很多操作的实现中，都会根据数据项的第1个字节是不是255来判断当前是不是到达ziplist的结尾了，因此一个正常的数据的第1个字节（也就是<code>&lt;prevrawlen&gt;</code>的第1个字节）是不能够取255这个值的，否则就冲突了。</p><p>而<code>&lt;len&gt;</code>字段就更加复杂了，它根据第1个字节的不同，总共分为9种情况（下面的表示法是按二进制表示）：</p><ol><li>|00pppppp| - 1 byte。第1个字节最高两个bit是00，那么<code>&lt;len&gt;</code>字段只有1个字节，剩余的6个bit用来表示长度值，最高可以表示63 (2^6-1)。</li><li>|01pppppp|qqqqqqqq| - 2 bytes。第1个字节最高两个bit是01，那么<code>&lt;len&gt;</code>字段占2个字节，总共有14个bit用来表示长度值，最高可以表示16383 (2^14-1)。</li><li>|10__|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| - 5 bytes。第1个字节最高两个bit是10，那么len字段占5个字节，总共使用32个bit来表示长度值（6个bit舍弃不用），最高可以表示2^32-1。</li></ol><p>需要注意的是：在前三种情况下，<code>&lt;data&gt;</code>都是按字符串来存储的；从下面第4种情况开始，<code>&lt;data&gt;</code>开始变为按整数来存储了。</p><ol start="4"><li>|11000000| - 1 byte。<code>&lt;len&gt;</code>字段占用1个字节，值为0xC0，后面的数据<code>&lt;data&gt;</code>存储为2个字节的int16_t类型。</li><li>|11010000| - 1 byte。<code>&lt;len&gt;</code>字段占用1个字节，值为0xD0，后面的数据<code>&lt;data&gt;</code>存储为4个字节的int32_t类型。</li><li>|11100000| - 1 byte。<code>&lt;len&gt;</code>字段占用1个字节，值为0xE0，后面的数据<code>&lt;data&gt;</code>存储为8个字节的int64_t类型。</li><li>|11110000| - 1 byte。<code>&lt;len&gt;</code>字段占用1个字节，值为0xF0，后面的数据<code>&lt;data&gt;</code>存储为3个字节长的整数。</li><li>|11111110| - 1 byte。<code>&lt;len&gt;</code>字段占用1个字节，值为0xFE，后面的数据<code>&lt;data&gt;</code>存储为1个字节的整数。</li><li>|1111xxxx| – (xxxx的值在0001和1101之间)。这是一种特殊情况，xxxx从1到13一共13个值，这时就用这13个值来表示真正的数据。注意，这里是表示真正的数据，而不是数据长度了。也就是说，在这种情况下，后面不再需要一个单独的<code>&lt;data&gt;</code>字段来表示真正的数据了，而是<code>&lt;len&gt;</code>和<code>&lt;data&gt;</code>合二为一了。另外，由于xxxx只能取0001和1101这13个值了（其它可能的值和其它情况冲突了，比如0000和1110分别同前面第7种第8种情况冲突，1111跟结束标记冲突），而小数值应该从0开始，因此这13个值分别表示0到12，即xxxx的值减去1才是它所要表示的那个整数数据的值。</li></ol><p>好了，ziplist的数据结构定义，我们介绍了完了，现在我们看一个具体的例子。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_27.png"></p><p>上图是一份真实的ziplist数据。我们逐项解读一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">* 这个ziplist一共包含33个字节。字节编号从byte[0]到byte[32]。图中每个字节的值使用16进制表示。</span><br><span class="line">* 头4个字节（0x21000000）是按小端（little endian）模式存储的&lt;zlbytes&gt;字段。什么是小端呢？就是指数据的低字节保存在内存的低地址中（参见维基百科词条Endianness）。因此，这里&lt;zlbytes&gt;的值应该解析成0x00000021，用十进制表示正好就是33。</span><br><span class="line">* 接下来4个字节（byte[4..7]）是&lt;zltail&gt;，用小端存储模式来解释，它的值是0x0000001D（值为29），表示最后一个数据项在byte[29]的位置（那个数据项为0x05FE14）。</span><br><span class="line">* 再接下来2个字节（byte[8..9]），值为0x0004，表示这个ziplist里一共存有4项数据。</span><br><span class="line">* 接下来6个字节（byte[10..15]）是第1个数据项。其中，prevrawlen=0，因为它前面没有数据项；len=4，相当于前面定义的9种情况中的第1种，表示后面4个字节按字符串存储数据，数据的值为&quot;name&quot;。</span><br><span class="line">* 接下来8个字节（byte[16..23]）是第2个数据项，与前面数据项存储格式类似，存储1个字符串&quot;tielei&quot;。</span><br><span class="line">* 接下来5个字节（byte[24..28]）是第3个数据项，与前面数据项存储格式类似，存储1个字符串&quot;age&quot;。</span><br><span class="line">* 接下来3个字节（byte[29..31]）是最后一个数据项，它的格式与前面的数据项存储格式不太一样。其中，第1个字节prevrawlen=5，表示前一个数据项占用5个字节；第2个字节=FE，相当于前面定义的9种情况中的第8种，所以后面还有1个字节用来表示真正的数据，并且以整数表示。它的值是20（0x14）。</span><br><span class="line">* 最后1个字节（byte[32]）表示&lt;zlend&gt;，是固定的值255（0xFF）。</span><br></pre></td></tr></table></figure><p>总结一下，这个ziplist里存了4个数据项，分别为：</p><ul><li>字符串: “name”</li><li>字符串: “tielei”</li><li>字符串: “age”</li><li>整数: 20</li></ul><p>实际上，这个ziplist是通过两个hset命令创建出来的。这个我们后边会再提到。</p><h3 id="ziplist的接口"><a href="#ziplist的接口" class="headerlink" title="ziplist的接口"></a>ziplist的接口</h3><p>我们先不着急看实现，先来挑几个ziplist的重要的接口，看看它们长什么样子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">unsigned char *ziplistNew(void);</span><br><span class="line">unsigned char *ziplistMerge(unsigned char **first, unsigned char **second);</span><br><span class="line">unsigned char *ziplistPush(unsigned char *zl, unsigned char *s, unsigned int slen, int where);</span><br><span class="line">unsigned char *ziplistIndex(unsigned char *zl, int index);</span><br><span class="line">unsigned char *ziplistNext(unsigned char *zl, unsigned char *p);</span><br><span class="line">unsigned char *ziplistPrev(unsigned char *zl, unsigned char *p);</span><br><span class="line">unsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen);</span><br><span class="line">unsigned char *ziplistDelete(unsigned char *zl, unsigned char **p);</span><br><span class="line">unsigned char *ziplistFind(unsigned char *p, unsigned char *vstr, unsigned int vlen, unsigned int skip);</span><br><span class="line">unsigned int ziplistLen(unsigned char *zl);</span><br></pre></td></tr></table></figure><p>我们从这些接口的名字就可以粗略猜出它们的功能，下面简单解释一下：</p><ul><li>ziplist的数据类型，没有用自定义的struct之类的来表达，而就是简单的unsigned char *。这是因为ziplist本质上就是一块连续内存，内部组成结构又是一个高度动态的设计（变长编码），也没法用一个固定的数据结构来表达。</li><li>ziplistNew: 创建一个空的ziplist（只包含<code>&lt;zlbytes&gt;&lt;zltail&gt;&lt;zllen&gt;&lt;zlend&gt;</code>）。</li><li>ziplistMerge: 将两个ziplist合并成一个新的ziplist。</li><li>ziplistPush: 在ziplist的头部或尾端插入一段数据（产生一个新的数据项）。注意一下这个接口的返回值，是一个新的ziplist。调用方必须用这里返回的新的ziplist，替换之前传进来的旧的ziplist变量，而经过这个函数处理之后，原来旧的ziplist变量就失效了。为什么一个简单的插入操作会导致产生一个新的ziplist呢？这是因为ziplist是一块连续空间，对它的追加操作，会引发内存的realloc，因此ziplist的内存位置可能会发生变化。实际上，我们在之前介绍sds的文章中提到过类似这种接口使用模式（参见sdscatlen函数的说明）。</li><li>ziplistIndex: 返回index参数指定的数据项的内存位置。index可以是负数，表示从尾端向前进行索引。</li><li>ziplistNext和ziplistPrev分别返回一个ziplist中指定数据项p的后一项和前一项。</li><li>ziplistInsert: 在ziplist的任意数据项前面插入一个新的数据项。</li><li>ziplistDelete: 删除指定的数据项。</li><li>ziplistFind: 查找给定的数据（由vstr和vlen指定）。注意它有一个skip参数，表示查找的时候每次比较之间要跳过几个数据项。为什么会有这么一个参数呢？其实这个参数的主要用途是当用ziplist表示hash结构的时候，是按照一个field，一个value来依次存入ziplist的。也就是说，偶数索引的数据项存field，奇数索引的数据项存value。当按照field的值进行查找的时候，就需要把奇数项跳过去。</li><li>ziplistLen: 计算ziplist的长度（即包含数据项的个数）。</li></ul><h4 id="ziplist的插入逻辑解析"><a href="#ziplist的插入逻辑解析" class="headerlink" title="ziplist的插入逻辑解析"></a>ziplist的插入逻辑解析</h4><p>ziplist的相关接口的具体实现，还是有些复杂的，限于篇幅的原因，我们这里只结合代码来讲解插入的逻辑。插入是很有代表性的操作，通过这部分来一窥ziplist内部的实现，其它部分的实现我们也就会很容易理解了。</p><p>ziplistPush和ziplistInsert都是插入，只是对于插入位置的限定不同。</p><p>它们在内部实现都依赖一个名为__ziplistInsert的内部函数:</p><details><summary>__ziplistInsert源码（出自ziplist.c）</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line">static unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) &#123;</span><br><span class="line">    size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen;</span><br><span class="line">    unsigned int prevlensize, prevlen = 0;</span><br><span class="line">    size_t offset;</span><br><span class="line">    int nextdiff = 0;</span><br><span class="line">    unsigned char encoding = 0;</span><br><span class="line">    long long value = 123456789; </span><br><span class="line">    zlentry tail;</span><br><span class="line"></span><br><span class="line">    /* Find out prevlen for the </span><br><span class="line">     * entry that is inserted. */</span><br><span class="line">    if (p[0] != ZIP_END) &#123;</span><br><span class="line">        ZIP_DECODE_PREVLEN(p, prevlensize, prevlen);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl);</span><br><span class="line">        if (ptail[0] != ZIP_END) &#123;</span><br><span class="line">            prevlen = zipRawEntryLength(ptail);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;  </span><br><span class="line">    /* See if the entry can be encoded */</span><br><span class="line">    if (zipTryEncoding(s,slen,&amp;value,&amp;encoding)) &#123;        </span><br><span class="line">        /* &#x27;encoding&#x27; is set to the </span><br><span class="line">         * appropriate integer encoding */</span><br><span class="line">        reqlen = zipIntSize(encoding);</span><br><span class="line">    &#125; else &#123;        </span><br><span class="line">        /* &#x27;encoding&#x27; is untouched, </span><br><span class="line">         * however zipEncodeLength will use </span><br><span class="line">         * the string length to figure out </span><br><span class="line">         * how to encode it. */</span><br><span class="line">        reqlen = slen;</span><br><span class="line">    &#125;</span><br><span class="line">            </span><br><span class="line">    /* We need space for both the length </span><br><span class="line">     * of the previous entry and</span><br><span class="line">     * the length of the payload. */</span><br><span class="line">    reqlen += zipPrevEncodeLength(NULL,prevlen);</span><br><span class="line">    reqlen += zipEncodeLength(NULL,encoding,slen);</span><br><span class="line"></span><br><span class="line">    /* When the insert position is not </span><br><span class="line">     * equal to the tail, we need to</span><br><span class="line">     * make sure that the next entry can </span><br><span class="line">     * hold this entry&#x27;s length in</span><br><span class="line">     * its prevlen field. */</span><br><span class="line">    nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;</span><br><span class="line"></span><br><span class="line">    /* Store offset because a realloc</span><br><span class="line">     * may change the address of zl. */</span><br><span class="line">    offset = p-zl;</span><br><span class="line">    zl = ziplistResize(zl,curlen+reqlen+nextdiff);</span><br><span class="line">    p = zl+offset;</span><br><span class="line"></span><br><span class="line">    /* Apply memory move when necessary </span><br><span class="line">     * and update tail offset. */</span><br><span class="line">    if (p[0] != ZIP_END) &#123;       </span><br><span class="line">        /* Subtract one because of </span><br><span class="line">         * the ZIP_END bytes */</span><br><span class="line">        memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);</span><br><span class="line"></span><br><span class="line">        /* Encode this entry&#x27;s raw </span><br><span class="line">         * length in the next entry. */</span><br><span class="line">        zipPrevEncodeLength(p+reqlen,reqlen);</span><br><span class="line"></span><br><span class="line">        /* Update offset for tail */</span><br><span class="line">        ZIPLIST_TAIL_OFFSET(zl) =</span><br><span class="line">            intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen);</span><br><span class="line"></span><br><span class="line">        /* When the tail contains more </span><br><span class="line">         * than one entry, we need to take</span><br><span class="line">         * &quot;nextdiff&quot; in account as well. </span><br><span class="line">         * Otherwise, a change in the</span><br><span class="line">         * size of prevlen doesn&#x27;t have an </span><br><span class="line">         * effect on the *tail* offset. */</span><br><span class="line">        zipEntry(p+reqlen, &amp;tail);</span><br><span class="line">        if (p[reqlen+tail.headersize+tail.len] != ZIP_END) &#123;</span><br><span class="line">            ZIPLIST_TAIL_OFFSET(zl) =</span><br><span class="line">                intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; else &#123;        </span><br><span class="line">        /* This element will be the new tail. */</span><br><span class="line">        ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl);</span><br><span class="line">    &#125;    </span><br><span class="line">    /* When nextdiff != 0, the raw </span><br><span class="line">     *length of the next entry has changed, so</span><br><span class="line">     * we need to cascade the update </span><br><span class="line">     * throughout the ziplist */</span><br><span class="line">    if (nextdiff != 0) &#123;</span><br><span class="line">        offset = p-zl;</span><br><span class="line">        zl = __ziplistCascadeUpdate(zl,p+reqlen);</span><br><span class="line">        p = zl+offset;</span><br><span class="line">    &#125;    </span><br><span class="line">    </span><br><span class="line">    /* Write the entry */</span><br><span class="line">    p += zipPrevEncodeLength(p,prevlen);</span><br><span class="line">    p += zipEncodeLength(p,encoding,slen);</span><br><span class="line">    if (ZIP_IS_STR(encoding)) &#123;</span><br><span class="line">        memcpy(p,s,slen);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        zipSaveInteger(p,value,encoding);</span><br><span class="line">    &#125;</span><br><span class="line">    ZIPLIST_INCR_LENGTH(zl,1);</span><br><span class="line">    return zl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>我们来简单解析一下这段代码：</p><ul><li>这个函数是在指定的位置p插入一段新的数据，待插入数据的地址指针是s，长度为slen。<br>插入后形成一个新的数据项，占据原来p的配置，原来位于p位置的数据项以及后面的所有数据项，需要统一向后移动，给新插入的数据项留出空间。<br>参数p指向的是ziplist中某一个数据项的起始位置，或者在向尾端插入的时候，它指向ziplist的结束标记<code>&lt;zlend&gt;</code>。</li><li>函数开始先计算出待插入位置前一个数据项的长度<code>prevlen</code>。这个长度要存入新插入的数据项的<code>&lt;prevrawlen&gt;</code>字段。</li><li>然后计算当前数据项占用的总字节数reqlen，它包含三部分：<code>&lt;prevrawlen&gt;, &lt;len&gt;, 真正的数据</code>。<br>其中的数据部分会通过调用<code>zipTryEncoding</code>先来尝试转成整数。</li><li>由于插入导致的ziplist对于内存的新增需求，除了待插入数据项占用的reqlen之外，还要考虑原来p位置的数据项（现在要排在待插入数据项之后）的<code>&lt;prevrawlen&gt;</code>字段的变化。<br>本来它保存的是前一项的总长度，现在变成了保存当前插入的数据项的总长度。<br>这样它的<code>&lt;prevrawlen&gt;</code>字段本身需要的存储空间也可能发生变化，这个变化可能是变大也可能是变小。<br>这个变化了多少的值nextdiff，是调用zipPrevLenByteDiff计算出来的。<br>如果变大了，nextdiff是正值，否则是负值。</li><li>现在很容易算出来插入后新的ziplist需要多少字节了，然后调用ziplistResize来重新调整大小。<br>ziplistResize的实现里会调用allocator的zrealloc，它有可能会造成数据拷贝。</li><li>现在额外的空间有了，接下来就是将原来p位置的数据项以及后面的所有数据都向后挪动，并为它设置新的<code>&lt;prevrawlen&gt;</code>字段。此外，还可能需要调整ziplist的<code>&lt;zltail&gt;</code>字段。</li><li>最后，组装新的待插入数据项，放在位置p。</li></ul><h3 id="hash与ziplist"><a href="#hash与ziplist" class="headerlink" title="hash与ziplist"></a>hash与ziplist</h3><p>hash是Redis中可以用来存储一个对象结构的比较理想的数据类型。一个对象的各个属性，正好对应一个hash结构的各个field。</p><p>我们在网上很容易找到这样一些技术文章，它们会说存储一个对象，使用hash比string要节省内存。<br>实际上这么说是有前提的，具体取决于对象怎么来存储：</p><ul><li>如果你把对象的多个属性存储到多个key上（各个属性值存成string），当然占的内存要多。</li><li>但如果你采用一些序列化方法，比如Protocol Buffers，或者Apache Thrift，先把对象序列化为字节数组，然后再存入到Redis的string中，那么跟hash相比，哪一种更省内存，就不一定了。</li></ul><p>当然，hash比序列化后再存入string的方式，在支持的操作命令上，还是有优势的：</p><ul><li>它既支持多个field同时存取（hmset/hmget），</li><li>也支持按照某个特定的field单独存取（hset/hget）。</li></ul><p>实际上，hash随着数据的增大，其底层数据结构的实现是会发生变化的，当然存储效率也就不同。</p><ul><li>在field比较少，各个value值也比较小的时候，hash采用ziplist来实现；</li><li>而随着field增多和value值增大，hash可能会变成dict来实现。</li></ul><p>当hash底层变成dict来实现的时候，它的存储效率就没法跟那些序列化方式相比了。</p><p>当我们为某个key第一次执行 hset key field value 命令的时候，Redis会创建一个hash结构，这个新创建的hash底层就是一个ziplist。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">robj *createHashObject(void) &#123;</span><br><span class="line">    unsigned char *zl = ziplistNew();</span><br><span class="line">    robj *o = createObject(OBJ_HASH, zl);</span><br><span class="line">    o-&gt;encoding = OBJ_ENCODING_ZIPLIST;</span><br><span class="line">    return o;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的createHashObject函数，出自object.c，它负责的任务就是创建一个新的hash结构。可以看出，它创建了一个type = OBJ_HASH但encoding = OBJ_ENCODING_ZIPLIST的robj对象。</p><p>实际上，本文前面给出的那个ziplist实例，就是由如下两个命令构建出来的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hset user:100 name tielei</span><br><span class="line">hset user:100 age 20</span><br></pre></td></tr></table></figure><p>每执行一次hset命令，插入的field和value分别作为一个新的数据项插入到ziplist中（即每次hset产生两个数据项）。</p><p>当随着数据的插入，hash底层的这个ziplist就可能会转成dict。那么到底插入多少才会转呢？</p><p>还记得本文开头提到的两个Redis配置吗？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hash-max-ziplist-entries 512</span><br><span class="line">hash-max-ziplist-value 64</span><br></pre></td></tr></table></figure><p>这个配置的意思是说，在如下两个条件之一满足的时候，ziplist会转成dict：</p><ul><li>当hash中的数据项（即field-value对）的数目超过512的时候，也就是ziplist数据项超过1024的时候（请参考t_hash.c中的hashTypeSet函数）。</li><li>当hash中插入的任意一个value的长度超过了64的时候（请参考t_hash.c中的hashTypeTryConversion函数）。</li></ul><p>Redis的hash之所以这样设计，是因为当ziplist变得很大的时候，它有如下几个缺点：</p><ul><li>每次插入或修改引发的realloc操作会有更大的概率造成内存拷贝，从而降低性能。</li><li>一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。</li><li>当ziplist数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。</li></ul><p>总之，ziplist本来就设计为各个数据项挨在一起组成连续的内存空间，这种结构<strong>并不擅长做修改操作</strong>。一旦数据发生改动，就会引发内存realloc，可能导致内存拷贝。</p><h2 id="Redis-quicklist"><a href="#Redis-quicklist" class="headerlink" title="Redis quicklist"></a>Redis quicklist</h2><h3 id="quickList概述"><a href="#quickList概述" class="headerlink" title="quickList概述"></a>quickList概述</h3><p>Redis对外暴露的上层list数据类型，经常被用作队列使用。比如它支持的如下一些操作：</p><ul><li>lpush: 在左侧（即列表头部）插入数据。</li><li>rpop: 在右侧（即列表尾部）删除数据。</li><li>rpush: 在右侧（即列表尾部）插入数据。</li><li>lpop: 在左侧（即列表头部）删除数据。</li></ul><p>这些操作都是O(1)时间复杂度的。</p><p>当然，list也支持在任意中间位置的存取操作，比如lindex和linsert，但它们都需要对list进行遍历，所以时间复杂度较高。</p><p>概况起来，list具有这样的一些特点：</p><ul><li>它是一个有序列表，便于在表的两端追加和删除数据，而对于中间位置的存取具有O(N)的时间复杂度。 </li></ul><p>这不正是一个双向链表所具有的特点吗？ list的内部实现quicklist正是一个双向链表。</p><p>在quicklist.c的文件头部注释中，是这样描述quicklist的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A doubly linked list of ziplists</span><br></pre></td></tr></table></figure><p>它确实是一个双向链表，而且是一个ziplist的双向链表。</p><p>ziplist本身也是一个有序列表，而且是一个内存紧缩的列表（各个数据项在内存上前后相邻）。</p><p>比如，一个包含3个节点的quicklist，如果每个节点的ziplist又包含4个数据项，那么对外表现上，这个list就总共包含12个数据项。</p><p>quicklist的结构为什么这样设计呢？总结起来，大概又是一个空间和时间的折中：</p><ul><li>双向链表便于在表的两端进行push和pop操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。</li><li>ziplist由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的realloc。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝，进一步降低性能。</li></ul><p>于是，结合了双向链表和ziplist的优点，quicklist就应运而生了。</p><p>不过，这也带来了一个新问题：到底一个quicklist节点包含多长的ziplist合适呢？比如，同样是存储12个数据项，既可以是一个quicklist包含3个节点，而每个节点的ziplist又包含4个数据项，也可以是一个quicklist包含6个节点，而每个节点的ziplist又包含2个数据项。</p><p>这又是一个需要找平衡点的难题。我们只从存储效率上分析一下：</p><ul><li>每个quicklist节点上的ziplist越短，则内存碎片越多。内存碎片多了，有可能在内存中产生很多无法被利用的小碎片，从而降低存储效率。这种情况的极端是每个quicklist节点上的ziplist只包含一个数据项，这就蜕化成一个普通的双向链表了。</li><li>每个quicklist节点上的ziplist越长，则为ziplist分配大块连续内存空间的难度就越大。有可能出现内存里有很多小块的空闲空间（它们加起来很多），但却找不到一块足够大的空闲空间分配给ziplist的情况。这同样会降低存储效率。这种情况的极端是整个quicklist只有一个节点，所有的数据项都分配在这仅有的一个节点的ziplist里面。这其实蜕化成一个ziplist了。</li></ul><p>可见，一个quicklist节点上的ziplist要保持一个合理的长度。那到底多长合理呢？这可能取决于具体应用场景。实际上，Redis提供了一个配置参数list-max-ziplist-size，就是为了让使用者可以来根据自己的情况进行调整。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list-max-ziplist-size -2</span><br></pre></td></tr></table></figure><p>我们来详细解释一下这个参数的含义。它可以取正值，也可以取负值。</p><p>当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。</p><p>当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下：</p><ul><li>-5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes）</li><li>-4: 每个quicklist节点上的ziplist大小不能超过32 Kb。</li><li>-3: 每个quicklist节点上的ziplist大小不能超过16 Kb。 </li><li>-2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值）</li><li>-1: 每个quicklist节点上的ziplist大小不能超过4 Kb。</li></ul><p>另外，list的设计目标是能够用来<strong>存储很长的数据列表</strong>的。</p><p>当列表很长的时候，最容易被访问的很可能是两端的数据，中间的数据被访问的频率比较低（访问起来性能也很低）。如果应用场景符合这个特点，那么list还提供了一个选项，能够把中间的数据节点进行压缩，从而进一步节省内存空间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list-compress-depth 0</span><br></pre></td></tr></table></figure><p>这个参数表示一个quicklist两端不被压缩的节点个数。注：这里的节点个数是指quicklist双向链表的节点个数，而不是指ziplist里面的数据项个数。实际上，一个quicklist节点上的ziplist，如果被压缩，就是整体被压缩的。</p><p>参数list-compress-depth的取值含义如下：</p><ul><li>0: 是个特殊值，表示都不压缩。这是Redis的默认值。</li><li>1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。</li><li>2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。</li><li>3: 表示quicklist两端各有3个节点不压缩，中间的节点压缩。</li><li>依此类推…</li></ul><p>由于0是个特殊值，很容易看出quicklist的头节点和尾节点总是不被压缩的，以便于在表的两端进行快速存取。</p><p>Redis对于quicklist内部节点的压缩算法，采用的<a href="http://oldhome.schmorp.de/marc/liblzf.html">LZF</a>——一种无损压缩算法。</p><h3 id="quicklist的数据结构定义"><a href="#quicklist的数据结构定义" class="headerlink" title="quicklist的数据结构定义"></a>quicklist的数据结构定义</h3><details><summary>quicklist相关的数据结构定义</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">typedef struct quicklistNode &#123;</span><br><span class="line">    struct quicklistNode *prev;</span><br><span class="line">    struct quicklistNode *next;</span><br><span class="line">    unsigned char *zl;</span><br><span class="line">    unsigned int sz;             /* ziplist size in bytes */</span><br><span class="line">    unsigned int count : 16;     /* count of items in ziplist */</span><br><span class="line">    unsigned int encoding : 2;   /* RAW==1 or LZF==2 */</span><br><span class="line">    unsigned int container : 2;  /* NONE==1 or ZIPLIST==2 */</span><br><span class="line">    unsigned int recompress : 1; /* was this node previous compressed? */</span><br><span class="line">    unsigned int attempted_compress : 1; /* node can&#x27;t compress; too small */</span><br><span class="line">    unsigned int extra : 10; /* more bits to steal for future usage */</span><br><span class="line">&#125; quicklistNode;</span><br><span class="line"></span><br><span class="line">typedef struct quicklistLZF &#123;</span><br><span class="line">    unsigned int sz; /* LZF size in bytes*/</span><br><span class="line">    char compressed[];</span><br><span class="line">&#125; quicklistLZF;</span><br><span class="line"></span><br><span class="line">typedef struct quicklist &#123;</span><br><span class="line">    quicklistNode *head;</span><br><span class="line">    quicklistNode *tail;</span><br><span class="line">    unsigned long count; /* total count of all entries in all ziplists */</span><br><span class="line">    unsigned int len; /* number of quicklistNodes */</span><br><span class="line">    int fill : 16; /* fill factor for individual nodes */</span><br><span class="line">    unsigned int compress : 16; /* depth of end nodes not to compress;0=off */</span><br><span class="line">&#125; quicklist;</span><br></pre></td></tr></table></figure></details><p>quicklistNode结构代表quicklist的一个节点，其中各个字段的含义如下：</p><ul><li>prev: 指向链表前一个节点的指针。</li><li>next: 指向链表后一个节点的指针。</li><li>zl: 数据指针。如果当前节点的数据没有压缩，那么它指向一个ziplist结构；否则，它指向一个quicklistLZF结构。</li><li>sz: 表示zl指向的ziplist的总大小（包括zlbytes, zltail,zllen, zlend和各个数据项）。需要注意的是：如果ziplist被压缩了，那么这个sz的值仍然是压缩前的ziplist大小。</li><li>count: 表示ziplist里面包含的数据项个数。这个字段只有16bit。稍后我们会一起计算一下这16bit是否够用。</li><li>encoding: 表示ziplist是否压缩了（以及用了哪个压缩算法）。目前只有两种取值：2表示被压缩了（而且用的是LZF压缩算法），1表示没有压缩。</li><li>container: 是一个预留字段。本来设计是用来表明一个quicklist节点下面是直接存数据，还是使用ziplist存数据，或者用其它的结构来存数据（用作一个数据容器，所以叫container）。但是，在目前的实现中，这个值是一个固定的值2，表示使用ziplist作为数据容器。</li><li>recompress: 当我们使用类似lindex这样的命令查看了某一项本来压缩的数据时，需要把数据暂时解压，这时就设置recompress=1做一个标记，等有机会再把数据重新压缩。</li><li>attempted_compress: 这个值只对Redis的自动化测试程序有用。我们不用管它。</li><li>extra: 其它扩展字段。目前Redis的实现里也没用上。</li></ul><p>quicklistLZF结构表示一个被压缩过的ziplist。其中：</p><ul><li>sz: 表示压缩后的ziplist大小。</li><li>compressed: 是个柔性数组（flexible array member），存放压缩后的ziplist字节数组。</li></ul><p>真正表示quicklist的数据结构是同名的quicklist这个struct：</p><ul><li>head: 指向头节点（左侧第一个节点）的指针。</li><li>tail: 指向尾节点（右侧第一个节点）的指针。</li><li>count: 所有ziplist数据项的个数总和。</li><li>len: quicklist节点的个数。</li><li>fill: 16bit，ziplist大小设置，存放list-max-ziplist-size参数的值。</li><li>compress: 16bit，节点压缩深度设置，存放list-compress-depth参数的值。</li></ul><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_32.png"><br>上图是一个quicklist的结构图举例（点击可以看大图）。图中例子对应的ziplist大小配置和节点压缩深度配置，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list-max-ziplist-size 3</span><br><span class="line">list-compress-depth 2</span><br></pre></td></tr></table></figure><p>这个例子中我们需要注意的几点是：</p><ul><li>两端各有2个橙黄色的节点，是没有被压缩的。它们的数据指针zl指向真正的ziplist。中间的其它节点是被压缩过的，它们的数据指针zl指向被压缩后的ziplist结构，即一个quicklistLZF结构。</li><li>左侧头节点上的ziplist里有2项数据，右侧尾节点上的ziplist里有1项数据，中间其它节点上的ziplist里都有3项数据（包括压缩的节点内部）。这表示在表的两端执行过多次push和pop操作后的一个状态。</li></ul><p>现在我们来大概计算一下quicklistNode结构中的count字段这16bit是否够用。</p><p>我们已经知道，ziplist大小受到list-max-ziplist-size参数的限制。按照正值和负值有两种情况：</p><ul><li>当这个参数取正值的时候，就是恰好表示一个quicklistNode结构中zl所指向的ziplist所包含的数据项的最大值。list-max-ziplist-size参数是由quicklist结构的fill字段来存储的，而fill字段是16bit，所以它所能表达的值能够用16bit来表示。</li><li>当这个参数取负值的时候，能够表示的ziplist最大长度是64 Kb。而ziplist中每一个数据项，最少需要2个字节来表示：1个字节的prevrawlen，1个字节的data（len字段和data合二为一；详见上一篇）。所以，ziplist中数据项的个数不会超过32 K，用16bit来表达足够了。</li></ul><p>实际上，在目前的quicklist的实现中，ziplist的大小还会受到另外的限制，根本不会达到这里所分析的最大值。</p><h3 id="quicklist执行过程源码"><a href="#quicklist执行过程源码" class="headerlink" title="quicklist执行过程源码"></a>quicklist执行过程源码</h3><h4 id="quicklist的创建"><a href="#quicklist的创建" class="headerlink" title="quicklist的创建"></a>quicklist的创建</h4><p>当我们使用lpush或rpush命令第一次向一个不存在的list里面插入数据的时候，Redis会首先调用</p><details><summary>quicklistCreate</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">quicklist *quicklistCreate(void) &#123;</span><br><span class="line">    struct quicklist *quicklist;</span><br><span class="line"></span><br><span class="line">    quicklist = zmalloc(sizeof(*quicklist));</span><br><span class="line">    quicklist-&gt;head = quicklist-&gt;tail = NULL;</span><br><span class="line">    quicklist-&gt;len = 0;</span><br><span class="line">    quicklist-&gt;count = 0;</span><br><span class="line">    quicklist-&gt;compress = 0;</span><br><span class="line">    quicklist-&gt;fill = -2;    </span><br><span class="line">    return quicklist;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details> <p>接口创建一个空的quicklist。</p><p>在很多介绍数据结构的书上，实现双向链表的时候经常会多增加一个空余的头节点，主要是为了插入和删除操作的方便。从上面quicklistCreate的代码可以看出，quicklist是一个不包含空余头节点的双向链表（head和tail都初始化为NULL）。</p><h4 id="quicklist的push操作"><a href="#quicklist的push操作" class="headerlink" title="quicklist的push操作"></a>quicklist的push操作</h4><p>quicklist的push操作是调用</p><details><summary>quicklistPush</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">void quicklistPush(quicklist *quicklist, void *value, const size_t sz,                   int where) &#123;    </span><br><span class="line">    if (where == QUICKLIST_HEAD) &#123;</span><br><span class="line">        quicklistPushHead(quicklist, value, sz);</span><br><span class="line">    &#125; else if (where == QUICKLIST_TAIL) &#123;</span><br><span class="line">        quicklistPushTail(quicklist, value, sz);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* Add new entry to head node of quicklist.</span><br><span class="line"> *</span><br><span class="line"> * Returns 0 if used existing head.</span><br><span class="line"> * Returns 1 if new head created. */</span><br><span class="line">int quicklistPushHead(quicklist *quicklist, void *value, size_t sz) &#123;</span><br><span class="line">    quicklistNode *orig_head = quicklist-&gt;head;</span><br><span class="line">    if (likely(</span><br><span class="line">            _quicklistNodeAllowInsert(quicklist-&gt;head, quicklist-&gt;fill, sz))) &#123;</span><br><span class="line">        quicklist-&gt;head-&gt;zl =</span><br><span class="line">            ziplistPush(quicklist-&gt;head-&gt;zl, value, sz, ZIPLIST_HEAD);</span><br><span class="line">        quicklistNodeUpdateSz(quicklist-&gt;head);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        quicklistNode *node = quicklistCreateNode();</span><br><span class="line">        node-&gt;zl = ziplistPush(ziplistNew(), value, sz, ZIPLIST_HEAD);</span><br><span class="line"></span><br><span class="line">        quicklistNodeUpdateSz(node);</span><br><span class="line">        _quicklistInsertNodeBefore(quicklist, quicklist-&gt;head, node);</span><br><span class="line">    &#125;</span><br><span class="line">    quicklist-&gt;count++;</span><br><span class="line">    quicklist-&gt;head-&gt;count++;    </span><br><span class="line">    return (orig_head != quicklist-&gt;head);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* Add new entry to tail node of quicklist.</span><br><span class="line"> *</span><br><span class="line"> * Returns 0 if used existing tail.</span><br><span class="line"> * Returns 1 if new tail created. */</span><br><span class="line">int quicklistPushTail(quicklist *quicklist, void *value, size_t sz) &#123;</span><br><span class="line">    quicklistNode *orig_tail = quicklist-&gt;tail;</span><br><span class="line">    if (likely(</span><br><span class="line">            _quicklistNodeAllowInsert(quicklist-&gt;tail, quicklist-&gt;fill, sz))) &#123;</span><br><span class="line">        quicklist-&gt;tail-&gt;zl =</span><br><span class="line">            ziplistPush(quicklist-&gt;tail-&gt;zl, value, sz, ZIPLIST_TAIL);</span><br><span class="line">        quicklistNodeUpdateSz(quicklist-&gt;tail);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        quicklistNode *node = quicklistCreateNode();</span><br><span class="line">        node-&gt;zl = ziplistPush(ziplistNew(), value, sz, ZIPLIST_TAIL);</span><br><span class="line"></span><br><span class="line">        quicklistNodeUpdateSz(node);</span><br><span class="line">        _quicklistInsertNodeAfter(quicklist, quicklist-&gt;tail, node);</span><br><span class="line">    &#125;</span><br><span class="line">    quicklist-&gt;count++;</span><br><span class="line">    quicklist-&gt;tail-&gt;count++;    </span><br><span class="line">    return (orig_tail != quicklist-&gt;tail);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>来实现的。</p><p>不管是在头部还是尾部插入数据，都包含两种情况：</p><ul><li>如果头节点（或尾节点）上ziplist大小没有超过限制（即_quicklistNodeAllowInsert返回1），那么新数据被直接插入到ziplist中（调用ziplistPush）。</li><li>如果头节点（或尾节点）上ziplist太大了，那么新创建一个quicklistNode节点（对应地也会新创建一个ziplist），然后把这个新创建的节点插入到quicklist双向链表中（调用_quicklistInsertNodeAfter）。</li></ul><p>在_quicklistInsertNodeAfter的实现中，还会根据list-compress-depth的配置将里面的节点进行压缩。它的实现比较繁琐，我们这里就不展开讨论了。</p><h4 id="quicklist的其它操作"><a href="#quicklist的其它操作" class="headerlink" title="quicklist的其它操作"></a>quicklist的其它操作</h4><p>quicklist的操作较多，且实现细节都比较繁杂，这里就不一一分析源码了，我们简单介绍一些比较重要的操作。</p><p>quicklist的pop操作是调用quicklistPopCustom来实现的。<br>quicklistPopCustom的实现过程基本上跟quicklistPush相反，先从头部或尾部节点的ziplist中把对应的数据项删除，如果在删除后ziplist为空了，那么对应的头部或尾部节点也要删除。<br>删除后还可能涉及到里面节点的解压缩问题。</p><p>quicklist不仅实现了从头部或尾部插入，也实现了从任意指定的位置插入。quicklistInsertAfter和quicklistInsertBefore就是分别在指定位置后面和前面插入数据项。这种在任意指定位置插入数据的操作，情况比较复杂，有众多的逻辑分支。</p><ul><li>当插入位置所在的ziplist大小没有超过限制时，直接插入到ziplist中就好了；</li><li>当插入位置所在的ziplist大小超过了限制，但插入的位置位于ziplist两端，并且相邻的quicklist链表节点的ziplist大小没有超过限制，那么就转而插入到相邻的那个quicklist链表节点的ziplist中；</li><li>当插入位置所在的ziplist大小超过了限制，但插入的位置位于ziplist两端，并且相邻的quicklist链表节点的ziplist大小也超过限制，这时需要新创建一个quicklist链表节点插入。</li><li>对于插入位置所在的ziplist大小超过了限制的其它情况（主要对应于在ziplist中间插入数据的情况），则需要把当前ziplist分裂为两个节点，然后再其中一个节点上插入数据。</li></ul><p>quicklistSetOptions用于设置ziplist大小配置参数（list-max-ziplist-size）和节点压缩深度配置参数（list-compress-depth）。代码比较简单，就是将相应的值分别设置给quicklist结构的fill字段和compress字段。</p><h2 id="Redis-SkipList"><a href="#Redis-SkipList" class="headerlink" title="Redis SkipList"></a>Redis SkipList</h2><h3 id="什么是跳跃表"><a href="#什么是跳跃表" class="headerlink" title="什么是跳跃表"></a>什么是跳跃表</h3><p>skiplist本质上也是一种<strong>查找结构</strong>，用于解决算法中的查找问题（Searching），即根据给定的key，快速查到它所在的位置（或者对应的value）。</p><p>介绍dict的时候，曾经讨论过：一般查找问题的解法分为两个大类：</p><ul><li>一个是基于各种平衡树，</li><li>一个是基于哈希表。</li></ul><p>但skiplist却比较特殊，它没法归属到这两大类里面。</p><h4 id="skiplist数据结构简介"><a href="#skiplist数据结构简介" class="headerlink" title="skiplist数据结构简介"></a>skiplist数据结构简介</h4><p>跳跃表是一种<strong>有序的</strong>数据结构，它通过在<strong>每个节点中维持多个指向其他节点的指针</strong>，从而达到快速访问节点的目的。</p><p>这么说，我们可能很难理解，我们可以先回忆一下链表。</p><p>对于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是 O(n)。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img.png"></p><p>如果我们想要提高其查找效率，可以考虑在链表上建索引的方式。每两个结点提取一个结点到上一级，我们把抽出来的那一级叫作索引。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_1.png"></p><p>这个时候，我们假设要查找节点8，我们可以先在索引层遍历，当遍历到索引层中值为 7 的结点时，发现下一个节点是9，那么要查找的节点8肯定就在这两个节点之间。</p><p>我们下降到链表层继续遍历就找到了8这个节点。</p><p>原先我们在单链表中找到8这个节点要遍历8个节点，而现在有了一级索引后只需要遍历五个节点。</p><p>从这个例子里，我们看出，加来一层索引之后，查找一个结点需要遍的结点个数减少了，也就是说查找效率提高了。</p><p>同理再加一级索引：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_2.png"></p><p>从图中我们可以看出，查找效率又有提升。在例子中我们的数据很少，当有大量的数据时，我们可以增加多级索引，其查找效率可以得到明显提升。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_3.png"></p><p>skiplist正是受这种多层链表的想法的启发而设计出来的。</p><p>实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。</p><p>但是，这种方法在插入数据的时候有很大的问题。</p><p>新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。<br>如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。<br>删除数据也有同样的问题。</p><p>skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是**为每个节点随机出一个层数(level)**。</p><p>比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。</p><p>为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程（点击看大图）：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_28.png"></p><p>从上面skiplist的创建和插入过程可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。</p><p>实际上，这是skiplist的一个很重要的特性，这让它在<strong>插入性能上明显优于平衡树</strong>的方案。这在后面我们还会提到。</p><p>根据上图中的skiplist结构，我们很容易理解这种数据结构的名字的由来。</p><p>skiplist，翻译成中文，可以翻译成“跳表”或“跳跃表”，指的就是除了最下面第1层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）。</p><p>这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，最终降到第1层链表来精确地确定数据位置。</p><p>在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。</p><p>刚刚创建的这个skiplist总共包含4层链表，现在假设我们在它里面依然查找23，下图给出了查找路径：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_29.png"></p><p>需要注意的是，前面演示的各个节点的插入过程，实际上在插入之前也要先经历一个类似的查找过程，在确定插入位置后，再完成插入操作。</p><p>至此，skiplist的查找和插入操作，我们已经很清楚了。而删除操作与插入操作类似，我们也很容易想象出来。这些操作我们也应该能很容易地用代码实现出来。</p><p>当然，实际应用中的skiplist每个节点应该包含key和value两部分。前面的描述中我们没有具体区分key和value，但实际上列表中是按照key进行排序的，查找过程也是根据key在比较。</p><h4 id="skiplist算法性能"><a href="#skiplist算法性能" class="headerlink" title="skiplist算法性能"></a>skiplist算法性能</h4><p>节点插入时随机出一个层数，仅仅依靠这样一个简单的随机数操作而构建出来的多层链表结构，能保证它有一个良好的查找性能吗？</p><p>在分析之前，我们还需要着重指出的是，执行插入操作时计算随机数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。</p><p>这并不是一个普通的服从均匀分布的随机数，它的计算过程如下：</p><ul><li>首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。</li><li>如果一个节点有第i层(i&gt;=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。</li><li>节点最大的层数不允许超过一个最大值，记为MaxLevel。</li></ul><p>这个计算随机层数的伪码如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">randomLevel()</span><br><span class="line">    level := 1</span><br><span class="line">    // random()返回一个[0...1)的随机数</span><br><span class="line">    while random() &lt; p and level &lt; MaxLevel do</span><br><span class="line">        level := level + 1</span><br><span class="line">    return level</span><br></pre></td></tr></table></figure><p>randomLevel()的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p = 1/4</span><br><span class="line">MaxLevel = 32</span><br></pre></td></tr></table></figure><p>我们先来计算一下每个节点所包含的平均指针数目（概率期望）。节点包含的指针数目，相当于这个算法在空间上的额外开销(overhead)，可以用来度量空间复杂度。</p><p>根据前面randomLevel()的伪码，我们很容易看出，产生越高的节点层数，概率越低。定量的分析如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">节点层数至少为1。而大于1的节点层数，满足一个概率分布。</span><br><span class="line">节点层数恰好等于1的概率为1-p。</span><br><span class="line">节点层数大于等于2的概率为p，而节点层数恰好等于2的概率为p(1-p)。</span><br><span class="line">节点层数大于等于3的概率为p2，而节点层数恰好等于3的概率为p2(1-p)。</span><br><span class="line">节点层数大于等于4的概率为p3，而节点层数恰好等于4的概率为p3(1-p)。</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>因此，一个节点的平均层数（也即包含的平均指针数目），计算如下：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_30.png"></p><p>现在很容易计算出：</p><ul><li>当p=1/2时，每个节点所包含的平均指针数目为2；</li><li>当p=1/4时，每个节点所包含的平均指针数目为1.33。这也是Redis里的skiplist实现在空间上的开销。</li></ul><p>接下来，为了分析时间复杂度，我们计算一下skiplist的平均查找长度。查找长度指的是查找路径上跨越的跳数，而查找过程中的比较次数就等于查找长度加1。<br>以前面图中标出的查找23的查找路径为例，从左上角的头结点开始，一直到结点22，查找长度为6。</p><p>为了计算查找长度，这里我们需要利用一点小技巧。我们注意到，每个节点插入的时候，它的层数是由随机函数randomLevel()计算出来的，而且随机的计算不依赖于其它节点，每次插入过程都是完全独立的。所以，从统计上来说，一个skiplist结构的形成与节点的插入顺序无关。</p><p>这样的话，为了计算查找长度，我们可以将查找过程倒过来看，从右下方第1层上最后到达的那个节点开始，沿着查找路径向左向上回溯，类似于爬楼梯的过程。我们假设当回溯到某个节点的时候，它才被插入，这虽然相当于改变了节点的插入顺序，但从统计上不影响整个skiplist的形成结构。</p><p>现在假设我们从一个层数为i的节点x出发，需要向左向上攀爬k层。这时我们有两种可能：</p><ul><li>如果节点x有第(i+1)层指针，那么我们需要向上走。这种情况概率为p。</li><li>如果节点x没有第(i+1)层指针，那么我们需要向左走。这种情况概率为(1-p)。</li></ul><p>用C(k)表示向上攀爬k个层级所需要走过的平均查找路径长度（概率期望）,得到一个差分方程并化简：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">C(k)=(1-p)(C(k)+1) + p(C(k-1)+1)</span><br><span class="line">C(k)=1/p+C(k-1)</span><br><span class="line">C(k)=k/p</span><br></pre></td></tr></table></figure><p>这个结果的意思是，我们每爬升1个层级，需要在查找路径上走1/p步。而我们总共需要攀爬的层级数等于整个skiplist的总层数-1。</p><p>那么接下来我们需要分析一下当skiplist中有n个节点的时候，它的总层数的概率均值是多少。这个问题直观上比较好理解。根据节点的层数随机算法，容易得出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">第1层链表固定有n个节点；</span><br><span class="line">第2层链表平均有n*p个节点；</span><br><span class="line">第3层链表平均有n*p2个节点；</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>所以，从第1层到最高层，各层链表的平均节点数是一个指数递减的等比数列。容易推算出，总层数的均值为log1/pn，而最高层的平均节点数为1/p。</p><p>综上，粗略来计算的话，平均查找长度约等于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C(log1/pn-1)=(log1/pn-1)/p</span><br></pre></td></tr></table></figure><p>即，**平均时间复杂度为O(log n)**。</p><p>当然，这里的时间复杂度分析还是比较粗略的：</p><ul><li>比如，沿着查找路径向左向上回溯的时候，可能先到达左侧头结点，然后沿头结点一路向上；</li><li>还可能先到达最高层的节点，然后沿着最高层链表一路向左。</li></ul><p>但这些细节不影响平均时间复杂度的最后结果。</p><p>另外，这里给出的时间复杂度只是一个概率平均值，但实际上计算一个精细的概率分布也是有可能的。</p><h4 id="skiplist与平衡树、哈希表的比较"><a href="#skiplist与平衡树、哈希表的比较" class="headerlink" title="skiplist与平衡树、哈希表的比较"></a>skiplist与平衡树、哈希表的比较</h4><ul><li>skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。</li><li>在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。</li><li>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li><li>从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。</li><li>查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。</li><li>从算法实现难度上来比较，skiplist比平衡树要简单得多。</li></ul><h3 id="Redis中SkipList使用"><a href="#Redis中SkipList使用" class="headerlink" title="Redis中SkipList使用"></a>Redis中SkipList使用</h3><p>Redis使用跳跃表作为有序集合键(sorted set)的底层实现之一(sorted set底层不仅仅使用了skiplist，还使用了ziplist和dict),</p><ul><li>如果一个有序集合包含的<strong>元素数量比较多</strong></li><li>又或者有序集合中元素的成员是<strong>比较长的字符串</strong>时,<br>Redis就会使用跳跃表来作为有序集合健的底层实现。</li></ul><p>这里我们需要思考一个问题——为什么元素数量比较多或者成员是比较长的字符串的时候Redis要使用跳跃表来实现？</p><p>从上面我们可以知道，跳跃表在链表的基础上增加了多级索引以提升查找的效率，但其是一个空间换时间的方案，必然会带来一个问题——<strong>索引是占内存的</strong>。</p><p>原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值值和几个指针，并不需要存储对象，因此当<strong>节点本身比较大或者元素数量比较多的时候，其优势必然会被放大，而缺点则可以忽略</strong>。</p><h3 id="Redis中SkipList的实现"><a href="#Redis中SkipList的实现" class="headerlink" title="Redis中SkipList的实现"></a>Redis中SkipList的实现</h3><h4 id="Redis中SkipList实现的特殊性"><a href="#Redis中SkipList实现的特殊性" class="headerlink" title="Redis中SkipList实现的特殊性"></a>Redis中SkipList实现的特殊性</h4><p>我们简单分析一下几个查询命令：</p><ul><li>zrevrank由数据查询它对应的排名，这在前面介绍的skiplist中并不支持。</li><li>zscore由数据查询它对应的分数，这也不是skiplist所支持的。</li><li>zrevrange根据一个排名范围，查询排名在这个范围内的数据。这在前面介绍的skiplist中也不支持。</li><li>zrevrangebyscore根据分数区间查询数据集合，是一个skiplist所支持的典型的范围查找（score相当于key）。</li></ul><p>实际上，Redis中sorted set的实现是这样的：</p><ul><li>当数据较少时，sorted set是由一个ziplist来实现的。</li><li>当数据多的时候，sorted set是由一个dict + 一个skiplist来实现的。<ul><li>dict用来查询数据到分数的对应关系</li><li>而skiplist用来根据分数查询数据（可能是范围查找）。</li></ul></li></ul><p>现在我们集中精力来看一下sorted set与skiplist的关系，：</p><ul><li>zscore(由数据查分数)的查询，不是由skiplist来提供的，而是由那个dict来提供的。 </li><li>为了支持排名(rank)，Redis里对skiplist做了扩展，使得根据排名能够快速查到数据，或者根据分数查到数据之后，也同时很容易获得排名。<ul><li>根据排名的查找，时间复杂度也为O(log n)。</li></ul></li><li>zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。</li><li>zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。</li></ul><p>前述的查询过程，也暗示了各个操作的时间复杂度：</p><ul><li>zscore只用查询一个dict，所以时间复杂度为O(1)</li><li>zrevrank, zrevrange, zrevrangebyscore由于要查询skiplist，所以<ul><li>zrevrank的时间复杂度为O(log n)，</li><li>而zrevrange, zrevrangebyscore的时间复杂度为O(log(n)+M)，其中M是当前查询返回的元素个数。</li></ul></li></ul><p>总结起来，Redis中的skiplist跟前面介绍的经典的skiplist相比，有如下不同：</p><ul><li>分数(score)允许重复，即skiplist的key允许重复。这在最开始介绍的经典skiplist中是不允许的。</li><li>在比较时，不仅比较分数（相当于skiplist的key），还比较数据本身。在Redis的skiplist实现中，数据本身的内容唯一标识这份数据，而不是由key来唯一标识。另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。</li><li>第1层链表不是一个单向链表，而是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。</li><li>在skiplist中可以很方便地计算出每个元素的排名(rank)。</li></ul><h4 id="SkipList的数据结构定义"><a href="#SkipList的数据结构定义" class="headerlink" title="SkipList的数据结构定义"></a>SkipList的数据结构定义</h4><p>Redis的跳跃表由zskiplistNode和skiplist两个结构定义,其中 </p><ul><li>zskiplistNode结构用于表示跳跃表节点,</li><li>而zskiplist结构则用于保存跳跃表节点的相关信息,比如节点的数量,以及指向表头节点和表尾节点的指针等等。</li></ul><details><summary>zskiplistNode & zskiplist 源码 (出自server.h)</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#define ZSKIPLIST_MAXLEVEL 32</span><br><span class="line">#define ZSKIPLIST_P 0.25</span><br><span class="line"></span><br><span class="line">typedef struct zskiplistNode &#123;</span><br><span class="line">    robj *obj;</span><br><span class="line">    double score;</span><br><span class="line">    struct zskiplistNode *backward;</span><br><span class="line">    struct zskiplistLevel &#123;</span><br><span class="line">        struct zskiplistNode *forward;</span><br><span class="line">        unsigned int span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br><span class="line"></span><br><span class="line">typedef struct zskiplist &#123;</span><br><span class="line">    struct zskiplistNode *header, *tail;</span><br><span class="line">    unsigned long length;</span><br><span class="line">    int level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><ul><li>开头定义了两个常量，ZSKIPLIST_MAXLEVEL和ZSKIPLIST_P，分别对应我们前面讲到的skiplist的两个参数：一个是MaxLevel，一个是p。</li><li>zskiplistNode定义了skiplist的节点结构。</li><li>zskiplist定义了真正的skiplist结构。</li></ul></details><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_4.png"></p><p>上图展示了一个跳跃表示例,其中最左边的是 <strong>skiplist</strong> 结构,该结构包含以下属性:</p><p><strong>头指针header、 尾指针tail</strong>: 通过这个指针程序定位表头、表尾节点的时间复杂度就为O(1)</p><p><strong>总层数level</strong>: 当前所有节点层数的最大值(表头节点的层数不计算在内)，通过这个属性可以再O(1)的时间复杂度内获取层高最好的节点的层数。</p><p><strong>链表长度length</strong>: 记录跳跃表的长度,也即是,跳跃表目前包含节点的数量(新创建的skiplist包含一个空的头指针，这个头指针不计算在内)，通过这个属性，程序可以再O(1)的时间复杂度内返回跳跃表的长度。</p><p>结构右方的是四个 <strong>zskiplistNode</strong> 结构,该结构包含以下属性。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_5.png"></p><p><strong>level[]</strong>: 指向各层链表后一个节点的指针（后向指针）</p><ul><li>每层对应1个后向指针，用forward字段表示。 </li><li>每个后向指针还对应了一个span值，它表示当前的指针跨越了多少个节点<ul><li>span用于计算元素排名(rank)，这正是前面我们提到的Redis对于skiplist所做的一个扩展。</li><li>注意的是，level[]是一个柔性数组（flexible array member），因此它占用的内存不在zskiplistNode结构里面，而需要插入节点的时候单独为它分配。</li><li>也正因为如此，skiplist的每个节点所包含的指针数目才是不固定的，我们前面分析过的结论——skiplist每个节点包含的指针数目平均为1/(1-p)——才能有意义。</li></ul></li><li>每次创建一个新跳跃表节点的时候,程序都根据幂次定律(powerlaw,越大的数出现的概率越小)随机生成一个介于1和32之间的值作为level数组的大小,这个大小就是层的“高度”。</li></ul><p><strong>backward指针</strong>：指向链表前一个节点的指针（前向指针）</p><ul><li>节点中用BW字样标记节点的前向指针,它指向位于当前节点的前一个节点。</li><li>前向指针在程序从表尾向表头遍历时使用。</li><li>与后向指针所不同的是每个节点只有一个前向指针，因此每次只能后退一个节点（所以只有第1层链表是一个双向链表。）。</li></ul><p><strong>分值(score)</strong>: 数据对应的分数</p><ul><li>在跳跃表中,节点按各自所保存的分值<strong>从小到大</strong>排列。</li></ul><p><strong>成员对象(oj)</strong>: 一个string robj的节点对象</p><ul><li>本来一个string robj可能存放的不是sds，而是long型，但zadd命令在将数据插入到skiplist里面之前先进行了解码，所以这里的obj字段里存储的一定是一个sds。 </li><li>方便在查找的时候对数据进行字典序的比较（分值相同的节点将按照成员对象在字典序中的大小来进行排序），而且，skiplist里的数据部分是数字的可能性也比较小。</li><li>成员对象较小的节点会排在前面(靠近表头的方向),而成员对象较大的节点则会排在后面(靠近表尾的方向)。</li></ul><p>下图以一个常规的代数课成绩表为例，展示了Redis中一个skiplist的可能结构：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_31.png"></p><p>注意：图中前向指针上面括号中的数字，表示对应的span的值。即当前指针跨越了多少个节点，这个计数不包括指针的起点节点，但包括指针的终点节点。</p><p>假设我们在这个skiplist中查找score=89.0的元素（即Bob的成绩数据），在查找路径中，我们会跨域图中标红的指针，这些指针上面的span值累加起来，就得到了Bob的排名(2+2+1)-1=4（减1是因为rank值以0起始）。需要注意这里算的是从小到大的排名，而如果要算从大到小的排名，只需要用skiplist长度减去查找路径上的span累加值，即6-(2+2+1)=1。</p><p>可见，在查找skiplist的过程中，通过累加span值的方式，我们就能很容易算出排名。相反，如果指定排名来查找数据（类似zrange和zrevrange那样），也可以不断累加span并时刻保持累加值不超过指定的排名，通过这种方式就能得到一条O(log n)的查找路径。</p><h4 id="Redis中的SortedSet"><a href="#Redis中的SortedSet" class="headerlink" title="Redis中的SortedSet"></a>Redis中的SortedSet</h4><p>我们前面提到过，Redis中的sorted set，是在skiplist, dict和ziplist基础上构建起来的:</p><ul><li>当数据较少时，sorted set是由一个ziplist来实现的。</li><li>当数据多的时候，sorted set是由一个叫zset的数据结构来实现的，这个zset包含一个dict + 一个skiplist。dict用来查询数据到分数(score)的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。</li></ul><p>在这里我们先来讨论一下前一种情况——基于ziplist实现的sorted set。ziplist是由很多数据项组成的一大块连续内存。</p><p>由于sorted set的每一项元素都由数据和score组成，因此，当使用zadd命令插入一个(数据, score)对的时候，底层在相应的ziplist上就插入两个数据项：数据在前，score在后。</p><p>ziplist的主要优点是节省内存，但它上面的查找操作只能按顺序查找（可以正序也可以倒序）。因此，sorted set的各个查询操作，就是在ziplist上从前向后（或从后向前）一步步查找，每一步前进两个数据项，跨域一个(数据, score)对。</p><p>随着数据的插入，sorted set底层的这个ziplist就可能会转成zset的实现（转换过程详见t_zset.c的zsetConvert）。那么到底插入多少才会转呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zset-max-ziplist-entries 128</span><br><span class="line">zset-max-ziplist-value 64</span><br></pre></td></tr></table></figure><p>这个配置的意思是说，在如下两个条件之一满足的时候，ziplist会转成zset（具体的触发条件参见t_zset.c中的zaddGenericCommand相关代码）：</p><ul><li>当sorted set中的元素个数，即(数据, score)对的数目超过128的时候，也就是ziplist数据项超过256的时候。</li><li>当sorted set中插入的任意一个数据的长度超过了64的时候。</li></ul><p>最后，zset结构的代码定义如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typedef struct zset &#123;</span><br><span class="line">    dict *dict;</span><br><span class="line">    zskiplist *zsl;</span><br><span class="line">&#125; zset;</span><br></pre></td></tr></table></figure><h3 id="Redis中SkipList常用操作时间复杂度"><a href="#Redis中SkipList常用操作时间复杂度" class="headerlink" title="Redis中SkipList常用操作时间复杂度"></a>Redis中SkipList常用操作时间复杂度</h3><table><thead><tr><th>操作</th><th>时间复杂度</th></tr></thead><tbody><tr><td>创建一个跳跃表</td><td>O(1)</td></tr><tr><td>释放给定跳跃表以及其中包含的节点</td><td>O(N)</td></tr><tr><td>添加给定成员和分值的新节点</td><td>平均O(logN),最坏O(logN)(N为跳跃表的长度)</td></tr><tr><td>删除除跳跃表中包含给定成员和分值的节点</td><td>平均O(logN),最坏O(logN)(N为跳跃表的长度)</td></tr><tr><td>返回给定成员和分值的节点再表中的排位</td><td>平均O(logN),最坏O(logN)(N为跳跃表的长度)</td></tr><tr><td>返回在给定排位上的节点</td><td>平均O(logN),最坏O(logN)(N为跳跃表的长度)</td></tr><tr><td>给定一个分值范围,返回跳跃表中第一个符合这个范围的节点</td><td>O(1)</td></tr><tr><td>给定一个分值范围,返回跳跃表中最后一个符合这个范围的节点</td><td>平均O(logN),最坏O(logN)(N为跳跃表的长度)</td></tr><tr><td>给定一个分值范围,除跳跃表中所有在这个范围之内的节点</td><td>平均O(logN),最坏O(logN)(N为跳跃表的长度)</td></tr><tr><td>给定一个排位范围,鼎除跳跃表中所有在这个范围之内的节点</td><td>O(N),N为被除节点数量</td></tr><tr><td>给定一个分值范固(range),比如0到15,20到28,诸如此类,如果跳氏表中有至少一个节点的分值在这个范間之内,那么返回1,否则返回0</td><td>O(N),N为被除节点数量</td></tr></tbody></table><h2 id="Redis-IntSet"><a href="#Redis-IntSet" class="headerlink" title="Redis IntSet"></a>Redis IntSet</h2><p>Redis里面使用intset是为了实现集合(set)这种对外的数据结构。<br>set结构类似于数学上的集合的概念，它包含的元素无序，且不能重复。<br>Redis里的set结构还实现了基础的集合并、交、差的操作。</p><p>与Redis对外暴露的其它数据结构类似，set的底层实现，随着元素类型是否是整型以及添加的元素的数目多少，而有所变化。<br>概括来讲：</p><ul><li>当set中添加的元素都是整型且元素数目较少时，set使用intset作为底层数据结构，</li><li>否则，set使用dict作为底层数据结构。</li></ul><h3 id="intset数据结构简介"><a href="#intset数据结构简介" class="headerlink" title="intset数据结构简介"></a>intset数据结构简介</h3><p>intset顾名思义，是由整数组成的集合。</p><p>实际上，intset是一个由整数组成的有序集合，从而便于在上面进行二分查找，用于快速地判断一个元素是否属于这个集合。</p><p>它在内存分配上与ziplist有些类似，是连续的一整块内存空间，而且对于大整数和小整数（按绝对值）采取了不同的编码，尽量对内存的使用进行了优化。</p><details><summary>intset的数据结构定义</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">typedef struct intset &#123;</span><br><span class="line">    uint32_t encoding;</span><br><span class="line">    uint32_t length;</span><br><span class="line">    int8_t contents[];</span><br><span class="line">&#125; intset;</span><br><span class="line"></span><br><span class="line">#define INTSET_ENC_INT16 (sizeof(int16_t))</span><br><span class="line">#define INTSET_ENC_INT32 (sizeof(int32_t))</span><br><span class="line">#define INTSET_ENC_INT64 (sizeof(int64_t))</span><br></pre></td></tr></table></figure></details><p>各个字段含义如下：</p><ul><li><p>encoding: 数据编码，表示intset中的每个数据元素用几个字节来存储。它有三种可能的取值：</p><ul><li>INTSET_ENC_INT16表示每个元素用2个字节存储，</li><li>INTSET_ENC_INT32表示每个元素用4个字节存储，</li><li>INTSET_ENC_INT64表示每个元素用8个字节存储。</li></ul><p>因此，intset中存储的整数最多只能占用64bit。</p></li><li><p>length: 表示intset中的元素个数。encoding和length两个字段构成了intset的头部（header）。</p></li><li><p>contents: 是一个柔性数组（flexible array member），表示intset的header后面紧跟着数据元素。</p><ul><li>这个数组的总长度（即总字节数）等于encoding * length。</li><li>柔性数组在Redis的很多数据结构的定义中都出现过（例如sds,quicklist, skiplist），用于表达一个偏移量。</li><li>contents需要单独为其分配空间，这部分内存不包含在intset结构当中。</li></ul></li></ul><p>其中需要注意的是，intset可能会随着数据的添加而改变它的数据编码：</p><ul><li>最开始，新创建的intset使用占内存最小的INTSET_ENC_INT16（值为2）作为数据编码。</li><li>每添加一个新元素，则根据元素大小决定是否对数据编码进行升级。</li></ul><p>下图给出了一个添加数据的具体例子（点击看大图）。</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_33.png"></p><p>在上图中：</p><ul><li>新创建的intset只有一个header，总共8个字节。其中encoding = 2, length = 0。</li><li>添加13, 5两个元素之后，因为它们是比较小的整数，都能使用2个字节表示，所以encoding不变，值还是2。</li><li>当添加32768的时候，它不再能用2个字节来表示了（2个字节能表达的数据范围是-215~215-1，而32768等于215，超出范围了），因此encoding必须升级到INTSET_ENC_INT32（值为4），即用4个字节表示一个元素。</li><li>在添加每个元素的过程中，intset始终保持从小到大有序。</li><li>与ziplist类似，intset也是按小端（little endian）模式存储的（参见维基百科词条Endianness）。比如，在上图中intset添加完所有数据之后，表示encoding字段的4个字节应该解释成0x00000004，而第5个数据应该解释成0x000186A0 = 100000。</li></ul><p>intset与ziplist相比：</p><ul><li>ziplist可以存储任意二进制串，而intset只能存储整数。</li><li>ziplist是无序的，而intset是从小到大有序的。因此，在ziplist上查找只能遍历，而在intset上可以进行二分查找，性能更高。</li><li>ziplist可以对每个数据项进行不同的变长编码（每个数据项前面都有数据长度字段len），而intset只能整体使用一个统一的编码（encoding）。</li></ul><h3 id="intset的查找和添加操作"><a href="#intset的查找和添加操作" class="headerlink" title="intset的查找和添加操作"></a>intset的查找和添加操作</h3><p>要理解intset的一些实现细节，只需要关注intset的两个关键操作基本就可以了：查找（intsetFind）和添加（intsetAdd）元素。</p><h4 id="intsetFind"><a href="#intsetFind" class="headerlink" title="intsetFind"></a>intsetFind</h4><p>intsetFind的关键代码如下：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_34.png"></p><p>关于以上代码，我们需要注意的地方包括：</p><ul><li>intsetFind在指定的intset中查找指定的元素value，找到返回1，没找到返回0。</li><li>_intsetValueEncoding函数会根据要查找的value落在哪个范围而计算出相应的数据编码（即它应该用几个字节来存储）。</li><li>如果value所需的数据编码比当前intset的编码要大，则它肯定在当前intset所能存储的数据范围之外（特别大或特别小），所以这时会直接返回0；否则调用intsetSearch执行一个二分查找算法。</li><li>intsetSearch在指定的intset中查找指定的元素value，如果找到，则返回1并且将参数pos指向找到的元素位置；如果没找到，则返回0并且将参数pos指向能插入该元素的位置。</li><li>intsetSearch是对于二分查找算法的一个实现，它大致分为三个部分：<ul><li>特殊处理intset为空的情况。</li><li>特殊处理两个边界情况：当要查找的value比最后一个元素还要大或者比第一个元素还要小的时候。实际上，这两部分的特殊处理，在二分查找中并不是必须的，但它们在这里提供了特殊情况下快速失败的可能。</li><li>真正执行二分查找过程。注意：如果最后没找到，插入位置在min指定的位置。</li></ul></li><li>代码中出现的intrev32ifbe是为了在需要的时候做大小端转换的。<br>前面我们提到过，intset里的数据是按小端（little endian）模式存储的，因此在大端（big endian）机器上运行时，这里的intrev32ifbe会做相应的转换。</li></ul><p>这个查找算法的总的时间复杂度为O(log n)。</p><h4 id="intsetAdd"><a href="#intsetAdd" class="headerlink" title="intsetAdd"></a>intsetAdd</h4><p>intsetAdd的关键代码如下（出自intset.c）</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_35.png"></p><p>关于以上代码，我们需要注意的地方包括：</p><ul><li>intsetAdd在intset中添加新元素value。<ul><li>如果value在添加前已经存在，则不会重复添加， 这时参数success被置为0；</li><li>如果value在原来intset中不存在，则将value插入到适当位置，这时参数success被置为0。</li></ul></li><li>如果要添加的元素value所需的数据编码比当前intset的编码要大，那么则调用intsetUpgradeAndAdd将intset的编码进行升级后再插入value。</li><li>调用intsetSearch，如果能查到，则不会重复添加。</li><li>如果没查到，则调用intsetResize对intset进行内存扩充，使得它能够容纳新添加的元素。<ul><li><a href="http://man.cx/realloc">因为intset是一块连续空间，因此这个操作会引发内存的realloc, 这有可能带来一次数据拷贝</a></li><li>同时调用intsetMoveTail将待插入位置后面的元素统一向后移动1个位置，这也涉及到一次数据拷贝。<ul><li>值得注意的是，在intsetMoveTail中是调用memmove完成这次数据拷贝的。</li><li><a href="http://man.cx/memmove">memmove保证了在拷贝过程中不会造成数据重叠或覆盖</a></li></ul></li></ul></li><li>intsetUpgradeAndAdd的实现中也会调用intsetResize来完成内存扩充。<ul><li>在进行编码升级时，intsetUpgradeAndAdd的实现会把原来intset中的每个元素取出来，再用新的编码重新写入新的位置。</li></ul></li><li>注意一下intsetAdd的返回值，它返回一个新的intset指针。<ul><li>它可能与传入的intset指针is相同，也可能不同。调用方必须用这里返回的新的intset，替换之前传进来的旧的intset变量。类似这种接口使用模式，在Redis的实现代码中是很常见的，比如我们之前在介绍sds和ziplist的时候都碰到过类似的情况。</li></ul></li></ul><p>显然，这个intsetAdd算法总的时间复杂度为O(n)。</p><h3 id="Redis-Set结构"><a href="#Redis-Set结构" class="headerlink" title="Redis Set结构"></a>Redis Set结构</h3><p>为了更好地理解Redis对外暴露的set数据结构，我们先看一下set的一些关键的命令。下面是一些命令举例：</p><p><img src="/2022/03/09/%E4%B8%AD%E9%97%B4%E4%BB%B6/Cache/Redis/Redis%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3/img_36.png"></p><p>上面这些命令的含义：</p><ul><li>sadd用于分别向集合s1和s2中添加元素。添加的元素既有数字，也有非数字（”a”和”b”）。</li><li>sismember用于判断指定的元素是否在集合内存在。</li><li>sinter, sunion和sdiff分别用于计算集合的交集、并集和差集。</li></ul><p>我们前面提到过，set的底层实现，随着元素类型是否是整型以及添加的元素的数目多少，而有所变化。<br>例如，具体到上述命令的执行过程中，集合s1的底层数据结构会发生如下变化：</p><ul><li>在开始执行完sadd s1 13 5之后，由于添加的都是比较小的整数，所以s1底层是一个intset，其数据编码encoding= 2。</li><li>在执行完sadd s1 32768 10 100000之后，s1底层仍然是一个intset，但其数据编码encoding从2升级到了4。</li><li>在执行完sadd s1 a b之后，由于添加的元素不再是数字，s1底层的实现会转成一个dict。</li></ul><p>我们知道，dict是一个用于维护key和value映射关系的数据结构，那么当set底层用dict表示的时候，它的key和value分别是什么呢？</p><p>实际上，key就是要添加的集合元素，而value是NULL。</p><p>除了前面提到的由于添加非数字元素造成集合底层由intset转成dict之外，还有两种情况可能造成这种转换：</p><ul><li>添加了一个数字，但它无法用64bit的有符号数来表达。intset能够表达的最大的整数范围为-264~264-1，因此，如果添加的数字超出了这个范围，这也会导致intset转成dict。</li><li>添加的集合元素个数超过了set-max-intset-entries配置的值的时候，也会导致intset转成dict（具体的触发条件参见t_set.c中的setTypeAdd相关代码）。</li></ul><p>对于小集合使用intset来存储，主要的原因是节省内存。特别是当存储的元素个数较少的时候，dict所带来的内存开销要大得多（包含两个哈希表、链表指针以及大量的其它元数据）。所以，当存储大量的小集合而且集合元素都是数字的时候，用intset能节省下一笔可观的内存空间。</p><p>实际上，从时间复杂度上比较，intset的平均情况是没有dict性能高的。以查找为例，intset是O(log n)的，而dict可以认为是O(1)的。但是，由于使用intset的时候集合元素个数比较少，所以这个影响不大。</p><h3 id="RedisSet的并、交、叉算法"><a href="#RedisSet的并、交、叉算法" class="headerlink" title="RedisSet的并、交、叉算法"></a>RedisSet的并、交、叉算法</h3><p>Redis set的并、交、差算法的实现代码，在t_set.c中。</p><p>其中计算交集调用的是sinterGenericCommand，计算并集和差集调用的是sunionDiffGenericCommand。</p><p>它们都能同时对多个（可以多于2个）集合进行运算。</p><p>当对多个集合进行差集运算时，它表达的含义是：用第一个集合与第二个集合做差集，所得结果再与第三个集合做差集，依次向后类推。</p><h4 id="交集"><a href="#交集" class="headerlink" title="交集"></a>交集</h4><p>计算交集的过程大概可以分为三部分：</p><ol><li>检查各个集合，对于不存在的集合当做空集来处理。一旦出现空集，则不用继续计算了，最终的交集就是空集。</li><li>对各个集合按照元素个数由少到多进行排序。这个排序有利于后面计算的时候从最小的集合开始，需要处理的元素个数较少。</li><li>对排序后第一个集合（也就是最小集合）进行遍历，对于它的每一个元素，依次在后面的所有集合中进行查找。只有在所有集合中都能找到的元素，才加入到最后的结果集合中。</li></ol><p>需要注意的是，上述第3步在集合中进行查找，对于intset和dict的存储来说时间复杂度分别是O(log n)和O(1)。</p><p>但由于只有小集合才使用intset，所以可以粗略地认为intset的查找也是常数时间复杂度的。</p><p>因此,<br><a href="http://redis.io/commands/sinter">如Redis官方文档上所说</a><br>sinter命令的时间复杂度为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">O(N*M) worst case where N is the cardinality of the smallest set and M is the number of sets.</span><br></pre></td></tr></table></figure><h4 id="并集"><a href="#并集" class="headerlink" title="并集"></a>并集</h4><p>计算并集最简单，只需要遍历所有集合，将每一个元素都添加到最后的结果集合中。 向集合中添加元素会自动去重。</p><p>由于要遍历所有集合的每个元素，所以<br><a href="http://redis.io/commands/sunion">Redis官方文档</a><br>给出的sunion命令的时间复杂度为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">O(N) where N is the total number of elements in all given sets.</span><br></pre></td></tr></table></figure><p>注意，这里同前面讨论交集计算一样，将元素插入到结果集合的过程，忽略intset的情况，认为时间复杂度为O(1)。</p><h4 id="差集"><a href="#差集" class="headerlink" title="差集"></a>差集</h4><p>计算差集有两种可能的算法，它们的时间复杂度有所区别。</p><p>第一种算法：</p><ul><li>对第一个集合进行遍历，对于它的每一个元素，依次在后面的所有集合中进行查找。只有在所有集合中都找不到的元素，才加入到最后的结果集合中。</li></ul><p>这种算法的时间复杂度为O(N*M)，其中N是第一个集合的元素个数，M是集合数目。</p><p>第二种算法：</p><ul><li>将第一个集合的所有元素都加入到一个中间集合中。</li><li>遍历后面所有的集合，对于碰到的每一个元素，从中间集合中删掉它。</li><li>最后中间集合剩下的元素就构成了差集。</li></ul><p>这种算法的时间复杂度为O(N)，其中N是所有集合的元素个数总和。</p><p>在计算差集的开始部分，会先分别估算一下两种算法预期的时间复杂度，然后选择复杂度低的算法来进行运算。</p><p>还有两点需要注意：</p><ul><li>在一定程度上优先选择第一种算法，因为它涉及到的操作比较少，只用添加，而第二种算法要先添加再删除。</li><li>如果选择了第一种算法，那么在执行该算法之前，Redis的实现中对于第二个集合之后的所有集合，按照元素个数由多到少进行了排序。这个排序有利于以更大的概率查找到元素，从而更快地结束查找。</li></ul><p>对于sdiff的时间复杂度，<br><a href="http://redis.io/commands/sdiff">Redis官方文档</a><br>只给出了第二种算法的结果，是不准确的。</p><h2 id="参考阅读"><a href="#参考阅读" class="headerlink" title="参考阅读"></a>参考阅读</h2><p><a href="https://www.jianshu.com/p/c2841d65df4c">死磕Redis5.0之跳跃表</a></p><p><a href="https://mp.weixin.qq.com/s/3TU9qxHJyxHJgVDaYXoluA">Redis内部数据结构详解</a></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 跳跃表 </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从主流中间件看分布式系统主从同步策略</title>
      <link href="/2022/03/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E4%BB%8E%E4%B8%BB%E6%B5%81%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9C%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5/"/>
      <url>/2022/03/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E4%BB%8E%E4%B8%BB%E6%B5%81%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9C%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5/</url>
      
        <content type="html"><![CDATA[<h3 id="MySQL主从复制"><a href="#MySQL主从复制" class="headerlink" title="MySQL主从复制"></a>MySQL主从复制</h3><h4 id="复制过程"><a href="#复制过程" class="headerlink" title="复制过程"></a>复制过程</h4><p><img src="/2022/03/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E4%BB%8E%E4%B8%BB%E6%B5%81%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9C%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5/mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5.png" alt="mysql主从同步"></p><ul><li>主服务器（master）将数据更改的操作记录写到二进制redo日志（binlog）中</li><li>从服务器（slave）将主服务器中的二进制日志复制到自己的中继日志（relay log）中<ul><li>首先slave开始一个工作线程——I/O线程，I/O线程在master上打开一个普通的连接，然后开始Binlog dump process（Binlog转储过程），Binlog dump process从master的二进制日志中读取事件。</li><li>如果已经跟上master，它会睡眠并等待master产生新的事件。</li></ul></li><li>从服务器重做中继日志中的日志，把更改应用到自己的数据库中，保证数据的最终一致性<ul><li>中继日志通常存在系统的缓存中，所以中继日志的开销很小。</li></ul></li></ul><p>复制过程有一个很重要的限制，就是在slave上的复制是串行化的，master上是并行化的。</p><h4 id="同步-异步"><a href="#同步-异步" class="headerlink" title="同步/异步"></a>同步/异步</h4><ul><li>异步复制<ul><li>MySQL主从模式默认的复制，并不关心从库是否已经接收并处理</li><li>可能导致数据不完整</li></ul></li><li>同步复制<ul><li>MySQL Cluster为同步复制，所有客户端确认执行事务后才返回。</li><li>事务时间拉长、性能降低。</li></ul></li><li>半同步复制<ul><li>插件形式支持，至少一个从库接收并写ready log。</li><li>至少延迟一个TCP/IP时间，最好在低延迟网络使用。</li></ul></li></ul><h4 id="Mysql读写分离"><a href="#Mysql读写分离" class="headerlink" title="Mysql读写分离"></a>Mysql读写分离</h4><p>本身未实现读写分离：</p><ul><li>基于项目代码内部实现</li><li>基于中间代理实现<ul><li>MySQL-Proxy</li><li>amoeba(变形虫)</li></ul></li></ul><h3 id="Kafka的主从同步"><a href="#Kafka的主从同步" class="headerlink" title="Kafka的主从同步"></a>Kafka的主从同步</h3><p>kafka的主从同步，主要是针对它的broker来说。</p><p>在kafka的broker中，同一个topic可以被分配成多个Partition，每个Partition的可以有一个或者多个replicas（备份），即会有一个leader以及0到多个Follower。  </p><p>在consumer读取数据的时候，只会从Leader上读取数据，Follower只是在Leader宕机的时候来替代Leader（不支持读写分离）。  </p><p>主从同步有两种方式：同步复制和异步复制，Kafka采用的是中间策略ISR（In Sync Replicas）。</p><h4 id="Kafka的ISR策略"><a href="#Kafka的ISR策略" class="headerlink" title="Kafka的ISR策略"></a>Kafka的ISR策略</h4><p>在有数据写上Leader的时候，Leader会查看Follower组成的ISR列表，并且符合以下两点才算是属于ISR列表：</p><ul><li>broker可以维护和zookeeper的连接，zookeeper通过心跳机制检查每个节点的连接</li><li>如果节点是个follower它必须能及时同步Leader的写操作，不能延时太久。</li></ul><p>当某个主题的分区初始化创建时，每个副本都在ISR集合中。当新消息发布后，leader提交消息前会一直等待直到所有ISR副本收到消息。如果某个follower副本故障，它将会被从ISR中移除。leader会继续提交新的消息，只不过ISR数量与分区创建时的副本数量相比变少了。</p><p><a href="https://baijiahao.baidu.com/s?id=1649059417410404542&wfr=spider&for=pc">kafka如何保证数据一致性剖析？剖析ISR机制</a></p><h4 id="Kafka不支持读写分离"><a href="#Kafka不支持读写分离" class="headerlink" title="Kafka不支持读写分离"></a>Kafka不支持读写分离</h4><p><a href="https://blog.csdn.net/zl1zl2zl3/article/details/87982038">干货|为什么Kafka不支持读写分离</a></p><h3 id="Zookeeper的主从同步ZAB"><a href="#Zookeeper的主从同步ZAB" class="headerlink" title="Zookeeper的主从同步ZAB"></a>Zookeeper的主从同步ZAB</h3><p>Zookeeper的zab策略脱胎于Paxos算法，默认情况下，zk中写数据时，要有一半以上的从节点写入成功，才算是写入成功。</p><h3 id="Redis的主从同步"><a href="#Redis的主从同步" class="headerlink" title="Redis的主从同步"></a>Redis的主从同步</h3><p>redis因为是要提升性能，所以直接采用的异步复制，当在Master上写入数据后直接返回，然后把数据快照广播给Slave，让所有的Slaves去执行操作。</p><p>RBD全量同步 + AOF增量同步</p><p>Redis无磁盘化复制</p><ul><li>master将rbd文件不落地到磁盘，直接在内存中生成（需要配置repl-diskless-sync）</li></ul><p><a href="https://zhuanlan.zhihu.com/p/65712373">调研Redis高可用两种方案</a></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 主从同步 </tag>
            
            <tag> 设计理念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring三级缓存解决循环依赖</title>
      <link href="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/"/>
      <url>/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/</url>
      
        <content type="html"><![CDATA[<p>前置阅读<a href="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/" title="初读Spring的Bean生命周期">初读Spring的Bean生命周期</a></p><h3 id="三级缓存具体是什么"><a href="#三级缓存具体是什么" class="headerlink" title="三级缓存具体是什么"></a>三级缓存具体是什么</h3><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img.png"></p><p>可以看到填充属性的时候，spring会提前将已经实例化的bean通过ObjectFactory半成品暴露出去。</p><p>为什么称为半成品是因为这时候的bean对象实例化，但是未进行属性填充，是一个不完整的bean实例对象。</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_1.png"></p><p><strong>spring利用singletonObjects, earlySingletonObjects, singletonFactories三级缓存去解决的，所说的缓存其实也就是三个Map</strong></p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_2.png"></p><p>可以看到三级缓存各自保存的对象，这里重点关注二级缓存earlySingletonObjects和三级缓存singletonFactory，一级缓存可以进行忽略。</p><p>前面我们讲过先实例化的bean会通过ObjectFactory半成品提前暴露在三级缓存中</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_3.png"></p><p>singletonFactory是传入的一个匿名内部类，调用ObjectFactory.getObject()最终会调用getEarlyBeanReference方法。</p><h3 id="循环依赖中是怎么拿其它半成品的实例对象"><a href="#循环依赖中是怎么拿其它半成品的实例对象" class="headerlink" title="循环依赖中是怎么拿其它半成品的实例对象"></a>循环依赖中是怎么拿其它半成品的实例对象</h3><p>我们假设现在有这样的场景AService依赖BService，BService依赖AService</p><ol><li><p>AService首先实例化，实例化通过ObjectFactory半成品暴露在三级缓存中</p></li><li><p>填充属性BService，发现BService还未进行过加载，就会先去加载BService</p></li><li><p>再加载BService的过程中，实例化，也通过ObjectFactory半成品暴露在三级缓存</p></li><li><p>填充属性AService的时候，这时候能够从三级缓存中拿到半成品的ObjectFactory<br> <img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_4.png"><br> 三级缓存拿到ObjectFactory对象后，调用ObjectFactory.getObject()方法最终会调用getEarlyBeanReference()方法。</p><p> <strong>getEarlyBeanReference</strong>这个方法主要逻辑大概描述下如果bean被AOP切面代理则返回的是beanProxy对象，如果未被代理则返回的是原bean实例。</p><p>这时我们会发现能够拿到bean实例(属性未填充)，然后从三级缓存移除，放到二级缓存earlySingletonObjects中，而此时B注入的是一个半成品的实例A对象，不过随着B初始化完成后，A会继续进行后续的初始化操作，最终B会注入的是一个完整的A实例，因为在内存中它们是同一个对象。</p></li></ol><h3 id="为什么必须要三级缓存"><a href="#为什么必须要三级缓存" class="headerlink" title="为什么必须要三级缓存"></a>为什么必须要三级缓存</h3><p>我们发现这个二级缓存好像显得有点多余，好像可以去掉，只需要一级和三级缓存也可以做到解决循环依赖的问题？？？</p><p><strong>只要两个缓存确实可以做到解决循环依赖的问题，但是有一个前提这个bean没被AOP进行切面代理</strong></p><p>如果这个bean被AOP进行了切面代理，那么只使用两个缓存是无法解决问题。</p><p>下面来看一下bean被AOP进行了切面代理的场景：</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_5.png"></p><p>我们发现AService的testAopProxy被AOP代理了，看看传入的匿名内部类的getEarlyBeanReference返回的是什么对象。</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_6.png"></p><p>发现singletonFactory.getObject()返回的是一个AService的代理对象，还是被CGLIB代理的。</p><p>再看一张再执行一遍singletonFactory.getObject()返回的是否是同一个AService的代理对象</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_7.png"></p><p>我们会发现再执行一遍singleFactory.getObject()方法又是一个新的代理对象。</p><p>这就会有问题了，因为AService是单例的，每次执行singleFactory.getObject()方法又会产生新的代理对象。</p><p>假设这里只有一级和三级缓存的话，我每次从三级缓存中拿到singleFactory对象，执行getObject()方法又会产生新的代理对象，这是不行的，因为AService是单例的，所有这里我们要借助二级缓存来解决这个问题，将执行了singleFactory.getObject()产生的对象放到二级缓存中去，后面去二级缓存中拿，没必要再执行一遍singletonFactory.getObject()方法再产生一个新的代理对象，保证始终只有一个代理对象。</p><p>还有一个注意的点</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/Spring%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/img_8.png"></p><p>既然singleFactory.getObject()返回的是代理对象，那么注入的也应该是代理对象，我们可以看到注入的确实是经过CGLIB代理的AService对象。</p><p>所以<strong>如果没有AOP的话确实可以两级缓存就可以解决循环依赖的问题；如果加上AOP，每次执行singleFactory.getObject()方法会产生一个新的代理对象，所以还要借助另外一个缓存来保存产生的代理对象</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Bean </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初读Spring的Bean生命周期</title>
      <link href="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
      <url>/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="Bean的生命周期"><a href="#Bean的生命周期" class="headerlink" title="Bean的生命周期"></a>Bean的生命周期</h2><p>在spring的BeanFactory工厂列举了很多接口，代表着bean的生命周期。</p><details><summary>public interface BeanFactory</summary><ul><li>@author Rod Johnson</li><li>@author Juergen Hoeller</li><li>@author Chris Beams</li><li>@since 13 April 2001</li><li>@see BeanNameAware#setBeanName</li><li>@see BeanClassLoaderAware#setBeanClassLoader</li><li>@see BeanFactoryAware#setBeanFactory</li><li>@see org.springframework.context.ResourceLoaderAware#setResourceLoader</li><li>@see org.springframework.context.ApplicationEventPublisherAware#setApplicationEventPublisher</li><li>@see org.springframework.context.MessageSourceAware#setMessageSource</li><li>@see org.springframework.context.ApplicationContextAware#setApplicationContext</li><li>@see org.springframework.web.context.ServletContextAware#setServletContext</li><li>@see org.springframework.beans.factory.config.BeanPostProcessor#postProcessBeforeInitialization</li><li>@see InitializingBean#afterPropertiesSet</li><li>@see org.springframework.beans.factory.support.RootBeanDefinition#getInitMethodName</li><li>@see org.springframework.beans.factory.config.BeanPostProcessor#postProcessAfterInitialization</li><li>@see DisposableBean#destroy</li><li>@see org.springframework.beans.factory.support.RootBeanDefinition#getDestroyMethodName</li></ul></details><p>我们结合spring的源码来看这些接口主要是在哪里调用的。</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_1.png"></p><h3 id="第一步：-AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始"><a href="#第一步：-AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始" class="headerlink" title="第一步： AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始"></a>第一步： AbstractAutowireCapableBeanFactory类的doCreateBean方法是创建bean的开始</h3><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img.png"></p><p>我们可以看到首先需要实例化这个bean，也就是在堆中开辟一块内存空间给这个对象，createBeanInstance方法里面逻辑大概就是采用反射生成实例对象， 进行到这里表示对象还并未进行属性的填充，也就是@Autowired注解的属性还未得到注入</p><h3 id="第二步：-填充bean的成员属性"><a href="#第二步：-填充bean的成员属性" class="headerlink" title="第二步： 填充bean的成员属性"></a>第二步： 填充bean的成员属性</h3><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_2.png"></p><p>populateBean内逻辑大致就是对使用到了注入属性的注解就会进行注入，如果在注入的过程发现注入的对象还没生成，则会跑去生产要注入的对象</p><h3 id="第三步-调用initializeBean方法初始化bean内容"><a href="#第三步-调用initializeBean方法初始化bean内容" class="headerlink" title="第三步: 调用initializeBean方法初始化bean内容"></a>第三步: 调用initializeBean方法初始化bean内容</h3><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_3.png"></p><p>可以看到initializeBean方法中，首先调用的是使用的Aware接口的方法，我们具体看一下invokeAwareMethods方法中会调用Aware接口的那些方法</p><h4 id="invokeAwareMethods调用实现Aware接口的方法"><a href="#invokeAwareMethods调用实现Aware接口的方法" class="headerlink" title="invokeAwareMethods调用实现Aware接口的方法"></a>invokeAwareMethods调用实现Aware接口的方法</h4><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_4.png"></p><p>如果我们实现了BeanNameAware，BeanClassLoaderAware，BeanFactoryAware三个Aware接口的话，会依次调用setBeanName(), setBeanClassLoader(), setBeanFactory()方法</p><h4 id="applyBeanPostProcessorsBeforeInitialization"><a href="#applyBeanPostProcessorsBeforeInitialization" class="headerlink" title="applyBeanPostProcessorsBeforeInitialization"></a>applyBeanPostProcessorsBeforeInitialization</h4><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_5.png"></p><p>如果有类实现了BeanPostProcessor接口，就会执行postProcessBeforeInitialization方法，这里需要注意的是：</p><ul><li><p>如果多个类实现BeanPostProcessor接口，那么多个实现类都会执行postProcessBeforeInitialization方法，可以看到是for循环依次执行的。</p></li><li><p>如果加载A类到spring容器中，A类也重写了BeanPostProcessor接口的postProcessBeforeInitialization方法，这时要注意<strong>A类的postProcessBeforeInitialization方法并不会得到执行</strong>，因为A类还未加载完成，还未完全放到spring的singletonObjects一级缓存中。</p></li><li><p>可以看到ApplicationContextAwareProcessor也实现了BeanPostProcessor接口，重写了postProcessBeforeInitialization方法，方法里面并调用了invokeAwareInterfaces方法，而invokeAwareInterfaces方法也写着如果实现了众多的Aware接口，则会依次执行相应的方法，值得注意的是ApplicationContextAware接口的setApplicationContext方法<br>  <img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_6.png"><br>  <img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_7.png"><br>  <img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_8.png"></p></li></ul><h4 id="invokeInitMethods"><a href="#invokeInitMethods" class="headerlink" title="invokeInitMethods"></a>invokeInitMethods</h4><p>如果实现了InitializingBean接口，重写了afterPropertiesSet方法，则会调用afterPropertiesSet方法。</p><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_9.png"></p><p>最后还会调用是否指定了init-method，可以通过标签，或者@Bean注解的initMethod指定</p><h4 id="applyBeanPostProcessorsAfterInitialization"><a href="#applyBeanPostProcessorsAfterInitialization" class="headerlink" title="applyBeanPostProcessorsAfterInitialization"></a>applyBeanPostProcessorsAfterInitialization</h4><p><img src="/2022/03/06/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E5%88%9D%E8%AF%BBSpring%E7%9A%84Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/img_10.png"></p><p>跟之前的postProcessBeforeInitialization方法类似，也是循环遍历实现了BeanPostProcessor的接口实现类，执行postProcessAfterInitialization方法。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Bean </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB原理篇之BufferPool缓冲池</title>
      <link href="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8BBufferPool%E7%BC%93%E5%86%B2%E6%B1%A0/"/>
      <url>/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8BBufferPool%E7%BC%93%E5%86%B2%E6%B1%A0/</url>
      
        <content type="html"><![CDATA[<p>应用系统分层架构，为了加速数据访问，会把最常访问的数据，放在缓存(cache)里，避免每次都去访问数据库。</p><p>操作系统，会有<strong>缓冲池</strong>(buffer pool)机制，避免每次访问磁盘，以加速数据的访问。</p><p>MySQL作为一个存储系统，同样具有缓冲池(buffer pool)机制，以避免每次查询数据都进行磁盘IO。</p><h2 id="什么是InnoDB缓冲池"><a href="#什么是InnoDB缓冲池" class="headerlink" title="什么是InnoDB缓冲池"></a>什么是InnoDB缓冲池</h2><p><strong>缓存表数据与索引数据</strong>，把磁盘上的数据加载到缓冲池，避免每次访问都进行磁盘IO，起到加速访问的作用。</p><p>速度快，那为啥不把所有数据都放到缓冲池里？</p><p>凡事都具备两面性，抛开数据易失性不说，访问快速的反面是存储容量小：</p><ol><li>缓存访问快，但容量小，数据库存储了200G数据，缓存容量可能只有64G；</li><li>内存访问快，但容量小，买一台笔记本磁盘有2T，内存可能只有16G；</li></ol><p>因此，只能<strong>把“最热”的数据放到“最近”的地方</strong>，以“最大限度”的降低磁盘访问。</p><h2 id="如何管理与淘汰缓冲池，使得性能最大化呢？"><a href="#如何管理与淘汰缓冲池，使得性能最大化呢？" class="headerlink" title="如何管理与淘汰缓冲池，使得性能最大化呢？"></a>如何管理与淘汰缓冲池，使得性能最大化呢？</h2><p>在介绍具体细节之前，先介绍下“预读”的概念。</p><h3 id="预读"><a href="#预读" class="headerlink" title="预读"></a>预读</h3><h4 id="什么是预读"><a href="#什么是预读" class="headerlink" title="什么是预读"></a>什么是预读</h4><p>磁盘读写，并不是按需读取，而是按页读取，<strong>一次至少读一页数据</strong>（一般是4K），如果未来要读取的数据就在页中，就能够省去后续的磁盘IO，提高效率。</p><h4 id="预读为什么有效"><a href="#预读为什么有效" class="headerlink" title="预读为什么有效"></a>预读为什么有效</h4><p>数据访问，通常都遵循“集中读写”的原则，使用一些数据，大概率会使用附近的数据，这就是所谓的“<strong>局部性原理</strong>”，它表明提前加载是有效的，确实能够减少磁盘IO。</p><h4 id="按页读取，和InnoDB缓冲池设计有啥关系"><a href="#按页读取，和InnoDB缓冲池设计有啥关系" class="headerlink" title="按页读取，和InnoDB缓冲池设计有啥关系"></a>按页读取，和InnoDB缓冲池设计有啥关系</h4><ol><li>磁盘访问按页读取能够提高性能，所以缓冲池一般也是按页缓存数据；</li><li>预读机制启示了我们，能把一些“可能要访问”的页提前加入缓冲池，避免未来的磁盘IO操作；</li></ol><h3 id="InnoDB是以什么算法，来管理这些缓冲页呢？"><a href="#InnoDB是以什么算法，来管理这些缓冲页呢？" class="headerlink" title="InnoDB是以什么算法，来管理这些缓冲页呢？"></a>InnoDB是以什么算法，来管理这些缓冲页呢？</h3><p>最容易想到的，就是LRU(Least recently used)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：memcache，OS都会用LRU来进行页置换管理，但MySQL的玩法并不一样。</span><br></pre></td></tr></table></figure><h4 id="传统的LRU如何进行缓冲页管理"><a href="#传统的LRU如何进行缓冲页管理" class="headerlink" title="传统的LRU如何进行缓冲页管理"></a>传统的LRU如何进行缓冲页管理</h4><p>最常见的玩法是，把入缓冲池的页放到LRU的头部，作为最近访问的元素，从而最晚被淘汰。</p><p>这里又分两种情况：</p><ol><li>页已经在缓冲池里，那就只做“移至”LRU头部的动作，而没有页被淘汰；</li><li>页不在缓冲池里，除了做“放入”LRU头部的动作，还要做“淘汰”LRU尾部页的动作；</li></ol><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8BBufferPool%E7%BC%93%E5%86%B2%E6%B1%A0/img.png"></p><p>如上图，假如管理缓冲池的LRU长度为10，缓冲了页号为1，3，5…，40，7的页。</p><p>假如，接下来要访问的数据在页号为4的页中：</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8BBufferPool%E7%BC%93%E5%86%B2%E6%B1%A0/img_1.png"></p><ol><li>页号为4的页，本来就在缓冲池里；</li><li>把页号为4的页，放到LRU的头部即可，没有页被淘汰；</li></ol><p>假如，再接下来要访问的数据在页号为50的页中：</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8BBufferPool%E7%BC%93%E5%86%B2%E6%B1%A0/img_2.png"></p><ol><li>页号为50的页，原来不在缓冲池里；</li><li>把页号为50的页，放到LRU头部，同时淘汰尾部页号为7的页；</li></ol><p>传统的LRU缓冲池算法十分直观，OS，memcache等很多软件都在用，MySQL为啥这么矫情，不能直接用呢？</p><p>这里有两个问题：</p><ol><li>预读失效；</li><li>缓冲池污染。</li></ol><h4 id="预读失效"><a href="#预读失效" class="headerlink" title="预读失效"></a>预读失效</h4><p>由于预读(Read-Ahead)，提前把页放入了缓冲池，但最终MySQL并没有从页中读取数据，称为预读失效。</p><p><strong>如何对预读失效进行优化？</strong></p><p>要优化预读失效，思路是：</p><ol><li>让预读失败的页，停留在缓冲池LRU里的时间尽可能短；</li><li>让真正被读取的页，才挪到缓冲池LRU的头部；</li></ol><p>以保证，真正被读取的热数据留在缓冲池里的时间尽可能长。</p><p>具体方法是：</p><ol><li>将LRU分为两个部分：<ul><li>新生代(new sublist)</li><li>老生代(old sublist)</li></ul></li><li>新老生代收尾相连，即：新生代的尾(tail)连接着老生代的头(head)；</li><li>新页（例如被预读的页）加入缓冲池时，只加入到老生代头部：<ul><li>如果数据真正被读取（预读成功），才会加入到新生代的头部</li><li>如果数据没有被读取，则会比新生代里的“热数据页”更早被淘汰出缓冲池</li></ul></li></ol><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8BBufferPool%E7%BC%93%E5%86%B2%E6%B1%A0/img_3.png"></p><p>举个例子，整个缓冲池LRU如上图：</p><ol><li>整个LRU长度是10；</li><li>前70%是新生代；</li><li>后30%是老生代；</li><li>新老生代首尾相连</li></ol><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8BBufferPool%E7%BC%93%E5%86%B2%E6%B1%A0/img_4.png"></p><p>假如有一个页号为50的新页被预读加入缓冲池：</p><ol><li>50只会从老生代头部插入，老生代尾部（也是整体尾部）的页会被淘汰掉；</li><li>假设50这一页不会被真正读取，即预读失败，它将比新生代的数据更早淘汰出缓冲池；</li></ol><p>假如50这一页立刻被读取到，例如SQL访问了页内的行row数据：</p><ol><li>它会被立刻加入到新生代的头部；</li><li>新生代的页会被挤到老生代，此时并不会有页面被真正淘汰；</li></ol><p><strong>改进版缓冲池LRU能够很好的解决“预读失败”的问题</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">但也不要因噎废食，因为害怕预读失败而取消预读策略，大部分情况下，局部性原理是成立的，预读是有效的。</span><br></pre></td></tr></table></figure><p>新老生代改进版LRU仍然解决不了缓冲池污染的问题。</p><h4 id="缓冲池污染"><a href="#缓冲池污染" class="headerlink" title="缓冲池污染"></a>缓冲池污染</h4><p>当某一个SQL语句，要<strong>批量扫描大量数据</strong>时，可能导致把缓冲池的所有页都替换出去，导致<strong>大量热数据被换出</strong>，MySQL性能急剧下降，这种情况叫缓冲池污染。</p><p>例如，有一个数据量较大的用户表，当执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from user where name like &quot;%shenjian%&quot;;</span><br></pre></td></tr></table></figure><p>虽然结果集可能只有少量数据，但这类like不能命中索引，必须<strong>全表扫描</strong>，就需要访问大量的页：</p><ol><li>把页加到缓冲池（插入老生代头部）；</li><li>从页里读出相关的row（插入新生代头部）；</li><li>row里的name字段和字符串shenjian进行比较，如果符合条件，加入到结果集中；</li><li>…直到扫描完所有页中的所有row…</li></ol><p>如此一来，<strong>所有的数据页都会被加载到新生代的头部，但只会访问一次，真正的热数据被大量换出</strong>。</p><p><strong>怎么解决这类扫码大量数据导致的缓冲池污染问题呢？</strong></p><p>MySQL缓冲池加入了一个“老生代停留时间窗口”的机制：</p><ol><li>假设T=老生代停留时间窗口；</li><li>插入老生代头部的页，即使立刻被访问，并不会立刻放入新生代头部；</li><li>只有满足“被访问”并且“在老生代停留时间”大于T，才会被放入新生代头部；</li></ol><h2 id="上述原理，对应InnoDB里哪些参数？"><a href="#上述原理，对应InnoDB里哪些参数？" class="headerlink" title="上述原理，对应InnoDB里哪些参数？"></a>上述原理，对应InnoDB里哪些参数？</h2><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8BBufferPool%E7%BC%93%E5%86%B2%E6%B1%A0/img_5.png"></p><h3 id="参数：innodb-buffer-pool-size"><a href="#参数：innodb-buffer-pool-size" class="headerlink" title="参数：innodb_buffer_pool_size"></a>参数：innodb_buffer_pool_size</h3><p>介绍：配置缓冲池的大小，在内存允许的情况下，DBA往往会建议调大这个参数，越多数据和索引放到内存里，数据库的性能会越好。</p><h3 id="参数：innodb-old-blocks-pct"><a href="#参数：innodb-old-blocks-pct" class="headerlink" title="参数：innodb_old_blocks_pct"></a>参数：innodb_old_blocks_pct</h3><p>介绍：老生代占整个LRU链长度的比例，默认是37，即整个LRU中新生代与老生代长度比例是63:37。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如果把这个参数设为100，就退化为普通LRU了。</span><br></pre></td></tr></table></figure><h3 id="参数：innodb-old-blocks-time"><a href="#参数：innodb-old-blocks-time" class="headerlink" title="参数：innodb_old_blocks_time"></a>参数：innodb_old_blocks_time</h3><p>介绍：老生代停留时间窗口，单位是毫秒，默认是1000，即同时满足“被访问”与“在老生代停留时间超过1秒”两个条件，才会被插入到新生代头部。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>缓冲池(buffer pool)是一种常见的<strong>降低磁盘访问</strong>的机制；</li><li>缓冲池通常<strong>以页(page)为单位缓存数据</strong>；</li><li>缓冲池的<strong>常见管理算法是LRU</strong>，memcache，OS，InnoDB都使用了这种算法；</li><li>InnoDB对普通LRU进行了优化：<ul><li>将缓冲池分为<strong>老生代和新生代</strong>，入缓冲池的页，优先进入老生代，页被访问，才进入新生代，以解决预读失效的问题</li><li>页被访问，且在老生代<strong>停留时间超过配置阈值</strong>的，才进入新生代，以解决批量数据访问，大量热数据淘汰的问题</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB原理篇之数据页与索引初探</title>
      <link href="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/"/>
      <url>/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<p>文档说明：转载自<a href="https://mp.weixin.qq.com/s/BVqxg-k8Ro4wAisktLT0Tg">InnoDB原理篇：聊聊数据页变成索引这件事</a></p><p>文档意义：通过数据页到最后的索引，体会数据库查询优化的过程</p><h2 id="数据页"><a href="#数据页" class="headerlink" title="数据页"></a>数据页</h2><p>数据库执行<code>CRUD</code>的时候，都会从磁盘上加载数据页到<code>Buffer Pool</code>的缓存页里去，更新缓存页后，由异步线程刷回磁盘的数据页。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img.png"></p><p>所以MySQL进行数据操作的最小单位是数据页，接下来就分析分析，数据页到底长什么样。</p><p>每个数据页默认16kb的大小，数据页由多个部分组成，如下图所示</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_1.png"></p><h3 id="空闲空间"><a href="#空闲空间" class="headerlink" title="空闲空间"></a>空闲空间</h3><p>其实数据页还未写入数据时，是没有数据行的，只有空闲空间。</p><p>一旦写入，空闲空间会减少一些，直到空闲空间耗尽，具体过程如下图</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_2.png"></p><p>数据页满了，自然需要开辟新的数据页出来存储数据。</p><p>但是随着数据页多起来，它们怎么知道上一页与下一页在那呢？</p><h3 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h3><p>其实在数据页文件头中存放了特别多的信息，如当前页号、页类型、所属表空间、上一页号、下一页号等等。</p><p>所以数据页是通过上下页号，组成双向链表，如下图所示</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_3.png"></p><p>数据页内部会存储一行一行的数据，每一行数据都会按照主键大小进行排序存储，同时每一行数据都有指针指向下一行数据，组成单向链表。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_4.png"></p><p>但是这个结构并不高效，假设根据主键ID查询数据，只能进入数据页，挨个挨个的对单向链表遍历查询。</p><p>所以要再加点料，把<strong>二分查找</strong>利用起来</p><h3 id="数据页目录"><a href="#数据页目录" class="headerlink" title="数据页目录"></a>数据页目录</h3><p>这个料就是数据页目录部分，数据页目录存储的内容就是主键ID和行位置。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_5.png"></p><p>这样就可以通过数据页目录走二分查找，快速定位到数据页内的数据行。</p><p>如果只有一个数据页，倒没啥问题，哪有成千上万个数据页呢，还是得一个一个进数据页，搜索数据页目录。</p><p>有没有觉得，这似乎是在做全表扫描？</p><p>没错，在没有索引的情况下，数据库就是这样执行的。</p><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>如果没有索引，查询速度可以说是慢到惊人，一般是不能让查询走全表扫描的。</p><p>因此数据库中的查询，必须要运用索引来加速。</p><h3 id="页分裂"><a href="#页分裂" class="headerlink" title="页分裂"></a>页分裂</h3><p>在说索引之前，先说个前置知识，索引的核心基础要求后一个数据页的主键值都大于前面一个数据页的主键值，如果你的主键是自增的，可以保证这一点。</p><p>但有时候主键并不是自增长的，可能会出现后一个数据页的主键值小于前一个数据页的主键值。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_6.png"></p><p>为了保证索引的核心基础，有个交换行数据的过程，这个过程叫页分裂。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_7.png"></p><p>过程如下：</p><ul><li>数据页0的id=6行数据挪到数据页1</li><li>数据页1的页目录更新</li><li>数据页1的id=3行数据挪到数据页0</li><li>数据页0的页目录更新</li></ul><h3 id="主键目录"><a href="#主键目录" class="headerlink" title="主键目录"></a>主键目录</h3><p>好了，现在我们以主键为例，创建一个主键索引，这个主键索引就是主键目录，它会维护所有数据页的最小主键值与对应的页号。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_8.png"></p><p>有了主键目录的加持，那找数据就非常快了，过程如下：</p><ul><li>二分查找主键目录，找到对应的数据页</li><li>进入数据页，二分查找数据页目录，找到对应的行数据</li></ul><p>可是又来一个新问题，表里的数据可能有几百万，几千万，甚至几亿条数据，会有大量的数据页，意味着主键目录要存储大量的数据页号和最小主键值。</p><p>可能主键目录存储不下，就算能存储，海量的数据仅仅靠二分查找也很吃力。</p><p>所以InnoDB实际上是把主键目录数据存储在多个数据页中，我们把这个数据页称为索引页</p><h3 id="索引页"><a href="#索引页" class="headerlink" title="索引页"></a>索引页</h3><p>索引页，顾名思义，就是存储索引信息的数据页，在数据页的文件头部，有页类型来进行区分。</p><p>索引页会存储两类内容，一类是最小主键值与索引页号，另一类是最小主键值与数据页号。</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_9.png"></p><p>把大量的索引信息分散在多个索引页中，再将多个索引页组建成B+树结构，方便二分查找，结构如下图</p><p><img src="/2022/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/InnoDB%E5%8E%9F%E7%90%86%E7%AF%87%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%A1%B5%E4%B8%8E%E7%B4%A2%E5%BC%95%E5%88%9D%E6%8E%A2/img_10.png"></p><p>一直说InnoDB的索引是用B+树来组成的，其实就是这个意思，当然真实的B+树不长这样，这样画还是为了帮助大家理解。</p><p>现在整个搜索过程就十分简单了：</p><ul><li>根据主键id二分查找索引页</li><li>找到对应索引页，再二分查找数据页</li><li>进入数据页，二分查找数据页目录，找到对应的行数据</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库MySQL系列之主从同步与GTID特性</title>
      <link href="/2022/02/24/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8EGTID%E7%89%B9%E6%80%A7/"/>
      <url>/2022/02/24/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8EGTID%E7%89%B9%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL主从同步原理"><a href="#MySQL主从同步原理" class="headerlink" title="MySQL主从同步原理"></a>MySQL主从同步原理</h2><h3 id="为什么需要主从同步"><a href="#为什么需要主从同步" class="headerlink" title="为什么需要主从同步"></a>为什么需要主从同步</h3><ol><li><p>在业务复杂的系统中，有这么一个情景，有一句sql语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。</p></li><li><p>做数据的热备</p></li><li><p>架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。</p></li></ol><h3 id="MySQL主从复制"><a href="#MySQL主从复制" class="headerlink" title="MySQL主从复制"></a>MySQL主从复制</h3><h4 id="复制过程"><a href="#复制过程" class="headerlink" title="复制过程"></a>复制过程</h4><p><img src="/2022/02/24/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8EGTID%E7%89%B9%E6%80%A7/mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5.png" alt="mysql主从同步"></p><ul><li>主服务器（master）将数据更改的操作记录写到二进制redo日志（binlog）中</li><li>从服务器（slave）将主服务器中的二进制日志复制到自己的中继日志（relay log）中<ul><li>首先slave开始一个工作线程——I/O线程，I/O线程在master上打开一个普通的连接，然后开始Binlog dump process（Binlog转储过程），Binlog dump process从master的二进制日志中读取事件。</li><li>如果已经跟上master，它会睡眠并等待master产生新的事件。</li></ul></li><li>从服务器重做中继日志中的日志，把更改应用到自己的数据库中，保证数据的最终一致性<ul><li>中继日志通常存在系统的缓存中，所以中继日志的开销很小。</li></ul></li></ul><p>复制过程有一个很重要的限制，就是在slave上的复制是串行化的，master上是并行化的。</p><h4 id="同步-异步"><a href="#同步-异步" class="headerlink" title="同步/异步"></a>同步/异步</h4><ul><li>异步复制<ul><li>MySQL主从模式默认的复制，并不关心从库是否已经接收并处理</li><li>可能导致数据不完整</li></ul></li><li>同步复制<ul><li>MySQL Cluster为同步复制，所有客户端确认执行事务后才返回。</li><li>事务时间拉长、性能降低。</li></ul></li><li>半同步复制<ul><li>插件形式支持，至少一个从库接收并写ready log。</li><li>至少延迟一个TCP/IP时间，最好在低延迟网络使用。</li></ul></li></ul><h4 id="Mysql读写分离"><a href="#Mysql读写分离" class="headerlink" title="Mysql读写分离"></a>Mysql读写分离</h4><p>本身未实现读写分离：</p><ul><li>基于项目代码内部实现</li><li>基于中间代理实现<ul><li>MySQL-Proxy</li><li>amoeba(变形虫)</li></ul></li></ul><h2 id="MySQL-GTID特性"><a href="#MySQL-GTID特性" class="headerlink" title="MySQL GTID特性"></a>MySQL GTID特性</h2><p>TODO</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库MySQL系列之MVCC浅探</title>
      <link href="/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8BInnoDB%E4%B8%ADMVCC%E6%B5%85%E6%8E%A2/"/>
      <url>/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8BInnoDB%E4%B8%ADMVCC%E6%B5%85%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="MVCC简介"><a href="#MVCC简介" class="headerlink" title="MVCC简介"></a>MVCC简介</h1><h2 id="MVCC名词解释"><a href="#MVCC名词解释" class="headerlink" title="MVCC名词解释"></a>MVCC名词解释</h2><p>MVCC (Multiversion Concurrency Control)，即多版本并发控制技术。</p><h2 id="MVCC解决了什么问题"><a href="#MVCC解决了什么问题" class="headerlink" title="MVCC解决了什么问题"></a>MVCC解决了什么问题</h2><p>它使得大部分支持行锁的事务引擎（InnoDB,Falcon以及PBXT等），不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来。<br>只需要很小的开销，就可以实现非锁定读，从而大大提高数据库系统的并发性能。</p><h2 id="锁分类"><a href="#锁分类" class="headerlink" title="锁分类"></a>锁分类</h2><ul><li><strong>读锁</strong>：也叫共享锁、S锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S 锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。</li><li><strong>写锁</strong>：又称排他锁、X锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。</li><li><strong>表锁</strong>：操作对象是数据表。Mysql大多数锁策略都支持(常见mysql innodb)，是系统开销最低但并发性最低的一个锁策略。事务t对整个表加读锁，则其他事务可读不可写，若加写锁，则其他事务增删改都不行。</li><li><strong>行级锁</strong>：操作对象是数据表中的一行。是MVCC技术用的比较多的，但在MYISAM用不了，行级锁用mysql的储存引擎实现而不是mysql服务器。但行级锁对系统开销较大，处理高并发较好。</li></ul><h1 id="MVCC实现原理"><a href="#MVCC实现原理" class="headerlink" title="MVCC实现原理"></a>MVCC实现原理</h1><p>MVCC是通过保存数据在某个时间点的快照来实现的。不同存储引擎的MVCC实现是不同的，典型的有乐观并发控制和悲观并发控制。</p><h2 id="InnoDB-MVCC具体实现分析"><a href="#InnoDB-MVCC具体实现分析" class="headerlink" title="InnoDB MVCC具体实现分析"></a>InnoDB MVCC具体实现分析</h2><p>innodb MVCC主要是为<strong>Repeatable-Read事务隔离级别</strong>做的。在此隔离级别下，A、B客户端所示的数据相互隔离，互相更新不可见。</p><p>innodb存储的最基本row中包含一些额外的存储信息： DATA_TRX_ID，DATA_ROLL_PTR，DB_ROW_ID，DELETE BIT。</p><ul><li>6字节的DATA_TRX_ID 标记了最新更新这条行记录的transaction id，每处理一个事务，其值自动+1；</li><li>7字节的DATA_ROLL_PTR 指向当前记录项的rollback segment的undo log记录，找之前版本的数据就是通过这个指针；</li><li>6字节的DB_ROW_ID，当由innodb自动产生聚集索引时，聚集索引包括这个DB_ROW_ID的值，否则聚集索引中不包括这个值，这个用于索引当中；</li><li>DELETE BIT位用于标识该记录是否被删除，这里的不是真正的删除数据，而是标志出来的删除，真正意义的删除是在commit的时候。</li></ul><p><img src="/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%97%E4%B9%8BInnoDB%E4%B8%ADMVCC%E6%B5%85%E6%8E%A2/img.png" alt="img.png"></p><p>具体的执行过程</p><p>begin-&gt;用排他锁锁定该行-&gt;记录redo log-&gt;记录undo log-&gt;修改当前行的值，写事务编号，回滚指针指向undo log中的修改前的行</p><p>该过程准确说是UPDATE的事务过程，其实undo log分insert和update undo log，因为insert时，原始的数据并不存在，所以回滚时把insert undo log丢弃即可，而update undo log则必须遵守上述过程。</p><h3 id="SELECT"><a href="#SELECT" class="headerlink" title="SELECT"></a>SELECT</h3><p>Innodb检查每行数据，确保他们符合两个标准：</p><ol><li><p>InnoDB只查找版本早于当前事务版本的数据行(也就是数据行的版本必须小于或等于当前事务的版本)，这确保当前事务读取的行要么是事务之前已经存在的，要么是由当前事务创建或修改的；</p></li><li><p>行的删除版本要么未定义,要么大于当前事务版本号,这可以确保事务读取到的行，在事务开始之前未被删除。</p></li></ol><p>只有a,b同时满足的记录，才能返回作为查询结果。</p><h3 id="INSERT"><a href="#INSERT" class="headerlink" title="INSERT"></a>INSERT</h3><p>InnoDB为新插入的每一行保存当前事务版本号作为版本号。</p><h3 id="DELETE"><a href="#DELETE" class="headerlink" title="DELETE"></a>DELETE</h3><p>InnoDB会为删除的每一行保存当前事务的版本号(事务的ID)作为删除标识。</p><h3 id="UPDATE"><a href="#UPDATE" class="headerlink" title="UPDATE"></a>UPDATE</h3><p>InnoDB执行UPDATE，实际上是新插入了一行记录，并保存其创建时间为当前事务的ID，同时保存当前事务ID到要UPDATE的行的删除时间。</p><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>insert操作时 “创建时间”=DB_ROW_ID，这时，“删除时间 ”是未定义的；</p><p>update时，复制新增行的“创建时间”=DB_ROW_ID，删除时间未定义，旧数据行“创建时间”不变，删除时间=该事务的DB_ROW_ID；</p><p>delete操作，相应数据行的“创建时间”不变，删除时间=该事务的DB_ROW_ID；</p><p>select操作对两者都不修改，只读相应的数据</p><h1 id="对于MVCC的总结"><a href="#对于MVCC的总结" class="headerlink" title="对于MVCC的总结"></a>对于MVCC的总结</h1><p>上述更新前建立undo log，根据各种策略读取时非阻塞就是MVCC，undo log中的行就是MVCC中的多版本。</p><p>这个可能与我们所理解的MVCC有较大的出入，一般我们认为MVCC有下面几个特点：</p><ul><li>每行数据都存在一个版本，每次数据更新时都更新该版本</li><li>修改时Copy出当前版本随意修改，各个事务之间无干扰 </li><li>保存时比较版本号，如果成功（commit），则覆盖原记录；失败则放弃copy（rollback）</li></ul><p>就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道。</p><p>而Innodb的实现方式是：</p><ul><li>事务以排他锁的形式修改原始数据</li><li>把修改前的数据存放于undo log，通过回滚指针与主数据关联</li><li>修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）</li></ul><p>二者最本质的区别是，当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ </p><p>Innodb的实现真算不上MVCC，因为并没有实现核心的多版本共存，undo log中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。</p><p>但理想的MVCC是难以实现的，当事务仅修改一行记录使用理想的MVCC模式是没有问题的，可以通过比较版本号进行回滚；但当事务影响到多行数据时，理想的MVCC据无能为力了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">比如，如果Transaciton1执行理想的MVCC，修改Row1成功，而修改Row2失败，此时需要回滚Row1，但因为Row1没有被锁定，其数据可能又被Transaction2所修改，如果此时回滚Row1的内容，则会破坏Transaction2的修改结果，导致Transaction2违反ACID。</span><br></pre></td></tr></table></figure><p>理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。</p><p>修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二提交是目前这种场景保证一致性的唯一手段。</p><p>二段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的MVCC难以真正在实际中被应用，Innodb只是借了MVCC这个名字，提供了读的非阻塞而已。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> InnoDB </tag>
            
            <tag> MVCC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>事务数据库特性及隔离级别</title>
      <link href="/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BA%8B%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%B9%E6%80%A7%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
      <url>/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BA%8B%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%B9%E6%80%A7%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>说明： 文章转账自<a href="https://www.cnblogs.com/z-sm/p/7245981.html">数据库事务的特性、隔离级别、传播策略</a></p><h2 id="事务ACID特性"><a href="#事务ACID特性" class="headerlink" title="事务ACID特性"></a>事务ACID特性</h2><p>数据库管理系统中事务(transaction)的四个特性（分析时根据首字母缩写依次解释）：</p><ul><li>原子性（Atomicity）</li><li>一致性（Consistency）</li><li>隔离性（Isolation）</li><li>持久性（Durability）</li></ul><p>所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。（执行单个逻辑功能的一组指令或操作称为事务）</p><h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>原子性是指事务是一个<strong>不可再分割的工作单元</strong>，事务中的操作要么都发生，要么都不发生。</p><p>可采用“<strong>A向B转账</strong>”这个例子来说明解释。</p><p>在DBMS中，默认情况下<strong>一条SQL就是一个单独事务，事务是自动提交的</strong>。</p><p>只有显式的使用<strong>start transaction</strong>开启一个事务，才能将一个代码块放在事务中执行。</p><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>一致性是指在<strong>事务开始之前和事务结束以后，数据库的完整性约束没有被破坏</strong>。这是说数据库事务不能破坏关系<strong>数据的完整性以及业务逻辑上的一致性</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如A给B转账，不论转账的事务操作是否成功，其两者的存款总额不变（这是业务逻辑的一致性，至于数据库关系约束的完整性就更好理解了）。</span><br></pre></td></tr></table></figure><p>保障机制：</p><ul><li>数据库层面: 在一个事务执行之前和之后，数据符合你设置的约束（唯一约束，外键约束,check约束等)和触发器设置；</li><li>此外: 数据库的内部数据结构（如 B 树索引或双向链表）都必须是正确的。</li></ul><p>业务的一致性一般由开发人员进行保证，亦可转移至数据库层面。</p><h3 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h3><p><strong>多个事务并发访问时，事务之间是隔离的</strong>，一个事务不应该影响其它事务运行效果。</p><p>在并发环境中，当<strong>不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间</strong>。</p><p>由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。</p><p>事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，<strong>事务不会查看到中间状态的数据</strong>。</p><p>事务最复杂问题都是由事务隔离性引起的。完全的隔离性是不现实的，完全的隔离性要求数据库同一时间只执行一条事务，这样会严重影响性能。</p><h3 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h3><p>意味着在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。</p><p>完成的事务是系统永久的部分，对系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Write-Ahead Logging：SQL Server中使用了WAL（Write-Ahead Logging）技术来保证事务日志的ACID特性，在数据写入到数据库之前，先写入到日志，再将日志记录变更到存储器中。</span><br></pre></td></tr></table></figure><h2 id="事务隔离"><a href="#事务隔离" class="headerlink" title="事务隔离"></a>事务隔离</h2><p>当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性。</p><h3 id="不用事务隔离带来的问题"><a href="#不用事务隔离带来的问题" class="headerlink" title="不用事务隔离带来的问题"></a>不用事务隔离带来的问题</h3><h4 id="更新丢失"><a href="#更新丢失" class="headerlink" title="更新丢失"></a>更新丢失</h4><p>此写彼写： 两事务同时更新，一个失败回滚覆盖另一个事务的更新。或事务1执行更新操作，在事务1结束前事务2也更新，则事务1的更新结果被事务2的覆盖了。</p><ul><li>两个事务分别写，然后：都回滚则没问题；</li><li>一回滚一提交 或 都提交 则会出现更新丢失问题<ol><li>更新丢失（Lostupdate）: 两个事务都做更新操作，一个事务回滚会覆盖另一个事务更新的数据，导致更新丢失</li><li>两次更新问题（Secondlost updates problem）: 两个事务都做更新操作，后提交事务者会覆盖先提交者的更新。</li></ol></li></ul><h4 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h4><p>此写彼读： 事务T2读取到事务T1修改了但是事务1还未提交的数据，之后事务T1又回滚其更新操作，导致事务T2读到的是脏数据。</p><h4 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h4><p>此读彼写： 对于数据库中的某个数据，一个事务内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。</p><p>例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。</p><p>在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主；但在另一些情况下就有可能发生问题，例如对于同一个数据被A和B依次查询得到的结果就可能不同，A和B就可能打起来了……</p><h4 id="幻读-虚读"><a href="#幻读-虚读" class="headerlink" title="幻读/虚读"></a>幻读/虚读</h4><p>此读彼写： 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。</p><h4 id="各问题区别"><a href="#各问题区别" class="headerlink" title="各问题区别"></a>各问题区别</h4><ul><li><p>脏读和不可重复读的区别：脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。</p></li><li><p>不可重复读和幻读的异同：都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。</p></li></ul><h3 id="事务隔离的级别"><a href="#事务隔离的级别" class="headerlink" title="事务隔离的级别"></a>事务隔离的级别</h3><p>为此我们需要通过提供不同类型的“锁”机制针对数据库事务进行不同程度的并发访问控制，由此产生了不同的事务隔离级别：隔离级别（低-&gt;高）。</p><p>SQL、SQL2标准定义了四种隔离级别：</p><h4 id="读未提交（Read-Uncommitted）"><a href="#读未提交（Read-Uncommitted）" class="headerlink" title="读未提交（Read Uncommitted）"></a>读未提交（Read Uncommitted）</h4><p>含义解释：只限制同一数据写事务禁止其他写事务。解决”更新丢失”。（一事务写时禁止其他事务写）</p><p>名称解释：可读取未提交数据</p><p>所需的锁：排他写锁</p><h4 id="读提交（Read-Committed）"><a href="#读提交（Read-Committed）" class="headerlink" title="读提交（Read Committed）"></a>读提交（Read Committed）</h4><p>含义解释：只限制同一数据写事务禁止其它读写事务。解决”脏读”，以及”更新丢失”。（一事务写时禁止其他事务读写）</p><p>名称解释：必须提交以后的数据才能被读取</p><p>所需的锁：排他写锁、瞬间共享读锁</p><h4 id="可重复读（Repeatable-Read）"><a href="#可重复读（Repeatable-Read）" class="headerlink" title="可重复读（Repeatable Read）"></a>可重复读（Repeatable Read）</h4><p>含义解释：限制同一数据写事务禁止其他读写事务，读事务禁止其它写事务(允许读)。解决”不可重复读”，以及”更新丢失”和”脏读”。（一事务写时禁止其他事务读写、一事务读时禁止其他事务写）</p><p>注意没有解决幻读，解决幻读的方法是增加范围锁（range lock）或者表锁。</p><p>名称解释：能够重复读取</p><p>所需的锁：排他写锁、共享读锁</p><h4 id="串行化（Serializable）"><a href="#串行化（Serializable）" class="headerlink" title="串行化（Serializable）"></a>串行化（Serializable）</h4><p>含义解释：限制所有读写事务都必须串行化实行。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。（一事务写时禁止其他事务读写、一事务读时禁止其他事务读写）</p><p>所须的锁：范围锁或表锁</p><h3 id="各隔离级别对各种异常的控制能力"><a href="#各隔离级别对各种异常的控制能力" class="headerlink" title="各隔离级别对各种异常的控制能力"></a>各隔离级别对各种异常的控制能力</h3><table><thead><tr><th></th><th>更新丢失</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>RU(读未提交)</td><td>避免</td><td></td><td></td><td></td></tr><tr><td>RC（读提交）</td><td>避免</td><td>避免</td><td></td><td></td></tr><tr><td>RR（可重复读）</td><td>避免</td><td>避免</td><td>避免</td><td></td></tr><tr><td>S（串行化）</td><td>避免</td><td>避免</td><td>避免</td><td>避免</td></tr></tbody></table><p>四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，数据完整性越好，但执行效率就越低。</p><p>像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁)使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。</p><h3 id="常见数据库的默认事务隔离级别"><a href="#常见数据库的默认事务隔离级别" class="headerlink" title="常见数据库的默认事务隔离级别"></a>常见数据库的默认事务隔离级别</h3><table><thead><tr><th>数据库</th><th>默认隔离级别</th><th>备注</th></tr></thead><tbody><tr><td>MySQL</td><td>可重复读（Repeatable Read）</td><td>MySQL的Repeatable Read隔离级别也解决了幻读问题（通过Next-key lock加锁方法即范围锁解决不可重复读和幻读问题，如select * from t where a&gt;10会对key为[10,infinite）范围的行加锁，这样其他事务就不能对此范围内key对应的行更改）达到了SQL、SQL2标准中的Serializable级别。</td></tr><tr><td>Oracle</td><td>读提交（Read Committed）</td><td>只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别</td></tr><tr><td>SQLServer</td><td>读提交（Read Committed）</td><td></td></tr><tr><td>DB2</td><td>读提交（Read Committed）</td><td></td></tr><tr><td>PostgreSQL</td><td>读提交（Read Committed）</td><td></td></tr></tbody></table><p>在MySQL数据库中查看当前事务的隔离级别：</p><pre><code>select @@tx_isolation;</code></pre><p>在MySQL数据库中设置事务的隔离级别：</p><pre><code>set  [glogal | session]  transaction isolation level 隔离级别名称; //设置全部连接或当前连接的事务隔离级别set tx_isolation=’隔离级别名称; //设置当前连接的事务隔离级别</code></pre><p><strong>设置数据库的隔离级别一定要是在开启事务之前！</strong></p><p>如果是使用JDBC对数据库的事务设置隔离级别的话，也应该是在调用Connection对象的setAutoCommit(false)方法之前。调用Connection对象的setTransactionIsolation(level)即可设置当前链接的隔离级别，至于参数level，可以使用Connection对象的字段：</p><p><img src="/2022/02/23/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BA%8B%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%B9%E6%80%A7%E4%B8%8E%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/img.png"></p><p>在JDBC中设置隔离级别的部分代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">try (Connection conn = JdbcUtils.getConnection()) &#123;</span><br><span class="line">  conn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);</span><br><span class="line">  conn.setAutoCommit(false);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>后记：隔离级别的设置只对当前链接有效。对于使用MySQL命令窗口而言，一个窗口就相当于一个链接，当前窗口设置的隔离级别只对当前窗口中的事务有效；对于JDBC操作数据库来说，一个Connection对象相当于一个链接，而对于Connection对象设置的隔离级别只对该Connection对象有效，与其他链接Connection对象无关。</p><h2 id="事务传播"><a href="#事务传播" class="headerlink" title="事务传播"></a>事务传播</h2><p>事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。</p><p>需要注意的是，传播是指一个线程内的传播，不同线程间是没有传播一说的，即不同线程间无法在一个事务内（不然还要事务隔离干嘛），因为他们通常是不同的数据库连接。因此子异步线程事务回滚与否不会影响父线程的事务回滚与否。</p><p>以Spring Transaction为例，在TransactionDefinition接口定义中包括了如下几个表示传播行为的常量（3+3+1）：</p><ul><li>TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。</li><li>TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。</li><li>TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。</li><li>TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。</li><li>TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。</li><li>TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。</li><li>TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则新建事务。</li></ul><p>示例可参阅：<a href="https://blog.csdn.net/f641385712/article/details/98642777">https://blog.csdn.net/f641385712/article/details/98642777</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA并发编程之线程安全及解决方案大纲</title>
      <link href="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%A4%A7%E7%BA%B2/"/>
      <url>/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E5%A4%A7%E7%BA%B2/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么需要多线程"><a href="#为什么需要多线程" class="headerlink" title="为什么需要多线程"></a>为什么需要多线程</h2><p>线程是Java语言中不可或缺的重要部分，它们能使复杂的异步代码变得简单，简化复杂系统的开发；能充分发挥多处理器系统的强大计算能力。</p><h3 id="多线程优点"><a href="#多线程优点" class="headerlink" title="多线程优点"></a>多线程优点</h3><ol><li><p><strong>充分利用硬件资源</strong>。由于线程是cpu的基本调度单位，所以如果是单线程，那么最多只能同时在一个处理器上运行，意味着其他的CPU资源都将被浪费。而多线程可以同时在多个处理器上运行，只要各个线程间的通信设计正确，那么多线程将能充分利用处理器的资源。</p></li><li><p><strong>结构优雅</strong>。多线程程序能将代码量巨大，复杂的程序分成一个个简单的功能模块，每块实现复杂程序的一部分单一功能，这将会使得程序的建模，测试更加方便，结构更加清晰，更加优雅。</p></li><li><p><strong>简化异步处理</strong>。为了避免阻塞，单线程应用程序必须使用非阻塞I/O,这样的I/O复杂性远远高于同步I/O，并且容易出错。</p></li></ol><h3 id="多线程缺点"><a href="#多线程缺点" class="headerlink" title="多线程缺点"></a>多线程缺点</h3><ol><li><p><strong>线程安全</strong>：由于统一进程下的多个线程是共享同样的地址空间和数据的，又由于线程执行顺序的不可预知性，一个线程可能会修改其他线程正在使用的变量，这一方面是给数据共享带来了便利；另一方面，如果处理不当，会产生脏读，幻读等问题，好在Java提供了一系列的同步机制来帮助解决这一问题，例如内置锁。</p></li><li><p><strong>活跃性问题</strong>。可能会发生长时间的等待锁，甚至是死锁。</p></li><li><p><strong>性能问题</strong>。 线程的频繁调度切换会浪费资源，同步机制会导致内存缓冲区的数据无效，以及增加同步流量。</p></li></ol><h2 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替运行，并且在主调试代码中不需要任何额外的同步或者协同，这个类都能表现出正确的行为，则称这个类时线程安全的。</p><p>线程安全类中封装了必要的同步机制，因此客户端无须进一步采取同步措施。</p><h3 id="线程安全问题产生的原因"><a href="#线程安全问题产生的原因" class="headerlink" title="线程安全问题产生的原因"></a>线程安全问题产生的原因</h3><p>正确性取决于多个线程的交替执行时序，产生了竞态条件。</p><h3 id="原子类"><a href="#原子类" class="headerlink" title="原子类"></a>原子类</h3><p>应尽量使用原子类，这样会让你分析线程安全时更加方便，但需要注意的是用线程安全类构建的类并不能保证线程安全。</p><p>例如，一个AtomicInteger get() 和 AtomicInteger set() 是线程安全的，在一个类的一个方法 f()中同时用到了这两个方法，此时的f()就是线程不安全的，因为你不能保证这个复合操作中的get 和 set同时更新。</p><h2 id="线程安全的解决方案"><a href="#线程安全的解决方案" class="headerlink" title="线程安全的解决方案"></a>线程安全的解决方案</h2><h3 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h3><ol><li><p>锁能使其保护的代码以串行的形式来访问，当给一个复合操作加锁后，能使其成为原子操作。一种错误的思想是只要对写数据的方法加锁，其实这是错的，对数据进行操作的所有方法都需加锁，不管是读还是写。</p></li><li><p>加锁时需要考虑性能问题，不能总是一味地给整个方法加锁synchronized就了事了，应该将方法中不影响共享状态且执行时间比较长的代码分离出去。</p></li><li><p>加锁的含义不仅仅局限于互斥，还包括可见性。为了确保所有线程都能看见最新值，读操作和写操作必须使用同样的锁对象。</p></li></ol><h3 id="不共享状态"><a href="#不共享状态" class="headerlink" title="不共享状态"></a>不共享状态</h3><ol><li><p>无状态对象： 无状态对象一定是线程安全的，因为不会影响到其他线程。</p></li><li><p>线程关闭： 仅在单线程环境下使用。</p></li></ol><h3 id="不可变对象"><a href="#不可变对象" class="headerlink" title="不可变对象"></a>不可变对象</h3><p>可以使用final修饰的对象保证线程安全，由于final修饰的引用型变量(除String外)不可变是指引用不可变，但其指向的对象是可变的，所以此类必须安全发布，也即不能对外提供可以修改final对象的接口。</p>]]></content>
      
      
      <categories>
          
          <category> 并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> 锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA并发编程之这个&quot;破玩意儿&quot;叫锁</title>
      <link href="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/"/>
      <url>/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/</url>
      
        <content type="html"><![CDATA[<p>说明： 转载自<a href="https://mp.weixin.qq.com/s/PL-oTc5J_pe5Oyb8mdltjQ">中间件兴趣圈-你管这“破玩意儿”叫锁</a></p><h2 id="锁的种类"><a href="#锁的种类" class="headerlink" title="锁的种类"></a>锁的种类</h2><p>首先以一个非常常见的生活场景举例，例如一个三口之家居住在一个二房一厅的房子里，只有一个卫生间，早上一起床，大家都有抢卫生间，这里就会发生： 一人在如厕，其他人排队等待的场景。</p><p>这个场景下有如下几个关键的特征：</p><ul><li>独占 “厕所“作为一个资源，在任意时刻只能被一个人占用，为了实现该效果，使用资源之前，需要先获得与该资源关联的锁</li><li>当多个线程都需要访问该资源时，必须先获得锁，而且在同一时刻有且只会有一个线程获得锁，那没有获得锁的线程就需要排队等待。是一直等，还是等得不耐烦时就放弃？</li><li>当有多人排队时，一个线程将锁释放后，交给谁？什么样的策略？</li></ul><p>上面是最常见的锁应用场景，有一个非常响亮的名称：<strong>互斥锁、排它锁</strong>。</p><h3 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h3><p>在java领域中，实现互斥锁通常有两种方式：</p><ul><li>synchronized</li><li>ReentrantLock</li></ul><p>互斥锁的基本语义：</p><table><thead><tr><th>语义</th><th>说明</th><th>ReentrantLock</th><th>synchronized</th></tr></thead><tbody><tr><td>可重入性</td><td>一个线程获取锁后，没有释放之前，继续申请</td><td>支持</td><td>支持</td></tr><tr><td>锁只能被锁的拥有者释放</td><td><strong>基于redis实现分布式锁时，要特别注意这个特质</strong></td><td>——</td><td>——</td></tr><tr><td>中断</td><td>申请锁时是否支持被中断</td><td>调用lockInterruptibly方法，可以支持线程中断，即停止继续申请锁</td><td>不支持</td></tr><tr><td>公平锁或非公平锁</td><td>当拥有锁的线程释放锁后，锁的下一个获取者就是锁等待队列中的第一个元素</td><td>支持</td><td>不支持</td></tr></tbody></table><h3 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h3><p>与互斥锁相对应的是共享锁，所谓的共享锁是<strong>同一时间可以被多个线程共同申请</strong>，一个非常经典的使用场景就是<strong>读写锁</strong>。</p><p>例如在一个缓存场景，在一个商品系统中，为了提供对商品的访问性能，通常会引入一个缓存区(Map)来缓存商品的数据，缓存数据对查询请求(读请求)是可以并行执行的，即多个线程同时查询缓存区的数据，这个是一个非常安全的操作，但不允许多个线程对缓存区进行修改。这里共享锁的意义就发挥出来了。</p><p>既然多个线程对缓存区可以同时进行读操作，那为什么还要加共享锁呢？主要的目的是<strong>避免写操作与读操作同时进行</strong>。</p><p>只要当前有读操作在进行，写操作就需要排队，请看如下示例图：<br><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img.png"><br>如上图所示：例如 线程T1,T2,T3连续申请共享锁，然后T4申请写锁，再T5申请读锁，那各个线程的并发执行情况如下所示：</p><ul><li>线程 T1、T2、T3 将并发执行</li><li>T4由于是申请的写锁，必须等 T1、T2、T3释放锁后，才能执行。</li><li>T5虽然申请是共享锁，但由于T4持有写锁，故T5也需要阻塞，直至T4释放锁。</li></ul><p>在Java等世界中按<strong>锁的排斥性</strong>来分基本就包含<strong>排它锁与共享锁</strong>，其他读写锁、间隙锁等是以锁的粒度这个纬度进行细分。</p><h2 id="锁的实现原理"><a href="#锁的实现原理" class="headerlink" title="锁的实现原理"></a>锁的实现原理</h2><p>从某种意义上来说，锁的实现原理就是两个队列：<strong>同步阻塞队列、条件等待队列</strong>。</p><h3 id="同步阻塞队列"><a href="#同步阻塞队列" class="headerlink" title="同步阻塞队列"></a>同步阻塞队列</h3><p>阻塞队列的作用说明如下图所示：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_1.png"></p><p>上面使用synchronized，其传入的是一个锁对象，如果此时有5个线程同时去执行这段代码，由于锁的互斥性，同一时间只有一个线程能获得锁，<strong>其他线程需要排队等待</strong>，故需要引入一个队列来存储在这些排队的线程，所以<strong>synchronized的实现机制中，会在锁对象中开辟一个队列，用来存储等待获取当前锁的线程</strong>。</p><h3 id="条件等待队列"><a href="#条件等待队列" class="headerlink" title="条件等待队列"></a>条件等待队列</h3><p>Object对象中有一对特殊的方法：wait()/notify()/notifyAll()，消费者/生产者中示例中，使用过wait,notify方法，示例代码如下：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_2.png"></p><p>wait方法必须在synchronized中调用，并且通常是<strong>线程调用锁对象的wait方法</strong>，表示当前继续往下执行的条件不足，当前线程需要等待，故需要为锁对象再维护一个个队列，用来存储等待的线程，俗称条件等待队列。</p><p>当其他线程调用锁对象的notify方法或notifyAll方法，会唤醒等待队列中的线程。</p><pre><code>温馨提示： Object.wait方法，会使当前线程进入等待状态，并且释放锁。通常条件等待会使用while语句，避免条件不满足时被误唤醒，故使用while对条件进行再一次的判断。当被唤醒后，并不立即去执行while条件判断，而是需要重新去申请锁，即可能会进入到阻塞队列。</code></pre><h2 id="锁的优化思路"><a href="#锁的优化思路" class="headerlink" title="锁的优化思路"></a>锁的优化思路</h2><p>大家都对锁很敏感，因为性能低下，但锁肯定有其存在的原因，主要解决<strong>数据访问的安全性</strong></p><p>大家可能会感到惊讶，作为一款高性能的消息中间件(RocketMQ)，在消息写入时也使用了锁，其代码如下:</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_3.png"></p><p>这是因为RocketMQ是顺序写文件，多个请求同时申请写一个文件，必须排队执行，否则会带来逻辑异常，此时锁是不用不行了。</p><p>对锁的优化策略，通常基于如下原则：</p><ul><li>能不用锁就不使用锁，</li><li>必须使用锁则尽量保证被锁包裹代码的快速执行</li><li>降低锁的粒度。</li></ul><h3 id="优化锁执行时间"><a href="#优化锁执行时间" class="headerlink" title="优化锁执行时间"></a>优化锁执行时间</h3><p>当然能不用锁就不用锁，但有些场景是必须使用锁来保证多线程环境下结果的正确性。</p><p>就以RocketMQ顺序写commitlog文件为例，对同一个文件写入，需要记录当前的写入位置，然后另外一个线程就进行追加，故这个为写入位置是多线程不安全的，故必须引入锁。</p><p>那RocketMQ作为一款高性能的消息中间件，是如何做到消息发送的高并发，低延迟能力低呢？</p><p>核心法宝：<strong>控制锁的范围，确保被锁包含的代码执行性能高效</strong>，接下来我们看一下RocketMQ消息写入的几个重要步骤：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_4.png"></p><p>并不是需要将上述三个步骤都加锁，而是只对写内存这段加锁即可，这段代码非常高效。</p><h3 id="优化锁的粒度"><a href="#优化锁的粒度" class="headerlink" title="优化锁的粒度"></a>优化锁的粒度</h3><p>锁的性能优化是一个永恒的主旨，另外一个核心思路是：<strong>降低锁的粒度，提高并发度</strong>。</p><p>接下来我们以JDK中的HashTable与ConcurrentHashMap的实现原理为例，让大家体会一下如何降低锁的粒度从而提高并发度。</p><p>Hashtable的性能低下是众所周知，因为整个容器就一把锁，因为它的get、put都是被synchronized修饰，synchronized用来修饰非static方法，其锁对象为Hashtable是对象锁。</p><ul><li>并发度：同一时间只有一个线程能向该容器添加数据、获取数据。</li></ul><p>而jkd1.7及其版本，ConcurrentHashMap的内部数据结构如下图所示：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_5.png"></p><p>可以看出ConcurrentHashMap的设计思路是将整个HashMap分割成多个小的HashMap，然后为每一个HashMap加锁，从而降低锁的粒度，从而提高并发度。</p><p>在JDK1.8及版本后，ConcurrentHashMap的存储结构又发了很大改变，摒弃分段思想，使用来数组 + Node ，进一步释放读写的并发度，其数据结构如下图所示：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_6.png"></p><p>其中，对每一个链表的Node节点，写操作时会加锁，但在查询时候，并不会对各个Node加锁，提高读操作的并发度；并且会基于CAS机制实现无锁化处理，使用volatile保证可见性。</p><h3 id="无锁化设计"><a href="#无锁化设计" class="headerlink" title="无锁化设计"></a>无锁化设计</h3><p>锁的存在必然有其使用场景，特别是需要<strong>被锁保护的资源众多</strong>，即临界区中的逻辑复杂，对其进行拆分会使代码变的臃肿，直接使用锁保护会清晰明了，但评估是否需要引入锁时需要慎重，特别是一些对吞吐量有极高要求的场景，能不用锁就不要用锁.</p><p><strong>无锁化设计的基础：CAS，比较和交换。</strong></p><p>在Java领域也提供了对应的原子操作工具：CAS</p><p>CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。</p><ul><li>如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。</li><li>否则，处理器不做任何操作。</li><li>*CAS是CPU指令级命令**。</li></ul><p>CAS简单使用示例如下：</p><p><img src="/2022/02/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%99%E4%B8%AA%E7%A0%B4%E7%8E%A9%E6%84%8F%E5%84%BF%E5%8F%AB%E9%94%81/img_7.png"></p>]]></content>
      
      
      <categories>
          
          <category> 并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> 锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA并发编程之通用多线程基础</title>
      <link href="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/"/>
      <url>/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="Java多线程"><a href="#Java多线程" class="headerlink" title="Java多线程"></a>Java多线程</h2><h3 id="线程-amp-程序-amp-进程"><a href="#线程-amp-程序-amp-进程" class="headerlink" title="线程&amp;程序&amp;进程"></a>线程&amp;程序&amp;进程</h3><ul><li>进程: 程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。<ul><li>各进程相互独立</li></ul></li><li>线程：比进程更小的执行单位。<ul><li>同类的多个线程共享进程的堆和方法区资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多。</li><li>每个线程有自己的程序计数器、虚拟机栈和本地方法栈。</li><li>同一进程中的线程极有可能会相互影响。</li></ul></li></ul><h3 id="线程基本状态"><a href="#线程基本状态" class="headerlink" title="线程基本状态"></a>线程基本状态</h3><p>Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。<br><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png" alt="Java线程状态"></p><p>线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）：<br><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/Java%20%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E8%BF%81.png" alt="Java线程状态变迁"></p><ul><li>线程创建之后它将处于 NEW（新建） 状态</li><li>调用 start() 方法后开始运行，线程这时候处于 READY（可运行） 状态。</li><li>可运行状态的线程获得了 cpu 时间片（timeslice）后就处于 RUNNING（运行） 状态。</li><li>当线程执行 wait()方法之后，线程进入 WAITING（等待）状态， 进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态</li><li>而 TIME_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将 Java 线程置于 TIMED WAITING 状态。</li><li>当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。</li><li>当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 BLOCKED（阻塞） 状态。</li><li>线程在执行 Runnable 的run()方法之后将会进入到 TERMINATED（终止） 状态。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">操作系统隐藏 Java 虚拟机（JVM）中的 READY 和 RUNNING 状态，它只能看到 RUNNABLE 状态，所以 Java 系统一般将这两个状态统称为 RUNNABLE（运行中） 状态 。</span><br></pre></td></tr></table></figure><h3 id="sleep-amp-wait"><a href="#sleep-amp-wait" class="headerlink" title="sleep&amp;wait"></a>sleep&amp;wait</h3><p>两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。<br>两者都可以暂停线程的执行。</p><ul><li>Wait 通常被用于线程间交互/通信，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法, 可以使用 wait(long timeout)超时后线程会自动苏醒。</li><li>sleep 通常被用于暂停执行, 线程会自动苏醒。</li></ul><h3 id="start-amp-run"><a href="#start-amp-run" class="headerlink" title="start() &amp; run()"></a>start() &amp; run()</h3><ul><li>new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。</li><li>start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。</li><li>而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。</li></ul><h2 id="Java锁"><a href="#Java锁" class="headerlink" title="Java锁"></a>Java锁</h2><h3 id="从对象头看锁实现原理"><a href="#从对象头看锁实现原理" class="headerlink" title="从对象头看锁实现原理"></a>从对象头看锁实现原理</h3><h4 id="对象头转换过程"><a href="#对象头转换过程" class="headerlink" title="对象头转换过程"></a>对象头转换过程</h4><p><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/markword.png" alt="markword"></p><ul><li><p>对象未加锁的时候，lock标志位为01，包含哈希值、年龄分代和偏向锁标志位等，此时偏向锁标志位为0；</p></li><li><p>当对象被施加偏向锁时，哈希值和一部分无用内存会转化为锁主人的线程信息，以及加锁的时间戳epoch，此时lock标志位没变，偏向锁为1，也就是说，偏向锁和lock标志位共同决定是否偏向锁状态。</p><p>偏向锁的加锁步骤：</p><ul><li>Load-and-test，也就是简单判断一下当前线程id是否与Markword当中的线程id是否一致.</li><li>如果一致，则说明此线程已经成功获得了锁，继续执行下面的代码.</li><li>如果不一致，则要检查一下对象是否还是可偏向，即“是否偏向锁”标志位的值。</li><li>如果还未偏向，则利用CAS操作来竞争锁，也即是第一次获取锁时的操作。</li></ul></li><li><p>当发生锁竞争时，偏向锁会变为轻量级锁，这时需要先将偏向锁进行锁撤销，这一步骤也会消耗不少的性能，轻量级锁的Mark Word中，lock标志位为00，其余内容被替换为一个指针，指向了栈里面的锁记录。</p><p>锁撤销的过程如下：</p><ul><li>在一个安全点停止拥有锁的线程。</li><li>遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。</li><li>唤醒当前线程，将当前锁升级成轻量级锁。</li></ul><p>所以，如果某些同步代码块大多数情况下都是有两个及以上的线程竞争的话，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭</p><p>轻量级锁的加锁步骤：</p><ul><li>线程在自己的栈桢中创建锁记录LockRecord。</li><li>将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。</li><li>将锁记录中的Owner指针指向锁对象。</li><li>将锁对象的对象头的MarkWord替换为指向锁记录的指针。</li></ul><p>轻量级锁主要有两种：自旋锁和自适应自旋锁。自旋锁会导致空耗CPU且很可能锁不公平；自适应是指根据上一次该线程是否成功或者多久获取过该锁设置旋转次数，若上次失败很可能直接进入重量级锁</p></li><li><p>如果竞争线程增多，锁继续膨胀，变为重量级锁，也是互斥锁，即synchronized，其lock标志位为10，Mark Word其余内容被替换为一个指向对象监视器Monitor的指针。</p></li><li><p>特殊的是，如果此对象已经被GC标记过，lock会变为11，不含其余内容。</p></li></ul><h4 id="Monitor对象"><a href="#Monitor对象" class="headerlink" title="Monitor对象"></a>Monitor对象</h4><p>每个对象都有一个Monitor对象相关联，Monitor对象中记录了持有锁的线程信息、等待队列等。Monitor对象包含以下三个字段：</p><ul><li>_owner 记录当前持有锁的线程</li><li>_EntryList 是一个队列，记录所有阻塞等待锁的线程</li><li>_WaitSet 也是一个队列，记录调用 wait() 方法并还未被通知的线程</li></ul><p>当线程持有锁的时候，线程id等信息会拷贝进owner字段，其余线程会进入阻塞队列entrylist，当持有锁的线程执行wait方法，会立即释放锁进入waitset，当线程释放锁的时候，owner会被置空，公平锁条件下，entrylist中的线程会竞争锁，竞争成功的线程id会写入owner，其余线程继续在entrylist中等待。</p><h4 id="Monitor与Synchronized"><a href="#Monitor与Synchronized" class="headerlink" title="Monitor与Synchronized"></a>Monitor与Synchronized</h4><ul><li>对于Synchronized的同步代码块，JVM会在进入代码块之前加上monitorenter ，如果进入monitor成功，线程便获取了锁，一个对象的monitor同一时刻只能被一个线程锁占有；</li><li>对于同步方法，JVM会讲方法设置 ACC_SYNCHRONIZED 标志，调用的时候 JVM 根据这个标志判断是否是同步方法。</li><li>采用Synchronized给对象加锁会使线程阻塞，因而会造成线程状态的切换，而线程状态的切换必须要操作系统来执行，因此需要将用户态切换为内核态，这个切换的过程是十分耗时的都需要操作系统来帮忙，有可能比用户执行代码的时间还要长。</li></ul><h4 id="Synchronized"><a href="#Synchronized" class="headerlink" title="Synchronized"></a>Synchronized</h4><p>JVM级别的锁，它在不断被优化着，从目前来看Synchronized已经远没有以前那么“重”了，也大概就是JUC包源码（如ConcurrentHashMap）中大量使用Synchronized的原因吧。</p><p><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/Java%20Synchronized.png" alt="java syschronized"></p><h3 id="偏向锁、轻量级锁、重量级锁"><a href="#偏向锁、轻量级锁、重量级锁" class="headerlink" title="偏向锁、轻量级锁、重量级锁"></a>偏向锁、轻量级锁、重量级锁</h3><p><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/img.png"></p><p><a href="https://www.cnblogs.com/cxuanBlog/p/11684390.html">看完你就明白的锁系列之锁的状态</a></p><p><a href="https://www.jianshu.com/p/36eedeb3f912">浅谈偏向锁、轻量级锁、重量级锁</a></p><h4 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h4><p>内置锁在Java中被抽象为监视器锁（monitor），在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。<br>这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。<br>因此，后来称这种锁为“重量级锁”。</p><h4 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h4><p>内核态与用户态的切换上不容易优化。但通过自旋锁，可以<em><strong>减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）</strong></em>。</p><ul><li>当前线程竞争锁失败时，打算阻塞自己</li><li>不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会</li><li>在自旋的同时重新竞争锁</li><li>如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己</li></ul><p>如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。</p><ul><li><p>单核处理器上，不存在实际的并行，当前线程不阻塞自己的话，旧owner就不能执行，锁永远不会释放，此时不管自旋多久都是浪费；进而，如果线程多而处理器少，自旋也会造成不少无谓的浪费。</p></li><li><p>自旋锁要占用CPU，如果是计算密集型任务，这一优化通常得不偿失，减少锁的使用是更好的选择。</p></li><li><p>如果锁竞争的时间比较长，那么自旋通常不能获得锁，白白浪费了自旋占用的CPU时间。这通常发生在锁持有时间长，且竞争激烈的场景中，此时应主动禁用自旋锁。</p><pre><code>使用-XX:-UseSpinning参数关闭自旋锁优化；-XX:PreBlockSpin参数修改默认的自旋次数。</code></pre></li></ul><h4 id="自适应自旋锁"><a href="#自适应自旋锁" class="headerlink" title="自适应自旋锁"></a>自适应自旋锁</h4><p>自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定.</p><ul><li>如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。</li><li>相反的，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能减少自旋时间甚至省略自旋过程，以避免浪费处理器资源。</li></ul><p>自适应自旋解决的是“锁竞争时间不确定”的问题。<em>自适应自旋假定不同线程持有同一个锁对象的时间基本相当，竞争程度趋于稳定，因此，可以根据上一次自旋的时间与结果调整下一次自旋的时间。</em></p><ul><li>如果默认的自旋次数设置不合理（过高或过低），那么自适应的过程将很难收敛到合适的值。</li></ul><h4 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h4><p>轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。</p><ul><li>使用轻量级锁时，不需要申请互斥量，仅仅将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record</li><li>如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁</li><li>否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。</li></ul><p>由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。</p><ul><li>如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁，那么维持轻量级锁的过程就成了浪费。</li></ul><h4 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h4><p>偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。</p><ul><li>“偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁）</li><li>因此，只需要在Mark Word中CAS记录owner（本质上也是更新，但初始值为空）</li><li>如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁</li><li>否则，说明有其他线程竞争，膨胀为轻量级锁。</li></ul><p>偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定</p><ul><li>如果明显存在其他线程申请锁，那么偏向锁将很快膨胀为轻量级锁。</li></ul><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。</li><li>轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。</li><li>重量级锁：有实际竞争，且锁竞争时间长。</li></ul><h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><p>ReentrantLock 类实现了 Lock ，它拥有与 synchronized 相同的并发性和内存语义，但是添加了类似锁投票、定时锁等候和可中断锁等候的一些特性。</p><details><summary>使用</summary><pre><code>public class Printer  &#123;     private Lock lock = new ReentrantLock();// 锁对象       public void printLetters(char c) &#123;         lock.lock();// 得到锁           try &#123;             for(int i = 0; i<5; i++) &#123; system.out.print(c); &#125; system.out.println(); &#125;finally lock.unlock(); 释放锁 < code></5;></code></pre></details><h3 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。</p><p>创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（） 和 set（） 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。</p><ul><li>Thread 类中有一个 threadLocals 和 一个  inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量,我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap;</li><li>最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。</li><li>同一个线程中声明了两个 ThreadLocal 对象的话，会使用 Thread内部都是使用仅有那个ThreadLocalMap 存放数据的，ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值。</li><li>ThreadLocalMap是ThreadLocal的静态内部类。</li></ul><h4 id="ThreadLocal-内存泄露问题"><a href="#ThreadLocal-内存泄露问题" class="headerlink" title="ThreadLocal 内存泄露问题"></a>ThreadLocal 内存泄露问题</h4><p>ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。</p><p>所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。</p><p>这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后最好手动调用remove()方法。</p><h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><h4 id="为什么使用线程池"><a href="#为什么使用线程池" class="headerlink" title="为什么使用线程池"></a>为什么使用线程池</h4><p>线程池提供了一种限制和管理资源（包括执行一个任务）。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。</p><ul><li>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</li><li>提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。</li><li>提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。</li></ul><h4 id="Runnable-amp-Callable"><a href="#Runnable-amp-Callable" class="headerlink" title="Runnable&amp;Callable"></a>Runnable&amp;Callable</h4><p>Runnable 接口不会返回结果或抛出检查异常，但是Callable 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口，这样代码看起来会更加简洁。</p><h4 id="execute-amp-submit"><a href="#execute-amp-submit" class="headerlink" title="execute() &amp; submit()"></a>execute() &amp; submit()</h4><ul><li>execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；</li><li>submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</li></ul><h3 id="Atomic原子类"><a href="#Atomic原子类" class="headerlink" title="Atomic原子类"></a>Atomic原子类</h3><h4 id="AtomicInteger使用示例"><a href="#AtomicInteger使用示例" class="headerlink" title="AtomicInteger使用示例"></a>AtomicInteger使用示例</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AtomicIntegerTest</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> AtomicInteger count = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line">      <span class="comment">//使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increment</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                  count.incrementAndGet();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> count.get();</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="AtomicInteger线程安全原理"><a href="#AtomicInteger线程安全原理" class="headerlink" title="AtomicInteger线程安全原理"></a>AtomicInteger线程安全原理</h4><p>AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。</p><p>CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。</p><h3 id="AbstractQueuedSynchronizer"><a href="#AbstractQueuedSynchronizer" class="headerlink" title="AbstractQueuedSynchronizer"></a>AbstractQueuedSynchronizer</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。</p><pre><code>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。</code></pre><p>AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state;<span class="comment">//共享变量，使用volatile修饰保证线程可见性</span></span><br></pre></td></tr></table></figure><p>状态信息通过protected类型的getState，setState，compareAndSetState进行操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//返回同步状态的当前值</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getState</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">return</span> state;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 设置同步状态的值</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">setState</span><span class="params">(<span class="keyword">int</span> newState)</span> </span>&#123; </span><br><span class="line">    state = newState;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">compareAndSetState</span><span class="params">(<span class="keyword">int</span> expect, <span class="keyword">int</span> update)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> unsafe.compareAndSwapInt(<span class="keyword">this</span>, stateOffset, expect, update);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="AQS-对资源的共享方式"><a href="#AQS-对资源的共享方式" class="headerlink" title="AQS 对资源的共享方式"></a>AQS 对资源的共享方式</h4><ul><li>Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：<ul><li>公平锁：按照线程在队列中的排队顺序，先到者先拿到锁</li><li>非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的</li></ul></li><li>Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock</li></ul><p>ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。</p><p>不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。</p><h4 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h4><ul><li>使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）</li><li>将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。</li></ul><p>AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。</span><br><span class="line">tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。</span><br><span class="line">tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。</span><br><span class="line">tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。</span><br><span class="line">tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。</span><br></pre></td></tr></table></figure><p>这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。</p><h4 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h4><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247484832&amp;idx=1&amp;sn=f902febd050eac59d67fc0804d7e1ad5&source=41#wechat_redirect">并发编程面试必备：AQS 原理以及 AQS 同步组件总结</a></p><h3 id="同步辅助类"><a href="#同步辅助类" class="headerlink" title="同步辅助类"></a>同步辅助类</h3><p><img src="/2022/02/15/JAVA%E5%9F%BA%E7%A1%80/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/JAVA%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E9%80%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/%E5%B9%B6%E5%8F%91%E8%BE%85%E5%8A%A9%E7%B1%BB.png" alt="并发辅助类"></p><h4 id="CountDownLatch-–-减计数器"><a href="#CountDownLatch-–-减计数器" class="headerlink" title="CountDownLatch – 减计数器"></a>CountDownLatch – 减计数器</h4><p>允许一个或多个线程等待直到在其他线程中执行的一组操作完成的同步辅助。</p><details>    <summary>使用示例</summary>    <pre><code>public class CountDownLatchDemo &#123;    public static void main(String[] args) throws InterruptedException &#123;        //定义：允许一个或多个线程等待直到在其他线程中执行的一组操作完成的同步辅助。        //用途：1.一个CountDownLatch为一个计数的CountDownLatch用作一个简单的开/关锁存器，或者门：        //      所有线程调用await在门口等待，直到被调用countDown()的线程打开。        //     2.一个CountDownLatch初始化N可以用来做一个线程等待，直到N个线程完成某项操作，或某些动作已经完成N次        CountDownLatch countDownLatch = new CountDownLatch(20);        for (int i=1 ;i<=20;i++)&#123; new thread(()->&#123;                countDownLatch.countDown();                System.out.println(Thread.currentThread().getName()+">="+countDownLatch.getCount());            //&#125;,String.valueOf(i)).start();        &#125;        // 特性：它不要求调用countDown线程等待计数到达零之前继续，        // 它只是阻止任何线程通过await ，直到所有线程可以通过。        System.out.println("我可以在Await方法之前执行");        countDownLatch.await();        System.out.println("我为什么在最后执行呢");    &#125;&#125;</=20;i++)&#123;></code></pre></details><p>CountDownLatch的构造函数接收一个int类型的参数作为计数器，如果你想等待N个点完成，这里就传入N。<br>当我们调用CountDownLatch的countDown方法时，N就会减1，CountDownLatch的await方法会阻塞当前线程，直到N变成零。由于countDown方法可以用在任何地方，所以这里说的N个点，可以是N个线程，也可以是1个线程里的N个执行步骤。用在多个线程时，只需要把这个CountDownLatch的引用传递到线程里即可。<br>如果有某个解析sheet的线程处理得比较慢，我们不可能让主线程一直等待，所以可以使用另外一个带指定时间的await方法——await（long time，TimeUnit unit），这个方法等待特定时间后，就会不再阻塞当前线程。join也有类似的方法。</p><ul><li>计数器必须大于等于0，只是等于0时候，计数器就是零，调用await方法时不会阻塞当前线程</li><li>CountDownLatch不可能重新初始化或者修改CountDownLatch对象的内部计数器的值</li><li>一个线程调用countDown方法happen-before，另外一个线程调用await方法</li></ul><details><summary>源码</summary><pre><code>public class CountDownLatch &#123;    /**Synchronization control For CountDownLatch. Uses AQS state to represent count.*/    private static final class Sync extends AbstractQueuedSynchronizer &#123;        private static final long serialVersionUID = 4982264981922014374L;        Sync(int count) &#123;            setState(count);//初始化同步状态        &#125;        int getCount() &#123;            return getState();        &#125;        protected int tryAcquireShared(int acquires) &#123;            return (getState() == 0) ? 1 : -1;        &#125;        protected boolean tryReleaseShared(int releases) &#123;            // Decrement count; signal when transition to zero            for (;;) &#123;                int c = getState();                if (c == 0)                    return false;                int nextc = c-1;                if (compareAndSetState(c, nextc))                    return nextc == 0;            &#125;        &#125;    &#125;    private final Sync sync;//组合一个同步器（AQS）    public CountDownLatch(int count) &#123;        if (count < 0) throw new IllegalArgumentException("count < 0");        this.sync = new Sync(count);//初始化同步状态    &#125;    /*Causes the current thread to wait until the latch has counted down to     * zero, unless the thread is &#123;@linkplain Thread#interrupt interrupted&#125;.*/    public void await() throws InterruptedException &#123;        sync.acquireSharedInterruptibly(1);//    &#125;    public boolean await(long timeout, TimeUnit unit)        throws InterruptedException &#123;        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));    &#125;    public void countDown() &#123;        sync.releaseShared(1);//释放同步状态    &#125;    public long getCount() &#123;        return sync.getCount();    &#125;    public String toString() &#123;        return super.toString() + "[Count = " + sync.getCount() + "]";    &#125;&#125;</code></pre></details><h4 id="CyclicBarrier-–-加计数器"><a href="#CyclicBarrier-–-加计数器" class="headerlink" title="CyclicBarrier – 加计数器"></a>CyclicBarrier – 加计数器</h4><p>等待多个操作完成，再执行下一步</p><details>    <summary>使用示例</summary>    <pre><code>public class CyclicBarrierDemo &#123;    public static void main(String[] args) throws BrokenBarrierException, InterruptedException &#123;        //适用需等待多个操作完成，再执行下一步        CyclicBarrier cyclicBarrier = new CyclicBarrier(7,()->&#123;            System.out.println("舍利子集齐成功，如来重生");        &#125;);        for (int i=1;i<=7;i++)&#123; int finali="i;" new thread(()->&#123;                System.out.println(Thread.currentThread().getName()+"：收集了"+ finalI +"颗");                try &#123;                    //等待，舍利子集齐，一起向下执行                    cyclicBarrier.await();                    System.out.println("无天必须在如来重生之后，再死");                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125; catch (BrokenBarrierException e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;    &#125;&#125;    </=7;i++)&#123;></code></pre></details><h4 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h4><p>可循环使用（Cyclic）的屏障（Barrier）。<br>它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。</p><p>CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。</p><details><summary>使用示例</summary><pre><code>import java.util.Random; import java.util.concurrent.CyclicBarrier;import java.util.concurrent.atomic.AtomicInteger;public class CyclicBarrierTest &#123;    private static Random sr=new Random(47);     private static AtomicInteger result=new AtomicInteger(0);    private static int threadCount=10;    //屏障后面执行汇总    private static CyclicBarrier barrier=new CyclicBarrier(threadCount,new Accumulate());    private static class Parser implements Runnable&#123;         String name;        public Parser(String name)&#123;            this.name=name;        &#125;        @Override        public void run() &#123;            int sum=0;            int seed=Math.abs(sr.nextInt()) ;            Random r=new Random(47);             for(int i=0;i<(seed%100*100000);i++)&#123; sum+="r.nextInt(seed);" &#125; result.addandget(sum); system.out.println(system.currenttimemillis()+"-"+name+"线程的解析结果："+sum); try &#123; barrier.await(); system.out.println(system.currenttimemillis()+"-"+name+"线程越过屏障！"); catch (exception e) e.printstacktrace(); static class accumulate implements runnable&#123; @override public void run() system.out.println("所有线程解析结束！"); system.out.println("所有线程的解析结果："+result); main(string[] args) throws interruptedexception thread[] threads="new" thread[threadcount]; for(int i="0;i<threadCount;i++)&#123;" threads[i]="new" thread(new parser("parser-"+i)); threads[i].start(); < code></(seed%100*100000);i++)&#123;></code></pre></details><ul><li>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。</li><li>CyclicBarrier还提供其他有用的方法，比如getNumberWaiting方法可以获得Cyclic-Barrier阻塞的线程数量。isBroken()方法用来了解阻塞的线程是否被中断。</li></ul><h4 id="Semaphore并发数控制"><a href="#Semaphore并发数控制" class="headerlink" title="Semaphore并发数控制"></a>Semaphore并发数控制</h4><p>限流、多个资源的互斥使用</p><details><summary>使用示例</summary><pre><code>public class SemaphoreDemo &#123;    public static void main(String[] args) &#123;        // 限流：停车位为3，车位满之后，等待车走，再进一个。        // 多个资源的互斥使用        Semaphore semaphore = new Semaphore(3);        for (int i = 1; i <= 6; i++) &#123; new thread(() -> &#123;                try &#123;                    //先占一个位                    semaphore.acquire();                    System.out.println(Thread.currentThread().getName() + "抢到了车位");                    TimeUnit.SECONDS.sleep(2);                    System.out.println(Thread.currentThread().getName() + "离开了车位");                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125; finally &#123;                    // 释放一个位置                    semaphore.release();                &#125;            &#125;, String.valueOf(i)).start();        &#125;    &#125;&#125;</=></code></pre></details><p>Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore（10）表示允许10个线程获取许可证，也就是最大并发数是10。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证，使用完之后调用release()方法归还许可证。<br>还可以用tryAcquire()方法尝试获取许可证。</p><ul><li>int availablePermits()：返回此信号量中当前可用的许可证数。</li><li>int getQueueLength()：返回正在等待获取许可证的线程数。</li><li>boolean hasQueuedThreads()：是否有线程正在等待获取许可证。</li><li>void reducePermits（int reduction）：减少reduction个许可证，是个protected方法。</li><li>Collection getQueuedThreads()：返回所有等待获取许可证的线程集合，是个protected方法。</li></ul><h4 id="Exchanger-–-线程数据交换"><a href="#Exchanger-–-线程数据交换" class="headerlink" title="Exchanger – 线程数据交换"></a>Exchanger – 线程数据交换</h4><p>Exchanger用于进行线程间的数据交换。</p><p>它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。<br>这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。</p><ul><li>Exchanger可以用于遗传算法，遗传算法里需要选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。</li><li>Exchanger也可以用于校对工作，比如我们需要将纸制银行流水通过人工的方式录入成电子银行流水，为了避免错误，采用AB岗两人进行录入，录入到Excel之后，系统需要加载这两个Excel，并对两个Excel数据进行校对，看看是否录入一致.</li></ul><details><summary>使用示例</summary><pre><code>public class ExchangerTest &#123;    private static final Exchanger<String> exgr = new Exchanger<String>();    private static ExecutorService threadPool = Executors.newFixedThreadPool(2);    public static void main(String[] args) &#123;        threadPool.execute(new Runnable() &#123;            @Override            public void run() &#123;                try &#123;                    String A = "银行流水100";// A录入银行流水数据                    String B=exgr.exchange(A);                    System.out.println("A的视角：A和B数据是否一致：" + A.equals(B) + "，A录入的是：" + A + "，B录入是：" + B);                &#125; catch (InterruptedException e) &#123;                &#125;            &#125;        &#125;);        threadPool.execute(new Runnable() &#123;            @Override            public void run() &#123;                try &#123;                    String B = "银行流水200";// B录入银行流水数据                    String A = exgr.exchange(B);                    System.out.println("B的视角：A和B数据是否一致：" + A.equals(B) + "，A录入的是：" + A + "，B录入是：" + B);                &#125; catch (InterruptedException e) &#123;                &#125;            &#125;        &#125;);        threadPool.shutdown();    &#125;&#125;结果：B的视角：A和B数据是否一致：false，A录入的是：银行流水100，B录入是：银行流水200A的视角：A和B数据是否一致：false，A录入的是：银行流水100，B录入是：银行流水200</String></String></code></pre></details><p>如果两个线程有一个没有执行exchange()方法，则会一直等待，如果担心有特殊情况发生，避免一直等待，可以使用exchange（V x，longtimeout，TimeUnit unit）设置最大等待时长。</p>]]></content>
      
      
      <categories>
          
          <category> 并发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 并发 </tag>
            
            <tag> 锁 </tag>
            
            <tag> 线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>增量数据同步之Debezium技术研究</title>
      <link href="/2021/12/08/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%8A%80%E6%9C%AF/%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%B9%8BDebezium%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/"/>
      <url>/2021/12/08/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%8A%80%E6%9C%AF/%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%B9%8BDebezium%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="常见关系型数据库数据同步思路"><a href="#常见关系型数据库数据同步思路" class="headerlink" title="常见关系型数据库数据同步思路"></a>常见关系型数据库数据同步思路</h2><h3 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h3><h4 id="JDBC-Batch"><a href="#JDBC-Batch" class="headerlink" title="JDBC-Batch"></a>JDBC-Batch</h4><p>分页查询源端的表，然后通过 jdbc的batch 方式插入到目标表</p><p>需要注意的是，分页查询时，一定要按照主键id来排序分页，避免重复插入。</p><h4 id="数据文件导出导入"><a href="#数据文件导出导入" class="headerlink" title="数据文件导出导入"></a>数据文件导出导入</h4><p>一般只适用于同种数据库之间的同步，如果是不同的数据库，这种方式可能会存在问题。</p><h3 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h3>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据同步 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RocketMQ初探之整体设计简介</title>
      <link href="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/"/>
      <url>/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<p>说明： 文章转账自<a href="https://www.cnblogs.com/weifeng1463/p/12889300.html">RocketMQ之一：RocketMQ整体介绍</a></p><h2 id="什么是RocketMQ"><a href="#什么是RocketMQ" class="headerlink" title="什么是RocketMQ"></a>什么是RocketMQ</h2><p>RocketMQ 是阿里巴巴开源的分布式消息中间件。</p><p>支持:</p><ul><li>事务消息<ul><li>对于分布式事务来说提供了又一种解决思路。</li></ul></li><li>顺序消息：<ul><li>保证消息消费者按照消息发送的顺序对消息进行消费。</li><li>分为全局有序和局部有序</li><li>一般推荐使用局部有序，即生产者通过将某一类消息按顺序发送至同一个队列来实现</li></ul></li><li>批量消息</li><li>定时消息</li><li>消息回溯<ul><li>指消费者已经消费成功的消息，由于业务上需求需要重新消费</li><li>RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。</li></ul></li></ul><p>它里面有几个区别于标准消息中件间的概念，如</p><ul><li>Group</li><li>Topic</li><li>Queue</li></ul><p>系统组成由</p><ul><li>Producer</li><li>Consumer</li><li>Broker</li><li>NameServer</li></ul><h3 id="RocketMQ特点"><a href="#RocketMQ特点" class="headerlink" title="RocketMQ特点"></a>RocketMQ特点</h3><ul><li>一个队列模型的消息中间件，具有高性能、高可靠、高实时、分布式等特点</li><li>Producer、Consumer、队列都可以分布式</li><li>Producer 向一些队列轮流发送消息，队列集合称为 Topic<ul><li>Consumer 如果做广播消费，则一个 Consumer 实例消费这个 Topic 对应的所有队列</li><li><font color="#FF0000">如果做集群消费，则多个 Consumer 实例平均消费这个 Topic 对应的队列集合</font><ul><li>如何实现平均消费？</li></ul></li></ul></li><li>能够保证严格的消息顺序</li><li>支持 <font color="#FF0000">拉（pull）和推（push）两种消息模式</font></li><li>高效的订阅者水平扩展能力</li><li>实时的消息订阅机制</li><li>亿级消息堆积能力，堆积了这么多消息后依然保持写入低延迟</li><li>支持多种消息协议，如 JMS、OpenMessaging 等</li><li>较少的依赖</li></ul><h2 id="RocketMQ概念解读"><a href="#RocketMQ概念解读" class="headerlink" title="RocketMQ概念解读"></a>RocketMQ概念解读</h2><h3 id="RocketMQ核心概念"><a href="#RocketMQ核心概念" class="headerlink" title="RocketMQ核心概念"></a>RocketMQ核心概念</h3><p>消息队列 RocketMQ 在任何一个环境都是可扩展的，生产者必须是一个集群，消息服务器必须是一个集群，消费者也同样。</p><p>集群级别的高可用，是消息队列 RocketMQ 跟其他的消息服务器的主要区别，消息生产者发送一条消息到消息服务器，消息服务器会<font color="#FF0000">随机的选择一个消费者</font><br>，只要这个消费者消费成功就认为是成功了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：文中所提及的消息队列 RocketMQ 的服务端或者服务器包含 Name Server、Broker 等。服务端不等同于 Broker。</span><br></pre></td></tr></table></figure><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011406.png"></p><p>RocketMQ主要由 Producer、Broker、Consumer 三部分组成。</p><p>其中：</p><ul><li>Producer 负责生产消息，<ul><li>同步<ul><li>指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包</li><li>一般用于重要通知消息，例如重要通知邮件、营销短信。</li></ul></li><li>异步<ul><li>发送方发出数据后，不等接收方发回响应，接着发送下个数据包</li><li>一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。</li></ul></li><li>单向</li></ul></li><li>Consumer 负责消费消息，<ul><li>ConsumerGroup 由多个 Consumer 实例构成。</li></ul></li><li>Broker 负责存储消息。<ul><li>Broker 在实际部署过程中对应一台服务器，每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。</li><li>Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。</li></ul></li></ul><p>图中所涉及到的概念如下所述：</p><h4 id="Name-Server-名称服务充当路由消息的提供者。"><a href="#Name-Server-名称服务充当路由消息的提供者。" class="headerlink" title="Name Server: 名称服务充当路由消息的提供者。"></a>Name Server: 名称服务充当路由消息的提供者。</h4><p>一个几乎无状态节点，可集群部署，节点之间无任何信息同步。在消息队列 RocketMQ 中提供命名服务，更新和发现 Broker 服务。</p><p><strong>两个功能</strong></p><ul><li>接收broker的请求，注册broker的路由信息</li><li>接收client（producer/consumer）的请求，根据某个topic获取其到broker的路由信息</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NameServer没有状态，可以横向扩展。</span><br><span class="line"></span><br><span class="line">每个broker在启动的时候会到NameServer注册； Producer在发送消息前会根据topic到NameServer获取路由(到broker)信息； </span><br><span class="line">Consumer也会定时获取topic路由信息。</span><br><span class="line"></span><br><span class="line">无信息同步如何实现数据持久化</span><br></pre></td></tr></table></figure><h4 id="Broker：消息中转角色，负责存储消息，转发消息。"><a href="#Broker：消息中转角色，负责存储消息，转发消息。" class="headerlink" title="Broker：消息中转角色，负责存储消息，转发消息。"></a>Broker：消息中转角色，负责存储消息，转发消息。</h4><p>Broker可以理解为消息队列服务器，提供了消息的接收、存储、拉取和转发服务。 它是RocketMQ的核心，<font color="#FF0000">需要保证broker的高可用</font>。</p><ul><li>broker分为 Master Broker 和 Slave Broker，一个 Master Broker 可以对应多个 Slave Broker，但是一个 Slave Broker<br>只能对应一个 Master Broker。</li><li>Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。</li><li>每个Broker与Name Server集群中的所有节点建立长连接，定时注册Topic信息到所有Name Server。Broker 启动后需要完成一次将自己注册至 Name Server<br>的操作；随后每隔 30s 定期向 Name Server 上报 Topic 路由信息。<ul><li>如果Master挂了，需要30s才能被Name Server感知</li></ul></li></ul><h4 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h4><p>与 Name Server 集群中的其中一个节点（随机）建立长链接（Keep-alive），定期从 Name Server 读取 Topic 路由信息，并向提供 Topic 服务的 Master<br>Broker 建立长链接，且定时向 Master Broker 发送心跳。</p><h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><p>与 Name Server 集群中的其中一个节点（随机）建立长连接，定期从 Name Server 拉取 Topic 路由信息，并向提供 Topic 服务的 Master Broker、Slave<br>Broker 建立长连接，且定时向 Master Broker、Slave Broker 发送心跳。</p><p>Consumer 既可以从 Master Broker 订阅消息，也可以从 Slave Broker 订阅消息，订阅规则由 Broker 配置决定。</p><h3 id="Topic、Queue、tags"><a href="#Topic、Queue、tags" class="headerlink" title="Topic、Queue、tags"></a>Topic、Queue、tags</h3><p>RocketMQ的Topic/Queue和JMS中的Topic/Queue概念有一定的差异:</p><ul><li>JMS中所有消费者都会消费一个Topic消息的副本，而Queue中消息只会被一个消费者消费；</li><li><strong>RocketMQ中Topic只代表普通的消息队列，而Queue是组成Topic的更小单元</strong>。</li></ul><h4 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h4><p>表示消息的第一级类型，比如一个电商系统的消息可以分为：交易消息、物流消息…… 一条消息必须有一个Topic。</p><h4 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h4><p>主题被划分为一个或多个子主题，称为“message queues”。一个topic下，我们可以设置多个queue(消息队列)。</p><p>当我们发送消息时，需要要指定该消息的topic。RocketMQ会轮询该topic下的所有队列，将消息发送出去。</p><p><strong>定义： Queue是Topic在一个Broker上的分片，在分片基础上再等分为若干份（可指定份数）后的其中一份，是负载均衡过程中资源分配的基本单元。</strong></p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011721.png"></p><p>集群消费模式下一个消费者只消费该Topic中部分Queue中的消息，当一个消费者开启广播模式时则会消费该Topic下所有Queue中的消息。</p><h4 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h4><p>Tags是Topic下的次级消息类型/二级类型（注：Tags也支持TagA || TagB这样的表达式），可以在同一个Topic下基于Tags进行消息过滤。</p><p>Tags的过滤需要经过两次比对，首先会在Broker端通过Tag hashcode进行一次比对过滤，匹配成功传到consumer端后再对具体Tags进行比对，以防止Tag hashcode重复的情况。</p><p>比如交易消息又可以分为：交易创建消息，交易完成消息….. 一条消息可以没有Tag。</p><p>RocketMQ提供2级消息分类，方便大家灵活控制。标签，换句话说，为用户提供了额外的灵活性。有了标签，来自同一个业务模块的不同目的的消息可能具有相同的主题和不同的标签。标签将有助于保持您的代码干净和连贯，并且标签还可以为RocketMQ提供的查询系统提供帮助。</p><p>Queue中具体的存储单元结构如下图，最后面的8个Byte存储Tag信息。</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011726.png"></p><p>具体参考<a href="https://www.cnblogs.com/duanxz/p/5020398.html">RocketMQ消息存储</a></p><h3 id="Group"><a href="#Group" class="headerlink" title="Group"></a>Group</h3><h4 id="Producer-amp-amp-Producer-Group"><a href="#Producer-amp-amp-Producer-Group" class="headerlink" title="Producer &amp;&amp; Producer Group"></a>Producer &amp;&amp; Producer Group</h4><p>Producer表示消息队列的生产者。消息队列的本质就是实现了pub/sub模式，生产者生产消息，消费者消费消息。</p><ul><li>所以这里的Producer就是用来生产和发送消息的，一般指业务系统。</li><li>RocketMQ提供了发送：普通消息（同步、异步和单向（one-way）消息）、定时消息、延时消息、事务消息。</li></ul><p>Producer Group是一类Producer的集合名称，这类Producer通常发送一类消息，且发送逻辑一致。相同角色的生产者被分组在一起。</p><ul><li>同一生产者组的另一个生产者实例可能被broker联系，以提交或回滚事务，以防原始生产者在交易后崩溃。</li></ul><p><font color="#FF0000">警告： 考虑提供的生产者在发送消息时足够强大，每个生产者组只允许一个实例，以避免对生产者实例进行不必要的初始化。</font></p><h4 id="Consumer-amp-amp-Consumer-Group"><a href="#Consumer-amp-amp-Consumer-Group" class="headerlink" title="Consumer &amp;&amp; Consumer Group"></a>Consumer &amp;&amp; Consumer Group</h4><p>Consumer: 消息消费者，一般由业务后台系统异步的消费消息。</p><ul><li>Push Consumer： Consumer 的一种，应用通常向 Consumer 对象注册一个 Listener 接口，一旦收到消息，Consumer 对象立刻回调 Listener<br>接口方法。</li><li>Pull Consumer： Consumer 的一种，应用通常主动调用 Consumer 的拉消息方法从 Broker 拉消息，主动权由应用控制。</li></ul><p>Consumer Group： Consumer Group是一类Consumer的集合名称，这类Consumer通常消费一类消息，且消费逻辑一致(使用相同 Group ID<br>的订阅者属于同一个集群。同一个集群下的订阅者消费逻辑必须完全一致（包括 Tag 的使用），这些订阅者在逻辑上可以认为是一个消费节点)。</p><ul><li>消费者群体是一个伟大的概念，它实现了负载平衡和容错的目标，在信息消费方面，是非常容易的。</li></ul><p><font color="#FF0000">警告： 消费者群体的消费者实例<strong>必须</strong>订阅完全相同的主题。</font></p><h2 id="RocketMQ组件关系"><a href="#RocketMQ组件关系" class="headerlink" title="RocketMQ组件关系"></a>RocketMQ组件关系</h2><h3 id="Broker-amp-amp-Producer-amp-amp-Consumer"><a href="#Broker-amp-amp-Producer-amp-amp-Consumer" class="headerlink" title="Broker &amp;&amp; Producer &amp;&amp; Consumer"></a>Broker &amp;&amp; Producer &amp;&amp; Consumer</h3><p>如果不考虑负载均衡和高可用，最简单的Broker，Producer和Consumer之间的关系如下图所示：</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011748.png"></p><h3 id="Topic-amp-amp-Topic分片-amp-amp-Queue"><a href="#Topic-amp-amp-Topic分片-amp-amp-Queue" class="headerlink" title="Topic &amp;&amp; Topic分片 &amp;&amp; Queue"></a>Topic &amp;&amp; Topic分片 &amp;&amp; Queue</h3><p>从本质上来说，RocketMQ中的Queue是数据分片的产物。 为了更好地理解Queue的定义，我们还需要引入一个新的概念：Topic分片。</p><p>在分布式数据库和分布式缓存领域，分片概念已经有了清晰的定义。</p><p>同理，对于RocketMQ，一个Topic可以分布在各个Broker上，我们可以把一个Topic分布在一个Broker上的子集定义为一个Topic分片。</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011757.png"></p><p>对应上图，TopicA有3个Topic分片，分布在Broker1,Broker2和Broker3上，TopicB有2个Topic分片，分布在Broker1和Broker2上，TopicC有2个Topic分片，分布在Broker2和Broker3上。</p><p><strong>将Topic分片再切分为若干等分，其中的一份就是一个Queue</strong></p><p>每个Topic分片等分的Queue的数量可以不同，由用户在创建Topic时指定。</p><p>数据分片的主要目的是突破单点的资源（网络带宽，CPU，内存或文件存储）限制从而实现水平扩展。 RocketMQ<br>在进行Topic分片以后，已经达到水平扩展的目的了，为什么还需要进一步切分为Queue呢？</p><p>解答这个问题还需要从<strong>负载均衡</strong>说起。以消息消费为例，借用Rocket MQ官方文档中的Consumer负载均衡示意图来说明：</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021307.png"></p><p>如图所示，TOPIC_A在一个Broker上的Topic分片有5个Queue，一个Consumer<br>Group内有2个Consumer按照集群消费的方式消费消息，按照平均分配策略进行负载均衡得到的结果是：第一个 Consumer 消费3个Queue，第二个Consumer<br>消费2个Queue。如果增加Consumer，每个Consumer分配到的Queue会相应减少。</p><p>Rocket MQ的负载均衡策略规定：Consumer数量应该小于等于Queue数量，如果Consumer超过Queue数量，那么多余的Consumer 将不能消费消息。</p><p>在一个Consumer<br>Group内，Queue和Consumer之间的对应关系是一对多的关系：一个Queue最多只能分配给一个Consumer，一个Cosumer可以分配得到多个Queue。这样的分配规则，每个Queue只有一个消费者，可以避免消费过程中的多线程处理和资源锁定，有效提高各Consumer消费的并行度和处理效率。</p><p>由此，我们可以给出Queue的定义：</p><p>Queue是Topic在一个Broker上的分片等分为指定份数后的其中一份，是负载均衡过程中资源分配的基本单元。</p><h4 id="Queue数量指定方式"><a href="#Queue数量指定方式" class="headerlink" title="Queue数量指定方式"></a>Queue数量指定方式</h4><ul><li><p>代码指定</p><ul><li>producer.setDefaultTopicQueueNums(8);</li></ul></li><li><p>配置文件指定</p><ul><li>同时设置broker服务器的配置文件broker.properties：defaultTopicQueueNums=16</li></ul></li><li><p>rocket-console控制台指定</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112011801.png"></p></li></ul><h2 id="RocketMQ发布订阅大体流程"><a href="#RocketMQ发布订阅大体流程" class="headerlink" title="RocketMQ发布订阅大体流程"></a>RocketMQ发布订阅大体流程</h2><ol><li><p>producer生产者连接nameserver，产生数据放入不同的topic；</p></li><li><p>对于RocketMQ，一个Topic可以分布在各个Broker上，我们可以把一个Topic分布在一个Broker上的子集定义为一个Topic分片；</p></li><li><p>将Topic分片再切分为若干等分，其中的一份就是一个Queue。每个Topic分片等分的Queue的数量可以不同，由用户在创建Topic时指定。</p></li><li><p>consumer消费者连接nameserver，根据broker分配的Queue来消费数据。</p></li></ol><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021312.png"></p><h2 id="消息分类"><a href="#消息分类" class="headerlink" title="消息分类"></a>消息分类</h2><h3 id="发送类型分类"><a href="#发送类型分类" class="headerlink" title="发送类型分类"></a>发送类型分类</h3><h4 id="同步消息"><a href="#同步消息" class="headerlink" title="同步消息"></a>同步消息</h4><p>指消息发送方发出数据后，<strong>会阻塞直到MQ服务方发回响应消息</strong>。</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021324.png"></p><p>应用场景：此种方式应用场景非常广泛，例如重要通知邮件、报名短信通知、营销短信系统等。</p><p>关键代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SendResult sendResult = producer.send(msg);</span><br></pre></td></tr></table></figure><h4 id="异步消息"><a href="#异步消息" class="headerlink" title="异步消息"></a>异步消息</h4><p>发送方发出数据后，不等接收方发回响应，接着发送下个数据包的通讯方式。</p><p><strong>MQ<br>的异步发送，需要用户实现异步发送回调接口（SendCallback），在执行消息的异步发送时，应用不需要等待服务器响应即可直接返回，通过回调接口接收服务器响应，并对服务器的响应结果进行处理。</strong></p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021327.png" class><p>应用场景：异步发送一般用于链路耗时较长，对 RT 响应时间较为敏感的业务场景，例如用户视频上传后通知启动转码服务，转码完成后通知推送转码结果等。</p><p>关键代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">producer.sendAsync(msg, new SendCallback() &#123;//...&#125;);</span><br></pre></td></tr></table></figure><h4 id="单向消息"><a href="#单向消息" class="headerlink" title="单向消息"></a>单向消息</h4><p>只负责发送消息，不等待服务器回应且没有回调函数触发，即只发送请求不等待应答。</p><p><strong>此方式发送消息的过程耗时非常短，一般在微秒级别。但是可能存在数据丢失</strong></p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112021330.png"></p><p>应用场景：适用于某些耗时非常短，但对可靠性要求并不高的场景，例如日志收集。</p><p>关键代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">producer.sendOneway(msg);</span><br></pre></td></tr></table></figure><h3 id="按照功能使用划分"><a href="#按照功能使用划分" class="headerlink" title="按照功能使用划分"></a>按照功能使用划分</h3><h4 id="普通消息-amp-amp-顺序消息"><a href="#普通消息-amp-amp-顺序消息" class="headerlink" title="普通消息 &amp;&amp; 顺序消息"></a>普通消息 &amp;&amp; 顺序消息</h4><h4 id="广播消息"><a href="#广播消息" class="headerlink" title="广播消息"></a>广播消息</h4><h4 id="延时消息"><a href="#延时消息" class="headerlink" title="延时消息"></a>延时消息</h4><h5 id="定时消息"><a href="#定时消息" class="headerlink" title="定时消息"></a>定时消息</h5><p>定时消息，单位毫秒（ms），在指定时间戳（当前时间之后）进行投递</p><p>核心代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 例如 2016-03-07 16:21:00 投递。</span><br><span class="line">// 如果被设置成当前时间戳之前的某个时刻，消息将立刻投递给消费者。    </span><br><span class="line">long timeStamp = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).parse(&quot;2016-03-07 16:21:00&quot;).getTime();    </span><br><span class="line">msg.setStartDeliverTime(timeStamp);​    </span><br><span class="line">// 发送消息，只要不抛异常就是成功    </span><br><span class="line">SendResult sendResult = producer.send(msg);   </span><br></pre></td></tr></table></figure><h5 id="延时消息-1"><a href="#延时消息-1" class="headerlink" title="延时消息"></a>延时消息</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Message sendMsg = new Message(topic, tags, message.getBytes());</span><br><span class="line">sendMsg.setDelayTimeLevel(delayLevel);</span><br><span class="line">// 默认3秒超时</span><br><span class="line">SendResult sendResult = rocketMQProducer.send(sendMsg);</span><br></pre></td></tr></table></figure><h4 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h4><p>RocketMQ提供类似X/Open XA的分布式事务功能来确保业务发送方和MQ消息的最终一致性。</p><p><strong>其本质是通过半消息(prepare消息和commit消息)的方式把分布式事务放在MQ端来处理</strong>。</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031329.png"></p><p>其中：</p><ol><li>发送方向消息队列 RocketMQ 服务端发送消息。</li><li>服务端将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功，此时消息为半消息。</li><li>发送方开始执行本地事务逻辑。</li><li>发送方根据本地事务执行结果向服务端提交二次确认（Commit 或是 Rollback），服务端收到 Commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；服务端收到 Rollback<br>状态则删除半消息，订阅方将不会接受该消息。</li></ol><p>补偿流程：</p><ol start="5"><li>在断网或者是应用重启的特殊情况下，上述步骤 4 提交的二次确认最终未到达服务端，经过固定时间后服务端将对该消息发起消息回查。</li><li>发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li><li>发送方根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤 4 对半消息进行操作。</li></ol><p><strong><font color="#FF0000">RocketMQ的半消息机制的注意事项是</font></strong></p><ol><li>根据第六步可以看出他要求发送方提供业务回查接口。</li><li>不能保证发送方的消息幂等，在ack没有返回的情况下，可能存在重复消息</li><li>消费方要做幂等处理。</li></ol><h2 id="发布订阅模型"><a href="#发布订阅模型" class="headerlink" title="发布订阅模型"></a>发布订阅模型</h2><p>在RocketMQ中，producer发布消息，consumer订阅消息。消息的收发模型如下图：</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031342.png"></p><h3 id="producer端消息发布原理"><a href="#producer端消息发布原理" class="headerlink" title="producer端消息发布原理"></a>producer端消息发布原理</h3><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031345.png"></p><p>producer完全无状态，可以集群部署。</p><h3 id="consumer端消息获取模式（push-pull）"><a href="#consumer端消息获取模式（push-pull）" class="headerlink" title="consumer端消息获取模式（push/pull）"></a>consumer端消息获取模式（push/pull）</h3><p>consumer有两种消息的获取模式</p><ul><li>Push模式，即MQServer主动向消费端推送；</li><li>Pull模式，即消费端在需要时，主动到MQServer拉取。</li></ul><p>实际实现中： <strong>Push和Pull模式都是采用消费端主动拉取的方式</strong>。</p><p>消费端的Push模式是通过长轮询的模式来实现的：</p><ul><li>Consumer端每隔一段时间主动向broker发送拉消息请求，broker在收到Pull请求后<ul><li>如果有消息就立即返回数据，Consumer端收到返回的消息后，再回调消费者设置的Listener方法。</li><li>消息队列里没有数据，broker端会阻塞请求直到有数据传递或超时才返回。</li></ul></li><li>当然，Consumer端是通过一个线程将阻塞队列LinkedBlockingQueue<PullRequest>中的PullRequest发送到broker拉取消息，以防止Consumer一致被阻塞。</PullRequest></li><li>而Broker端，在接收到Consumer的PullRequest时，如果发现没有消息，就会把PullRequest扔到ConcurrentHashMap中缓存起来。</li><li>broker在启动时，会启动一个线程不停的从ConcurrentHashMap取出PullRequest检查，直到有数据返回。</li></ul><h3 id="consumer端消息消费模式-集群-广播"><a href="#consumer端消息消费模式-集群-广播" class="headerlink" title="consumer端消息消费模式(集群/广播)"></a>consumer端消息消费模式(集群/广播)</h3><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>消息队列 RocketMQ 是基于发布/订阅模型的消息系统。消息的订阅方订阅关注的 Topic，以获取并消费消息。</p><p>由于订阅方应用一般是分布式系统，以集群方式部署有多台机器。</p><h4 id="集群消费"><a href="#集群消费" class="headerlink" title="集群消费"></a>集群消费</h4><p>使用相同 Group ID 的订阅者属于同一个集群。同一个集群下的订阅者消费逻辑必须完全一致（包括 Tag 的使用），这些订阅者在逻辑上可以认为是一个消费节点。</p><p>当使用集群消费模式时，消息队列 RocketMQ 认为任意一条消息只需要被集群内的任意一个消费者处理即可。</p><p>一个Consumer Group中的Consumer实例平均分摊消费消息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">例如某个Topic有 9 条消息，其中一个Consumer Group有 3 个实例(可能是 3 个进程,或者 3 台机器)，那么每个实例只消费其中的 3 条消息。</span><br></pre></td></tr></table></figure><h5 id="使用场景-amp-amp-注意事项"><a href="#使用场景-amp-amp-注意事项" class="headerlink" title="使用场景 &amp;&amp; 注意事项"></a>使用场景 &amp;&amp; 注意事项</h5><ul><li>消费端集群化部署，每条消息只需要被处理一次。</li><li>由于消费进度在服务端维护，可靠性更高。</li><li>集群消费模式下，<strong>每一条消息都只会被分发到一台机器上处理</strong>。如果需要被集群下的每一台机器都处理，请使用广播模式。</li><li>集群消费模式下，<strong>不保证每一次失败重投的消息路由到同一台机器上</strong>，因此处理消息时不应该做任何确定性假设。</li></ul><h4 id="广播消费"><a href="#广播消费" class="headerlink" title="广播消费"></a>广播消费</h4><p>当使用广播消费模式时，消息队列 RocketMQ 会将每条消息推送给集群内所有注册过的客户端，保证消息至少被每台机器消费一次。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一条消息被多个Consumer消费，即使这些Consumer属于同一个Consumer Group，消息也会被Consumer Group中的每个Consumer都消费一次。</span><br></pre></td></tr></table></figure><p><strong>在广播消费中的Consumer Group概念可以认为在消息划分方面无意义</strong>。</p><h5 id="使用场景-amp-amp-注意事项-1"><a href="#使用场景-amp-amp-注意事项-1" class="headerlink" title="使用场景 &amp;&amp; 注意事项"></a>使用场景 &amp;&amp; 注意事项</h5><ul><li>广播消费模式下<strong>不支持顺序消息</strong>。</li><li>广播消费模式下<strong>不支持重置消费位点</strong>。</li><li>每条消息都需要被相同逻辑的多台机器处理。</li><li>消费进度在客户端维护，出现重复的概率稍大于集群模式。</li><li>广播模式下，消息队列 RocketMQ 保证每条消息至少被每台客户端消费一次，但是并<strong>不会对消费失败的消息进行失败重投</strong>，因此业务方需要关注消费失败的情况。</li><li>广播模式下，客户端每一次重启都会从最新消息消费。<strong>客户端在被停止期间发送至服务端的消息将会被自动跳过</strong>，请谨慎选择。</li><li>广播模式下，每条消息都会被大量的客户端重复处理，因此推荐尽可能使用集群模式。</li><li>目前仅 Java 客户端支持广播模式。</li><li>广播模式下服务端不维护消费进度，所以消息队列 RocketMQ 控制台<strong>不支持消息堆积查询、消息堆积报警和订阅关系查询功能</strong>。</li></ul><h4 id="使用集群模式模拟广播"><a href="#使用集群模式模拟广播" class="headerlink" title="使用集群模式模拟广播"></a>使用集群模式模拟广播</h4><p>如果业务需要使用广播模式，也可以创建多个 Group ID，用于订阅同一个 Topic。</p><h5 id="适用场景-amp-amp-注意事项"><a href="#适用场景-amp-amp-注意事项" class="headerlink" title="适用场景 &amp;&amp; 注意事项"></a>适用场景 &amp;&amp; 注意事项</h5><ul><li>每条消息都需要被多台机器处理，每台机器的逻辑可以相同也可以不一样。</li><li>消费进度在服务端维护，可靠性高于广播模式。</li><li>对于一个 Group ID 来说，可以部署一个消费端实例，也可以部署多个消费端实例。 <ul><li>当部署多个消费端实例时，实例之间又组成了集群模式（共同分担消费消息）。</li><li>假设 Group ID 1 部署了三个消费者实例 C1、C2、C3，那么这三个实例将共同分担服务器发送给 Group ID 1 的消息。 </li><li>实例之间订阅关系必须保持一致。</li></ul></li></ul><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><h3 id="生产端负载均衡"><a href="#生产端负载均衡" class="headerlink" title="生产端负载均衡"></a>生产端负载均衡</h3><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031427.png"></p><p>首先分析一下RocketMQ的客户端发送消息的源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DefaultMQProducer defaultMQProducer = new DefaultMQProducer(&quot;ProducerGroupName&quot;);</span><br><span class="line">// 初始化Producer， 整个生命周期只需要一次</span><br><span class="line">producer.start();</span><br><span class="line">// 构造Message</span><br><span class="line">Message msg = new Message(&quot;Topic&quot;, &quot;TagA&quot;, &quot;key&quot;, &quot;aaaaaaaa&quot;.getBytes());</span><br><span class="line">// 发送消息并返回结果</span><br><span class="line">SendResult sendResult = producer.send(msg);</span><br><span class="line">// 清理资源、关闭网络、注销自己</span><br><span class="line">producer.shutdown();</span><br></pre></td></tr></table></figure><p>在整个应用生命周期内，生产者需要调用一次start方法来初始化，初始化主要完成的任务有：</p><ul><li>如果没有指定namesrv地址，将会自动寻址</li><li>启动定时任务<ul><li>更新namesrv地址</li><li>从namsrv更新topic路由信息</li><li>清理已经挂掉的broker</li><li>向所有broker发送心跳…</li></ul></li><li>启动负载均衡的服务</li></ul><p>初始化完成后，开始发送消息，发送消息的主要代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">privete SendResult sendDefaultImpl(Message msg, .....) &#123;</span><br><span class="line">  // 检查Producer状态是否Running</span><br><span class="line">  this.makesureStateOK();</span><br><span class="line">  // 检查msg是否合法，是否为null, topic、body是否为空，body是否超长</span><br><span class="line">  Validators.checkMessage(msg, this.defaultMQProducer);</span><br><span class="line">  // 获取路由信息</span><br><span class="line">  TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic());</span><br><span class="line">  // 从路由中悬着一个消息队列</span><br><span class="line">  MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, info);</span><br><span class="line">  // </span><br><span class="line">  sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码中需要关注的两个方法tryToFindTopicPublishInfo和selectOneMessageQueue。</p><ul><li>前面说过在producer初始化时，会启动定时任务获取路由信息并更新到本地缓存，所以tryToFindTopicPublishInfo会首先从缓存中获取topic路由信息，如果没有获取到，则会自己去namesrv获取路由信息。</li><li>selectOneMessageQueue方法通过轮询的方式，返回一个队列，以达到负载均衡的目的。</li></ul><p>如果Producer发送消息失败，会自动重试，重试的策略：</p><ul><li>重试次数 &lt; retryTimesWhenSendFailed（可配置）</li><li>总的耗时（包含重试n次的耗时） &lt; sendMsgTimeout（发送消息时传入的参数）</li><li>同时满足上面两个条件后，Producer会选择另外一个队列发送消息</li></ul><h3 id="消费端负载均衡"><a href="#消费端负载均衡" class="headerlink" title="消费端负载均衡"></a>消费端负载均衡</h3><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031500.png"></p><p>producer向一些队列轮流发送消息，队列集合称为Topic：</p><ul><li>Consumer如果做广播消费，则一个consumer实例消费这个Topic对应的所有队列；</li><li>如果做集群消费，则多个Consumer实例平均消费这个Topic对应的队列集合</li></ul><p>集群模式里，每个consumer消费部分消息，这里的负载均衡是怎样的呢:</p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/RocketMQ/RocketMQ%E5%88%9D%E6%8E%A2%E4%B9%8B%E6%95%B4%E4%BD%93%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B/202112031503.png"></p><p>消费端会通过RebalanceService线程，20秒钟做一次基于topic下的所有队列负载：</p><ul><li>遍历Consumer下的所有topic，然后根据topic订阅所有的消息</li><li>获取同一topic和Consumer Group下的所有Consumer</li><li>然后根据具体的分配策略来分配消费队列，分配的策略包含：平均分配、消费端配置等</li></ul><p>如同上图所示：如果有 3 个队列，2 个 consumer，那么第一个 Consumer 消费 2 个队列，第二 consumer 消费 1 个队列。这里采用的就是平均分配策略，它类似于我们的分页，TOPIC下面的所有queue就是记录，Consumer的个数就相当于总的页数，那么每页有多少条记录，就类似于某个Consumer会消费哪些队列。</p><p>通过这样的策略来达到大体上的平均消费，这样的设计也可以很方面的水平扩展Consumer来提高消费能力。</p><h2 id="部署架构"><a href="#部署架构" class="headerlink" title="部署架构"></a>部署架构</h2><ul><li>单Master模式：无需多言，一旦单个broker重启或宕机，一切都结束了！。</li><li>多Master模式：全是Master，没有Slave。<ul><li>当然，一个broker宕机了，应用是无影响的</li><li>缺点在于宕机的Master上未被消费的消息在Master没有恢复之前不可以订阅。</li></ul></li><li>多Master多Slave模式（异步复制）：多对Master-Slave，高可用！<ul><li>采用异步复制的方式，主备之间短暂延迟，MS级别。</li><li>Master宕机，消费者可以从Slave上进行消费，不受影响。</li><li>但是Master的宕机，会导致丢失掉极少量的消息。</li></ul></li><li>多Master多Slave模式（同步双写）：在Master/Slave都写成功的前提下，向应用返回成功<ul><li>不论是数据，还是服务都没有单点，都非常可靠！</li><li>缺点在于同步的性能比异步稍低。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> RocketMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MQ详解及四大常用MQ对比</title>
      <link href="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/"/>
      <url>/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/</url>
      
        <content type="html"><![CDATA[<h2 id="消息队列概述"><a href="#消息队列概述" class="headerlink" title="消息队列概述"></a>消息队列概述</h2><h3 id="消息队列使用场景及其优缺点"><a href="#消息队列使用场景及其优缺点" class="headerlink" title="消息队列使用场景及其优缺点"></a>消息队列使用场景及其优缺点</h3><ul><li><p>消息队列使用场景</p><ul><li>异步通信<ul><li>紧急重要（需要立刻响应）的业务放到该调用方法中，响应要求不高的使用消息队列，放到MQ队列中，供消费者处理。</li><li>提高系统响应时长</li></ul></li><li>削峰<ul><li>过载保护和缓冲</li></ul></li><li>解耦<ul><li>降低工程间的强依赖程度，针对异构系统进行适配。</li></ul></li><li>冗余<ul><li>消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。</li><li>许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</li></ul></li><li>保证执行顺序</li><li>数据流处理<ul><li>ELK</li></ul></li></ul></li><li><p>消息队列优点</p><ul><li>低耦合</li><li>可靠投递</li><li>广播</li><li>流量控制</li><li>最终一致性</li><li>实时处理框架支撑等</li></ul></li><li><p>消息队列的问题</p><ul><li>系统可用性降低<ul><li>如何保证消息队列可用性？</li></ul></li><li>系统复杂度提高<ul><li>消息队列语义</li><li>如何保证没有重复消费</li><li>如何保证没有消息丢失</li><li>如何保证消息顺序</li></ul></li><li>一致性问题<ul><li>部分消费成功部分消费失败？</li></ul></li></ul></li></ul><h3 id="消息中间件组成"><a href="#消息中间件组成" class="headerlink" title="消息中间件组成"></a>消息中间件组成</h3><h4 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h4><p>消息服务器，作为server提供消息核心服务</p><h4 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h4><p>消息生产者，业务的发起方，负责生产消息传输给broker，</p><h4 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h4><p>主题，发布订阅模式下的消息统一汇集地，不同生产者向topic发送消息，由MQ服务器分发到不同的订阅者，实现消息的<strong>广播</strong></p><h4 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h4><p>队列，PTP模式下，特定生产者向特定queue发送消息，消费者订阅特定的queue完成指定消息的接收</p><h4 id="Topic-VS-Queue"><a href="#Topic-VS-Queue" class="headerlink" title="Topic VS Queue"></a>Topic VS Queue</h4><ul><li><p><strong>Queue</strong>: 实现了负载均衡，将producer生产的消息发送到消息队列中，由多个消费者消费。但一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有一个可用的消费者。</p></li><li><p><strong>Topic</strong>: 实现了发布和订阅，当你发布一个消息，所有订阅这个topic的服务都能得到这个消息，所以从1到N个订阅者都能得到一个消息的拷贝。</p></li></ul><h4 id="Message"><a href="#Message" class="headerlink" title="Message"></a>Message</h4><p>消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传输</p><h3 id="消息中间件模式"><a href="#消息中间件模式" class="headerlink" title="消息中间件模式"></a>消息中间件模式</h3><h4 id="点对点（PTP）"><a href="#点对点（PTP）" class="headerlink" title="点对点（PTP）"></a>点对点（PTP）</h4><p>PTP点对点： <strong>使用Queue作为通信载体</strong></p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/202112011037.png"></p><p>说明：</p><ul><li>消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。</li><li>消息被消费以后，queue中不再存储，所以消息消费者不可能消费到已经被消费的消息。 Queue支持存在多个消费者，<strong>但是对一个消息而言，只会有一个消费者可以消费</strong>。</li></ul><h4 id="发布-订阅-PUB-SUB"><a href="#发布-订阅-PUB-SUB" class="headerlink" title="发布/订阅(PUB/SUB)"></a>发布/订阅(PUB/SUB)</h4><p>Pub/Sub发布订阅（广播）：<strong>使用topic作为通信载体</strong></p><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/202112011041.png"></p><p>说明：</p><ul><li>消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，<strong>发布到topic的消息会被所有订阅者消费</strong>。</li></ul><h3 id="消息中间件常用协议"><a href="#消息中间件常用协议" class="headerlink" title="消息中间件常用协议"></a>消息中间件常用协议</h3><h4 id="AMQP-Advanced-Message-Queuing-Protocol-协议"><a href="#AMQP-Advanced-Message-Queuing-Protocol-协议" class="headerlink" title="AMQP(Advanced Message Queuing Protocol)协议"></a>AMQP(Advanced Message Queuing Protocol)协议</h4><p>一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。</p><p>基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。</p><p>优点：可靠、通用</p><h4 id="MQTT（Message-Queuing-Telemetry-Transport，消息队列遥测传输）协议"><a href="#MQTT（Message-Queuing-Telemetry-Transport，消息队列遥测传输）协议" class="headerlink" title="MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）协议"></a>MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）协议</h4><p>IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。</p><p>该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和致动器（比如通过Twitter让房屋联网）的通信协议。 </p><p>优点：格式简洁、占用带宽小、移动端通信、PUSH、嵌入式系统</p><h4 id="STOMP（Streaming-Text-Orientated-Message-Protocol，流文本定向消息协议）协议"><a href="#STOMP（Streaming-Text-Orientated-Message-Protocol，流文本定向消息协议）协议" class="headerlink" title="STOMP（Streaming Text Orientated Message Protocol，流文本定向消息协议）协议"></a>STOMP（Streaming Text Orientated Message Protocol，流文本定向消息协议）协议</h4><p>是一种为MOM(Message Oriented Middleware，面向消息的中间件)设计的简单文本协议。</p><p>STOMP提供一个可互操作的连接格式，允许客户端与任意STOMP消息代理（Broker）进行交互。</p><p>优点：命令模式（非topic\queue模式）</p><h4 id="XMPP（Extensible-Messaging-and-Presence-Protocol，可扩展消息处理现场协议）协议"><a href="#XMPP（Extensible-Messaging-and-Presence-Protocol，可扩展消息处理现场协议）协议" class="headerlink" title="XMPP（Extensible Messaging and Presence Protocol，可扩展消息处理现场协议）协议"></a>XMPP（Extensible Messaging and Presence Protocol，可扩展消息处理现场协议）协议</h4><p>基于可扩展标记语言（XML）的协议，多用于即时消息（IM）以及在线现场探测。</p><p>适用于服务器之间的准即时操作。</p><p>核心是基于XML流传输，这个协议可能最终允许因特网用户向因特网上的其他任何人发送即时消息，即使其操作系统和浏览器不同。</p><p>优点：通用公开、兼容性强、可扩展、安全性高，但XML编码格式占用带宽大</p><h4 id="其他基于TCP-IP自定义的协议"><a href="#其他基于TCP-IP自定义的协议" class="headerlink" title="其他基于TCP/IP自定义的协议"></a>其他基于TCP/IP自定义的协议</h4><p>有些特殊框架（如：redis、kafka、zeroMq等）根据自身需要未严格遵循MQ规范，而是基于TCP\IP自行封装了一套协议，通过网络socket接口进行传输，实现了MQ的功能。</p><h3 id="常用消息中间件MQ总结"><a href="#常用消息中间件MQ总结" class="headerlink" title="常用消息中间件MQ总结"></a>常用消息中间件MQ总结</h3><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><p>Apache下的一个子项目，使用scala实现的一个高性能分布式Pub/Sub消息队列系统，具有以下特性：</p><ul><li>快速持久化：通过磁盘顺序读写与零拷贝机制，可以在O(1)的系统开销下进行消息持久化；</li><li>高吞吐：在一台普通的服务器上既可以达到10W/s的吞吐速率；</li><li>高堆积：支持topic下消费者较长时间离线，消息堆积量大；</li><li>完全的分布式系统：Broker、Producer、Consumer都原生自动支持分布式，依赖zookeeper（已移除）自动实现复杂均衡；</li><li>支持Hadoop数据并行加载：对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。</li></ul><h4 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h4><p>阿里参照kafka设计思想使用java实现的一套mq。同时将阿里系内部多款mq产品（Notify、metaq）进行整合，只维护核心功能，去除了所有其他运行时依赖，保证核心功能最简化，在此基础上配合阿里上述其他开源产品实现不同场景下mq的架构，目前主要多用于订单交易系统。</p><p>具有以下特点：</p><ul><li>能够保证严格的消息顺序</li><li>提供针对消息的过滤功能</li><li>提供丰富的消息拉取模式</li><li>高效的订阅者水平扩展能力</li><li>实时的消息订阅机制</li><li>亿级消息堆积能力</li></ul><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP,STOMP，也正是如此，使的它变的非常重量级，更适合于企业级的开发。</p><p>同时实现了Broker架构，核心思想是生产者不会将消息直接发送给队列，消息在发送给客户端时先在中心队列排队。</p><p>对路由(Routing)，负载均衡(Load balance)、数据持久化都有很好的支持。</p><p>多用于进行企业级的ESB整合。</p><h4 id="ZeroMQ"><a href="#ZeroMQ" class="headerlink" title="ZeroMQ"></a>ZeroMQ</h4><p>号称最快的消息队列系统，专门为高吞吐量/低延迟的场景开发，在金融界的应用中经常使用，偏重于实时数据通信场景。</p><p>ZMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，开发成本高。</p><p>因此ZeroMQ具有一个独特的非中间件的模式，更像一个socket library，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序本身就是使用ZeroMQ API完成逻辑服务的角色。</p><p>但是ZeroMQ仅提供<strong>非持久性的队列</strong>，如果down机，数据将会丢失。如：Twitter的Storm中使用ZeroMQ作为数据流的传输。</p><p>ZeroMQ套接字是与传输层无关的：ZeroMQ套接字对所有传输层协议定义了统一的API接口。默认支持 进程内(inproc) ，进程间(IPC) ，多播，TCP协议，在不同的协议之间切换只要简单的改变连接字符串的前缀。可以在任何时候以最小的代价从进程间的本地通信切换到分布式下的TCP通信。ZeroMQ在背后处理连接建立，断开和重连逻辑。</p><p>特性：</p><ul><li>无锁的队列模型：对于跨线程间的交互（用户端和session）之间的数据交换通道pipe，采用无锁的队列算法CAS；在pipe的两端注册有异步事件，在读或者写消息到pipe的时，会自动触发读写事件。</li><li>批量处理的算法：对于批量的消息，进行了适应性的优化，可以批量的接收和发送消息。</li><li>多核下的线程绑定，无须CPU切换：区别于传统的多线程并发模式，信号量或者临界区，zeroMQ充分利用多核的优势，每个核绑定运行一个工作者线程，避免多线程之间的CPU切换开销。</li></ul><h4 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h4><p>本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。</p><p>实验表明：</p><ul><li>入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；</li><li>出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。</li></ul><h3 id="主要消息中间件的比较"><a href="#主要消息中间件的比较" class="headerlink" title="主要消息中间件的比较"></a>主要消息中间件的比较</h3><p><img src="/2021/12/01/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/MQ%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%9B%9B%E5%A4%A7%E5%B8%B8%E7%94%A8MQ%E5%AF%B9%E6%AF%94/202112011141.png"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>详解HTTP2.0及HTTPS协议</title>
      <link href="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/"/>
      <url>/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<p>说明： 转自<a href="https://juejin.cn/post/7034668672262242318">详解 HTTP2.0 及 HTTPS 协议</a></p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>本文基于运维视角在阐述解析HTTP2.0协议相比较HTTP1.1的优点的同时讲述HTTPS协议的原理，并结合实际业务场景作为案例，目的是可以通过本文掌握HTTP2.0及HTTPS协议，了解原理，具备定位排查问题，调优的能力。</p><h2 id="HTTP1-1-VS-HTTP2"><a href="#HTTP1-1-VS-HTTP2" class="headerlink" title="HTTP1.1 VS HTTP2"></a>HTTP1.1 VS HTTP2</h2><p>严格意义上HTTP2.0和HTTPS并没有什么必然的联系，只是搭配使用更香一些，HTTP2 是1999年HTTP1.1之后的第一次更新。</p><p>HTTP2具有更好的效率和资源利用率，尤其适用于页面比较重，有大量资源加载的场景（公司的业务属于典型的场景），根据网络上的测试数据，在大量图片、资源需要加载的场景下，HTTP2解决HTTP1.1的线头阻塞（一次请求交互必须等待前一次请求交互的完成）问题相比HTTP1.1可以达到5倍以上的速度提升，目前，淘宝，天猫，京东等平台都已启用HTTP2，如果是<strong>页面存在大量惊天资源需要加载</strong>的情况，启用HTTP2.0，绝对物超所值。</p><h3 id="HTTP2-0特性"><a href="#HTTP2-0特性" class="headerlink" title="HTTP2.0特性"></a>HTTP2.0特性</h3><h4 id="二进制分帧"><a href="#二进制分帧" class="headerlink" title="二进制分帧"></a>二进制分帧</h4><ul><li>HTTP/2 采用二进制格式传输数据，而非 HTTP 1.x 的文本格式，二进制协议解析起来更高效。</li><li>HTTP/1 的请求和响应报文，都是由起始行，首部和实体正文（可选）组成，各部分之间以文本换行符分隔。 HTTP/2 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。</li><li>HTTP1.1 的纯文本形式看起来一目了然，非常直观，但这只是对人的体验而言，事实上这种方式存在多义性，例如大小写、空白字符、回车换行、多字少字等，程序在处理的时候需要复杂的处理。</li><li>而二进制的方式，只是0和1，可以严格规定字段大小，顺序，标志位等，不存在歧义，提交小，同时也提升了数据在网络中传输的效率。</li></ul><h4 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h4><ul><li>HTTP1.1中一次请求与响应的交互必须要等待前面的请求交互完成，否则后面的只能等待。</li><li>而在HTTP2.0中，一次链接成功后，只要链接还没断开，那么 client 端就可以在一个链接中并发的发起多个请求，且每个请求的响应不需要等待其他请求。<ul><li>多路复用，代替原来的序列和阻塞机制。所有就是请求的都是通过一个 TCP连接并发完成。 HTTP 1.x 中，如果想并发多个请求，必须使用多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8个的TCP链接请求限制。常见的一个情况是，如果一个页面需要加载的静态资源过多，因为只有6-8个并发，所以客户端浏览器的等待时间就会比较久。</li></ul></li></ul><h4 id="服务器推送"><a href="#服务器推送" class="headerlink" title="服务器推送"></a>服务器推送</h4><ul><li><p>HTTP2中服务端可以在发送页面HTML时主动推送其它资源，而不用等到浏览器解析到相应位置，发起请求再响应。例如服务端可以主动把JS和CSS文件推送给客户端，而不需要客户端解析HTML时再发送这些请求。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当然，如果一次性推送了太多的资源，因为浏览器需要处理所有推送过来的资源。反而会拖累性能。所以需要根据业务场景做权衡。</span><br></pre></td></tr></table></figure></li></ul><h4 id="头部压缩"><a href="#头部压缩" class="headerlink" title="头部压缩"></a>头部压缩</h4><ul><li><p>HTTP 1.1请求的大小变得越来越大，有时甚至会大于TCP窗口的初始大小，因为它们需要等待带着ACK的响应回来以后才能继续被发送。HTTP/2对消息头采用HPACK（专为http/2头部设计的压缩格式）进行压缩传输，能够节省消息头占用的网络的流量。而HTTP/1.x每次请求，都会携带大量冗余头信息，浪费了很多带宽资源。像cookie这些信息，每个请求都会附带，产生了很多不必要的资源消耗。为了减少这块的资源消耗并提升性能， HTTP/2对这些首部采取了压缩策略：</p><ul><li>HTTP/2在客户端和服务器端使用“首部表”来跟踪和存储之前发送的键－值对，对于相同的数据，不再通过每次请求和响应发送；</li><li>首部表在HTTP/2的连接存续期内始终存在，由客户端和服务器共同渐进地更新;</li><li>每个新的首部键－值对要么被追加到当前表的末尾，要么替换表中之前的值。</li></ul></li></ul><h3 id="ALPN-应用协议协商"><a href="#ALPN-应用协议协商" class="headerlink" title="ALPN 应用协议协商"></a>ALPN 应用协议协商</h3><p>HTTPS 握手的时候，客户端会首先告诉服务端自己支持的协议，由服务端选择客户端服务端都支持的协议。如果服务端Nginx开启了HTTP2支持，服务端会选择HTTP2协议，否则，服务端就会选择HTTP1.1协议来通讯。</p><h2 id="SSL-TLS模型"><a href="#SSL-TLS模型" class="headerlink" title="SSL/TLS模型"></a>SSL/TLS模型</h2><h3 id="TLS版本"><a href="#TLS版本" class="headerlink" title="TLS版本"></a>TLS版本</h3><p><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img.png"></p><p>历史版本的TLS/SSL因为安全漏洞和性能问题已经慢慢成为历史的尘埃，目前应用最为广泛的是TLS1.2版本，而TLS 1.3 是对于TLS1.2的升级，提供更强大的安全性和更高的性能。</p><h3 id="加密套件"><a href="#加密套件" class="headerlink" title="加密套件"></a>加密套件</h3><p><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img1.png"></p><p>加密套件：TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA</p><p>解释:</p><ul><li>基于TLS协议，使用ECDHE和RSA作为秘钥交换算法，加密算法是AES GCM，秘钥长度128位，哈希算法使用sha256</li><li>AES-GCM 是目前常用的分组加密算法，但是其有一个缺点就是计算量大，导致性能和电量开销比较大。为了解决这个问题，Intel 推出了名为 AES NI（Advanced Encryption Standard new instructions）的 x86 指令拓展集，从硬件上提供对 AES 的支持。对于支持 AES NI 指令的主机来说，使用 AES-GCM 是最佳选择。AES-GCM的优点在于可以利用多核提高加解密性能。</li></ul><h3 id="HTTPS握手过程"><a href="#HTTPS握手过程" class="headerlink" title="HTTPS握手过程"></a>HTTPS握手过程</h3><p><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img2.png"></p><ul><li><p><strong>Client-hello 阶段</strong></p><p>Client-hello 是TCP链接建立后客户端发送的第一条消息，主要目的是把客户端支持的功能和选项告诉服务端。</p><ul><li>浏览器中完成地址输入后, 解析域名获得 IP Host 地址, 浏览器会与此 Host 的443(默认, 如果指定其他端口则会连接此端口) 三次握手建立TCP连接，然后进入TLS 握手协议的 Client-hello。这一步骤中浏览器会将客户端支持的加密套件，目标Host等信息发送给服务器, 并会附上一份随机生成的 session ticket1.</li><li>ALPN协商: 应用层可以协商在安全连接层之上使用什么协议, 避免了额外的往返通讯。<br><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img_1.png"></li></ul></li><li><p><strong>Server-hello阶段</strong></p><ul><li>服务器收到浏览器发送来的 TLS 握手请求后, 存储浏览器发送的session ticket1, 然后根据发送来的 host 寻找对应的服务器证书, 然后会将服务器证书, 服务器从Client Hello提供的客户端支持的加密套件清单中按照优先级选择一个双方都支持的套件（如果服务端支持的套件和client支持的套件交集为空则握手失败）, 和一份随机生成的 session ticket2 返回给浏览器.</li></ul><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img_2.png" class></li></ul><p><strong>Client-hello和server-hello的步骤很像是买东西： 客户端： 我有多少钱，能支付宝也能微信付款， 服务端：需要xxx RMB，我们使用支付宝吧。</strong></p><ul><li><p>Cipher-spec 阶段</p><p>经过Client Hello和Server Hello 客户端和服务端完成了加密套件的协商。进入Cipher-spec 阶段会核验证书的有效性。</p><p>验证步骤如下:</p><ul><li>验证证书有效期</li><li>验证证书域名与实际的host是否匹配。</li><li>验证证书吊销状态(CRL+OCSP)确认证书是否被吊销。</li><li>验证证书颁发机构, 如果颁发机构是中间证书（基本都是）, 再验证中间证书的有效期/颁发机构/吊销状态. 一直验证到最后一层证书, 中途任何一个环节不通过都会提示不信任。</li><li>若检查通过, 随机生成一份 session ticket 3 (这是浏览器生成的第二份 ticket), 通过返回证书中的公钥, 用协商的加密算法加密, 返回给服务器.同时浏览器用 session ticket 1(浏览器) &amp; session ticket 2(服务器) &amp; session ticket 3(浏浏览器) 组合成 session key。</li></ul></li><li><p>内容传输阶段</p><ul><li>TLS 连接建立完成, 在连接销毁前, 浏览器与服务器的交互数据均通过 session key 来进行对称加密.</li></ul></li></ul><h4 id="HTTPS握手过程抓包："><a href="#HTTPS握手过程抓包：" class="headerlink" title="HTTPS握手过程抓包："></a>HTTPS握手过程抓包：</h4><img src="/2021/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/11/26/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/%E8%AF%A6%E8%A7%A3HTTP2.0%E5%8F%8AHTTPS%E5%8D%8F%E8%AE%AE/img_3.png" class><ul><li>前三行为TCP三次握手，</li><li>第四行客户端发起Client hello，</li><li>第五行服务端ack回复， </li><li>第六行Server Hello，</li><li>第9行Cipher-spec阶段进行证书校验，</li><li>完成握手之后第13行进入数据交互阶段。</li></ul><h3 id="HSTS"><a href="#HSTS" class="headerlink" title="HSTS"></a>HSTS</h3><p>通常访问网址的时候我们大多不会刻意的在前面写上https，也很少会关注我们是通过HTTP协议还是HTTPS协议在浏览。而要求https访问的站点，在用户通过http访问的时候大多以重定向的方式重定向到HTTPS地址，而如果我劫持了用户流量，拦截向https的重定向请求，然后担当一个代理的角色，如实转发客户端请求并返回，但是客户端跟中间人的交互采用的是明文的HTTP协议，由于没有建立SSL连接，所以客户端提交的信息都会暴露。基于此问题，是国际互联网工程组织 IETF 发布了HSTS的安全策略机制，强制让浏览器使用HTTPS与站点进行通信。</p><p>HSTS（HTTP Strict Transport Security）的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。HSTS主要是通过服务器发送响应头的方式来控制浏览器操作：</p><ul><li><p>当客户端通过 HTTPS 发出请求时，服务器会在返回的 HTTP 响应头中包含 Strict-Transport-Security 字段（HSTS的开关由服务端控制）。</p></li><li><p>浏览器接收到这样的信息之后，在一定期限内对该网站的任何请求都会以 HTTPS 发起（浏览器内部307跳转），而不会以 HTTP发起再由服务器重定向到 HTTPS。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA集合概述之各集合基本对比</title>
      <link href="/2021/08/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E9%9B%86%E5%90%88/JAVA%E9%9B%86%E5%90%88%E6%A6%82%E8%BF%B0%E4%B9%8B%E5%90%84%E9%9B%86%E5%90%88%E5%9F%BA%E6%9C%AC%E5%AF%B9%E6%AF%94/"/>
      <url>/2021/08/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E9%9B%86%E5%90%88/JAVA%E9%9B%86%E5%90%88%E6%A6%82%E8%BF%B0%E4%B9%8B%E5%90%84%E9%9B%86%E5%90%88%E5%9F%BA%E6%9C%AC%E5%AF%B9%E6%AF%94/</url>
      
        <content type="html"><![CDATA[<p> <img src="/2021/08/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E9%9B%86%E5%90%88/JAVA%E9%9B%86%E5%90%88%E6%A6%82%E8%BF%B0%E4%B9%8B%E5%90%84%E9%9B%86%E5%90%88%E5%9F%BA%E6%9C%AC%E5%AF%B9%E6%AF%94/img.png"></p><h3 id="线性表"><a href="#线性表" class="headerlink" title="线性表"></a>线性表</h3><h4 id="链式存储（LinkedList）"><a href="#链式存储（LinkedList）" class="headerlink" title="链式存储（LinkedList）"></a>链式存储（LinkedList）</h4><ul><li>双向链表，没有初始化大小，也没有扩容的机制</li><li>它也可以被当作堆栈、队列或双端队列进行操作。</li><li>能克隆</li><li>支持序列化</li><li>非同步的</li></ul><h4 id="顺序存储-ArrayList"><a href="#顺序存储-ArrayList" class="headerlink" title="顺序存储(ArrayList)"></a>顺序存储(ArrayList)</h4><ul><li>自动扩容机制<ul><li>默认构造方法生成的空数组并且第一次添加数据。此时minCapacity等于默认的容量（10）那么根据下面逻辑可以看到最后数组的容量会从0扩容成10。而后的数组扩容才是按照当前容量的1.5倍进行扩容；</li><li>自定义初始容量构造方法创建并且指定初始容量为0。此时minCapacity等于1那么根据下面逻辑可以看到最后数组的容量会从0变成1。这边可以看到一个严重的问题，一旦我们执行了初始容量为0，那么根据下面的算法前四次扩容每次都+1，在第5次添加数据进行扩容的时候才是按照当前容量的1.5倍进行扩容。</li><li>当扩容量（newCapacity）大于ArrayList数组定义的最大值后会调用hugeCapacity来进行判断。如果minCapacity已经大于Integer的最大值（溢出为负数）那么抛出OutOfMemoryError（内存溢出）否则的话根据与MAX_ARRAY_SIZE的比较情况确定是返回Integer最大值还是MAX_ARRAY_SIZE。</li></ul></li><li>快速报错机制ConcurrentModificationException<ul><li>在遍历的过程中对ArrayList集合本身进行add,remove等操作时候就会发生。当然如果你用的是Iterator那么使用它的remove是允许的</li></ul></li><li>自行实现序列化</li></ul><h4 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h4><ul><li>线程安全</li></ul><h3 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h3><h4 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h4><ul><li>vector子类,LIFO<ul><li>中缀表达式转后缀表达式</li><li>后缀表达式求值</li></ul></li></ul><h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><h4 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h4><ul><li><p>ArrayBlockingQueue</p><ul><li>数组支持的有界队列,构造函数指定容量</li><li>FIFO（先进先出）</li><li>设置公平参数，若公平参数被设置true，等待时间最长的线程会优先得到处理</li></ul></li><li><p>LinkedBlockingQueue</p><ul><li>无上限</li><li>可以选择指定其最大容量</li><li>FIFO</li></ul></li><li><p>PriorityBlockingQueue</p><ul><li>priorityQueue的再封装，元素无上限</li><li>带优先级，非FIFO</li></ul></li><li><p>DelayQueue</p><ul><li>无界阻塞队列，只有在延迟期满时才能从中提取元素</li><li>基于PriorityQueue实现</li><li>缓存基石</li></ul></li><li><p>SynchronousQueue</p></li></ul><h4 id="非阻塞队列"><a href="#非阻塞队列" class="headerlink" title="非阻塞队列"></a>非阻塞队列</h4><ul><li>PriorityQueue<ul><li>维护了一个有序列表</li><li>根据天然排序/传递给构造函数的 java.util.Comparator 实现来定位</li></ul></li><li>ConcurrentLinkedQueue<ul><li>基于链接节点的、线程安全的队列</li><li>对公共集合的共享访问就可以工作得很好。</li><li>收集关于队列大小的信息会很慢，需要遍历队列。</li></ul></li></ul><h3 id="Set集合"><a href="#Set集合" class="headerlink" title="Set集合"></a>Set集合</h3><p>Set集合与Collection的方法相同，由于Set集合不允许存储相同的元素，所以如果把两个相同元素添加到同一个Set集合，则添加操作失败，新元素不会被加入，add()方法返回false。</p><h4 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h4><h5 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h5><p>底层使用HashMap实现（存在LinkedHashMap构造器为default修饰符，子类LinkedHashSet调用），key为HashSet存入的值，value为一个静态空Object变量，插入/删除/更新时直接调用HashMap接口实现，迭代器直接通过HashMap的Key列表迭代器。</p><h5 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h5><p>不能保证元素的顺序。</p><p>HashSet不是线程同步的，如果多线程操作HashSet集合，则应通过代码来保证其同步。</p><p>集合元素值可以是null（HashMap的Key值可以为空，空Key的Hash值为0）。</p><h4 id="LinkedHashSet"><a href="#LinkedHashSet" class="headerlink" title="LinkedHashSet"></a>LinkedHashSet</h4><p>HashSet的一个子类，构造器直接调用了HashSet基于LinkedHashMap的构造器（default修饰符），元素的顺序与插入顺序一致。性能略低于HashSet，但在迭代访问Set里的全部元素时有很好的性能。</p><h4 id="TreeSet"><a href="#TreeSet" class="headerlink" title="TreeSet"></a><strong>TreeSet</strong></h4><p>SortedSet接口的实现类，TreeSet可以保证元素处于排序状态，它采用红黑树的数据结构（NavigableMap）来存储集合元素。TreeSet支持两种排序方法：自然排序和定制排序，默认采用自然排序。</p><h5 id="自然排序"><a href="#自然排序" class="headerlink" title="自然排序"></a>自然排序</h5><p>TreeSet会调用集合元素的compareTo(Object obj)方法来比较元素的大小关系，然后将元素按照升序排列，这就是自然排序。如果试图将一个对象添加到TreeSet集合中，则该对象必须实现Comparable接口，否则会抛出异常。</p><p>对于TreeSet集合而言，它判断两个对象是否相等的标准是：两个对象通过compareTo(Object obj)方法比较是否返回0，如果返回0则相等。</p><h5 id="定制排序"><a href="#定制排序" class="headerlink" title="定制排序"></a>定制排序</h5><p>在创建TreeSet集合对象时，提供一个Comparator对象与该TreeSet集合关联，由Comparator对象负责集合元素的排序逻辑。</p><h4 id="EnumSet"><a href="#EnumSet" class="headerlink" title="EnumSet"></a>EnumSet</h4><p>EnumSet是一个专为枚举类设计的集合类，不允许添加null值。EnumSet的集合元素也是有序的，它以枚举值在Enum类内的定义顺序来决定集合元素的顺序。</p><p>不能自定义排序，底层为数组结构。</p><h4 id="各Set类性能对比"><a href="#各Set类性能对比" class="headerlink" title="各Set类性能对比"></a>各Set类性能对比</h4><p>HashSet比TreeSet性能高, TreeSet只在有序时使用；</p><p>LinkedHashSet插入和删除操作比HashSet要慢，但遍历比HashSet快；</p><p>EnumSet是所有Set实现类中性能最好的，但它只能保存同一个枚举类的枚举值作为集合元素。</p><h4 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h4><p>HashSet/LinkedHashSet/TreeSet/EnumSet全部线程不安全，如果多线程访问，必须手动保证集合的同步性。</p><h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><p><img src="/2021/08/18/JAVA%E5%9F%BA%E7%A1%80/JAVA%E9%9B%86%E5%90%88/JAVA%E9%9B%86%E5%90%88%E6%A6%82%E8%BF%B0%E4%B9%8B%E5%90%84%E9%9B%86%E5%90%88%E5%9F%BA%E6%9C%AC%E5%AF%B9%E6%AF%94/3857088f3d1c4e3d6193997aa545eca4.png"></p><h4 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h4><ul><li>数组+链表+红黑树的结构，也叫哈希桶</li><li>哈希表结构，元素的存取顺序不能保证一致。</li></ul><h4 id="LinkedHashMap"><a href="#LinkedHashMap" class="headerlink" title="LinkedHashMap"></a>LinkedHashMap</h4><ul><li>HashMap子类</li><li>存储数据采用的哈希表结构+链表结构，链表保证元素读取顺序一致</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM基础系列之垃圾回收器</title>
      <link href="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"/>
      <url>/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="JVM内存的分配与垃圾回收"><a href="#JVM内存的分配与垃圾回收" class="headerlink" title="JVM内存的分配与垃圾回收"></a>JVM内存的分配与垃圾回收</h2><p>在研究垃圾回收器钱，首先我们还是简单看下JVM的内存规则：</p><ul><li>新生代：一般来说新创建的对象都分配在这里。</li><li>年老代：经过几次垃圾回收，新生代的对象就会放在年老代里面。年老代中的对象保存的时间更久。</li><li>永久代：这里面存放的是class相关的信息，一般是不会进行垃圾回收的。</li></ul><p>JVM垃圾回收</p><p>由于JVM会替我们执行垃圾回收，因此开发者根本不需要关心对象的释放。但是如果不了解其中的原委，很容易内存泄漏，只能两眼望天了！</p><p>垃圾回收，大致可以分为下面几种：</p><ul><li>Minor GC:当新创建对象，内存空间不够的时候，就会执行这个垃圾回收。由于执行最频繁，因此一般采用复制回收机制。</li><li>Major GC:清理年老代的内存，这里一般采用的是标记清除+标记整理机制。</li><li>Full GC:有的说与Major GC差不多，有的说相当于执行minor+major回收，那么我们暂且可以认为Full GC就是全面的垃圾回收吧。</li></ul><h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><h3 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h3><p>将存活对象复制到一块区域中</p><p>优缺点：存活对象少场景下，复制效率高；但是会浪费一块内存空间用于存放存活对象</p><h3 id="标记清除算法"><a href="#标记清除算法" class="headerlink" title="标记清除算法"></a>标记清除算法</h3><p>将存活对象标记，然后删除未存活对象</p><p>优缺点：存在内存碎片</p><h3 id="标记整理算法"><a href="#标记整理算法" class="headerlink" title="标记整理算法"></a>标记整理算法</h3><p>将回收对象标记，存活对象整理到一边，最后清除另一边区域</p><p>优缺点：内存空间连续，gc时间长</p><h2 id="常见垃圾收集器"><a href="#常见垃圾收集器" class="headerlink" title="常见垃圾收集器"></a>常见垃圾收集器</h2><h3 id="各种垃圾收集器质检的关系图"><a href="#各种垃圾收集器质检的关系图" class="headerlink" title="各种垃圾收集器质检的关系图"></a>各种垃圾收集器质检的关系图</h3><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img.png"></p><p>1、图片展示了各种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用（这个关系不是一成不变的，由于维护和兼容性测试的成本，在JDK 8时将 Serial + CMS、ParNew + Serial Old这两个组合声明为废弃，并在JDK 9中完全取消了这些组合的支持），图中收集器所处的区域，则表示它是属于新生代收集器或是老年代收集器。</p><p>2、在介绍这些收集器各自的特性之前，需要明确一个观点：虽然会对各个收集器进行比较，但并非为了挑选一个最好的收集器出来，虽然垃圾收集器的技术在不断进步，但直到现在还没有最好的收集器出现，更加<strong>不存在“万能”的收集器</strong>，所以我们选择的只是对具体应用最合适的收集器。</p><h3 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h3><h4 id="Serial收集器运行示意图"><a href="#Serial收集器运行示意图" class="headerlink" title="Serial收集器运行示意图"></a>Serial收集器运行示意图</h4><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img_1.png"></p><h4 id="Serial收集器介绍"><a href="#Serial收集器介绍" class="headerlink" title="Serial收集器介绍"></a>Serial收集器介绍</h4><ul><li>Serial收集器是最基础、历史最悠久的收集器，曾经（在JDK 1.3.1之前）是HotSpot虚拟机新生代收集器的唯一选择。</li><li>大家只看名字就能够猜到，这个收集器是一个单线程工作的收集器，它在进行垃圾收集时，必须暂停其他所有工作线程，直到它收集结束。</li><li>“Stop The World”这个词语也许听起来很酷，但这项工作是由虚拟机在后台自动发起和自动完成的，在用户不可知、不可控的情况下把用户的正常工作的线程全部停掉，这对很多应用来说都是不能接受的</li></ul><h4 id="Serial收集器适用场景"><a href="#Serial收集器适用场景" class="headerlink" title="Serial收集器适用场景"></a>Serial收集器适用场景</h4><ul><li>简单而高效（与其他收集器的单线程相比）<ul><li>对于内存资源受限的环境，它是所有收集器里额外内存消耗最小的；</li><li>对于单核处理器或处理器核心数较少的环境来说，Serial收集器由于没有线程交互的开销，收集效率高。</li></ul></li><li>在用户桌面的应用场景中，分配给虚拟机管理的内存一般来说并不会特别大，收集几十兆甚至一两百兆的新生代（仅仅是指新生代使用的内存），垃圾收集的停顿时间完全可以控制在十几、几十毫秒，最多一百多毫秒以内，只要不是频繁发生收集，这点停顿时间对许多用户来说是完全可以接受的。</li><li>所以，Serial收集器对于<strong>运行在客户端模式下的虚拟机</strong>来说是一个很好的选择</li></ul><h3 id="ParNew收集器"><a href="#ParNew收集器" class="headerlink" title="ParNew收集器"></a>ParNew收集器</h3><h4 id="ParNew收集器运行示意图"><a href="#ParNew收集器运行示意图" class="headerlink" title="ParNew收集器运行示意图"></a>ParNew收集器运行示意图</h4><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img_2.png"></p><h4 id="ParNew收集器介绍"><a href="#ParNew收集器介绍" class="headerlink" title="ParNew收集器介绍"></a>ParNew收集器介绍</h4><p>ParNew收集器实质上是Serial收集器的多线程并行版本，除了同时使用多条线程进行垃圾收集之外，其余的行为包括Serial收集器可用的所有控制参数（例如：-XX：SurvivorRatio、-XX：PretenureSizeThreshold、-XX：HandlePromotionFailure等）、收集算法、STW、对象分配规则、回收策略等都与Serial收集器完全一致，在实现上这两种收集器也共用了相当多的代码。</p><h4 id="ParNew收集器适用场景"><a href="#ParNew收集器适用场景" class="headerlink" title="ParNew收集器适用场景"></a>ParNew收集器适用场景</h4><p>ParNew收集器除了支持多线程并行收集之外，其他与Serial收集器相比并没有太多创新之处，但它却是不少运行在服务端模式下的HotSpot虚拟机，尤其是JDK 7之前的遗留系统中首选的新生代收集器。</p><p><strong>其中有一个与功能、性能无关但其实很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器配合工作。</strong></p><h3 id="Parallel-Scavenge收集器"><a href="#Parallel-Scavenge收集器" class="headerlink" title="Parallel Scavenge收集器"></a>Parallel Scavenge收集器</h3><h4 id="Parallel-Scavenge收集器运行示意图"><a href="#Parallel-Scavenge收集器运行示意图" class="headerlink" title="Parallel Scavenge收集器运行示意图"></a>Parallel Scavenge收集器运行示意图</h4><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img_3.png"></p><h4 id="Parallel-Scavenge收集器介绍"><a href="#Parallel-Scavenge收集器介绍" class="headerlink" title="Parallel Scavenge收集器介绍"></a>Parallel Scavenge收集器介绍</h4><p>Parallel Scavenge收集器也是一款新生代收集器，它同样是基于标记-复制算法实现的收集器，也是能够并行收集的多线程收集器……Parallel Scavenge的诸多特性从表面上看和ParNew非常相似，那它有什么特别之处呢？</p><p>Parallel Scavenge收集器的特点是它的关注点与其他收集器不同：</p><ul><li>CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间</li><li>而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（<strong>处理器用于运行用户代码的时间与处理器总消耗时间的比值</strong>）。</li></ul><h4 id="Parallel-Scavenge收集器适用场景"><a href="#Parallel-Scavenge收集器适用场景" class="headerlink" title="Parallel Scavenge收集器适用场景"></a>Parallel Scavenge收集器适用场景</h4><p>如果对于收集器运作不太了解，手工优化存在困难的话，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成也许是一个很不错的选择。</p><p>只需要把基本的内存数据设置好（如-Xmx设置最大堆），然后使用-XX：MaxGCPauseMillis参数（更关注最大停顿时间）或-XX：GCTimeRatio（更关注吞吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。</p><p><strong>自适应调节策略也是Parallel Scavenge收集器区别于ParNew收集器的一个重要特性。</strong></p><p>其实ParNew的Par就是Parallel的简写，ParNew就是Parallel Scavenge的增强版，为了配合CMS ParNew做了一些增强。</p><h3 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h3><h4 id="Serial-Old收集器运行示意图（同Serial示意图）"><a href="#Serial-Old收集器运行示意图（同Serial示意图）" class="headerlink" title="Serial Old收集器运行示意图（同Serial示意图）"></a>Serial Old收集器运行示意图（同Serial示意图）</h4><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img_4.png"></p><h4 id="Serial-Old收集器介绍"><a href="#Serial-Old收集器介绍" class="headerlink" title="Serial Old收集器介绍"></a>Serial Old收集器介绍</h4><p>Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记-整理算法。</p><h4 id="Serial-Old收集器适用场景"><a href="#Serial-Old收集器适用场景" class="headerlink" title="Serial Old收集器适用场景"></a>Serial Old收集器适用场景</h4><p>Serial Old收集器的主要意义也是供客户端模式下的HotSpot虚拟机使用。</p><p>如果在服务端模式下，它也可能有两种用途：</p><ul><li>在JDK 5以及之前的版本中与Parallel Scavenge收集器搭配使用，</li><li>作为CMS收集器发生失败时的后备预案，在并发收集发生Concurrent Mode Failure时使用。</li></ul><h3 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h3><h4 id="Parallel-Old收集器运行示意图（同Parallel-Scavenge）"><a href="#Parallel-Old收集器运行示意图（同Parallel-Scavenge）" class="headerlink" title="Parallel Old收集器运行示意图（同Parallel Scavenge）"></a>Parallel Old收集器运行示意图（同Parallel Scavenge）</h4><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img_5.png"></p><h4 id="Parallel-Old收集器介绍"><a href="#Parallel-Old收集器介绍" class="headerlink" title="Parallel Old收集器介绍"></a>Parallel Old收集器介绍</h4><p>Parallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现。</p><p>这个收集器是直到JDK 6时才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于相当尴尬的状态，原因是如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old收集器以外别无选择，其他表现良好的老年代收集器，如CMS无法与它配合工作。</p><p>由于老年代Serial Old收集器在服务端应用性能上的“拖累”，使用Parallel Scavenge收集器也未必能在整体上获得吞吐量最大化的效果。同样，由于单线程的老年代收集中无法充分利用服务器多处理器的并行处理能力，在老年代内存空间很大而且硬件规格比较高级的运行环境中，这种组合的总吞吐量甚至不一定比ParNew加CMS的组合来得优秀。</p><h4 id="Parallel-Old收集器适用场景"><a href="#Parallel-Old收集器适用场景" class="headerlink" title="Parallel Old收集器适用场景"></a>Parallel Old收集器适用场景</h4><p>在Parallel Old收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的搭配组合，在<strong>注重吞吐量或者处理器资源较为稀缺的场合</strong>，都可以优先考虑Parallel Scavenge加Parallel Old收集器这个组合。</p><h3 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h3><h4 id="CMS收集器运行示意图"><a href="#CMS收集器运行示意图" class="headerlink" title="CMS收集器运行示意图"></a>CMS收集器运行示意图</h4><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img_6.png"></p><h4 id="CMS收集器介绍"><a href="#CMS收集器介绍" class="headerlink" title="CMS收集器介绍"></a>CMS收集器介绍</h4><p>CMS（Concurrent Mark Sweep）收集器是一种以<strong>获取最短回收停顿时间为目标</strong>的收集器。</p><p>目前很大一部分的Java应用集中在互联网网站或者基于浏览器的B/S系统的服务端上，这类应用通常都会较为关注服务的响应速度，希望系统STW尽可能短，以给用户带来良好的交互体验。CMS收集器就非常符合这类应用的需求。</p><p>从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于<strong>标记-清除算法</strong>实现的，它的运作过程相对于前面几种收集器来说要更复杂一些。</p><p>整个过程分为四个步骤，包括：</p><ol><li>初始标记（CMS initial mark）</li></ol><p>有STW；初始标记仅仅只是标记一下GCRoots能直接关联到的对象，速度很快。</p><ol start="2"><li>并发标记（CMS concurrent mark）</li></ol><p>并发标记阶段就是从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与GC线程一起并发运行。</p><ol start="3"><li>重新标记（CMS remark）</li></ol><p>有STW；重新标记阶段是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录；采用三色标记算法和增量更新避免漏标。</p><ol start="4"><li>并发清除（CMS concurrent sweep）</li></ol><p>清理删除掉标记阶段判断的已经死亡的 对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发执行的。</p><h4 id="CMS收集器的缺点"><a href="#CMS收集器的缺点" class="headerlink" title="CMS收集器的缺点"></a>CMS收集器的缺点</h4><ol><li>CMS收集器对处理器资源非常敏感。</li><li>由于CMS收集器无法处理“浮动垃圾”（Floating Garbage），有可能出现“Con-current Mode Failure”失败进而导致另一次完全STW的Full GC的产生，即让Serial Old来进行收集。浮动垃圾就是并发标记、并发清理时产生的垃圾。</li><li>大量空间碎片的产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很多剩余空间，但就是无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次Full GC的情况。</li></ol><h3 id="Garbage-First收集器"><a href="#Garbage-First收集器" class="headerlink" title="Garbage First收集器"></a>Garbage First收集器</h3><h4 id="G1收集器分区示意图"><a href="#G1收集器分区示意图" class="headerlink" title="G1收集器分区示意图"></a>G1收集器分区示意图</h4><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img_7.png"></p><ul><li>E：Eden区</li><li>S：Survivor区</li><li>H：Humongous区（存放大对象）</li></ul><h4 id="G1运行示意图"><a href="#G1运行示意图" class="headerlink" title="G1运行示意图"></a>G1运行示意图</h4><p><img src="/2021/08/17/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/img_8.png"></p><h4 id="G1收集器介绍"><a href="#G1收集器介绍" class="headerlink" title="G1收集器介绍"></a>G1收集器介绍</h4><p>在G1收集器出现之前的所有其他收集器，包括CMS在内，垃圾收集的目标范围要么是整个新生代（Minor GC），要么就是整个老年代（Major GC），再要么就是整个Java堆（Full GC）。而G1跳出了这个樊笼，它可以面向堆内存任何部分来组成回收集（Collection Set，一般简称CSet）进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是G1收集器的Mixed GC模式。</p><p>G1开创的<strong>基于Region的堆内存布局</strong>是它能够实现垃圾优先回收目标的关键。虽然G1也仍是<strong>遵循分代收集理论设计</strong>的，但其堆内存的布局与G1之前的收集器有非常明显的差异：G1不再坚持固定大小以及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域（Region），每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理，这样无论是新创建的对象还是已经存活了一段时间、熬过多次收集的旧对象都能获取很好的收集效果。</p><p>虽然G1仍然保留新生代和老年代的概念，但新生代和老年代不再是固定的了，它们都是一系列区域（不需要连续）的动态集合。G1收集器之所以能建立可预测的停顿时间模型，是因为它将Region作为单次回收的最小单元，即每次收集到的内存空间都是Region大小的整数倍，这样可以有计划地避免在整个Java堆中进行全区域的垃圾收集。</p><p>更具体的处理思路是让G1收集器去跟踪各个Region里面的垃圾堆积的“价值”大小，价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间（使用参数-XX：MaxGCPauseMillis指定，默认值是200毫秒），优先处理回收价值收益最大的那些Region，这也就是“Garbage First”名字的由来。</p><h4 id="G1收集器缺点"><a href="#G1收集器缺点" class="headerlink" title="G1收集器缺点"></a>G1收集器缺点</h4><p>G1无论是为了垃圾收集产生的内存占用还是程序运行时的额外执行负载都要比CMS高</p><h4 id="G1收集器适用场景"><a href="#G1收集器适用场景" class="headerlink" title="G1收集器适用场景"></a>G1收集器适用场景</h4><p>目前在小内存应用上CMS的表现大概率仍然要会优于G1，而在大内存应用上G1则大多能发挥其优势，这个优劣势的Java堆容量平衡点通常在6GB至8GB之间，当然，这也不是绝对的，不同应用需要量体裁衣地实际测试才能得出最合适的结论，随着HotSpot的开发者对G1的不断优化，也会让对比结果继续向G1倾斜。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>总的来说，HotSpot的垃圾收集器是伴随着内存发展而不断前进的：</p><ul><li>早期几十M的内存，Serial+Serial Old单线程进行回收就足以；</li><li>但是内存达到几百M时，就得使用PS+PO多线程的GC线程来回收；</li><li>当内存达到几个G时， 多线程也忙不过来，就得使用并发的CMS+ParNew收集器；</li><li>当到了动辄几十个G内存的时候，以前那种每次GC都进行新生代或老年代或整个堆的回收的STW也无法忍受时，就得使用G1了。</li></ul><p>目前绝大数的生产环境都是使用的JDK8，若没有进行过调优，默认使用的是PS+PO的收集器； 但是要进行调优时，会在CMS和G1中来进行选择，如果内存比较大（10G以上），最好使用G1，内存较小（几个G）可以考虑CMS。</p><p>如果有一种放之四海皆准、任何场景下都适用的完美收集器存在，HotSpot虚拟机完全没必要实现那么多种不同的收集器了。也就是只有最合适的收集器，没有最好的收集器。</p><h2 id="System-gc"><a href="#System-gc" class="headerlink" title="System.gc()"></a>System.gc()</h2><h3 id="为什么需要System-gc"><a href="#为什么需要System-gc" class="headerlink" title="为什么需要System.gc()"></a>为什么需要System.gc()</h3><h4 id="使用并管理堆外内存的框架，需要FullGC的机制触发堆外内存回收"><a href="#使用并管理堆外内存的框架，需要FullGC的机制触发堆外内存回收" class="headerlink" title="使用并管理堆外内存的框架，需要FullGC的机制触发堆外内存回收"></a>使用并管理堆外内存的框架，需要FullGC的机制触发堆外内存回收</h4><details><summary>JVM 的内存，不止堆内存，还有其他很多块，通过 Native Memory Tracking 可以看到</summary><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">Native Memory Tracking:</span><br><span class="line"> </span><br><span class="line">Total: reserved=6308603KB, committed=4822083KB</span><br><span class="line">-                 Java Heap (reserved=4194304KB, committed=4194304KB)</span><br><span class="line">                            (mmap: reserved=4194304KB, committed=4194304KB) </span><br><span class="line"> </span><br><span class="line">-                     Class (reserved=1161041KB, committed=126673KB)</span><br><span class="line">                            (classes #21662)</span><br><span class="line">                            (  instance classes #20542, array classes #1120)</span><br><span class="line">                            (malloc=3921KB #64030) </span><br><span class="line">                            (mmap: reserved=1157120KB, committed=122752KB) </span><br><span class="line">                            (  Metadata:   )</span><br><span class="line">                            (    reserved=108544KB, committed=107520KB)</span><br><span class="line">                            (    used=105411KB)</span><br><span class="line">                            (    free=2109KB)</span><br><span class="line">                            (    waste=0KB =0.00%)</span><br><span class="line">                            (  Class space:)</span><br><span class="line">                            (    reserved=1048576KB, committed=15232KB)</span><br><span class="line">                            (    used=13918KB)</span><br><span class="line">                            (    free=1314KB)</span><br><span class="line">                            (    waste=0KB =0.00%)</span><br><span class="line"> </span><br><span class="line">-                    Thread (reserved=355251KB, committed=86023KB)</span><br><span class="line">                            (thread #673)</span><br><span class="line">                            (stack: reserved=353372KB, committed=84144KB)</span><br><span class="line">                            (malloc=1090KB #4039) </span><br><span class="line">                            (arena=789KB #1344)</span><br><span class="line"> </span><br><span class="line">-                      Code (reserved=252395KB, committed=69471KB)</span><br><span class="line">                            (malloc=4707KB #17917) </span><br><span class="line">                            (mmap: reserved=247688KB, committed=64764KB) </span><br><span class="line"> </span><br><span class="line">-                        GC (reserved=199635KB, committed=199635KB)</span><br><span class="line">                            (malloc=11079KB #29639) </span><br><span class="line">                            (mmap: reserved=188556KB, committed=188556KB) </span><br><span class="line"> </span><br><span class="line">-                  Compiler (reserved=2605KB, committed=2605KB)</span><br><span class="line">                            (malloc=2474KB #2357) </span><br><span class="line">                            (arena=131KB #5)</span><br><span class="line"> </span><br><span class="line">-                  Internal (reserved=3643KB, committed=3643KB)</span><br><span class="line">                            (malloc=3611KB #8683) </span><br><span class="line">                            (mmap: reserved=32KB, committed=32KB) </span><br><span class="line"> </span><br><span class="line">-                     Other (reserved=67891KB, committed=67891KB)</span><br><span class="line">                            (malloc=67891KB #2859) </span><br><span class="line"> </span><br><span class="line">-                    Symbol (reserved=26220KB, committed=26220KB)</span><br><span class="line">                            (malloc=22664KB #292684) </span><br><span class="line">                            (arena=3556KB #1)</span><br><span class="line"> </span><br><span class="line">-    Native Memory Tracking (reserved=7616KB, committed=7616KB)</span><br><span class="line">                            (malloc=585KB #8238) </span><br><span class="line">                            (tracking overhead=7031KB)</span><br><span class="line"> </span><br><span class="line">-               Arena Chunk (reserved=10911KB, committed=10911KB)</span><br><span class="line">                            (malloc=10911KB) </span><br><span class="line"> </span><br><span class="line">-                   Tracing (reserved=25937KB, committed=25937KB)</span><br><span class="line">                            (malloc=25937KB #8666) </span><br><span class="line"> </span><br><span class="line">-                   Logging (reserved=5KB, committed=5KB)</span><br><span class="line">                            (malloc=5KB #196) </span><br><span class="line"> </span><br><span class="line">-                 Arguments (reserved=18KB, committed=18KB)</span><br><span class="line">                            (malloc=18KB #486) </span><br><span class="line"> </span><br><span class="line">-                    Module (reserved=532KB, committed=532KB)</span><br><span class="line">                            (malloc=532KB #3579) </span><br><span class="line"> </span><br><span class="line">-              Synchronizer (reserved=591KB, committed=591KB)</span><br><span class="line">                            (malloc=591KB #4777) </span><br><span class="line"> </span><br><span class="line">-                 Safepoint (reserved=8KB, committed=8KB)</span><br><span class="line">                            (mmap: reserved=8KB, committed=8KB)</span><br><span class="line">————————————————</span><br><span class="line">版权声明：本文为CSDN博主「java  分享官」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。</span><br><span class="line">原文链接：https://blog.csdn.net/aa119101/article/details/124406444</span><br></pre></td></tr></table></figure></details><ul><li>Java Heap: 堆内存，即 -Xmx 限制的最大堆大小的内存。</li><li>Class：加载的类似方法信息，其实就是 metaspace，包含两部分： 一是 metadata，被 -XX:MaxMetaspaceSize 限制最大大小，另外是 class space，被 -XX:CompressedClassSpaceSize 限制最大大小</li><li>Thread：线程与线程栈占用内存，每个线程栈占用大小受 -Xss 限制，但是总大小没有限制。</li><li>Code：JIT 即时编译后（C1 C2 编译器优化）的代码占用内存，受 -XX:ReservedCodeCacheSize 限制</li><li>GC：垃圾回收占用内存，例如垃圾回收需要的 CardTable，标记数，区域划分记录，还有标记 GC Root 等等，都需要内存。这个不受限制，一般不会很大的。</li><li>Compiler：C1 C2 编译器本身的代码和标记占用的内存，这个不受限制，一般不会很大的</li><li>Internal：命令行解析，JVMTI 使用的内存，这个不受限制，一般不会很大的</li><li>Symbol: 常量池占用的大小，字符串常量池受 -XX:StringTableSize 个数限制，总内存大小不受限制</li><li>Native Memory Tracking：内存采集本身占用的内存大小，如果没有打开采集（那就看不到这个了，哈哈），就不会占用，这个不受限制，一般不会很大的</li><li>Arena Chunk：所有通过 arena 方式分配的内存，这个不受限制，一般不会很大的</li><li>Tracing：所有采集占用的内存，如果开启了 JFR 则主要是 JFR 占用的内存。这个不受限制，一般不会很大的</li><li>Logging，Arguments，Module，Synchronizer，Safepoint，Other，这些一般我们不会关心。</li></ul><p>除了 Native Memory Tracking 记录的内存使用，还有两种内存 <strong>Native Memory Tracking 没有记录</strong> ，那就是：</p><ul><li>Direct Buffer：直接内存</li><li>MMap Buffer：文件映射内存</li></ul><p>针对除了堆内存以外，其他的内存，有些也是需要 GC 的。</p><pre><code>例如：MetaSpace，CodeCache，Direct Buffer，MMap Buffer 等等。</code></pre><p>早期在 Java 8 之前的 JVM，对于这些内存回收的机制并不完善，很多情况下都需要 FullGC 扫描整个堆才能确定这些区域中哪些内存可以回收。</p><p>有一些框架，大量使用并管理了这些堆外空间。例如:</p><ul><li>netty 使用了 Direct Buffer，</li><li>Kafka 和 RocketMQ 使用了 Direct Buffer 和 MMap Buffer。</li></ul><p>他们都是提前从系统申请好一块内存，之后管理起来并使用。</p><p>在空间不足时，继续向系统申请，并且也会有缩容。</p><p>例如 netty: </p><ul><li>在使用的 Direct Buffer 达到 -XX:MaxDirectMemorySize 的限制之后，则会先尝试将不可达的Reference对象加入Reference链表中，依赖Reference的内部守护线程触发可以被回收DirectByteBuffer关联的Cleaner的run()方法。</li><li>如果内存还是不足， 则执行 System.gc() ，期望触发full gc ，来回收堆内存中的 DirectByteBuffer 对象来触发堆外内存回收，</li><li>如果还是超过限制，则抛出 java.lang.OutOfMemoryError .</li></ul><h4 id="使用了-WeakReference，-SoftReference-的程序，需要相应的-GC-回收。"><a href="#使用了-WeakReference，-SoftReference-的程序，需要相应的-GC-回收。" class="headerlink" title="使用了 WeakReference， SoftReference 的程序，需要相应的 GC 回收。"></a>使用了 WeakReference， SoftReference 的程序，需要相应的 GC 回收。</h4><ul><li>WeakReference，只要发生 GC，无论是 Young GC 还是 FullGC 就会被回收。</li><li>SoftReference 只有在 FullGC 的时候才会被回收。</li></ul><p>当我们程序想主动对于这些引用进行回收的时候，需要能触发 GC 的方法，这就用到了 System.gc() 。</p><h4 id="测试、学习-JVM-机制的时候"><a href="#测试、学习-JVM-机制的时候" class="headerlink" title="测试、学习 JVM 机制的时候"></a>测试、学习 JVM 机制的时候</h4><p>有些时候，我们为了测试，学习 JVM 的某些机制，需要让 JVM 做一次 GC 之后开始，这也会用到 System.gc() 。</p><h3 id="System-gc-做了什么"><a href="#System-gc-做了什么" class="headerlink" title="System.gc()做了什么"></a>System.gc()做了什么</h3><p>System.gc()我们都知道是手动垃圾回收，这点无需多说，今天我们来了解一下System.gc()是怎么进行垃圾回收的。</p><p>System.gc()内部调用了 Runtime.getRuntiom</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">gc</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Runtime.getRuntime().gc();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在往深一层则是本地方法了</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Runs the garbage collector.</span></span><br><span class="line"><span class="comment"> * Calling this method suggests that the Java virtual machine expend</span></span><br><span class="line"><span class="comment"> * effort toward recycling unused objects in order to make the memory</span></span><br><span class="line"><span class="comment"> * they currently occupy available for quick reuse. When control</span></span><br><span class="line"><span class="comment"> * returns from the method call, the virtual machine has made</span></span><br><span class="line"><span class="comment"> * its best effort to recycle all discarded objects.</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * The name &lt;code&gt;gc&lt;/code&gt; stands for &quot;garbage</span></span><br><span class="line"><span class="comment"> * collector&quot;. The virtual machine performs this recycling</span></span><br><span class="line"><span class="comment"> * process automatically as needed, in a separate thread, even if the</span></span><br><span class="line"><span class="comment"> * &lt;code&gt;gc&lt;/code&gt; method is not invoked explicitly.</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * The method &#123;<span class="doctag">@link</span> System#gc()&#125; is the conventional and convenient</span></span><br><span class="line"><span class="comment"> * means of invoking this method.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">gc</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure><p>对应JVM源码</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">JVM_ENTRY_NO_ENV</span>(<span class="keyword">void</span>, <span class="built_in">JVM_GC</span>(<span class="keyword">void</span>))</span><br><span class="line">  <span class="built_in">JVMWrapper</span>(<span class="string">&quot;JVM_GC&quot;</span>);</span><br><span class="line">  <span class="comment">//如果没有将JVM启动参数 DisableExplicitGC 设置为 false，则执行 GC，GC 原因是 System.gc 触发，对应 GCCause::_java_lang_system_gc</span></span><br><span class="line">  <span class="keyword">if</span> (!DisableExplicitGC) &#123;</span><br><span class="line">    Universe::<span class="built_in">heap</span>()-&gt;<span class="built_in">collect</span>(GCCause::_java_lang_system_gc);</span><br><span class="line">  &#125;</span><br><span class="line">JVM_END</span><br></pre></td></tr></table></figure><p>System.gc()会执行FullGC,对新生代和老年代进行回收</p><p>注意: <strong>此时垃圾回收线程可能并不会立即执行</strong></p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="堆外内存回收"><a href="#堆外内存回收" class="headerlink" title="堆外内存回收"></a>堆外内存回收</h3><p>参考文档: <a href="http://t.zoukankan.com/duanxz-p-6089485.html">堆外内存回收方法</a></p>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM基础系列之对象的创建与访问</title>
      <link href="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/"/>
      <url>/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h3><h4 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h4><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/f301a9680197b8c1538bc25cf3823c32.jpg" alt="对象创建过程"></p><h5 id="类加载检查"><a href="#类加载检查" class="headerlink" title="类加载检查"></a>类加载检查</h5><p>虚拟机遇到一条 new 指令时: </p><ol><li>检查这个指令的参数是否能在常量池中定位到这个类的符号引用<ul><li>若常量池中没有这个类的符号引用，说明这个类还没有被定义，抛出ClassNotFoundException</li></ul></li><li>这个符号引用代表的类是否已被加载过、解析和初始化过。<ul><li>如果有，为新生对象分配内存</li><li>如果没有，必须先执行相应的类加载过程。</li></ul></li></ol><h5 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h5><p>对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。</p><p><code>一个对象所需的内存大小是在这个对象所属类被定义完就能确定的, 因此一个类所生产的所有对象的内存大小是一样的</code></p><p>分配方式无非有两种方法：</p><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/da8bf89a0c0434b587b2b37bb1bc3547.png" alt="java类内存分配"></p><ul><li>“指针碰撞”： 通过一个类似于指针的东西为对象分配内存，前提是堆空间是相对规整的。</li><li>“空闲列表”： 堆空间不规整，使用一个列表记录了哪些空间是空闲的，分配内存的时候会更新列表。 </li></ul><p><code>这是两种不同的方法，具体选择那种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。值得注意的是，复制算法内存也是规整的。</code></p><p><strong>java类内存分配如何保证并发线程安全</strong></p><p>多线程并发时会出现正在给对象 A 分配内存，还没来得及修改指针，对象 B 又用这个指针分配内存，这样就出现问题了。解决这种问题有两种方案：</p><ul><li>CAS+失败重试<ul><li>采用同步方法，使用 CAS 配上失败重试的方式保证更新操作的原子性。</li></ul></li><li>本地线程分配缓冲(Thread Local Allocation Buffer, TLAB)<ul><li>为每一个线程预先在 Eden 区分配一块儿内存(线程私有)，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配</li><li>扩展阅读： <a href="https://juejin.cn/post/6925217498723778568">TLAB</a></li></ul></li></ul><h5 id="初始化零值"><a href="#初始化零值" class="headerlink" title="初始化零值"></a>初始化零值</h5><p>虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头)</p><p><code>注意零值不是初始化方法指定的值，数字设置为0，布尔设置为false</code></p><p>保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。</p><h5 id="设置对象头"><a href="#设置对象头" class="headerlink" title="设置对象头"></a>设置对象头</h5><p>虚拟机要对对象进行必要的设置，例如</p><ul><li>这个对象是那个类的实例</li><li>如何才能找到类的元数据信息</li><li>对象的哈希码</li><li>对象的 GC 分代年龄等信息。</li></ul><p>这些信息存放在对象头中。</p><ul><li>另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。</li></ul><h5 id="执行-init-方法"><a href="#执行-init-方法" class="headerlink" title="执行 init 方法"></a>执行 init 方法</h5><p>在上⾯⼯作都完成之后，从虚拟机的视⻆来看，⼀个新的对象已经产⽣了，但从Java 程序的视⻆来看，对象创建才刚开始，⽅法还没有执⾏，所有的字段都还为零</p><p>把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。</p><p><strong>初始化顺序</strong></p><p>在new B一个实例时首先要进行类的装载。（<strong>类只有在使用New调用创建的时候才会被java类装载器装入</strong>）</p><ul><li>先装载父类A，完成静态动作（包括静态代码和变量，它们的级别是相同的，按照代码中出现的顺序初始化）</li><li>再装载子类B，完成静态动作</li></ul><p>类装载完成，开始进行实例化</p><ul><li>父类A的成员实例化（非静态代码）</li><li>父类A的构造方法</li><li>子类B的成员实例化（非静态代码）</li><li>子类B的构造方法</li></ul><h4 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h4><p>在HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。</p><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/img.png"></p><h5 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h5><p>对象头主要划分为三个部分</p><ul><li><p>存储对象自身的运行时数据(markword)</p><ul><li>哈希码[jvm计算得到，对象重写的hashcode未写入对象头]、</li><li>GC 分代年龄: 扩展阅读: <a href="file:///G:\code\example\doc\java\Java多线程.md">从对象头状态变迁看内置锁实现</a></li><li>锁状态标志</li></ul></li><li><p>类型指针（class pointer）</p><ul><li>即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Klass Word  这里其实是虚拟机设计的一个oop-klass model模型，这里的OOP是指Ordinary Object Pointer（普通对象指针），看起来像个指针实际上是藏在指针里的对象。而 klass 则包含 元数据和方法信息，用来描述 Java 类。它在64位虚拟机开启压缩指针的环境下占用 32bits 空间。</span><br></pre></td></tr></table></figure></li><li><p>数组长度（对象数组）</p></li></ul><h5 id="实例数据-instance-data"><a href="#实例数据-instance-data" class="headerlink" title="实例数据(instance data)"></a>实例数据(instance data)</h5><p>对象真正存储的有效信息，在程序中所定义的各种类型的字段内容</p><p>存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在 Java 源码中定义顺序的影响</p><p>分配策略:相同宽度的字段总是放在一起，比如double和long</p><h5 id="对齐填充-padding"><a href="#对齐填充-padding" class="headerlink" title="对齐填充(padding)"></a>对齐填充(padding)</h5><p>对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">由于HotSpot规定对象的大小必须是8的整数倍，对象头刚好是整数倍，如果实例数据不是的话，就需要占位符对齐填充。</span><br></pre></td></tr></table></figure><h4 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h4><p>对象的访问方式由虚拟机决定，java虚拟机提供两种主流的方式：句柄访问对象和直接指针访问对象</p><h5 id="句柄访问对象"><a href="#句柄访问对象" class="headerlink" title="句柄访问对象"></a>句柄访问对象</h5><p>Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；</p><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/img_1.png"></p><p>优点:引用中存储的是稳定的句柄地址,在对象被移动【垃圾收集时移动对象是常态】只需改变句柄中实例数据的指针，不需要改动引用【ref】本身。</p><h5 id="直接指针访问对象"><a href="#直接指针访问对象" class="headerlink" title="直接指针访问对象"></a>直接指针访问对象</h5><p>Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference 中存储的直接就是对象的地址。</p><p><img src="/2021/08/13/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA%E4%B8%8E%E8%AE%BF%E9%97%AE/img_2.png"></p><p>优点:优势很明显，就是速度快，相比于句柄访问少了一次指针定位的开销时间。【可能是出于Java中对象的访问时十分频繁的,平时我们常用的JVM HotSpot采用此种方式】</p><h4 id="创建一个新对象的内存分配全流程"><a href="#创建一个新对象的内存分配全流程" class="headerlink" title="创建一个新对象的内存分配全流程"></a>创建一个新对象的内存分配全流程</h4>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM基础系列之Java类加载机制</title>
      <link href="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"/>
      <url>/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h3><h4 id="什么叫类加载"><a href="#什么叫类加载" class="headerlink" title="什么叫类加载"></a>什么叫类加载</h4><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/9f1e696004981c0f9249ad145474feea.jpg" alt="类装载器"></p><p>类的加载指的是将类的.class文件中的二进制数据读入到内存中，并为之创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。</p><p>类的加载过程是由类加载器来完成，类加载器由JVM提供。我们开发人员也可以通过继承ClassLoader来实现自己的类加载器。</p><h4 id="什么时候启动类加载"><a href="#什么时候启动类加载" class="headerlink" title="什么时候启动类加载"></a>什么时候启动类加载</h4><p>类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它。</p><p>如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误），如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。</p><h4 id="从什么地方加载-class文件"><a href="#从什么地方加载-class文件" class="headerlink" title="从什么地方加载.class文件"></a>从什么地方加载.class文件</h4><ul><li>本地磁盘</li><li>网上加载.class文件</li><li>数据库中</li><li>压缩文件（ZAR，JAR等）</li><li>从其他文件生成（JSP应用）</li><li>把一个java源文件动态编译，并执行加载。</li></ul><h4 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h4><p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：<strong>加载、验证、准备、解析、初始化、使用和卸载</strong>七个阶段。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/f2f2e86a8bedea038839b34d67e7dc90.jpg" alt="类生命周期"></p><p>类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">加载、验证、准备和初始化这四个阶段发生的顺序是确定的，</span><br><span class="line"></span><br><span class="line">而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始。</span><br><span class="line"></span><br><span class="line">另外,注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。</span><br></pre></td></tr></table></figure><h5 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h5><ul><li>通过类的全限定名称获取其定义的二进制字节流</li><li>将字节流代表的今天存储结构转化为方法区的运行时数据结构</li><li>在<strong>堆</strong>中生成一个代表这个类的 java.lang.Class 对象，作为方法区这些数据的访问入口。（注意不是方法区的数据结构）</li></ul><h5 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h5><blockquote><p>通过类的加载，内存中已经创建了一个Class对象。链接负责将二进制数据合并到 JRE中。链接需要通过验证、准备、解析三个阶段。</p></blockquote><h6 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h6><blockquote><p>验证阶段用于检查被加载的类是否有正确的内部结构，并和其他类协调一致，即是否满足java虚拟机的约束。</p></blockquote><ol><li>文件格式的验证：验证.class文件字节流是否符合class文件的格式的规范，并且能够被当前版本的虚拟机处理。这里面主要对魔数、主版本号、常量池等等的校验。</li><li>元数据验证：主要是对字节码描述的信息进行语义分析，以保证其描述的信息符合java语言规范的要求，比如说验证这个类是不是有父类，类中的字段方法是不是和父类冲突等等。</li><li>字节码验证：这是整个验证过程最复杂的阶段，主要是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。在元数据验证阶段对数据类型做出验证后，这个阶段主要对类的方法做出分析，保证类的方法在运行时不会做出危害虚拟机安全的事。</li><li>符号引用验证：它是验证的最后一个阶段，发生在虚拟机将符号引用转化为直接引用的时候。主要是对类自身以外的信息进行校验。目的是确保解析动作能够完成。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">符号引用:</span><br><span class="line">以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义的定位到目标即可。</span><br><span class="line">例如，在Class文件中它以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现。</span><br><span class="line">符号引用与虚拟机的内存布局无关，引用的目标并不一定加载到内存中。</span><br><span class="line">在Java中，一个java类将会编译成一个class文件。</span><br><span class="line">在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。</span><br><span class="line">比如org.simple.People类引用了org.simple.Language类，在编译时People类并不知道Language类的实际内存地址，因此只能使用符号org.simple.Language（假设是这个，当然实际中是由类似于CONSTANT_Class_info的常量来表示的）来表示Language类的地址。</span><br><span class="line">各种虚拟机实现的内存布局可能有所不同，但是它们能接受的符号引用都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。</span><br><span class="line">  </span><br><span class="line">直接引用:</span><br><span class="line">直接指向目标的指针（比如，指向“类型”【Class对象】、类变量、类方法的直接引用可能是指向方法区的指针）</span><br><span class="line">相对偏移量（比如，指向实例变量、实例方法的直接引用都是偏移量）</span><br><span class="line">一个能间接定位到目标的句柄</span><br><span class="line">直接引用是和虚拟机的布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经被加载入内存中了。</span><br></pre></td></tr></table></figure><blockquote><p>对整个类加载机制而言，验证阶段是一个很重要但是非必需的阶段，如果我们的代码能够确保没有问题，那么我们就没有必要去验证，毕竟验证需要花费一定的的时间。当然我们可以使用-Xverfity:none来关闭大部分的验证。</p></blockquote></li></ol><h6 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h6><blockquote><p>准备阶段主要为类变量分配内存并设置初始值。</p></blockquote><ul><li>类变量（static）会分配内存（方法区），但是实例变量不会，实例变量主要随着对象的实例化一块分配到java堆中;</li><li>这里的初始值指的是数据类型默认值(例如int为0， boolean为false)，而不是代码中被显示赋予的值。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public static int value = 1; //在这里准备阶段过后的value值为0，而不是1。赋值为1的动作在初始化阶段。</span><br></pre></td></tr></table></figure><h6 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h6>在类还未加载到虚拟机时，无法获取实际方法的引用地址。对于一个方法的调用，编译器会生成一个包含目标方法所在的类、目标方法名、接收参数类型以及返回值类型的符号引用，来指代要调用的方法。</li></ul><blockquote><p>解析阶段主要是虚拟机将常量池中的符号引用转化为直接引用的过程。</p></blockquote><p>主要针对<strong>类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符</strong>7类符号引用进行。</p><p>如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必会触发解析与初始化）</p><h5 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h5><blockquote><p>在初始化阶段，主要为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。</p></blockquote><h6 id="类变量初始化方式"><a href="#类变量初始化方式" class="headerlink" title="类变量初始化方式"></a>类变量初始化方式</h6><ol><li>申明类变量时指定初始值</li><li>使用静态代码块为类变量指定初始值</li></ol><h6 id="JVM初始化步骤"><a href="#JVM初始化步骤" class="headerlink" title="JVM初始化步骤"></a>JVM初始化步骤</h6><ul><li>假如这个类还没有被加载和连接，则程序先加载并连接该类</li><li>假如该类的直接父类还没有被初始化，则先初始化其直接父类</li><li>假如类中有初始化语句，则系统依次执行这些初始化语句</li></ul><h6 id="类初始化时机"><a href="#类初始化时机" class="headerlink" title="类初始化时机"></a>类初始化时机</h6><blockquote><p>只有对类的主动使用才会导致类的初始化</p></blockquote><ol><li>当虚拟机启动时(用户需要指定一个主类（包含main()方法的类）)，初始化用户指定的主类。</li><li>当遇到用以新建目标类实例的new指令时，初始化new指令的目标类</li><li>当遇到调用静态方法或者使用静态变量或者对该静态变量赋值(放入常量池中的常量除外)，初始化静态变量或方法所在的类； </li><li>初始化某个类的子类，则其父类也会被初始化</li><li>如果一个接口定义了default方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口初始化；</li><li>使用反射API对某个类进行反射调用时（如 Class.forName(“com.hepeng.Test”)），初始化这个类</li><li>使用jdk1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、RE_invokeStatic的方法句柄，并且这个方法句柄对应的类没有进行初始化，则需要先触发其初始化。</li></ol><h6 id="lt-clinit-gt-方法"><a href="#lt-clinit-gt-方法" class="headerlink" title="&lt; clinit&gt;方法"></a>&lt; clinit&gt;方法</h6><blockquote><p>虚拟机会收集类及父类中的类变量及类方法组合为&lt; clinit&gt;方法，根据定义的顺序进行初始化。</p></blockquote><ol><li><p>虚拟机会保证子类的&lt; clinit&gt;执行之前，父类的&lt; clinit&gt;方法先执行完毕。</p> <details><summary>一个简单的小Demo</summary>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;    </span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> A = <span class="number">10</span>;    </span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        A = <span class="number">20</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test1</span> <span class="keyword">extends</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> B = A;    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;        </span><br><span class="line">        System.out.println(Test1.B);    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 输出结果</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">20</span><br></pre></td></tr></table></figure><p> 从输出中看出，父类的静态初始化块在子类静态变量初始化之前初始化完毕，所以输出结果是20，不是10。</p> </details> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">因此，虚拟机中第一个被执行完毕的&lt; clinit&gt;方法肯定是java.lang.Object方法</span><br></pre></td></tr></table></figure></li><li><p>如果类或者父类中都没有静态变量及方法，虚拟机不会为其生成&lt; clinit&gt;方法。</p></li><li><p>接口与类不同的是，执行接口的＜clinit＞方法不需要先执行父接口的＜clinit＞方法。 </p><ul><li>只有当父接口中定义的变量使用时，父接口才会初始化。</li><li>另外，接口的实现类在初始化时也一样不会执行接口的＜clinit＞方法。</li></ul> <details><summary>这与普通类加载不一致</summary> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">InterfaceInitTest</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> A = CurrentTime.getTime();</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">InterfaceInitTest1</span> <span class="keyword">extends</span> <span class="title">InterfaceInitTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> B = <span class="number">100</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InterfaceInitTestImpl</span> <span class="keyword">implements</span> <span class="title">InterfaceInitTest1</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(InterfaceInitTestImpl.B);</span><br><span class="line">        System.out.println(<span class="string">&quot;---------------------------&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;当前时间：&quot;</span>+InterfaceInitTestImpl.A);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CurrentTime</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;加载了InterfaceInitTest接口&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 输出结果</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">100</span><br><span class="line">---------------------------</span><br><span class="line">加载了InterfaceInitTest接口</span><br><span class="line">当前时间：1560158880660</span><br></pre></td></tr></table></figure> </details></li><li><p>虚拟机会保证一个类的&lt; clinit&gt;方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只有一个线程去执行这个类的&lt; clinit&gt;方法，其他线程都需要阻塞等待，直到活动线程执行&lt; clinit&gt;方法完毕。</p> <details><summary>Demo</summary> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiThreadInitTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> A = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        System.out.println(Thread.currentThread()+<span class="string">&quot;init MultiThreadInitTest&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123; </span><br><span class="line">            TimeUnit.SECONDS.sleep(<span class="number">10</span>); </span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123; </span><br><span class="line">            e.printStackTrace(); </span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Runnable runnable = () -&gt; &#123; </span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot;start&quot;</span>);</span><br><span class="line">            System.out.println(MultiThreadInitTest.A);</span><br><span class="line">            System.out.println(Thread.currentThread() + <span class="string">&quot;run over&quot;</span>); </span><br><span class="line">        &#125;;</span><br><span class="line">        Thread thread1 = <span class="keyword">new</span> Thread(runnable);</span><br><span class="line">        Thread thread2 = <span class="keyword">new</span> Thread(runnable);</span><br><span class="line">        thread1.start();</span><br><span class="line">        thread2.start();</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure><p> 输出结果</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Thread[main,5,main]init MultiThreadInitTest</span><br><span class="line">Thread[Thread-0,5,main]start</span><br><span class="line">10</span><br><span class="line">Thread[Thread-0,5,main]run over</span><br><span class="line">Thread[Thread-1,5,main]start</span><br><span class="line">10</span><br><span class="line">Thread[Thread-1,5,main]run over</span><br></pre></td></tr></table></figure><p> 只有第一个线程对MultiThreadInitTest进行了一次初始化，第二个线程一直阻塞等待等第一个线程初始化完毕</p> </details></li></ol><h6 id="final定义的初始化"><a href="#final定义的初始化" class="headerlink" title="final定义的初始化"></a>final定义的初始化</h6><p>对于一个使用final定义的常量，如果在编译时就已经确定了值，在引用时不会触发初始化，因为在编译的时候就已经确定下来，就是“宏变量”。如果在编译时无法确定，在初次使用才会导致初始化。</p><details><summary>单例模式静态内部类实现方式</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StaticInnerSingleton</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 使用静态内部类实现单例：</span></span><br><span class="line"><span class="comment">   * 1：线程安全</span></span><br><span class="line"><span class="comment">   * 2：懒加载</span></span><br><span class="line"><span class="comment">   * 3：非反序列化安全，即反序列化得到的对象与序列化时的单例对象不是同一个，违反单例原则</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">LazyHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> StaticInnerSingleton INNER_SINGLETON = <span class="keyword">new</span> StaticInnerSingleton();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">StaticInnerSingleton</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> StaticInnerSingleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> LazyHolder.INNER_SINGLETON;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看到单例实例使用final定义，但在编译时无法确定下来，所以在第一次使用StaticInnerSingleton.getInstance()方法时，才会触发静态内部类的加载，也就是延迟加载。</p><p>这里想指出，<strong>如果final定义的变量在编译时无法确定，则在使用时还是会进行类的初始化</strong>。</p></details><h6 id="ClassLoader只会对类进行加载，不会进行初始化"><a href="#ClassLoader只会对类进行加载，不会进行初始化" class="headerlink" title="ClassLoader只会对类进行加载，不会进行初始化"></a>ClassLoader只会对类进行加载，不会进行初始化</h6><h4 id="类加载方式"><a href="#类加载方式" class="headerlink" title="类加载方式"></a>类加载方式</h4><ul><li><p>通过命令行启动应用时由JVM初始化加载含有main()方法的主类。</p></li><li><p>通过Class.forName()方法动态加载，会默认执行初始化块（static{}），但是Class.forName(name,initialize,loader)中的initialze可指定是否要执行初始化块。</p></li><li><p>通过ClassLoader.loadClass()方法动态加载，不会执行初始化块。</p></li></ul><h3 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h3><p>Java虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便<strong>让应用程序自己决定如何去获取所需的类</strong>。实现这个动作的代码被称为“类加载器”（Class Loader）。</p><h4 id="类与类加载器"><a href="#类与类加载器" class="headerlink" title="类与类加载器"></a>类与类加载器</h4><p>类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远超类加载阶段。</p><p>对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。</p><p>这句话可以表达得更通俗一些：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">每个类在JVM中使用全限定类名（包名+类名）与类加载器联合为唯一的ID，所以如果同一个类使用不同的类加载器，可以被加载到虚拟机，但彼此不兼容。</span><br></pre></td></tr></table></figure><h4 id="类加载机制-1"><a href="#类加载机制-1" class="headerlink" title="类加载机制"></a>类加载机制</h4><ol><li><strong>全盘负责</strong>：   当一个类加载器负责加载某个Class时，该Class所依赖和引用的其他Class也由该类加载器负责载入，除非显示使用另一个类加载器来载入。</li><li><strong>父类委托（双亲委派）</strong>：先让父加载器试图加载该Class，只有在父加载器无法加载时该类加载器才会尝试从自己的类路径中加载该类。</li><li><strong>缓存机制</strong>：缓存机制会将已经加载的class缓存起来，当程序中需要使用某个Class时，类加载器先从缓存区中搜寻该Class，只有当缓存中不存在该Class时，系统才会读取该类的二进制数据，并将其转换为Class对象，存入缓存中。这就是为什么更改了class后，需要重启JVM才生效的原因。</li></ol><h4 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h4><h5 id="什么是双亲委派模型"><a href="#什么是双亲委派模型" class="headerlink" title="什么是双亲委派模型"></a>什么是双亲委派模型</h5><p>Java语言系统自带有三个类加载器:</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/c2a7c4bf19cfc90945643d8d94ac0f3d.png" alt="双亲委派机制"></p><ul><li><p>Bootstrap ClassLoader：启动类加载器, 最顶层的加载类</p><blockquote><p>这个类加载器使用C++语言实现，是虚拟机自身的一部分<br>其他所有的类加载器都由Java语言实现，独立存在于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。</p></blockquote><ul><li>主要加载核心类库，也就是我们环境变量下面%JRE_HOME%\lib下的rt.jar、resources.jar、charsets.jar和class等(按照文件名识别，名字不符合的类库即使放在lib目录中也不会被加载)。</li><li>另外需要注意的是可以通过启动jvm时指定-Xbootclasspath和路径来改变Bootstrap ClassLoader的加载目录。比如java -Xbootclasspath/a:path被指定的文件追加到默认的bootstrap路径中。</li><li>我们可以打开我的电脑，在上面的目录下查看，看看这些jar包是不是存在于这个目录。</li></ul></li><li><p>Extention ClassLoader ：扩展的类加载器</p><blockquote><p>类sun.misc.Launcher$ExtClassLoader中以Java方式实现</p></blockquote><ul><li>加载目录%JRE_HOME%\lib\ext目录下的jar包和class文件。</li><li>还可以加载-D java.ext.dirs选项指定的目录。</li></ul></li><li><p>Appclass Loader：也称为SystemAppClass。</p><blockquote><p>sun.misc.Launcher$AppClassLoader来实现。是ClassLoader类中的getSystem-ClassLoader()方法的返回值，所以有些场合中也称它为“系统类加载器”</p></blockquote><ul><li>它负责加载用户类路径（ClassPath）上所有的类库，开发者同样可以直接在代码中使用这个类加载器。 </li></ul></li></ul><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B%E5%9B%BE.png"></p><p>加载器加载顺序： Bootstrap ClassLoader &gt; Extention ClassLoader &gt; Appclass Loader</p><h5 id="双亲委派机制"><a href="#双亲委派机制" class="headerlink" title="双亲委派机制"></a>双亲委派机制</h5><p>当一个类加载器收到类加载任务，会先交给其父类加载器去完成，因此最终加载任务都会传递到顶层的启动类加载器，只有当父类加载器无法完成加载任务时，才会尝试执行加载任务。</p><ul><li>可以避免重复加载，父类已经加载了，子类就不需要再次加载</li><li>更加安全，很好的解决了各个类加载器的基础类的统一问题，如果不使用该种方式，那么用户可以随意定义类加载器来加载核心api，会带来相关隐患。</li></ul><blockquote><p>类加载可以理解为通过类加载器（ClassLoader）定制化的类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”的动作，一个复杂的JAVA程序可能会包含大量的依赖，而JAVA&amp;框架本身也有自己依赖，两个不同程序的依赖可能会产生冲突，存在同一个全限定名加载出来的接口也可能有不兼容的情况。<br>通过双亲委派模型（自下而上扫描，扫描结束后不直接加载，交给父加载器，父加载器反馈不能加载后再通过当前加载器加载），有效解决重复加载和加载安全问题。</p></blockquote><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8BJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F.png"></p><h5 id="Tomcat为什么要打破双亲委派机制"><a href="#Tomcat为什么要打破双亲委派机制" class="headerlink" title="Tomcat为什么要打破双亲委派机制"></a>Tomcat为什么要打破双亲委派机制</h5><p>tomcat运行起来也就是个jvm实例，内部会运行多个应用，<strong>不同应用可能会加载同一个类的不同版本</strong>，如果使用双亲委派机制，就只能加载一个类的一个版本，就无法满足要求了；</p><p>所以tomcat会为每个应用创建一个classloader，重写loadClass方法，就可以打破双亲委派机制，加载一个类的不同版本。</p><h4 id="自定义加载器"><a href="#自定义加载器" class="headerlink" title="自定义加载器"></a>自定义加载器</h4><p>实现方案:</p><ul><li>遵守双亲委派模型：继承ClassLoader，重写findClass()方法。</li><li>破坏双亲委派模型：继承ClassLoader,重写loadClass()方法。</li></ul><p>通常我们推荐采用第一种方法自定义类加载器，最大程度上的遵守双亲委派模型。</p><p>实现步骤: </p><ul><li>创建一个类继承ClassLoader抽象类</li><li>重写findClass()方法</li><li>在findClass()方法中调用defineClass()</li></ul><h4 id="OSGI动态模型系统"><a href="#OSGI动态模型系统" class="headerlink" title="OSGI动态模型系统"></a>OSGI动态模型系统</h4><p>OSGi(Open Service Gateway Initiative)，是面向 Java 的动态模型系统，是 Java 动态化模块化系统的一系列规范。</p><p>OSGi 服务平台提供在多种网络设备上无需重启的动态改变构造的功能。为了最小化耦合度和促使这些耦合度可管理，OSGi 技术提供一种面向服务的架构，它能使这些组件动态地发现对方。</p><p>OSGi 旨在为实现 Java 程序的模块化编程提供基础条件，基于OSGi的程序很可能可以实现<strong>模块级的热插拔功能</strong>，当程序升级更新时，可以只停用、重新安装然后启动程序的其中一部分，这对企 业级程序开发来说是非常具有诱惑力的特性。</p><p>OSGi 描绘了一个很美好的模块化开发目标，而且定义了实现这个目标的所需要服务与架构，同时也有成熟的框架进行实现支持。但并非所有的应用都适合采用 OSGi 作为基础架构，它在提供强大功能同时，也引入了额外的复杂度，因为它不遵守了类加载的双亲委托模型。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM基础系列之运行时内存分配模型</title>
      <link href="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/"/>
      <url>/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h3 id="JVM是什么"><a href="#JVM是什么" class="headerlink" title="JVM是什么"></a>JVM是什么</h3><p>而对于不同的操作系统，系统操作指令集（CPU原语）往往是不同的。JVM即Java虚拟机，是基于C/C++开发的一种抽象计算机，它对不同平台的系统指令集进行封装，对外提供了一套固定的指令集，在运行时操作各种内存区域，使JAVA成为可以跨平台的语言。</p><p><code>一般来说，使用特定编译器编译的程序只能在对应的平台运行，这里也可以说编译器是与平台相关的，编译后的文件也是与平台相关的。我们说的语言跨平台是编译后的文件跨平台，而不是源程序跨平台。</code></p><p>虚拟机有很多种，不同厂商提供了不同实现，只要遵循虚拟机规范即可，目前我们所说的虚拟机一般指的是Hot Spot。</p><p>JVM对Java语言一无所知，只知道一种特定的二进制格式，即类文件格式，我们写好的程序最终交给JVM执行的时候会被编译成二进制格式，JVM只认识二进制格式，所以任何语言只要编译后的格式符合要求，都可以在JVM上运行。</p><p><strong>JVM 组成部分</strong></p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img.png"></p><ul><li>类加载器，在 JVM 启动时或者类运行时将需要的 class 加载到 JVM 中。</li><li>内存区，将内存划分成若干个区以模拟实际机器上的存储、记录和调度功能模块，如实际机器上的各种功能的寄存器或者 PC 指针的记录器等。</li><li>执行引擎，执行引擎的任务是负责执行 class 文件中包含的字节码指令，相当于实际机器上的 CPU 。</li><li>本地方法调用，调用 C 或 C++ 实现的本地方法的代码返回结果。</li></ul><p>一个Java类在经过编译好类加载之后，会将加载后的数据放入运行时数据区域，这样我们在运行程序时就可以直接从运行时数据区域中读取信息。</p><h3 id="JVM运行时数据区域详解"><a href="#JVM运行时数据区域详解" class="headerlink" title="JVM运行时数据区域详解"></a>JVM运行时数据区域详解</h3><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_1.png"></p><p>JVM 内存布局规定了 Java 在运行过程中内存申请、分配、管理的策略 ，保证了 JVM 的高效稳定运行。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_8.png"></p><h4 id="从jdk版本差异解读各内存区域"><a href="#从jdk版本差异解读各内存区域" class="headerlink" title="从jdk版本差异解读各内存区域"></a>从jdk版本差异解读各内存区域</h4><p>实际上，为了更好的适应 CPU 性能提升，最大限度提升JVM 运行效率，JDK中各个版本对JVM进行了一些迭代，示意图如下</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/JVM%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB.png"></p><p>JDK1.6、JDK1.7、JDK1.8 JVM 内存模型主要有以下差异：</p><ul><li>JDK 1.6：有永久代，静态变量存放在永久代上。</li><li>JDK 1.7：有永久代，但已经把字符串常量池、静态变量，存放在堆上。逐渐的减少永久代的使用。</li><li>JDK 1.8：无永久代，运行时常量池、类常量池，都保存在元数据区，也就是常说的元空间。但字符串常量池仍然存放在堆上。</li></ul><h4 id="从线程是否共享解读各内存区域"><a href="#从线程是否共享解读各内存区域" class="headerlink" title="从线程是否共享解读各内存区域"></a>从线程是否共享解读各内存区域</h4><p>如果按照线程是否共享来分类的话，如下图所示：</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_9.png"></p><h5 id="线程私有"><a href="#线程私有" class="headerlink" title="线程私有"></a>线程私有</h5><h6 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h6><ul><li>字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。</li><li>在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储。<code>由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，CPU 只有把数据装载到寄存器才能够运行。寄存器存储指令相关的现场信息，由于CPU 时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。</code><ul><li>每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器用来存放执行指令的偏移量和行号指示器等，线程执行或恢复都要依赖程序计数器。</li></ul></li><li>如果该方法不是Native方法，即PC寄存器会记录当前正在执行的java虚拟机指令的地址; 如果线程当前执行的方法是本地的，那么java虚拟机的PC寄存器的值就是Undefined。</li><li><strong>唯一不会发生OOM的区</strong>，随线程创建而创建、随线程死亡而死亡，因此不需要进行 GC。</li></ul><h6 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h6><ul><li><p>Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：<strong>局部变量表、操作数栈、动态链接、方法出口信息</strong>。</p></li><li><p>局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用</p><ul><li><p>存放方法参数和方法内部定义的局部变量</p><p><code>所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</code> </p><ul><li><p>如果局部变量是Java的8种基本基本数据类型，则存在局部变量表中，如果是引用类型。如new出来的String，局部变量表中存的是引用，而实例在堆中。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_10.png"></p></li></ul></li></ul></li><li><p>操作数栈</p><ul><li>操作数栈（Operand Stack）看名字可以知道是一个栈结构。</li><li>Java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。</li><li>当JVM为方法创建栈帧的时候，在栈帧中为方法创建一个操作数栈，保证方法内指令可以完成工作。</li></ul><details><summary>用实操理解一下</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* <span class="doctag">@author</span> Richard_yyf</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OperandStackTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> a + b;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译生成.class文件之后，再反汇编查看汇编指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">javac OperandStackTest.java</span><br><span class="line">javap -v OperandStackTest.class &gt; 1.txt</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public int sum(int, int);</span><br><span class="line">  descriptor: (II)I</span><br><span class="line">  flags: ACC_PUBLIC</span><br><span class="line">  Code:</span><br><span class="line">    stack=2, locals=3, args_size=3 // 最大栈深度为2 局部变量个数为3</span><br><span class="line">       0: iload_1 // 局部变量1 压栈</span><br><span class="line">       1: iload_2 // 局部变量2 压栈</span><br><span class="line">       2: iadd    // 栈顶两个元素相加，计算结果压栈</span><br><span class="line">       3: ireturn</span><br><span class="line">    LineNumberTable:</span><br><span class="line">      line 10: 0</span><br></pre></td></tr></table></figure></details></li><li><p>动态链接</p><ul><li>每个栈帧中包含一个在常量池中<strong>对当前方法的引用</strong>， 目的是<strong>支持方法调用过程的动态连接</strong>。</li></ul></li><li><p>方法返回地址</p><p>方法执行时有两种退出情况：</p><ul><li>正常退出，即正常执行到任何方法的返回字节码指令，如 RETURN、IRETURN、ARETURN等</li><li>异常退出</li></ul><p>无论何种退出情况，都将返回至方法当前被调用的位置。方法退出的过程相当于弹出当前栈帧，退出可能有三种方式：</p><ul><li>返回值压入上层调用栈帧</li><li>异常信息抛给能够处理的栈帧</li><li>PC 计数器指向方法调用后的下一条指令</li></ul><p>扩展阅读： <a href="https://link.juejin.cn/?target=https://louluan.blog.csdn.net/article/details/50412126">JVM机器指令集图解</a></p></li><li><p>为执行字节码服务</p></li><li><p>StackOverFlowError（不允许动态扩展，栈深度大于虚拟机允许的栈深度） 和 OutOfMemoryError （允许动态扩展，内存不足）</p></li><li><p>方法执行时入栈，方法执行完出栈，入栈出栈的时机很明确，所以这块区域不需要进行 GC。<br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img4.png"></p></li><li><p>扩展阅读： <a href="https://www.cnblogs.com/noKing/p/8167700.html">栈帧</a></p></li><li><p>扩展阅读： <a href="https://www.pianshen.com/article/9519386034/">逃逸分析-栈上分配-TLAB</a>, 对于开启逃逸分析的程序而言，不会逃逸的对象也会分配在栈上。</p></li></ul><h6 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h6><ul><li>与虚拟机栈相似，为执行Native服务。</li><li>本地方法栈和虚拟机栈在有的虚拟机是合在一起的，例如Hot Spot虚拟机。</li></ul><h5 id="线程共享"><a href="#线程共享" class="headerlink" title="线程共享"></a>线程共享</h5><h6 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h6><ul><li><p>所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放<strong>对象实例和数组</strong>，<em>几乎</em> 所有的对象实例以及数组都在这里分配内存(随着JIT编译器的发展和逃逸分析技术的成熟，这个说法也不是那么绝对)。</p><p>  <img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/cb25f0d4c52a9ffca1925e9694c6954d.jpg" alt="java堆空间"></p></li><li><p>java8后永久代已移除。</p></li><li><p>堆中的对象永远不会被显式释放，必须由GC回收。GC主要区域，也叫GC堆，采用分代垃圾收集算法（年轻代&amp;老年代）。</p></li><li><p>Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。</p><p><code>值得注意的是，在通常情况下，服务器在运行过程中，堆空间不断地扩容与回缩，会形成不必要的系统压力 所以在线上生产环境中 JVM的Xms和 Xmx会设置成同样大小，避免在GC 后调整堆大小时带来的额外压力。</code></p></li></ul><h6 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h6><ul><li>方法区也是所有线程共享。主要用于存储<strong>类的信息、常量池、方法数据、方法代码</strong>等。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。</li><li>JDK 1.8中移除整个永久代，取而代之的是一个叫元空间（Metaspace）的区域, 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。  空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。</li><li>如果方法区的内存无法满足分配请求时也会抛出OutOfMemoryError</li><li>扩展阅读：<a href="https://www.cnblogs.com/paddix/p/5309550.html">Java8内存模型—永久代(PermGen)和元空间(Metaspace)</a></li></ul><p><em>运行时常量池</em></p><p>方法区的一部分，用于存储编译生成的字面量（基本数据类型或被final修饰的常量或字符串）和符号引用，类或接口的运行时常量池是在java虚拟机创建类或接口时创建的。</p><ul><li>jdk1.6及之前: Java中的字符串是放在方法区中的运行时常量池内，</li><li>jdk1.7以后: 将字符串常量池拿出来放在了堆中。</li></ul><details><summary>一个有趣的例子</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GcDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String [] args)</span> </span>&#123;</span><br><span class="line">        String str = <span class="keyword">new</span> String(<span class="string">&quot;lonely&quot;</span>)+<span class="keyword">new</span> String(<span class="string">&quot;wolf&quot;</span>);</span><br><span class="line">        System.out.println(str == str.intern());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码在jdk1.6中打印false，在jdk1.7和jdk1.8中打印true。 关于intern()方法：</p><ul><li>JDK1.6：调用String.intern()方法，会先去检查常量池中是否存在该字符串，如果不存在，则会在方法区中创建一个字符串，而new String()创建的字符串在堆中，两个字符串的地址当然不相等。</li><li>JDK1.8：字符串常量池从方法区的运行时常量池移到了堆中，调用String.intern()方法，首先会检查常量池是否存在，如果不存在，那么就会创建一个常量，并将引用指向堆，也就是说不会再重新创建一个字符串对象了，两者都会指向堆中的对象，所以返回true。</li></ul><p>只有一个new String()，产生两个对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GcDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String [] args)</span> </span>&#123;</span><br><span class="line">        String str = <span class="keyword">new</span> String(<span class="string">&quot;lonely&quot;</span>);</span><br><span class="line">        System.out.println(str == str.intern());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只有一个new String()，在jdk1.7和jdk1.8也会返回false，我们假设一开始字符串常量池没有任何字符串，执行一个new String(“lonely”)会产生两个对象，一个在堆，一个在字符串常量池。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_5.png"></p><p>String.intern()先检查字符串常量池，发现存在”lonely”的字符串，所以直接返回，这时候两个地址不一样，所以返回false。</p><ul><li><p>new String(“lonely”)+new String(“wolf”)会产生5个对象，2个在字符串常量池，3个在堆。<br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_6.png" alt="img.png"></p><ul><li>如果在1.7和1.8中会检查字符串常量池，发现没有lonelywolf的字符串，所以会在字符串常量池创建一个，指向堆中的字符串。</li><li>JDK1.6中不会指向堆，会重新创建一个lonelywolf的字符串放到字符串常量池，所以才会产生不同的结果。</li></ul></li></ul></details><h6 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h6><ul><li>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。</li><li>使用Native函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。  这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。</li><li>Java8后<strong>方法区的实现-元空间就在使用了直接内存实现</strong>（不进行GC进而提高了性能）</li><li>Code Cache<ul><li><strong>JVM代码缓存是JVM将其字节码存储为本机代码的区域</strong>。我们将可执行本机代码的每个块称为 nmethod 。该 nmethod可能是一个完整的或内联Java方法。</li><li>实时（JIT）编译器是代码缓存区域的最大消费者。这就是为什么一些开发人员将此内存称为JIT代码缓存的原因。 </li><li>一般情况下我们是不会关心这部分区域的且大部分开发人员对这块区域也不熟悉。如果这块区域OOM了，在日志里面就会看到 java.lang.OutOfMemoryError code cache。</li><li>扩展阅读: <a href="https://link.juejin.cn/?target=https://www.baeldung.com/jvm-code-cache">Introduction to JVM Code Cache</a></li></ul></li><li>也可能导致 OutOfMemoryError 异常出现。</li><li>扩展阅读：<a href="https://link.juejin.cn/?target=https://www.jianshu.com/p/35cf0f348275">堆外内存回收</a></li></ul><h3 id="从进程与线程的角度理解JVM运行时数据区设计原理"><a href="#从进程与线程的角度理解JVM运行时数据区设计原理" class="headerlink" title="从进程与线程的角度理解JVM运行时数据区设计原理"></a>从进程与线程的角度理解JVM运行时数据区设计原理</h3><p>首先，我们回顾一下进程与线程的区别与联系:</p><p><strong>进程 = 线程+内存+文件/网络句柄</strong></p><ul><li>这里的内存是逻辑内存，指的是内存的寻址空间。每个进程的内存是相互独立的。</li><li>文件/网络句柄是所有的进程所共有的，例如打开同一个文件，去抢同一个网络的端口这样的操作是被允许的</li></ul><p><strong>线程 = 栈+PC+TLS</strong></p><ul><li>通常都是说调用堆栈，调用堆栈就是调用栈的意思(这里的堆是没有含义的)。每次调用的时候，会把所有的参数和返回地址压入到栈中。</li><li>Program Counter: 程序计数器，我们的进程只是一个容器。PC就是指向当前的指令，而这个指令是放在内存中。每个线程都有一串自己的指针，去指向自己当前所在内存的指针。</li><li>thread local storage: 线程独立的内存就是TLS，可以用来存储我们线程所独有的数据。</li></ul><p><strong>总结如下</strong></p><ol><li>线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；</li><li>一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线；</li><li>进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见；</li><li>调度和切换：线程上下文切换比进程上下文切换要快得多。</li></ol><p>线程与进程关系的示意图：<br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_2.png"><br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_3.png"></p><p><strong>对于一个JAVA进程而言</strong>：</p><ul><li>JAVA进程间的内存分配保持独立</li><li>JAVA同进程的多线程间共享代码段（方法区）、数据集（堆）</li><li>JAVA各线程分别维护自己的寄存器（程序计数器）和方法栈（分为本地方法栈和虚拟机栈）</li></ul><h3 id="从操作系统层面理解JVM与系统物理内存分配"><a href="#从操作系统层面理解JVM与系统物理内存分配" class="headerlink" title="从操作系统层面理解JVM与系统物理内存分配"></a>从操作系统层面理解JVM与系统物理内存分配</h3><h4 id="系统进程占用的物理内存高于-Xmx"><a href="#系统进程占用的物理内存高于-Xmx" class="headerlink" title="系统进程占用的物理内存高于-Xmx"></a>系统进程占用的物理内存高于-Xmx</h4><p>在实际运行过程中，我们通常会发现: 系统进程占用的物理内存(Res/Rss)会大于设置的Xmx值</p><p>实际上，-Xmx和-Xms参数实际上只是Java堆对象将会占用的内存，而堆只是影响Java程序占用内存数量的一个因素。</p><p>除了堆，影响Java程序所占用内存的因素还包括: 栈、永生代、JVM本身、NIO中的DirectBuffer等。</p><p>因此，一般使用Xmx分配给JVM的，肯定不能太多。</p><p>而且，在操作系统上，运行的不仅仅是JVM应用，还会有其他一些守护进程，比如各种日志收集工具、监控工具、安全工具等。它们虽然占用的内存不是很多，但累加起来还是比较可观的。JVM内存和操作系统的剩余内存是一个此消彼长的关系，这些小内存挤占了JVM的发挥空间，就容易出问题。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_7.png"></p><p>JVM是我们的主体，所以要把它放在主人公的位置。这种划分方式，就可以把整个内存搞成JVM内存、操作系统物理内存、SWAP三个部分。</p><p>当JVM和其他程序占满了物理内存，接着占满了SWAP内存（交换分区一般不开，此处不展开），当在需要申请内存空间的时候，操作系统发现没有可用的内存空间了。</p><p>这个时候，Linux会启动oom-killer，杀死占用内存最大的进程，这个时候大概率我们的JVM进程。</p><p>由于这个OOM为操作系统本身的OOM，这个时候会出现的现象为: <strong>java进程死了，但是没有留下任何日志</strong></p><p><code>此日志可以通过dmesg命令找到，属于操作系统范畴</code></p><h4 id="对内存做一些更细致的划分"><a href="#对内存做一些更细致的划分" class="headerlink" title="对内存做一些更细致的划分"></a>对内存做一些更细致的划分</h4><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/%E5%86%85%E5%AD%98.png"></p><ul><li>堆内内存: 是我们平常打交道最多的地方，因为我们大部分Java对象，都是在堆上分配的。<ul><li>一旦有溢出问题，使用jmap + mat等一系列猛如虎的操作，就可以方便快捷的发现问题。</li></ul></li><li>堆外内存<ul><li>元空间<ul><li>jdk8以后才加入的，用来替换原来的永久代，用于存储那些变动很少的数据，稳定为主。</li><li>比如我们在jvm启动时，加载的那些class文件；以及在运行时，动态生成的代理类。</li><li>默认是没有上限的，极端情况下，会一直挤占操作系统的剩余内存。</li></ul></li><li>CodeCache<ul><li>JIT是JVM一个非常重要的特性，CodeCahe存放的，就是即时编译器所生成的二进制代码。</li><li>当然，JNI的代码也是放在这里的。</li><li>在不同的平台，大小都是不一样的，但一般够用了。<code>调的非常小的情况下，JVM不会溢出，这个区域也不会溢出，但是会退化成解释型执行模式，速度和JIT不可同日而语，慢个数量级也是可能的</code></li></ul></li><li>本地内存<ul><li>网络内存<ul><li>可以认为它是操作系统内核所占用的内存，也可以认为是JVM进程占用的内存</li><li>如果你的系统并发非常高，这部分内存的占用也是比较多的。因为连接一般对应着网卡的数据缓冲区，还有文件句柄的耗费。</li></ul></li><li>线程内存<ul><li>如果你造的线程非常多，JVM除了占用Thread对象本身很小的一部分堆内存，大部分是以轻量级进程的方式存在于操作系统。</li><li>这同样是一个积少成多的内存区域，但一般不会发生问题</li></ul></li><li>JNI内存<ul><li>上面谈到CodeCache存放的JNI代码，JNI内存就是指的这部分代码所malloc的具体内存。 </li><li>比如Java的zip库，就不是在JVM的堆里完成的，而是开辟了一个堆外的缓冲池进行运算。</li></ul></li><li>直接内存<ul><li>指的是使用了Java的直接内存API，进行操作的内存。</li><li>这部分内存可以受到JVM的管控，比如ByteBuffer类所做的事情。</li><li>ByteBuffer底层是用的unsafe, 但unsafe是不受直接内存的管控的，因此并不会造成JVM直接内存溢出，反而会造成操作系统内存溢出。。</li></ul></li></ul></li></ul></li></ul><h4 id="如何排查操作系统内存"><a href="#如何排查操作系统内存" class="headerlink" title="如何排查操作系统内存"></a>如何排查操作系统内存</h4><p>linux下有一个命令lsof，可以看到JVM进程所关联的所有句柄信息，一般可作为参考。</p><p>近一步，使用pmap函数，即可观测到具体的内存分布。但是不要怕，有很多是共享内存。</p><p>具体排查思路可以参考 <a href="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/" title="JAVA线上故障排查全套路">JAVA线上故障排查全套路</a> 中的堆外内存溢出。</p><h4 id="内存区域控制参数"><a href="#内存区域控制参数" class="headerlink" title="内存区域控制参数"></a>内存区域控制参数</h4><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%8F%82%E6%95%B0.png"></p><ul><li>堆  <code>-Xmx  -Xms</code></li><li>元空间 <code>-XX:MaxMetaspaceSize  -XX:MetaspaceSize</code></li><li>栈 <code>-Xss</code></li><li>直接内存  <code>-XX:MaxDirectMemorySize</code></li><li>JIT编译后代码存放 <code>-XX:ReservedCodeCacheSize</code></li><li>其他堆外内存 <code>无法控制！随缘吧</code></li></ul><p>可以看到，堆外内存的占用，其实还是比较多的。如果你太贪婪，整个内存很容易就玩玩。</p><p>一般的，我们使用操作系统的2/3作为堆空间，是比较合理的。这是一个经验值。比如6GB的内存，你分配给JVM的，最好不要超过4GB。</p><p>还有，我们上面谈到的swap交换分区，在高并发应用中，一般是关掉的。因为它会造成频繁的页交换，在GC的时候，会引起严重的卡顿。</p><p>但要辩证的思维看待问题。对于低频的，对内存大小有非常大的依赖的情况下，SWAP不仅要开，还要开的大一些。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码实用小套路之Java 性能优化的一些细节</title>
      <link href="/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BJava-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82/"/>
      <url>/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BJava-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<p>在JAVA程序中，性能问题的大部分原因并不在于JAVA语言，而是程序本身。养成良好的编码习惯非常重要，能够显著地提升程序性能。</p><ol><li><p>尽量在合适的场合使用单例</p><p> 使用单例可以减轻加载的负担，缩短加载的时间，提高加载的效率，但并不是所有地方都适用于单例</p><p> 简单来说，单例主要适用于以下三个方面：</p><ul><li>控制资源的使用，通过线程同步来控制资源的并发访问；</li><li>控制实例的产生，以达到节约资源的目的；</li><li>控制数据共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信。</li></ul></li><li><p>尽量避免随意使用静态变量</p><p> 当某个对象被定义为static变量所引用，那么GC通常是不会回收这个对象所占有的内存，如:</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> B b = <span class="keyword">new</span> B();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时静态变量 b 的生命周期与A类同步，如果A类不会卸载，那么b对象会常驻内存，直到程序终止。</p></li><li><p>尽量避免过多过常地创建Java对象</p><p>尽量避免在经常调用的方法，循环中new对象，由于系统不仅要花费时间来创建对象，而且还要花时间对这些对象进行垃圾回收和处理。</p><p>在我们可以控制的范围内，最大限度地重用对象，最好能用基本的数据类型或数组来替代对象。</p></li><li><p>尽量使用final修饰符</p><p>带有final修饰符的类是不可派生的。在JAVA核心API中，有许多应用final的例子，例如java、lang、String，为String类指定final防止了使用者覆盖length()方法。</p><p>另外，如果一个类是final的，则该类所有方法都是final的。java编译器会寻找机会内联（inline）所有的final方法（这和具体的编译器实现有关），此举能够使性能平均提高50%。</p><p>如：让访问实例内变量的getter/setter方法变成”final：简单的getter/setter方法应该被置成final，这会告诉编译器，这个方法不会被重载，所以，可以变成”inlined”,例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MAF</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSize</span> <span class="params">(<span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">     _size = size;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> _size;</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"><span class="comment">// 更正</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DAF_fixed</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">final</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSize</span> <span class="params">(<span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">     _size = size;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> _size;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>尽量使用局部变量</p><p>调用方法时传递的参数以及在调用中创建的临时变量都保存在栈（Stack）中，速度较快；其他变量，如静态变量、实例变量等，都在堆（Heap）中创建，速度较慢。</p></li><li><p>尽量处理好包装类型和基本类型两者的使用场所</p><p>虽然包装类型和基本类型在使用过程中是可以相互转换，但它们两者所产生的内存区域是完全不同的</p><ul><li><p>基本类型数据产生和处理都在栈中处理，包装类型作为对象是在堆中产生实例（开启逃逸分析小对象也在栈上分配?）。</p></li><li><p>在集合类对象，有对象方面需要的处理适用包装类型，其他的处理提倡使用基本类型。</p></li></ul></li><li><p>慎用synchronized，尽量减小synchronize的方法</p><p>都知道，实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。</p><p>synchronize方法被调用时，直接会把当前对象锁了，在方法执行完之前其他线程无法调用当前对象的其他方法。</p><p>所以，synchronize的方法尽量减小，并且应<strong>尽量使用方法同步代替代码块同步</strong>。</p></li><li><p>尽量不要使用finalize方法</p><p>实际上，将资源清理放在finalize方法中完成是非常不好的选择</p><p>由于GC的工作量很大，尤其是回收Young代内存时，大都会引起应用程序暂停，所以再选择使用finalize方法进行资源清理，会导致GC负担更大，程序运行效率更差。</p></li><li><p>尽量使用基本数据类型代替对象</p><p>String str = “hello”;</p><p>上面这种方式会创建一个“hello”字符串，而且JVM的字符缓存池还会缓存这个字符串；</p><p>String str = new String(“hello”);</p><p>此时程序除创建字符串外，str所引用的String对象底层还包含一个char[]数组，这个char[]数组依次存放了h,e,l,l,o</p></li><li><p>多线程在未发生线程安全前提下应尽量使用HashMap、ArrayList</p></li></ol><p>   HashTable、Vector等使用了同步机制，降低了性能。</p><ol start="11"><li>尽量合理的创建HashMap</li></ol><p>   当你要创建一个比较大的hashMap时，充分利用这个构造函数</p><p>   public HashMap(int initialCapacity, float loadFactor);</p><p>   避免HashMap多次进行了hash重构,扩容是一件很耗费性能的事</p><p>   在默认中initialCapacity只有16，而loadFactor是 0.75，需要多大的容量，你最好能准确的估计你所需要的最佳大小，同样的Hashtable，Vectors也是一样的道理。</p><ol start="12"><li>尽量减少对变量的重复计算</li></ol><p>   如：</p><p>   <code>for(int i=0;i&lt;list.size();i++)</code></p><p>   应该改为：<br>   <code>for(int i=0,len=list.size();i&lt;len;i++)</code></p><p>   并且在循环中应该避免使用复杂的表达式，在循环中，循环条件会被反复计算，如果不使用复杂表达式，而使循环条件值不变的话，程序将会运行的更快。</p><ol start="13"><li>尽量避免不必要的创建</li></ol><p>   如：</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A a = new A();</span><br><span class="line">if(i==1)&#123;</span><br><span class="line">   list.add(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   应该改为：</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if(i==1)&#123;</span><br><span class="line">   A a = new A();</span><br><span class="line">   list.add(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="14"><li>尽量在finally块中释放资源</li></ol><p>   程序中使用到的资源应当被释放，以避免资源泄漏，这最好在finally块中去做。不管程序执行的结果如何，finally块总是会执行的，以确保资源的正确关闭。</p><ol start="15"><li>尽量使用移位来代替’a/b’或者’a*b’的操作</li></ol><p>   “/“和”*”是一个代价很高的操作，使用移位的操作将会更快和更有效</p><p>   如：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int num = a / 4;</span><br><span class="line">int num = a / 8;</span><br><span class="line">int num = a * 4;</span><br><span class="line">int num = a * 8;</span><br></pre></td></tr></table></figure></p><p>   应该改为：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int num = a &gt;&gt; 2;</span><br><span class="line">int num = a &gt;&gt; 3;</span><br><span class="line">int num = a &lt;&lt; 2;</span><br><span class="line">int num = a &lt;&lt; 3;</span><br></pre></td></tr></table></figure></p><p>   但注意的是<strong>使用移位应添加注释</strong>，因为移位操作不直观，比较难理解。</p><ol start="16"><li>尽量确定StringBuffer的容量</li></ol><p>   StringBuffer 的构造器会创建一个默认大小（通常是16）的字符数组。</p><p>   在使用中，如果超出这个大小，就会重新分配内存，创建一个更大的数组，并将原先的数组复制过来，再丢弃旧的数组。</p><p>   在大多数情况下，你可以在创建 StringBuffer的时候指定大小，这样就避免了在容量不够的时候自动增长，以提高性能。如：</p><p>   StringBuffer buffer = new StringBuffer(1000);</p><ol start="17"><li>尽量早释放无用对象的引用</li></ol><p>   大部分时，方法局部引用变量所引用的对象会随着方法结束而变成垃圾，因此，大部分时候程序无需将局部，引用变量显式设为null。例如：</p><p>   Java代码<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Public void test()&#123;</span><br><span class="line">   Object obj = new Object();</span><br><span class="line">   ……</span><br><span class="line">   Obj = null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>   上面这个就没必要了，随着方法test()的执行完成，程序中obj引用变量的作用域就结束了。</p><p>   但是如果是改成下面：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Public void test()&#123;</span><br><span class="line">   Object obj = new Object();</span><br><span class="line">   ……</span><br><span class="line">   Obj = null;</span><br><span class="line">   //执行耗时，耗内存操作；或调用耗时，耗内存的方法</span><br><span class="line">   ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>   这时候就有必要将obj赋值为null，可以尽早的释放对Object对象的引用。</p><ol start="18"><li>尽量避免使用二维数组</li></ol><p>   二维数据占用的内存空间比一维数组多得多，大概10倍以上。</p><ol start="19"><li>尽量避免使用split</li></ol><p>   除非是必须的，否则应该避免使用split，split由于支持正则表达式，所以效率比较低</p><p>   如果是频繁的几十，几百万的调用将会耗费大量资源，如果确实需要频繁的调用split，可以考虑使用apache的StringUtils.split(string,char)，频繁split的可以缓存结果</p><ol start="20"><li>ArrayList &amp; LinkedList</li></ol><p>   一个是线性表，一个是链表，一句话，随机查询尽量使用ArrayList，ArrayList优于LinkedList，LinkedList还要移动指针，添加删除的操作LinkedList优于ArrayList，ArrayList还要移动数据</p><p>   不过这是理论性分析，事实未必如此，重要的是理解好2者得数据结构，对症下药。</p><ol start="21"><li>尽量使用System.arraycopy ()代替通过来循环复制数组</li></ol><p>   System.arraycopy() 要比通过循环来复制数组快的多。</p><ol start="22"><li>尽量缓存经常使用的对象</li></ol><p>   尽可能将经常使用的对象进行缓存，可以使用数组，或HashMap的容器来进行缓存，但这种方式可能导致系统占用过多的缓存，性能下降</p><p>   推荐可以使用一些第三方的开源工具，如EhCache，Oscache进行缓存，他们基本都实现了FIFO/FLU等缓存算法。</p><ol start="23"><li>尽量避免非常大的内存分配</li></ol><p>   有时候问题不是由当时的堆状态造成的，而是因为分配失败造成的。分配的内存块都必须是连续的，而随着堆越来越满，找到较大的连续块越来越困难。</p><ol start="24"><li>慎用异常</li></ol><p>   当创建一个异常时，需要收集一个栈跟踪(stack track)，这个栈跟踪用于描述异常是在何处创建的。</p><p>   构建这些栈跟踪时需要为运行时栈做一份快照，正是这一部分开销很大。</p><p>   当需要创建一个 Exception 时，JVM 不得不说：先别动，我想就您现在的样子存一份快照，所以暂时停止入栈和出栈操作。栈跟踪不只包含运行时栈中的一两个元素，而是包含这个栈中的每一个元素。</p><p>   如果您创建一个 Exception ，就得付出代价，好在捕获异常开销不大，因此可以使用 try-catch 将核心内容包起来。</p><p>   从技术上讲，你甚至可以随意地抛出异常，而不用花费很大的代价。招致性能损失的并不是 throw 操作——尽管在没有预先创建异常的情况下就抛出异常是有点不寻常。</p><p>   真正要花代价的是创建异常，幸运的是，好的编程习惯已教会我们，不应该不管三七二十一就抛出异常。异常是为异常的情况而设计的，使用时也应该牢记这一原则。</p><ol start="25"><li>尽量重用对象</li></ol><p>   特别是String对象的使用中，出现字符串连接情况时应使用StringBuffer代替，由于系统不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理。因此生成过多的对象将会给程序的性能带来很大的影响。</p><ol start="26"><li>不要重复初始化变量</li></ol><p>   默认情况下，调用类的构造函数时，java会把变量初始化成确定的值，所有的对象被设置成null，整数变量设置成0，float和double变量设置成0.0，逻辑值设置成false。</p><p>   当一个类从另一个类派生时，这一点尤其应该注意，因为用new关键字创建一个对象时，构造函数链中的所有构造函数都会被自动调用。</p><p>   这里有个注意，给成员变量设置初始值但需要调用其他方法的时候，最好放在一个方法。比如initXXX()中，因为直接调用某方法赋值可能会因为类尚未初始化而抛空指针异常，如：public int state = this.getState()。</p><ol start="27"><li><p>在java+Oracle的应用系统开发中，java中内嵌的SQL语言应尽量使用大写形式，以减少Oracle解析器的解析负担。</p></li><li><p>在java编程过程中，进行数据库连接，I/O流操作，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销。</p></li><li><p>过分的创建对象会消耗系统的大量内存，严重时，会导致内存泄漏</p></li></ol><p>   因此，保证过期的对象的及时回收具有重要意义。JVM的GC并非十分智能，因此建议在对象使用完毕后，手动设置成null。</p><ol start="30"><li>不要在循环中使用Try/Catch语句，应把Try/Catch放在循环最外层</li></ol><p>   Error是获取系统错误的类，或者说是虚拟机错误的类。不是所有的错误Exception都能获取到的，虚拟机报错Exception就获取不到，必须用Error获取。</p><ol start="31"><li>array(数组)和ArrayList的使用</li></ol><p>   array 数组效率最高，但容量固定，无法动态改变，ArrayList容量可以动态增长，但牺牲了效率。</p><ol start="32"><li><p>单线程应尽量使用 HashMap, ArrayList,除非必要，否则不推荐使用HashTable,Vector，它们使用了同步机制，而降低了性能。</p></li><li><p>考虑使用静态方法，如果你没有必要去访问对象的外部，那么就使你的方法成为静态方法。它会被更快地调用，因为它不需要一个虚拟函数导向表。</p></li></ol><p>   这同时也是一个很好的实践，因为它告诉你如何区分方法的性质，调用这个方法不会改变对象的状态。</p><ol start="34"><li><p>避免枚举，浮点数的使用。</p></li><li><p>使用32位的无符号整数（UNSIGNED INT）来存储IP地址，而不是使用字符串 </p><p>  相对字符串存储，使用无符号整数来存储有如下的好处：</p><ul><li>节省空间，不管是数据存储空间，还是索引存储空间<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">通常，在保存IPv4地址时，一个IPv4最小需要7个字符，最大需要15个字符，所以，使用VARCHAR(15)即可。MySQL在保存变长的字符串时，还需要额外的一个字节来保存此字符串的长度。而如果使用无符号整数来存储，只需要4个字节即可。</span><br></pre></td></tr></table></figure></li><li>便于使用范围查询（BETWEEN…AND），且效率更高</li></ul><p>  另外还可以使用4个字段分别存储IPv4中的各部分，但是通常这不管是存储空间和查询效率应该都不是很高（可能有的场景适合使用这种方式存储）。</p><p>  使用无符号整数来存储也有缺点：</p><ul><li>不便于阅读</li><li>需要手动转换</li></ul></li></ol>   <details><summary>对于转换来说，MySQL提供了相应的函数</summary>      <p>   把字符串格式的IP转换成整数<code>INET_ATON</code>，以及把整数格式的IP转换成字符串的<code>INET_NTOA</code>。如下所示：<br>   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> select inet_aton(<span class="string">&#x27;192.168.0.1&#x27;</span>);</span></span><br><span class="line">+--------------------------+</span><br><span class="line">| inet_aton(&#x27;192.168.0.1&#x27;) |</span><br><span class="line">+--------------------------+</span><br><span class="line">|               3232235521 |</span><br><span class="line">+--------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> select inet_ntoa(3232235521);</span></span><br><span class="line">+-----------------------+</span><br><span class="line">| inet_ntoa(3232235521) |</span><br><span class="line">+-----------------------+</span><br><span class="line">| 192.168.0.1           |</span><br><span class="line">+-----------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><br>   对于IPv6来说，使用VARBINARY同样可获得相同的好处，同时MySQL也提供了相应的转换函数，即<code>INET6_ATON</code>和<code>INET6_NTOA</code></p><p>   对于转换字符串IPv4和数值类型，可以放在应用层，下面是使用java代码来对二者转换：<br>   <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IpLongUtils</span> </span>&#123;</span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 把字符串IP转换成long</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> ipStr 字符串IP</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> IP对应的long值</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">ip2Long</span><span class="params">(String ipStr)</span> </span>&#123;</span><br><span class="line">      String[] ip = ipStr.split(<span class="string">&quot;\\.&quot;</span>);</span><br><span class="line">      <span class="keyword">return</span> (Long.valueOf(ip[<span class="number">0</span>]) &lt;&lt; <span class="number">24</span>) + (Long.valueOf(ip[<span class="number">1</span>]) &lt;&lt; <span class="number">16</span>)</span><br><span class="line">              + (Long.valueOf(ip[<span class="number">2</span>]) &lt;&lt; <span class="number">8</span>) + Long.valueOf(ip[<span class="number">3</span>]);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 把IP的long值转换成字符串</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> ipLong IP的long值</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span> long值对应的字符串</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">long2Ip</span><span class="params">(<span class="keyword">long</span> ipLong)</span> </span>&#123;</span><br><span class="line">      StringBuilder ip = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">      ip.append(ipLong &gt;&gt;&gt; <span class="number">24</span>).append(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">      ip.append((ipLong &gt;&gt;&gt; <span class="number">16</span>) &amp; <span class="number">0xFF</span>).append(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">      ip.append((ipLong &gt;&gt;&gt; <span class="number">8</span>) &amp; <span class="number">0xFF</span>).append(<span class="string">&quot;.&quot;</span>);</span><br><span class="line">      ip.append(ipLong &amp; <span class="number">0xFF</span>);</span><br><span class="line">      <span class="keyword">return</span> ip.toString();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      System.out.println(ip2Long(<span class="string">&quot;192.168.0.1&quot;</span>));</span><br><span class="line">      System.out.println(long2Ip(<span class="number">3232235521L</span>));</span><br><span class="line">      System.out.println(ip2Long(<span class="string">&quot;10.0.0.1&quot;</span>));</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>   输出结果如下：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">3232235521</span><br><span class="line">192.168.0.1</span><br><span class="line">167772161</span><br></pre></td></tr></table></figure><br>   </p></details><p></p>]]></content>
      
      
      <categories>
          
          <category> 代码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码实用小套路之Effective Java阅读笔记</title>
      <link href="/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BEffective-Java%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
      <url>/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BEffective-Java%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p><a href="https://jiapengcai.gitbooks.io/effective-java/content/">《Effective Java》第三版中文版</a></p>]]></content>
      
      
      <categories>
          
          <category> 代码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库版本管理之Flyway使用指南</title>
      <link href="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
      <url>/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<p>对于数据库版本管理，我们已经介绍过一款类似工具<a href="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" title="数据库版本管理之Liquibase使用指南">数据库版本管理之Liquibase使用指南</a></p><p>本文将介绍另一种数据库版本管理工具flyway.</p><p>老规矩，首先上<a href="https://flywaydb.org/documentation">官网</a></p><h3 id="Flyway是如何工作的"><a href="#Flyway是如何工作的" class="headerlink" title="Flyway是如何工作的"></a>Flyway是如何工作的</h3><p>flyway 工作原理与 Liquibase 基本一致，其工作流程如下:</p><ol><li>项目启动，应用程序完成数据库连接池的建立后，Flyway自动运行。</li><li>初次使用时，Flyway会创建一个flyway_schema_history表，用于记录sql执行记录。</li><li>Flyway会扫描项目指定路径下(默认是classpath:db/migration)的所有sql脚本，与flyway_schema_history表脚本记录进行比对。如果数据库记录执行过的脚本记录，与项目中的sql脚本不一致，Flyway会报错并停止项目执行。</li><li>如果校验通过，则根据表中的sql记录最大版本号，忽略所有版本号不大于该版本的脚本。再按照版本号从小到大，逐个执行其余脚本。</li></ol><h3 id="在SpringBoot项目使用Flyway"><a href="#在SpringBoot项目使用Flyway" class="headerlink" title="在SpringBoot项目使用Flyway"></a>在SpringBoot项目使用Flyway</h3><ol><li>初始化一个SpringBoot项目，引入MySQL数据库驱动依赖等，并且需要引入Flyway依赖：</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--引入flyway--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.flywaydb<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flyway-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>6.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li><p>添加Flyway配置</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring</span>:<span class="string"></span></span><br><span class="line"><span class="comment">  # 数据库连接配置</span></span><br><span class="line">  <span class="attr">datasource</span>:<span class="string"></span></span><br><span class="line">    <span class="meta">driver-class-name</span>: <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">url</span>: <span class="string">jdbc:mysql://localhost:3306/ssm-demo?characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8</span></span><br><span class="line">    <span class="attr">username</span>: <span class="string">xxx</span></span><br><span class="line">    <span class="attr">password</span>: <span class="string">xxx</span></span><br><span class="line">  <span class="attr">flyway</span>:<span class="string"></span></span><br><span class="line"><span class="comment">    # 是否启用flyway</span></span><br><span class="line">    <span class="attr">enabled</span>: <span class="string">true</span></span><br><span class="line"><span class="comment">    # 编码格式，默认UTF-8</span></span><br><span class="line">    <span class="attr">encoding</span>: <span class="string">UTF-8</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件存放路径，默认db/migration</span></span><br><span class="line">    <span class="attr">locations</span>: <span class="string">classpath:db/migration</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的前缀，默认V</span></span><br><span class="line">    <span class="meta">sql-migration-prefix</span>: <span class="string">V</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的分隔符，默认2个下划线__</span></span><br><span class="line">    <span class="meta">sql-migration-separator</span>: <span class="string">__</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的后缀</span></span><br><span class="line">    <span class="meta">sql-migration-suffixes</span>: <span class="string">.sql</span></span><br><span class="line"><span class="comment">    # 迁移时是否进行校验，默认true</span></span><br><span class="line">    <span class="meta">validate-on-migrate</span>: <span class="string">true</span></span><br><span class="line"><span class="comment">    # 当迁移发现数据库非空且存在没有元数据的表时，自动执行基准迁移，新建schema_version表</span></span><br><span class="line">    <span class="meta">baseline-on-migrate</span>: <span class="string">true</span></span><br></pre></td></tr></table></figure></li><li><p>根据在配置文件的脚本存放路径的配置，在resource目录下建立文件夹db/migration</p></li><li><p>添加需要运行的sql脚本。sql脚本的命名规范为：V+版本号(版本号的数字间以”.“或”_“分隔开)+双下划线(用来分隔版本号和描述)+文件描述+后缀名，例如：V20201100__create_user.sql。如图所示：<br> <img src="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/img.png"></p></li><li><p>启动项目。启动成功后，在数据库中可以看到已按照定义好的脚本，完成数据库变更，并在flyway_schema_history表插入了sql执行记录。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库版本管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库版本管理之Liquibase使用指南</title>
      <link href="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
      <url>/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h3 id="为什么需要数据库版本管理"><a href="#为什么需要数据库版本管理" class="headerlink" title="为什么需要数据库版本管理"></a>为什么需要数据库版本管理</h3><p>研发过程中经常涉及到数据库变更，对表结构的修复及对数据的修改，为了保证各环境都能正确的进行变更我们可能需要维护一个数据库升级文档来保存这些记录，有需要升级的环境按文档进行升级。</p><p>这样手工维护有几个缺点：</p><ul><li>无法保证每个环境都按要求执行</li><li>遇到问题不一定有相对的回滚语句</li><li>无法自动化</li></ul><p>为了解决这些问题，我们进行了一些调研，主要调研对象是Liquibase和Flyway，我们希望通过数据库版本管理工具实现以下几个目标：</p><ul><li>数据库升级</li><li>数据库回滚</li><li>版本标记</li></ul><h3 id="数据库版本管理工具Liquibase简介"><a href="#数据库版本管理工具Liquibase简介" class="headerlink" title="数据库版本管理工具Liquibase简介"></a>数据库版本管理工具Liquibase简介</h3><p>首先，上<a href="https://docs.liquibase.com/home.html">官方文档</a></p><h4 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h4><p>首先，Liquibase是用于管理数据库版本的，所以就会有这些概念：</p><ul><li>版本号<ul><li>它的版本号由开发人员来维护，使用 author + id(由ChangeSet定义)</li></ul></li><li>管理的数据</li><li>差异比较</li><li>版本回滚</li></ul><p>提交数据，比较差异，版本回滚 可以使用命令行 或者 maven ，ant 等构建工具来完成</p><h5 id="Changelog-文件"><a href="#Changelog-文件" class="headerlink" title="Changelog 文件"></a>Changelog 文件</h5><p>开发人员将数据库更改存储在其本地开发计算机上基于文本的文件中，并将其应用于其本地数据库。Changelog文件可以任意嵌套，以便更好地管理。</p><p>所有Liquibase更改的根源是更改日志文件, Liquibase使用更改日志按顺序列出对数据库所做的所有更改。</p><p>它是一个包含所有数据库更改记录的文件（变更集s）, Liquibase使用此更改日志记录审核您的数据库并执行尚未应用于您的数据库的任何更改。</p><p><strong>可用属性</strong></p><ul><li>logicalFilePath: 用于在创建changeSet的唯一标识符时覆盖文件名和路径。移动或重命名change logs时是必需的。</li></ul><p><strong>可用的子标签</strong></p><ul><li><p>preConditions: 执行更改日志所需的先决条件。<a href="http://www.liquibase.org/documentation/preconditions.html">read more</a></p><ul><li>记录更改日志的编写者在创建changelog时的假设。</li><li>强制使运行change log的用户不会违反这些假设</li><li>在执行不可恢复的更改（如 drop_Table）之前执行数据检查</li><li>根据数据库的状态控制哪些changeSet运行<details><summary>demo</summary><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">databaseChangeLog</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog/1.8&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog/1.8</span></span></span><br><span class="line"><span class="string"><span class="tag">http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-1.8.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">preConditions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dbms</span> <span class="attr">type</span>=<span class="string">&quot;oracle&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">runningAs</span> <span class="attr">username</span>=<span class="string">&quot;SYSTEM&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">preConditions</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">changeSet</span> <span class="attr">id</span>=<span class="string">&quot;1&quot;</span> <span class="attr">author</span>=<span class="string">&quot;bob&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">preConditions</span> <span class="attr">onFail</span>=<span class="string">&quot;WARN&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">sqlCheck</span> <span class="attr">expectedResult</span>=<span class="string">&quot;0&quot;</span>&gt;</span>select count(*) from oldtable<span class="tag">&lt;/<span class="name">sqlCheck</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">preConditions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">comment</span>&gt;</span>Comments should go after preCondition. If they are before then liquibase usually gives error.<span class="tag">&lt;/<span class="name">comment</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dropTable</span> <span class="attr">tableName</span>=<span class="string">&quot;oldtable&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">changeSet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">databaseChangeLog</span>&gt;</span></span><br></pre></td></tr></table></figure>仅当针对 Oracle执行的数据库和执行脚本的数据库用户为SYSTEM时，才会运行上述databasechangelog。<br>仅当”oldtable”中没有值时，它才会运行 drop_Table命令。</details></li></ul></li><li><p>property: 将属性设置为的值（如果不是通过其他方法设置）。<a href="http://www.liquibase.org/documentation/changelog_parameters.html">read more</a></p></li><li><p>changeSet: 要执行的changeSet。<a href="http://www.liquibase.org/documentation/changeset.html">read more</a></p></li><li><p>include: 包含要执行的changeSet的其他文件。<a href="http://www.liquibase.org/documentation/include.html">read more</a></p></li></ul><p>当 Liquibase 迁移器运行时，它将分析数据库 ChangeLog 标记。它首先检查指定的先决条件。如果先决条件失败，Liquibase将退出，并显示一条错误消息，解释失败的原因。先决条件对于记录和强制执行更改日志编写器的预期和假设（如要针对的 DBMS 或以用户身份运行更改）非常有用。</p><p>如果满足所有的先决条件，Liquibase将会开始运行在databaseChangeLog文件中按照顺序出现changeSet和include标签。</p><p><strong>changelog文件格式说明</strong></p><p>具体格式参考<a href="https://docs.liquibase.com/concepts/basic/changelog.html">官方文档</a></p><p>本文列举两种常见格式:</p><ul><li><p>SQL 文件格式</p><p>其实各种文件格式使用生成数据库脚本就可以看到格式了，照着写就行：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--liquibase formatted sql</span><br><span class="line"></span><br><span class="line">--changeset &lt;author&gt;:&lt;version&gt; </span><br><span class="line">sqls</span><br><span class="line"></span><br><span class="line">--rollback rollback sqls </span><br><span class="line"></span><br><span class="line">--comment: 注释都有特殊含义了，所以注释要这样加</span><br></pre></td></tr></table></figure></li><li><p>XML 文件格式</p><p>xml 比 sql 更加可控，它可以加一个预判断条件，来判断这个后面的 changeSet 要不要执行，但相应的就必须照它的语法来写语句了，没 sql 方便了，还好提供了 xsd</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;preConditions&gt;</span><br><span class="line">    &lt;runningAs username=&quot;liquibase&quot;/&gt;</span><br><span class="line">&lt;/preConditions&gt;</span><br><span class="line">&lt;!-- 版本 1 的修改--&gt;</span><br><span class="line">&lt;changeSet id=&quot;1&quot; author=&quot;sanri&quot;&gt;</span><br><span class="line">    &lt;addColumn tableName=&quot;person&quot;&gt;</span><br><span class="line">        &lt;column name=&quot;username&quot; type=&quot;varchar(8)&quot;/&gt;</span><br><span class="line">    &lt;/addColumn&gt;</span><br><span class="line">&lt;/changeSet&gt;</span><br></pre></td></tr></table></figure></li></ul><h5 id="ChangeSet"><a href="#ChangeSet" class="headerlink" title="ChangeSet"></a>ChangeSet</h5><p>changeSet由author和id属性以及changelog文件的位置唯一标识，是 Liquibase 跟踪执行的单位（管理的数据最小单元）。</p><p>changeSet 可以用 xml,yaml,json,sql 来编写</p><p>运行 Liquibase 时，它会查询标记为已执行的changSet的DATABASECHANGELOG 表，然后执行更改日志文件中尚未执行的所有changeSet。</p><h5 id="Changes"><a href="#Changes" class="headerlink" title="Changes"></a>Changes</h5><p>每个changeSet通常包含一个更改，该更改描述要应用于数据库的更改/重构。</p><p>Liquibase 支持为支持的数据库和原始 SQL 生成 SQL 的描述性更改。</p><p>通常，<strong>每个changeSet应只有一个更改</strong>，以避免可能使数据库处于意外状态的自动提交语句失败。</p><h5 id="Preconditions"><a href="#Preconditions" class="headerlink" title="Preconditions"></a>Preconditions</h5><p>先决条件可以应用于整个changelog或单个changeSet。如果先决条件失败，liquibase将停止执行。</p><h5 id="Contexts"><a href="#Contexts" class="headerlink" title="Contexts"></a>Contexts</h5><p>可以将上下文应用于changeSet，以控制在不同环境中运行的changeSet。例如，某些changeSet可以标记为production，另一些可以标记为test。如果未指定上下文，则无论执行上下文如何，changset都将运行。</p><h4 id="Liquibase是如何工作的"><a href="#Liquibase是如何工作的" class="headerlink" title="Liquibase是如何工作的"></a>Liquibase是如何工作的</h4><p>Liquibase的核心是依靠一种简单的机制来跟踪、版本和部署更改：</p><ul><li>Liquibase 使用更改日志（是更改的分类）按特定顺序显式列出数据库更改。更改日志中的每个更改都是一个change set。更改日志可以任意嵌套，以帮助组织和管理数据库迁移。<ul><li>最佳做法是确保每个change set都尽可能原子性更改，以避免失败的结果使数据库中剩下的未处理的语句处于unknown 状态;</li><li>不过，可以将大型 SQL 脚本视为单个更改集。</li></ul></li><li>Liquibase 使用跟踪表（具体称为DATABASECHANGELOG），该表位于每个数据库上，并跟踪已部署更改日志中的change set。<ul><li>如果 Liquibase所在的数据库没有跟踪表，Liquibase 将创建一个跟踪表。</li><li>为了协助处理您未从空白数据库开始的项目，Liquibase具有生成一条更改日志以表示数据库模式当前状态的功能。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">它会在你的目标数据库生成一张表 DATABASECHANGELOG 来管理版本 ，另一个 lock 的是防止多人同时操作数据库加的锁。</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>使用分类和跟踪表，Liquibase 能够：</p><ul><li>跟踪和以版本控制数据库更改 – 用户确切知道已部署到数据库的更改以及尚未部署的更改。</li><li>部署更改 — 具体来说，通过将分类(ledger)中的内容与跟踪表中的内容进行比较，Liquibase 只能将以前尚未部署到数据库的更改部署到数据库中。<ul><li>Liquibase 具有上下文、标签和先决条件等高级功能，可精确控制changeSet的部署时间以及位置。</li></ul></li></ul><h4 id="liquibase使用"><a href="#liquibase使用" class="headerlink" title="liquibase使用"></a>liquibase使用</h4><h5 id="命令行方式"><a href="#命令行方式" class="headerlink" title="命令行方式"></a>命令行方式</h5><p>虽然使用可以集成自 springboot ，但这种数据库脚本一般公司都是运维在维护，使用命令行是最方便的方式，所以我先说下使用命令行, <a href="http://www.liquibase.org/documentation/command_line.html">官网示例</a> </p><p>为先为了不每次都要写一大堆参数，可以在 liquibase 根目录加一个 liquibase.properties，用于配置数据库 jar、url、用户名、密码等参数, <a href="http://www.liquibase.org/documentation/config_properties.html">配置详情</a> </p><p>命令格式： liquibase [options] [command] [command parameters]</p><h6 id="比较开发库和测试库的差异，并生成升级包"><a href="#比较开发库和测试库的差异，并生成升级包" class="headerlink" title="比较开发库和测试库的差异，并生成升级包"></a>比较开发库和测试库的差异，并生成升级包</h6><p>如果要升级哪个，则哪个要做为源，则配置中的 url 不是 referenceUrl，使用如下命令创建升级包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase --changeLogFile=&quot;changeLogFiledevtest.postgresql.sql&quot; diffChangeLog</span><br></pre></td></tr></table></figure><p>changeLogFile 是有命名规则的，命名必须为 *.dbType.format ，如上所示</p><h6 id="为测试库打一个标签"><a href="#为测试库打一个标签" class="headerlink" title="为测试库打一个标签"></a>为测试库打一个标签</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase tag v1.0</span><br></pre></td></tr></table></figure><h6 id="使用差异升级源库"><a href="#使用差异升级源库" class="headerlink" title="使用差异升级源库"></a>使用差异升级源库</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; update</span><br></pre></td></tr></table></figure><h6 id="升级有问题需要回滚"><a href="#升级有问题需要回滚" class="headerlink" title="升级有问题需要回滚"></a>升级有问题需要回滚</h6><p>liquibase 有几种回滚策略，一种是根据标签回滚，回滚次数，和根据日期回滚；有 9 个与之对应的命令</p><p>回滚要求对应的 changeLogFile 有回滚标签 ，这个在后面文件格式说</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 按照 changeSet 次数回滚</span></span><br><span class="line">liquibase  --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; rollbackCount 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按照标签回滚</span></span><br><span class="line">liquibase  --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; rollback v1.0</span><br></pre></td></tr></table></figure><h6 id="生成数据库脚本-新环境"><a href="#生成数据库脚本-新环境" class="headerlink" title="生成数据库脚本(新环境)"></a>生成数据库脚本(新环境)</h6><p>liquibase –changeLogFile=”sqls/create_table.mysql.sql”  generateChangeLog</p><h5 id="使用构建工具"><a href="#使用构建工具" class="headerlink" title="使用构建工具"></a>使用构建工具</h5><p>我们也可以使用 maven 来执行这些操作，引入 maven 的一个插件就行</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.liquibase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>liquibase-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--指定执行主文件 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;changeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/master_changelog.xml&lt;/changeLogFile&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;diffChangeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/changelog/$&#123;maven.build.timestamp&#125;_changelog.xml&lt;/diffChangeLogFile&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;outputChangeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/changelog/changelog_original.xml&lt;/outputChangeLogFile&gt;--&gt;</span></span><br><span class="line"></span><br><span class="line">                   <span class="tag">&lt;<span class="name">propertyFile</span>&gt;</span>src/main/resources/liquibase/liquibase.properties<span class="tag">&lt;/<span class="name">propertyFile</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                    <span class="tag">&lt;<span class="name">dropFirst</span>&gt;</span>false<span class="tag">&lt;/<span class="name">dropFirst</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">verbose</span>&gt;</span>true<span class="tag">&lt;/<span class="name">verbose</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">logging</span>&gt;</span>debug<span class="tag">&lt;/<span class="name">logging</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!-- 是否需要弹出确认框 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">promptOnNonLocalDatabase</span>&gt;</span>false<span class="tag">&lt;/<span class="name">promptOnNonLocalDatabase</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--输出文件的编码 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">outputFileEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">outputFileEncoding</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--执行的时候是否显示详细的参数信息 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">verbose</span>&gt;</span>true<span class="tag">&lt;/<span class="name">verbose</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--是否每次都重新加载properties --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">propertyFileWillOverride</span>&gt;</span>true<span class="tag">&lt;/<span class="name">propertyFileWillOverride</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">rollbackTag</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">rollbackTag</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">tag</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p>相应的命令做成了目标(goal)，使用 -Dkey=value 来指定参数，如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行更新 sql</span> </span><br><span class="line">mvn liquibase:update -DchangeLogFile=&quot;file&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 打标签，这个版本号在插件中配置成项目版本了</span></span><br><span class="line">mvn liquibase:tag </span><br><span class="line"><span class="meta">#</span><span class="bash"> 将当前库导出表结构</span></span><br><span class="line">mvn liquibase:generateChangeLog </span><br></pre></td></tr></table></figure><h5 id="集成进-springboot-在项目启动的时候执行版本管理"><a href="#集成进-springboot-在项目启动的时候执行版本管理" class="headerlink" title="集成进 springboot, 在项目启动的时候执行版本管理"></a>集成进 springboot, 在项目启动的时候执行版本管理</h5><p>具体实现方案参考文章<a href="https://blog.csdn.net/qq_39508627/article/details/89883549?utm_medium=distribute.pc_feed_404.none-task-blog-2~default~BlogCommendFromBaidu~default-3.nonecase&depth_1-utm_source=distribute.pc_feed_404.none-task-blog-2~default~BlogCommendFromBaidu~default-3.nonecas">springboot引入liquibase</a></p><h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="项目开发中存在的问题"><a href="#项目开发中存在的问题" class="headerlink" title="项目开发中存在的问题"></a>项目开发中存在的问题</h4><p>随着项目的发展，一个项目中的代码量会非常庞大，同时数据库表也会错综复杂。如果一个项目使用了Liquibase对数据库结构进行管理，越来越多的问题会浮现出来。</p><ul><li>ChangeSet文件同时多人在修改，自己的ChangeSet被改掉，甚至被删除掉。</li><li>开发人员将ChangeSet添加到已经执行过的文件中，导致执行顺序出问题。</li><li>开发人员擅自添加对业务数据的修改，其它环境无法执行并报错。</li><li>ChangeSet中SQL包含schema名称，导致其它环境schema名称变化时，ChangeSet报错。</li><li>开发人员不小心改动了已经执行过的ChangeSet，在启动时会报错。</li></ul><h4 id="Liquibase基本规范"><a href="#Liquibase基本规范" class="headerlink" title="Liquibase基本规范"></a>Liquibase基本规范</h4><ul><li>ChangeSet id使用[任务ID]-[日期]-[序号]，如 T100-20181009-001</li><li>ChangeSet必须填写author</li><li>Liquibase禁止对业务数据进行sql操作</li><li>使用<sql>时，禁止包含schema名称</sql></li><li>Liquibase禁止使用存储过程</li><li>所有表，列要加remarks进行注释</li><li>已经执行过的ChangeSet严禁修改。</li><li>不要随便升级项目liquibase版本，特别是大版本升级。不同版本ChangeSet MD5SUM的算法不一样。</li></ul><p>其它数据库规范不再赘述。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">databaseChangeLog</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">changeSet</span> <span class="attr">id</span>=<span class="string">&quot;T100-20181009-001&quot;</span> <span class="attr">author</span>=<span class="string">&quot;markfredchen&quot;</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">createTable</span> <span class="attr">tableName</span>=<span class="string">&quot;demo_user&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户表&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">column</span> <span class="attr">name</span>=<span class="string">&quot;id&quot;</span> <span class="attr">type</span>=<span class="string">&quot;bigint&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户ID,主键&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">constraints</span> <span class="attr">nullable</span>=<span class="string">&quot;false&quot;</span> <span class="attr">primaryKey</span>=<span class="string">&quot;true&quot;</span> <span class="attr">primaryKeyName</span>=<span class="string">&quot;pk_demo_user_id&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">column</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">column</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> <span class="attr">type</span>=<span class="string">&quot;varchar(100)&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户名&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">constraints</span> <span class="attr">nullable</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">column</span>&gt;</span></span><br><span class="line">            ...</span><br><span class="line">        <span class="tag">&lt;/<span class="name">createTable</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">changeSet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">databaseChangeLog</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="有效文件管理"><a href="#有效文件管理" class="headerlink" title="有效文件管理"></a>有效文件管理</h4><p>使用Liquibase中提供<include file="xxx">tag，可以将ChangeSet分布在不同文件中。同时<include>支持多级引用。</include></include></p><p>基于此功能可以对项目中的ChangeSet进行有效管理。推荐使用以下规范进行管理。</p><h5 id="根据发布进行管理"><a href="#根据发布进行管理" class="headerlink" title="根据发布进行管理"></a>根据发布进行管理</h5><ul><li>每个发布新建一个文件夹，所有发布相关的ChangeSet文件以及数据初始化文件，均放在些文件夹中。</li><li>每个发布新建一个master.xml。此master.xml中，include本次发布需要执行的ChangeSet文件</li><li>根据开发小组独立ChangeSet文件(可选)</li><li>根据功能独立ChangeSet文件。例如user.xml, company.xml  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">resources</span><br><span class="line">|-liquibase</span><br><span class="line">|-user</span><br><span class="line">| |- master.xml</span><br><span class="line">| |- release.1.0.0</span><br><span class="line">| | |- release.xml</span><br><span class="line">| | |- user.xml -- 用户相关表ChangeSet</span><br><span class="line">| | |- user.csv -- 用户初始化数据</span><br><span class="line">| | |- company.xml -- 公司相关表ChangeSet</span><br><span class="line">| |- release.1.1.0</span><br><span class="line">| | |- release.xml</span><br><span class="line">| | |- ...</span><br></pre></td></tr></table></figure></li></ul><h5 id="模块化管理"><a href="#模块化管理" class="headerlink" title="模块化管理"></a>模块化管理</h5><p>当项目变得庞大之后，一个服务可能包含的功能模块会越来越多。此时大家会想尽办法进行模块拆分，逐步进行微服务化。然而在面对错综复杂的Liquibase ChangeSet就会无从下手。</p><p>针对这种将来可能会面对的问题，项目初期就对Liquibase进行模块化管理，将在未来带来很大收益。</p><p>首先说明一下Spring Boot中Liquibase默认是如何执行以及执行结果。</p><ul><li>在启动时，LiquibaseAutoConfiguration会根据默认配置初始化SpringLiquibase</li><li>SpringLiquibase.afterPropertiesSet()中执行ChangeSet文件</li><li>第一次跑ChangeSets的时候，会在数据库中自动创建两个表databasechangelog和databasechangeloglock</li></ul><p>因此我们可以认为一个SpringLiquibase执行为一个模块。</p><p>引入多模块管理时，基于上节文件管理规范，我们基于模块管理再做下调整。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">resources</span><br><span class="line">  |-liquibase</span><br><span class="line">    |-user</span><br><span class="line">    | |- master.xml</span><br><span class="line">    | |- release.1.0.0</span><br><span class="line">    | | |- release.xml</span><br><span class="line">    | | |- user.xml -- 用户相关表ChangeSet</span><br><span class="line">    | | |- user.csv -- 用户初始化数据</span><br><span class="line">    | | |- company.xml -- 公司相关表ChangeSet</span><br><span class="line">    | |- release.1.1.0</span><br><span class="line">    | | |- release.xml</span><br><span class="line">    | | |- ...</span><br><span class="line">    |- order</span><br><span class="line">    | |- master.xml</span><br><span class="line">    | |- release.1.0.0</span><br><span class="line">    | | |- ...</span><br></pre></td></tr></table></figure><p>当有一天我们需要把订单模块拆分成独立服务时，我们只需要将模块相关的ChangeSet文件迁出来。即可完成数据结构的拆分。</p><p>那如何在一个Spring Boot运行多个SpringLiquibase呢？需要对代码进行以下调整。</p><ol><li><p>禁用Spring Boot自动运行Liquibase。</p><p> 当以下配置被启用时，Spring Boot AutoConfigure会使用默认配置初始化名为springLiquibase的Bean。然后我们不对其进行配置，Spring Boot启动时会报错。</p> <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># application.properties</span></span><br><span class="line"><span class="comment"># spring boot 2以上</span></span><br><span class="line"><span class="meta">spring.liquibase.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># spring boot 2以下</span></span><br><span class="line"><span class="meta">liquibase.enabled</span>=<span class="string">false</span></span><br></pre></td></tr></table></figure></li><li><p>Spring Boot配置Liquibase Bean</p><p> 配置两个SpringLiquibase Bean，Bean名称分别为userLiquibase和orderLiqubase。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> class <span class="title">LiquibaseConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  用户模块Liquibase   </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SpringLiquibase <span class="title">userLiquibase</span><span class="params">(DataSource dataSource)</span> </span>&#123;</span><br><span class="line">        SpringLiquibase liquibase = <span class="keyword">new</span> SpringLiquibase();</span><br><span class="line">        <span class="comment">// 用户模块Liquibase文件路径</span></span><br><span class="line">        liquibase.setChangeLog(<span class="string">&quot;classpath:liquibase/user/master.xml&quot;</span>);</span><br><span class="line">        liquibase.setDataSource(dataSource);</span><br><span class="line">        liquibase.setShouldRun(<span class="keyword">true</span>);</span><br><span class="line">        liquibase.setResourceLoader(<span class="keyword">new</span> DefaultResourceLoader());</span><br><span class="line">        <span class="comment">// 覆盖Liquibase changelog表名</span></span><br><span class="line">        liquibase.setDatabaseChangeLogTable(<span class="string">&quot;user_changelog_table&quot;</span>);</span><br><span class="line">        liquibase.setDatabaseChangeLogLockTable(<span class="string">&quot;user_changelog_lock_table&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> liquibase;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  订单模块Liquibase   </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SpringLiquibase <span class="title">orderLiquibase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      SpringLiquibase liquibase = <span class="keyword">new</span> SpringLiquibase();</span><br><span class="line">      liquibase.setChangeLog(<span class="string">&quot;classpath:liquibase/order/master.xml&quot;</span>);</span><br><span class="line">      liquibase.setDataSource(dataSource);</span><br><span class="line">      liquibase.setShouldRun(<span class="keyword">true</span>);</span><br><span class="line">      liquibase.setResourceLoader(<span class="keyword">new</span> DefaultResourceLoader());</span><br><span class="line">      liquibase.setDatabaseChangeLogTable(<span class="string">&quot;order_changelog_table&quot;</span>);</span><br><span class="line">      liquibase.setDatabaseChangeLogLockTable(<span class="string">&quot;order_changelog_lock_table&quot;</span>);</span><br><span class="line">      <span class="keyword">return</span> liquibase;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://blog.csdn.net/u012934325/article/details/100652805">LiquiBase中文学习指南</a></p>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库版本管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务解决方案SpringCloud Alibaba系列之Sentinel初探</title>
      <link href="/2021/08/09/SpringCloudAlibaba/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88SpringCloud%20Alibaba%E7%B3%BB%E5%88%97%E4%B9%8BSentinel%E5%88%9D%E6%8E%A2/"/>
      <url>/2021/08/09/SpringCloudAlibaba/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88SpringCloud%20Alibaba%E7%B3%BB%E5%88%97%E4%B9%8BSentinel%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<h3 id="Sentinel-是什么"><a href="#Sentinel-是什么" class="headerlink" title="Sentinel 是什么"></a>Sentinel 是什么</h3><p>新技术学习第一步，<a href="https://sentinelguard.io/zh-cn/docs/introduction.html">官方文档</a></p><p>随着微服务的流行，服务和服务之间的稳定性变得越来越重要。</p><p>Sentinel 是面向分布式服务架构的流量控制组件，作为分布式系统的流量防卫兵， 以<strong>流量</strong>为切入点，从<strong>流量控制、熔断降级、系统负载保护</strong>等多个维度保护服务的稳定性。</p><h3 id="Sentinel-要做什么"><a href="#Sentinel-要做什么" class="headerlink" title="Sentinel 要做什么"></a>Sentinel 要做什么</h3><p>服务的动态注册、服务发现是 SOA、微服务架构体系中首先需要解决的基本问题，服务治理是 SOA 领域又一重要课题，而 dubbo 框架只提供了一些基本的服务治理能力，例如限制服务并发调用数、配置合适的业务线程数量等，但熔断相关的功能就涉及的较少。</p><p>Sentinel 将作为 Dubbo 生态的重要一员，将集中解决服务治理相关的课题，服务限流与熔断又是服务治理首先要解决的课题。</p><p>那什么是限流与熔断呢？</p><ul><li>限流：我们通常使用TPS对流量来进行描述，限流就是现在服务被调用的并发TPS，从而对系统进行自我保护。</li><li>熔断：就是当系统中某一个服务出现性能瓶颈是，对这个服务的调用进行快速失败，避免造成连锁反应，从而影响整个链路的调用。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 限流 </tag>
            
            <tag> Sentinel </tag>
            
            <tag> SpringCloud Alibaba </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之与Zookeeper的爱恨缠绵</title>
      <link href="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/"/>
      <url>/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/</url>
      
        <content type="html"><![CDATA[<p>在 <a href="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/" title="分布式协调组件之Zookeeper基础概念入门">分布式协调组件之Zookeeper基础概念入门</a> 一文中，我们简单介绍了Zookeeper的基础概念。</p><p>而Kafka作为Zookeeper分布式协调的重要案例，本文将通过Kafka与Zookeeper的合与分展示Kafka与Zookeeper的前世今生。</p><h3 id="Kafka为什么需要Zookeeper"><a href="#Kafka为什么需要Zookeeper" class="headerlink" title="Kafka为什么需要Zookeeper"></a>Kafka为什么需要Zookeeper</h3><p>Kafka中存在众多的Leader选举，熟悉Kafka的朋友应该知道，一个主题可以拥有多个分区(数据分片)，每一个数据分片可以配置多个副本，如何保证一个分区的数据在多个副本之间的一致性成为一个迫切的需求。</p><p>Kafka的实现套路就是一个分区的多个副本，从中选举出一个Leader用来承担客户端的读写请求，从节点从主节点处拷贝内容，Leader节点根据数据在副本中成功写入情况，进行抉择来确定是否写入成功。</p><p>Kafka中topic的分区分布示意图：</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_1.png"></p><p>故此处需要进行Leader选举,而基于Zookeeper能轻松实现，从此一拍即合，开启了一段“蜜月之旅”。</p><h3 id="Zookeeper为Kafka提供了什么"><a href="#Zookeeper为Kafka提供了什么" class="headerlink" title="Zookeeper为Kafka提供了什么"></a>Zookeeper为Kafka提供了什么</h3><p>ZooKeeper 作为给分布式系统提供协调服务的工具被 kafka 所依赖。</p><p>在分布式系统中，消费者需要知道有哪些生产者是可用的，而如果每次消费者都需要和生产者建立连接并测试是否成功连接，那效率也太低了，显然是不可取的。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_5.png"></p><p>通过使用 ZooKeeper 协调服务，Kafka 就能将 Producer，Consumer，Broker 等结合在一起，同时借助 ZooKeeper，Kafka 就能够将所有组件在无状态的条件下建立起生产者和消费者的订阅关系，实现负载均衡。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img.png"></p><ol><li><p>注册中心</p><ul><li><p>Broker 信息注册</p><ul><li>在 ZooKeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点，节点路径为 /brokers/ids。  </li><li>Kafka 的每个 Broker 启动时，都会在 ZooKeeper 中注册，创建 /brokers/ids/[0-N] 节点，写入 IP，端口等信息，每个 Broker 都有一个 BrokerId。  </li><li>Broker 创建的是临时节点，在连接断开时节点就会自动删除，所以在 ZooKeeper 上就可以通过 Broker 中节点的变化来得到 Broker 的可用性。</li></ul></li><li><p>Topic 信息注册</p><ul><li><p>在 Kafka 中可以定义很多个 Topic，每个 Topic 又被分为很多个 Partition。一般情况下，每个 Partition 独立在存在一个 Broker 上，所有的这些 Topic 和 Broker 的对应关系都由 ZooKeeper 进行维护。</p></li><li><p>Zookeeper会为topic分配一个单独节点，每个topic都会以/brokers/topics/[topic_name]的形式记录在Zookeeper。</p></li><li><p>一个topic的消息会被保存到多个partition，这些partition跟broker的对应关系也需要保存到Zookeeper。</p></li><li><p>partition是多副本保存的，上图中红色partition是leader副本。当leader副本所在的broker发生故障时，partition需要重新选举leader，这个需要由Zookeeper主导完成。</p></li><li><p>broker启动后，会把自己的Broker ID注册到到对应topic节点的分区列表中。</p><p>我们查看一个topic是xxx，分区编号是1的信息，命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master] get /brokers/topics/xxx/partitions/1/state</span><br><span class="line">&#123;&quot;controller_epoch&quot;:15,&quot;leader&quot;:11,&quot;version&quot;:1,&quot;leader_epoch&quot;:2,&quot;isr&quot;:[11,12,13]&#125;</span><br></pre></td></tr></table></figure><p><code>当broker退出后，Zookeeper会更新其对应topic的分区列表。</code></p></li></ul></li><li><p>consumer 信息注册</p><p>   消费者组也会向Zookeeper进行注册，Zookeeper会为其分配节点来保存相关数据，节点路径为/consumers/{group_id}，有3个子节点，如下图:</p><p>   <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_6.png"></p><p>   这样Zookeeper可以记录分区跟消费者的关系，以及分区的offset。</p></li></ul></li><li><p>负载均衡</p><p> 生产者需要将消息发送给 Broker，消费者需要从 Broker 上获取消息，通过使用 ZooKeeper，就都能监听 Broker 上节点的状态信息，从而实现动态负载均衡。</p><ul><li>broker向Zookeeper进行注册后，生产者根据broker节点来感知broker服务列表变化，这样可以实现动态负载均衡。</li><li>consumer group中的消费者，可以根据topic节点信息来拉取特定分区的消息,实现负载均衡。</li></ul></li><li><p>Controller</p><p> 在 Kafka 中会有多个 Broker，其中一个 Broker 会被选举成为 Controller（控制器），在任意时刻，Kafka 集群中有且仅有一个控制器。</p><p> Controller 负责管理集群中所有分区和副本的状态，当某个分区的 leader 副本出现故障时，由 Controller 为该分区选举出一个新的 leader。</p><p> Controller具体职责如下：</p><ul><li>监听分区变化<ul><li>当某个分区的leader出现故障时，Controller会为该分区选举新的leader。</li><li>当检测到分区的ISR集合发生变化时，Controller会通知所有broker更新元数据。</li><li>当某个topic增加分区时，Controller会负责重新分配分区。</li></ul></li><li>监听topic相关的变化</li><li>监听broker相关的变化</li><li>集群元数据管理</li></ul><p> 下面这张图展示了Controller、Zookeeper和broker的交互细节：<br> <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_7.png"></p><p> Controller选举成功后，会从Zookeeper集群中拉取一份完整的元数据初始化ControllerContext，这些元数据缓存在Controller节点。当集群发生变化时，比如增加topic分区，Controller不仅需要变更本地的缓存数据，还需要将这些变更信息同步到其他Broker。</p><p> Controller监听到Zookeeper事件、定时任务事件和其他事件后，将这些事件按照先后顺序暂存到LinkedBlockingQueue中，由事件处理线程按顺序处理，这些处理多数需要跟Zookeeper交互，Controller则需要更新自己的元数据。</p><p> Kafka 的 Controller 选举就依靠 ZooKeeper 来完成，成功竞选为 Controller 的 Broker 会在 ZooKeeper 中创建 /controller 这个临时节点，在 ZooKeeper 中使用 get 命令查看节点内容：</p><p> <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_2.png"></p><ul><li>“version”在目前版本中固定为1</li><li>“brokerid”表示 Broker 的编号</li><li>“timestamp”表示竞选称为 Controller 时的时间戳。</li></ul><p> Kafka Controller选举流程: 当 Broker 启动时，会尝试读取 /controller 中的“brokerid”: </p><ul><li>如果读取到的值不是-1，则表示已经有节点竞选成为 Controller 了，当前节点就会放弃竞选；</li><li>而如果读取到的值为-1，ZooKeeper 就会尝试创建 /controller 节点，当该 Broker 去创建的时候，可能还有其他 Broker 一起同时创建节点，但只有一个 Broker 能够创建成功，即成为唯一的 Controller。</li></ul></li></ol><h3 id="为什么Kafka要抛弃Zookeeper"><a href="#为什么Kafka要抛弃Zookeeper" class="headerlink" title="为什么Kafka要抛弃Zookeeper"></a>为什么Kafka要抛弃Zookeeper</h3><h4 id="外部依赖带来的复杂度及系统效率影响"><a href="#外部依赖带来的复杂度及系统效率影响" class="headerlink" title="外部依赖带来的复杂度及系统效率影响"></a>外部依赖带来的复杂度及系统效率影响</h4><p>对于 Kafka 来讲，ZooKeeper 是一套外部系统，要想部署一套 Kafka 集群，就要同时部署、管理、监控 ZooKeeper，Kafka的运维人员必须要具备Zookeeper的运维能力。</p><p>ZooKeeper 有自己的配置方式、管理工具，和 Kafka 完全不一样，所以，一起搞两套分布式系统，自然就提升了<strong>复杂度</strong>，也更容易出现问题。有时工作量还会加倍，例如要开启一些安全特性，Kafka 和 ZooKeeper 中都需要配置。</p><p>除了复杂度，外部存储也会<strong>降低系统效率</strong>。</p><p>例如 Kafka 集群每次启动的时候，Controller 必须从 ZooKeeper 加载集群的状态信息。</p><p>再比如选举出一个新的 Controller 之后也会比较麻烦，Kafaka依赖一个单一Controller节点跟Zookeeper进行交互，如果这个Controller节点发生了故障，就需要从broker中选择新的Controller。如下图,新的Controller变成了broker3。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_4.png"></p><p>新的Controller选举成功后，会重新从Zookeeper拉取元数据进行初始化，并且需要通知其他所有的broker更新ActiveControllerId。老的Controller需要关闭监听、事件处理线程和定时任务。分区数非常多时，这个过程非常耗时，而且这个过程中Kafka集群是不能工作的。</p><p>当分区数增加时，Zookeeper保存的元数据变多，Zookeeper集群压力变大，达到一定级别后，监听延迟增加，给Kafaka的工作带来了影响。</p><p>所以，Kafka单集群承载的<strong>分区数量是一个瓶颈</strong>。而这又恰恰是一些业务场景需要的。</p><h4 id="Zookeeper的致命缺陷"><a href="#Zookeeper的致命缺陷" class="headerlink" title="Zookeeper的致命缺陷"></a>Zookeeper的致命缺陷</h4><p>Zookeeper是集群部署，只要集群中超过半数节点存活，即可提供服务，例如一个由3个节点的Zookeeper，允许1个Zookeeper节点宕机，集群仍然能提供服务；一个由５个节点的Zookeeper，允许2个节点宕机。</p><p>但Zookeeper的设计是CP模型，即要保证数据的强一致性，必然在可用性方面做出牺牲。</p><p>Zookeeper集群中也存在所谓的Leader节点和从节点，Leader节点负责写，Leader与从节点可用接受读请求，但在Zookeeper内部节点在选举时整个Zookeeper无法对外提供服务。当然正常情况下选举会非常快，但在异常情况下就不好说了，例如Zookeeper节点发生full Gc，此时造成的影响将是毁灭性的。</p><p>Zookeeper节点如果频繁发生Full Gc，此时与客户端的会话将超时，由于此时无法响应客户端的心跳请求(Stop World)，从而与会话相关联的临时节点将被删除，注意，此时是所有的临时节点会被删除，Zookeeper依赖的事件通知机制将失效，整个集群的选举服务将失效。</p><h4 id="设计优雅性"><a href="#设计优雅性" class="headerlink" title="设计优雅性"></a>设计优雅性</h4><p>站在高可用性的角度，Kafka集群的可用性不仅取决于自身，还受到了外部组件的制约，从长久来看，显然都不是一个优雅的方案。</p><h4 id="分布式领域技术完善"><a href="#分布式领域技术完善" class="headerlink" title="分布式领域技术完善"></a>分布式领域技术完善</h4><p>随着分布式领域相关技术的不断完善，<strong>去中心化</strong>的思想逐步兴起，去Zookeeper的呼声也越来越高，在这个进程中涌现了一个非常优秀的算法：<strong>Raft协议</strong>。</p><p>Raft协议的两个重要组成部分：Leader选举、日志复制，而日志复制为多个副本提供数据强一致性提供了强一致性，并且一个显著的特点是Raft节点是去中心化的架构，不依赖外部的组件，而是作为一个协议簇嵌入到应用中的，即与应用本身是融合为一体的。</p><h3 id="Kafka去掉Zookeeper后怎么实现其功能"><a href="#Kafka去掉Zookeeper后怎么实现其功能" class="headerlink" title="Kafka去掉Zookeeper后怎么实现其功能"></a>Kafka去掉Zookeeper后怎么实现其功能</h3><p>KIP-500用Quorum Controller代替之前的Controller，Quorum中每个Controller节点都会保存所有元数据，通过KRaft协议保证副本的一致性。这样即使Quorum Controller节点出故障了，新的Controller迁移也会非常快。</p><p>以Kafka Topic的分布图举例，引用Raft协议的示例图如下：</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_3.png"></p><p>官方介绍，升级之后，Kafka可以轻松支持百万级别的分区。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafak团队把通过Raft协议同步数据的方式Kafka Raft Metadata mode,简称KRaft</span><br></pre></td></tr></table></figure><p>关于Raft协议，本文并不打算深入进行探讨，具体参考文章<a href="https://zhuanlan.zhihu.com/p/91288179">Raft协议原理详解</a></p><p>Raft协议为选主提供了另外一种可行方案，而且还无需依赖第三方组件，何乐而不为呢？故最终Kafka在2.8版本中正式废弃了Zookeeper，拥抱Raft。</p><p>Kafaka计划在3.0版本会兼容Zookeeper Controller和Quorum Controller，这样用户可以进行灰度测试。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在大规模集群和云原生的背景下，使用Zookeeper给Kafka的运维和集群性能造成了很大的压力。去除Zookeeper是必然趋势，这也符合大道至简的架构思想。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
            <tag> ZOOKEEPER </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件系列之死信、延迟、重试队列</title>
      <link href="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/"/>
      <url>/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<h3 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a>延迟队列</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在发送延时消息的时候并不是先投递到要发送的真实主题（real_topic）中，而是先投递到一些 Kafka 内部的主题（delay_topic）中，这些内部主题对用户不可见，</span><br><span class="line"></span><br><span class="line">然后通过一个自定义的服务拉取这些内部主题中的消息，并将满足条件的消息再投递到要发送的真实的主题中，消费者所订阅的还是真实的主题。</span><br></pre></td></tr></table></figure><p>如果采用这种方案，那么一般是按照不同的延时等级来划分的，比如设定5s、10s、30s、1min、2min、5min、10min、20min、30min、45min、1hour、2hour这些按延时时间递增的延时等级，延时的消息按照延时时间投递到不同等级的主题中，投递到同一主题中的消息的延时时间会被强转为与此主题延时等级一致的延时时间，这样延时误差控制在两个延时等级的时间差范围之内（比如延时时间为17s的消息投递到30s的延时主题中，之后按照延时时间为30s进行计算，延时误差为13s）。虽然有一定的延时误差，但是误差可控，并且这样只需增加少许的主题就能实现延时队列的功能。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_2.png"></p><p>发送到内部主题（delaytopic*）中的消息会被一个独立的 DelayService 进程消费，这个 DelayService 进程和 Kafka broker 进程以一对一的配比进行同机部署（参考下图），以保证服务的可用性。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_3.png"></p><p><strong>针对不同延时级别的主题，在 DelayService 的内部都会有单独的线程来进行消息的拉取，以及单独的 DelayQueue（这里用的是 JUC 中 DelayQueue）进行消息的暂存。</strong></p><p>与此同时，在 DelayService 内部还会有专门的消息发送线程来获取 DelayQueue 的消息并转发到真实的主题中。从消费、暂存再到转发，线程之间都是一一对应的关系。如下图所示，DelayService 的设计应当尽量保持简单，避免锁机制产生的隐患。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_4.png"></p><p>为了保障内部 DelayQueue 不会因为未处理的消息过多而导致内存的占用过大，DelayService 会对主题中的每个分区进行计数，当达到一定的阈值之后，就会暂停拉取该分区中的消息。</p><p>因为一个主题中一般不止一个分区，分区之间的消息并不会按照投递时间进行排序，DelayQueue的作用是将消息按照再次投递时间进行有序排序，这样下游的消息发送线程就能够按照先后顺序获取最先满足投递条件的消息。</p><h3 id="重试队列"><a href="#重试队列" class="headerlink" title="重试队列"></a>重试队列</h3><p>重试队列其实可以看作一种回退队列，具体指消费端消费消息失败时，为了防止消息无故丢失而重新将消息回滚到 broker 中。</p><p>与回退队列不同的是，重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大。</p><p>理解了他们的概念之后我们就可以为每个主题设置重试队列，消息第一次消费失败入重试队列 Q1，Q1 的重新投递延时为5s，5s过后重新投递该消息；如果消息再次消费失败则入重试队列 Q2，Q2 的重新投递延时为10s，10s过后再次投递该消息。</p><p>然后再设置一个主题作为死信队列，重试越多次重新投递的时间就越久，并且需要设置一个上限，超过投递次数就进入死信队列。重试队列与延时队列有相同的地方，都需要设置延时级别。</p><h3 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a>死信队列</h3><p>当一条消息初次消费失败，消息队列 MQ 会自动进行消息重试；</p><p>达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息; </p><p>此时，消息队列 MQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中，这种正常情况下无法被消费的消息称为<strong>死信消息</strong>（Dead-Letter Message），存储死信消息的特殊队列称为<strong>死信队列</strong>（Dead-Letter Queue）。</p><p>当一条消息在队列中出现以下三种情况的时候，该消息就会变成一条死信。</p><ul><li>消费者拒绝消费消息，并且不把消息重新放回原目标队列(消费者不想处理的数据)</li><li>消息TTL(time to live)过期(不符合处理要求的数据)</li><li>队列达到最大长度(消费者不能处理的数据)</li></ul><p>当消息在一个队列中变成一个死信之后，如果配置了死信队列，它将被重新publish到死信交换机，死信交换机将死信投递到一个队列上，这个队列就是死信队列。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img.png"></p><h4 id="死信队列处理的方式"><a href="#死信队列处理的方式" class="headerlink" title="死信队列处理的方式"></a>死信队列处理的方式</h4><ul><li>丢弃，如果不是很重要，可以选择丢弃</li><li>记录死信入库，然后做后续的业务分析或处理</li><li>通过死信队列，由负责监听死信的应用程序进行处理</li></ul><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_1.png"></p><h3 id="各中间件支持"><a href="#各中间件支持" class="headerlink" title="各中间件支持"></a>各中间件支持</h3><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><p>Kafka 没有重试机制不支持消息重试，也没有死信队列，因此使用 Kafka 做消息队列时，如果遇到了消息在业务处理时出现异常，就会很难进行下一步处理。</p><p><strong>使用KafkaConnector扩展实现死信队列</strong></p><p>Kafka连接器是Kafka的一部分，是在Kafka和其它技术之间构建流式管道的一个强有力的框架。它可用于将数据从多个地方（包括数据库、消息队列和文本文件）流式注入到Kafka，以及从Kafka将数据流式传输到目标端（如文档存储、NoSQL、数据库、对象存储等）中。</p><p>Kafka连接器可以配置为将无法处理的消息（例如上面提到的反序列化错误）发送到一个单独的Kafka主题，即死信队列。有效消息会正常处理，管道也会继续运行。然后可以从死信队列中检查无效消息，并根据需要忽略或修复并重新处理。</p><p>进行如下的配置可以启用死信队列：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">errors.tolerance</span> = <span class="string">all</span></span><br><span class="line"><span class="meta">errors.deadletterqueue.topic.name</span> =<span class="string"></span></span><br></pre></td></tr></table></figure><p>如果运行于单节点Kafka集群，还需要配置<code>errors.deadletterqueue.topic.replication.factor = 1</code>，其默认值为3。</p><p>但是只有看到消息才能知道它是无效的JSON，即便如此，也只能假设消息被拒绝的原因，要确定Kafka连接器将消息视为无效的实际原因，有两个方法：</p><ul><li>死信队列的消息头；</li><li>Kafka连接器的工作节点日志。</li></ul><p><strong>记录消息的失败原因：消息头</strong></p><p>消息头是使用Kafka消息的键、值和时间戳存储的附加元数据，是在Kafka 0.11版本中引入的。Kafka连接器可以将有关消息拒绝原因的信息写入消息本身的消息头中。这个做法比写入日志文件更好，因为它将原因直接与消息联系起来。</p><p>配置如下的参数，可以在死信队列的消息头中包含拒绝原因：</p><pre><code>errors.deadletterqueue.context.headers.enable = true</code></pre><p><strong>记录消息的失败原因：日志</strong></p><p>记录消息的拒绝原因的第二个选项是将其写入日志。根据安装方式不同，Kafka连接器会将其写入标准输出或日志文件。无论哪种方式都会为每个失败的消息生成一堆详细输出。进行如下配置可启用此功能：</p><pre><code>errors.log.enable = true</code></pre><p>通过配置<code>errors.log.include.messages = true</code>，还可以在输出中包含有关消息本身的元数据。此元数据中包括一些和上面提到的消息头中一样的项目，包括源消息的主题和偏移量。注意它不包括消息键或值本身</p><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>默认的处理机制中，如果我们只对消息做重复消费，达到最大重试次数之后消息就进入死信队列了。RocketMQ 的处理方式为将达到最大重试次数（16 次）的消息标记为死信消息，将该死信消息投递到 DLQ 死信队列中，业务需要进行人工干预。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码规范之JAVA代码安全指南</title>
      <link href="/2021/07/13/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/"/>
      <url>/2021/07/13/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h2 id="后台类"><a href="#后台类" class="headerlink" title="后台类"></a>后台类</h2><h3 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h3><h4 id="【必须】SQL语句默认使用预编译并绑定变量"><a href="#【必须】SQL语句默认使用预编译并绑定变量" class="headerlink" title="【必须】SQL语句默认使用预编译并绑定变量"></a>【必须】SQL语句默认使用预编译并绑定变量</h4><p>Web后台系统应默认使用预编译绑定变量的形式创建sql语句，保持查询语句和数据相分离。以从本质上避免SQL注入风险。</p><p>如使用Mybatis作为持久层框架，应通过#{}语法进行参数绑定，MyBatis 会创建 <code>PreparedStatement</code> 参数占位符，并通过占位符安全地设置参数。</p><p>示例：JDBC</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String custname=request.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        String query=<span class="string">&quot;SELECT * FROM user_data WHERE user_name = ? &quot;</span>;</span><br><span class="line">        PreparedStatement pstmt=connection.prepareStatement(query);</span><br><span class="line">        pstmt.setString(<span class="number">1</span>,custname);</span><br><span class="line">        ResultSet results=pstmt.executeQuery();</span><br></pre></td></tr></table></figure><p>Mybatis</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id=<span class="string">&quot;queryRuleIdByApplicationId&quot;</span>parameterType=<span class="string">&quot;java.lang.String&quot;</span>resultType=<span class="string">&quot;java.lang.String&quot;</span>&gt;</span><br><span class="line">        select rule_id from scan_rule_sqlmap_tab where application_id=#&#123;applicationId&#125;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure><p>应避免外部输入未经过滤直接拼接到SQL语句中，或者通过Mybatis中的${}传入SQL语句（即使使用PreparedStatement，SQL语句直接拼接外部输入也同样有风险。例如Mybatis中部分参数通过${}传入SQL语句后实际执行时调用的是PreparedStatement.execute()<br>，同样存在注入风险）。</p><h4 id="【必须】白名单过滤"><a href="#【必须】白名单过滤" class="headerlink" title="【必须】白名单过滤"></a>【必须】白名单过滤</h4><p>对于表名、列名等无法进行预编译的场景，比如外部数据拼接到order by, group<br>by语句中，需通过白名单的形式对数据进行校验，例如判断传入列名是否存在、升降序仅允许输入“ASC”和“DESC”、表名列名仅允许输入字符、数字、下划线等。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">someMethod</span><span class="params">(<span class="keyword">boolean</span> sortOrder)</span></span>&#123;</span><br><span class="line">        String SQLquery=<span class="string">&quot;some SQL ... order by Salary &quot;</span>+(sortOrder?<span class="string">&quot;ASC&quot;</span>:<span class="string">&quot;DESC&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><h4 id="【必须】文件类型限制"><a href="#【必须】文件类型限制" class="headerlink" title="【必须】文件类型限制"></a>【必须】文件类型限制</h4><p>须在服务器端采用白名单方式对上传或下载的文件类型、大小进行严格的限制。仅允许业务所需文件类型上传，避免上传.jsp、.jspx、.class、.java等可执行文件。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">String file_name=file.getOriginalFilename();</span><br><span class="line">String[]parts=file_name.split(<span class="string">&quot;\\.&quot;</span>);</span><br><span class="line">String suffix=parts[parts.length-<span class="number">1</span>];</span><br><span class="line"><span class="keyword">switch</span>(suffix)&#123;</span><br><span class="line">    <span class="keyword">case</span><span class="string">&quot;jpeg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpeg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;jpg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;bmp&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.bmp&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;png&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.png&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">//handle error</span></span><br><span class="line">        <span class="keyword">return</span><span class="string">&quot;error&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】禁止外部文件存储于可执行目录"><a href="#【必须】禁止外部文件存储于可执行目录" class="headerlink" title="【必须】禁止外部文件存储于可执行目录"></a>【必须】禁止外部文件存储于可执行目录</h4><p>禁止外部文件存储于WEB容器的可执行目录（appBase）。建议保存在专门的文件服务器中。</p><h4 id="【建议】避免路径拼接"><a href="#【建议】避免路径拼接" class="headerlink" title="【建议】避免路径拼接"></a>【建议】避免路径拼接</h4><p>文件目录避免外部参数拼接。保存文件目录建议后台写死并对文件名进行校验（字符类型、长度）。建议文件保存时，将文件名替换为随机字符串。</p><h4 id="【必须】避免路径穿越"><a href="#【必须】避免路径穿越" class="headerlink" title="【必须】避免路径穿越"></a>【必须】避免路径穿越</h4><p>如因业务需要不能满足避免路径拼接，文件路径、文件命中拼接了不可行数据，需判断请求文件名和文件路径参数中是否存在../或..\(仅windows)， 如存在应判定路径非法并拒绝请求。</p><h3 id="网络访问"><a href="#网络访问" class="headerlink" title="网络访问"></a>网络访问</h3><h4 id="【必须】避免直接访问不可信地址"><a href="#【必须】避免直接访问不可信地址" class="headerlink" title="【必须】避免直接访问不可信地址"></a>【必须】避免直接访问不可信地址</h4><p>服务器访问不可信地址时，禁止访问私有地址段及内网域名。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 以RFC定义的专有网络为例，如有自定义私有网段亦应加入禁止访问列表。</span><br><span class="line">10.0.0.0/8</span><br><span class="line">172.16.0.0/12</span><br><span class="line">192.168.0.0/16</span><br><span class="line">127.0.0.0/8</span><br></pre></td></tr></table></figure><p>建议通过URL解析函数进行解析，获取host或者domain后通过DNS获取其IP，然后和内网地址进行比较。</p><p>对已校验通过地址进行访问时，应关闭跟进跳转功能。</p><p>参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">httpConnection=(HttpURLConnection)Url.openConnection();</span><br><span class="line">httpConnection.setFollowRedirects(<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="XML读写"><a href="#XML读写" class="headerlink" title="XML读写"></a>XML读写</h3><h4 id="【必须】XML解析器关闭DTD解析"><a href="#【必须】XML解析器关闭DTD解析" class="headerlink" title="【必须】XML解析器关闭DTD解析"></a>【必须】XML解析器关闭DTD解析</h4><p>读取外部传入XML文件时，XML解析器初始化过程中设置关闭DTD解析。</p><p>参考示例：</p><p>javax.xml.parsers.DocumentBuilderFactory</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setXIncludeAware(<span class="keyword">false</span>);</span><br><span class="line">        dbf.setExpandEntityReferences(<span class="keyword">false</span>);</span><br><span class="line">        ……</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>org.dom4j.io.SAXReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">saxReader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><p>org.jdom2.input.SAXBuilder</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SAXBuilder builder=<span class="keyword">new</span> SAXBuilder();</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">Document doc=builder.build(<span class="keyword">new</span> File(fileName));</span><br></pre></td></tr></table></figure><p>org.xml.sax.XMLReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">XMLReader reader=XMLReaderFactory.createXMLReader();</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="响应输出"><a href="#响应输出" class="headerlink" title="响应输出"></a>响应输出</h3><h4 id="【必须】设置正确的HTTP响应包类型"><a href="#【必须】设置正确的HTTP响应包类型" class="headerlink" title="【必须】设置正确的HTTP响应包类型"></a>【必须】设置正确的HTTP响应包类型</h4><p>响应包的HTTP头“Content-Type”必须正确配置响应包的类型，禁止非HTML类型的响应包设置为“text/html”。此举会使浏览器在直接访问链接时，将非HTML格式的返回报文当做HTML解析，增加反射型XSS的触发几率。</p><h4 id="【建议】设置安全的HTTP响应头"><a href="#【建议】设置安全的HTTP响应头" class="headerlink" title="【建议】设置安全的HTTP响应头"></a>【建议】设置安全的HTTP响应头</h4><ul><li><p>X-Content-Type-Options：</p><p>建议添加“X-Content-Type-Options”响应头并将其值设置为“nosniff”，可避免部分浏览器根据其“Content-Sniff”特性，将一些非“text/html”类型的响应作为HTML解析，增加反射型XSS的触发几率。</p></li><li><p>HttpOnly：</p><p>控制用户登录鉴权的Cookie字段 应当设置HttpOnly属性以防止被XSS漏洞/JavaScript操纵泄漏。</p></li><li><p>X-Frame-Options：</p><p>设置X-Frame-Options响应头，并根据需求合理设置其允许范围。该头用于指示浏览器禁止当前页面在frame、iframe、embed等标签中展现。从而避免点击劫持问题。它有三个可选的值：<br>DENY： 浏览器会拒绝当前页面加载任何frame页面；<br>SAMEORIGIN：则frame页面的地址只能为同源域名下的页面<br>ALLOW-FROM origin：可以定义允许frame加载的页面地址。</p></li><li><p>Access-Control-Allow-Origin</p><p>当需要配置CORS跨域时，应对请求头的Origin值做严格过滤。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String currentOrigin = request.getHeader(<span class="string">&quot;Origin&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (currentOrigin.equals(<span class="string">&quot;https://domain.qq.com&quot;</span>)) &#123;</span><br><span class="line">       response.setHeader(<span class="string">&quot;Access-Control-Allow-Origin&quot;</span>, currentOrigin);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="【必须】外部输入拼接到response页面前进行编码处理"><a href="#【必须】外部输入拼接到response页面前进行编码处理" class="headerlink" title="【必须】外部输入拼接到response页面前进行编码处理"></a>【必须】外部输入拼接到response页面前进行编码处理</h4><p>当响应“content-type”为“html”类型时，外部输入拼接到响应包中，需根据输出位置进行编码处理。编码规则：</p><table><thead><tr><th>场景</th><th>编码规则</th></tr></thead><tbody><tr><td>输出点在HTML标签之间</td><td>需要对以下6个特殊字符进行HTML实体编码(&amp;, &lt;, &gt;, “, ‘,/)。<br>示例：<br>&amp; –&gt; &amp;amp;<br>&lt; –&gt; &amp;lt;<br>&gt;–&gt; &amp;gt;<br>“ –&gt; &amp;quot;<br>‘ –&gt; &amp;#x27;  <br>/ –&gt; &amp;#x2F;</td></tr><tr><td>输出点在HTML标签普通属性内（如href、src、style等，on事件除外）</td><td>要对数据进行HTML属性编码。<br>编码规则：除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为&#xHH;(以&amp;#x开头，HH则是指该字符对应的十六进制数字，分号作为结束符)</td></tr><tr><td>输出点在JS内的数据中</td><td>需要进行js编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \xHH （以 \x 开头，HH则是指该字符对应的十六进制数字）<br>Tips：这种场景仅限于外部数据拼接在js里被引号括起来的变量值中。除此之外禁止直接将代码拼接在js代码中。</td></tr><tr><td>输出点在CSS中（Style属性）</td><td>需要进行CSS编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \HH （以 \ 开头，HH则是指该字符对应的十六进制数字）</td></tr><tr><td>输出点在URL属性中</td><td>对这些数据进行URL编码<br>Tips：除此之外，所有链接类属性应该校验其协议。禁止JavaScript、data和Vb伪协议。</td></tr></tbody></table><p>以上编码规则相对较为繁琐，可参考或直接使用业界已有成熟第三方库如ESAPI.其提供以下函数对象上表中的编码规则:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ESAPI.encoder().encodeForHTML();</span><br><span class="line">        ESAPI.encoder().encodeForHTMLAttribute();</span><br><span class="line">        ESAPI.encoder().encodeForJavaScript();</span><br><span class="line">        ESAPI.encoder().encodeForCSS();</span><br><span class="line">        ESAPI.encoder().encodeForURL();</span><br></pre></td></tr></table></figure><h4 id="【必须】外部输入拼接到HTTP响应头中需进行过滤"><a href="#【必须】外部输入拼接到HTTP响应头中需进行过滤" class="headerlink" title="【必须】外部输入拼接到HTTP响应头中需进行过滤"></a>【必须】外部输入拼接到HTTP响应头中需进行过滤</h4><p>应尽量避免外部可控参数拼接到HTTP响应头中，如业务需要则需要过滤掉“\r”、”\n”等换行符，或者拒绝携带换行符号的外部输入。</p><h4 id="【必须】避免不可信域名的302跳转"><a href="#【必须】避免不可信域名的302跳转" class="headerlink" title="【必须】避免不可信域名的302跳转"></a>【必须】避免不可信域名的302跳转</h4><p>如果对外部传入域名进行302跳转，必须设置可信域名列表并对传入域名进行校验。</p><p>为避免校验被绕过，应避免直接对URL进行字符串匹配。应通过通过URL解析函数进行解析，获取host或者domain后和白名单进行比较。</p><p>需要注意的是，由于浏览器的容错机制，域名<code>https://www.qq.com\www.bbb.com</code>中的<code>\</code>会被替换成<code>/</code>，最终跳转到<code>www.qq.com</code><br>。而Java的域名解析函数则无此特性。为避免解析不一致导致绕过，建议对host中的<code>/</code>和<code>#</code>进行替换。</p><p>参考代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">String host=<span class="string">&quot;&quot;</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  url=url.replaceAll(<span class="string">&quot;[\\\\#]&quot;</span>,<span class="string">&quot;/&quot;</span>); <span class="comment">//替换掉反斜线和井号</span></span><br><span class="line">  host=<span class="keyword">new</span> URL(url).getHost();</span><br><span class="line">&#125; <span class="keyword">catch</span>(MalformedURLException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(host.endsWith(<span class="string">&quot;.qq.com&quot;</span>))&#123;</span><br><span class="line">    <span class="comment">//跳转操作</span></span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】避免通过Jsonp传输非公开敏感信息"><a href="#【必须】避免通过Jsonp传输非公开敏感信息" class="headerlink" title="【必须】避免通过Jsonp传输非公开敏感信息"></a>【必须】避免通过Jsonp传输非公开敏感信息</h4><p>jsonp请求再被CSRF攻击时，其响应包可被攻击方劫持导致信息泄露。应避免通过jsonp传输非公开的敏感信息，例如用户隐私信息、身份凭证等。</p><h4 id="【必须】限定JSONP接口的callback字符集范围"><a href="#【必须】限定JSONP接口的callback字符集范围" class="headerlink" title="【必须】限定JSONP接口的callback字符集范围"></a>【必须】限定JSONP接口的callback字符集范围</h4><p>JSONP接口的callback函数名为固定白名单。如callback函数名可用户自定义，应限制函数名仅包含 字母、数字和下划线。如：<code>[a-zA-Z0-9_-]+</code></p><h4 id="【必须】屏蔽异常栈"><a href="#【必须】屏蔽异常栈" class="headerlink" title="【必须】屏蔽异常栈"></a>【必须】屏蔽异常栈</h4><p>应用程序出现异常时，禁止将数据库版本、数据库结构、操作系统版本、堆栈跟踪、文件名和路径信息、SQL 查询字符串等对攻击者有用的信息返回给客户端。建议重定向到一个统一、默认的错误提示页面，进行信息过滤。</p><h4 id="【必须】模板-amp-表达式"><a href="#【必须】模板-amp-表达式" class="headerlink" title="【必须】模板&amp;表达式"></a>【必须】模板&amp;表达式</h4><p>web view层通常通过模板技术或者表达式引擎来实现界面与业务数据分离，比如jsp中的EL表达式。这些引擎通常可执行敏感操作，如果外部不可信数据未经过滤拼接到表达式中进行解析。则可能造成严重漏洞。</p><p>下列是基于EL表达式注入漏洞的演示demo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    <span class="meta">@RequestMapping(&quot;/ELdemo&quot;)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">ELdemo</span><span class="params">(RepeatDTO repeat)</span></span>&#123;</span><br><span class="line">    ExpressionFactory expressionFactory=<span class="keyword">new</span> ExpressionFactoryImpl();</span><br><span class="line">    SimpleContext simpleContext=<span class="keyword">new</span> SimpleContext();</span><br><span class="line">    String exp=<span class="string">&quot;$&#123;&quot;</span>+repeat.getel()+<span class="string">&quot;&#125;&quot;</span>;</span><br><span class="line">    ValueExpression valueExpression=expressionFactory.createValueExpression(simpleContext,exp,String.class);</span><br><span class="line">    <span class="keyword">return</span> valueExpression.getValue(simpleContext).toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>外部可通过el参数，将不可信输入拼接到EL表达式中并解析。</p><p>此时外部访问：x.x.x.x/ELdemo?el=”’’.getClass().forName(‘java.lang.Runtime’).getMethod(‘exec’,’’.getClass()).invoke(‘’<br>.getClass().forName(‘java.lang.Runtime’).getMethod(‘getRuntime’).invoke(null),’open /Applications/Calculator.app’)“<br>可执行操作系统命令调出计算器。</p><p>基于以上风险：</p><ul><li>应避免外部输入的内容拼接到EL表达式或其他表达式引起、模板引擎进行解析。</li><li>白名单过滤外部输入，仅允许字符、数字、下划线等。</li></ul><h3 id="OS命令执行"><a href="#OS命令执行" class="headerlink" title="OS命令执行"></a>OS命令执行</h3><h4 id="【建议】避免不可信数据拼接操作系统命令"><a href="#【建议】避免不可信数据拼接操作系统命令" class="headerlink" title="【建议】避免不可信数据拼接操作系统命令"></a>【建议】避免不可信数据拼接操作系统命令</h4><p>当不可信数据存在时，应尽量避免外部数据拼接到操作系统命令使用 <code>Runtime</code> 和 <code>ProcessBuilder</code> 来执行。优先使用其他同类操作进行代替，比如通过文件系统API进行文件操作而非直接调用操作系统命令。</p><h4 id="【必须】避免创建SHELL操作"><a href="#【必须】避免创建SHELL操作" class="headerlink" title="【必须】避免创建SHELL操作"></a>【必须】避免创建SHELL操作</h4><p>如无法避免直接访问操作系统命令，需要严格管理外部传入参数，使不可信数据仅作为执行命令的参数而非命令。</p><ul><li><p>禁止外部数据直接直接作为操作系统命令执行。</p></li><li><p>避免通过”cmd”、“bash”、“sh”等命令创建shell后拼接外部数据来执行操作系统命令。</p></li><li><p>对外部传入数据进行过滤。可通过白名单限制字符类型，仅允许字符、数字、下划线；或过滤转义以下符号：|;&amp;$&gt;&lt;`（反引号）!</p><p>白名单示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern FILTER_PATTERN = Pattern.compile(<span class="string">&quot;[0-9A-Za-z_]+&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (!FILTER_PATTERN.matcher(input).matches()) &#123;</span><br><span class="line">  <span class="comment">// 终止当前请求的处理</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="会话管理"><a href="#会话管理" class="headerlink" title="会话管理"></a>会话管理</h3><h4 id="【必须】非一次有效身份凭证禁止在URL中传输"><a href="#【必须】非一次有效身份凭证禁止在URL中传输" class="headerlink" title="【必须】非一次有效身份凭证禁止在URL中传输"></a>【必须】非一次有效身份凭证禁止在URL中传输</h4><p>身份凭证禁止在URL中传输，一次有效的身份凭证除外（如CAS中的st）。</p><h4 id="【必须】避免未经校验的数据直接给会话赋值"><a href="#【必须】避免未经校验的数据直接给会话赋值" class="headerlink" title="【必须】避免未经校验的数据直接给会话赋值"></a>【必须】避免未经校验的数据直接给会话赋值</h4><p>防止会话信息被篡改，如恶意用户通过URL篡改手机号码等。</p><h3 id="加解密"><a href="#加解密" class="headerlink" title="加解密"></a>加解密</h3><h4 id="【建议】对称加密"><a href="#【建议】对称加密" class="headerlink" title="【建议】对称加密"></a>【建议】对称加密</h4><p>建议使用AES，秘钥长度128位以上。禁止使用DES算法，由于秘钥太短，其为目前已知不安全加密算法。使用AES加密算法请参考以下注意事项：</p><ul><li>AES算法如果采用CBC模式：每次加密时IV必须采用密码学安全的伪随机发生器（如/dev/urandom）,禁止填充全0等固定值。</li><li>AES算法如采用GCM模式，nonce须采用密码学安全的伪随机数</li><li>AES算法避免使用ECB模式，推荐使用GCM模式。</li></ul><h4 id="【建议】非对称加密"><a href="#【建议】非对称加密" class="headerlink" title="【建议】非对称加密"></a>【建议】非对称加密</h4><p>建议使用RSA算法，秘钥2048及以上。</p><h4 id="【建议】哈希算法"><a href="#【建议】哈希算法" class="headerlink" title="【建议】哈希算法"></a>【建议】哈希算法</h4><p>哈希算法推荐使用SHA-2及以上。对于签名场景，应使用HMAC算法。如果采用字符串拼接盐值后哈希的方式，禁止将盐值置于字符串开头，以避免哈希长度拓展攻击。</p><h4 id="【建议】密码存储策略"><a href="#【建议】密码存储策略" class="headerlink" title="【建议】密码存储策略"></a>【建议】密码存储策略</h4><p>建议采用随机盐+明文密码进行多轮哈希后存储密码。</p><h3 id="查询业务"><a href="#查询业务" class="headerlink" title="查询业务"></a>查询业务</h3><h4 id="【必须】返回信息最小化"><a href="#【必须】返回信息最小化" class="headerlink" title="【必须】返回信息最小化"></a>【必须】返回信息最小化</h4><p>返回用户信息应遵循最小化原则，避免将业务需求之外的用户信息返回到前端。</p><h4 id="【必须】个人敏感信息脱敏展示"><a href="#【必须】个人敏感信息脱敏展示" class="headerlink" title="【必须】个人敏感信息脱敏展示"></a>【必须】个人敏感信息脱敏展示</h4><p>在满足业务需求的情况下，个人敏感信息需脱敏展示,如：</p><ul><li>鉴权信息（如口令、密保答案、生理标识等）不允许展示</li><li>身份证只显示第一位和最后一位字符，如3****************1。</li><li>移动电话号码隐藏中间6位字符，如134******48。</li><li>工作地址/家庭地址最多显示到“区”一级。</li><li>银行卡号仅显示最后4位字符，如************8639</li></ul><h4 id="【必须】数据权限校验"><a href="#【必须】数据权限校验" class="headerlink" title="【必须】数据权限校验"></a>【必须】数据权限校验</h4><p>查询个人非公开信息时，需要对当前访问账号进行数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>验当前用户是否具备访问数据的权限</li></ol><h3 id="操作业务"><a href="#操作业务" class="headerlink" title="操作业务"></a>操作业务</h3><h4 id="【必须】部署CSRF防御机制"><a href="#【必须】部署CSRF防御机制" class="headerlink" title="【必须】部署CSRF防御机制"></a>【必须】部署CSRF防御机制</h4><p>CSRF是指跨站请求伪造（Cross-site request forgery），是web常见的攻击之一。对于可重放的敏感操作请求，需部署CSRF防御机制。可参考以下两种常见的CSRF防御方式</p><ul><li><p>设置CSRF Token</p><p>服务端给合法的客户颁发CSRF<br>Token，客户端在发送请求时携带该token供服务端校验，服务端拒绝token验证不通过的请求。以此来防止第三方构造合法的恶意操作链接。Token的作用域可以是Request级或者Session级。下面以Session级CSRF<br>Token进行示例</p><ol><li><p>登录成功后颁发Token，并同时存储在服务端Session中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String uuidToken = UUID.randomUUID().toString();</span><br><span class="line">map.put(<span class="string">&quot;token&quot;</span>, uuidToken);</span><br><span class="line">request.getSession().setAttribute(<span class="string">&quot;token&quot;</span>,uuidToken );</span><br><span class="line"><span class="keyword">return</span> map;</span><br></pre></td></tr></table></figure></li></ol></li></ul><ol start="2"><li><p>创建Filter</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CsrfFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;  </span><br><span class="line">   HttpSession session = req.getSession();</span><br><span class="line">   Object token = session.getAttribute(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   String requestToken = req.getParameter(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span>(StringUtils.isBlank(requestToken) || !requestToken.equals(token))&#123;</span><br><span class="line">         AjaxResponseWriter.write(req, resp, ServiceStatusEnum.ILLEGAL_TOKEN, <span class="string">&quot;非法的token&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li></ol><p>CSRF Token应具备随机性，保证其不可预测和枚举。另外由于浏览器会自动对表单所访问的域名添加相应的cookie信息，所以CSRF Token不应该通过Cookie传输。</p><ul><li><p>校验Referer头</p><p>通过检查HTTP请求的Referer字段是否属于本站域名，非本站域名的请求进行拒绝。</p><p>这种校验方式需要注意两点：</p><ol><li>要需要处理Referer为空的情况，当Referer为空则拒绝请求</li><li>注意避免例如qq.com.evil.com 部分匹配的情况。</li></ol></li></ul><h4 id="【必须】权限校验"><a href="#【必须】权限校验" class="headerlink" title="【必须】权限校验"></a>【必须】权限校验</h4><p>对于非公共操作，应当校验当前访问账号进行操作权限（常见于CMS）和数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>校验当前用户是否具备该操作权限</li><li>校验当前用户是否具备所操作数据的权限。避免越权。</li></ol><h4 id="【建议】加锁操作"><a href="#【建议】加锁操作" class="headerlink" title="【建议】加锁操作"></a>【建议】加锁操作</h4><p>对于有次数限制的操作，比如抽奖。如果操作的过程中资源访问未正确加锁。在高并发的情况下可能造成条件竞争，导致实际操作成功次数多于用户实际操作资格次数。此类操作应加锁处理。</p>]]></content>
      
      
      <categories>
          
          <category> 代码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库MySQL系列01之死锁原理及其解决方案研究</title>
      <link href="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/"/>
      <url>/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是死锁"><a href="#什么是死锁" class="headerlink" title="什么是死锁"></a>什么是死锁</h1><p>死锁是并发系统中常见的问题，同样也会出现在数据库MySQL的并发读写请求场景中。<br>当两个及以上的事务，双方都在等待对方释放已经持有的锁或因为加锁顺序不一致造成循环等待锁资源，就会出现“死锁”。<br>常见的报错信息为 Deadlock found when trying to get lock…<br>举例来说 A 事务持有 X1 锁 ，申请 X2 锁，B事务持有 X2 锁，申请 X1 锁。A 和 B 事务持有锁并且申请对方持有的锁进入循环等待，就造成了死锁。</p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img.png" class><p>如上图，是右侧的四辆汽车资源请求产生了回路现象，即死循环，导致了死锁。</p><h1 id="死锁出现要素"><a href="#死锁出现要素" class="headerlink" title="死锁出现要素"></a>死锁出现要素</h1><ul><li>两个或者两个以上事务</li><li>每个事务都已经持有锁并且申请新的锁</li><li>锁资源同时只能被同一个事务持有或者不兼容</li><li>事务之间因为持有锁和申请锁导致彼此循环等待</li></ul><h1 id="经典案例"><a href="#经典案例" class="headerlink" title="经典案例"></a>经典案例</h1><h2 id="案例一-事务并发-insert-唯一键冲突"><a href="#案例一-事务并发-insert-唯一键冲突" class="headerlink" title="案例一:事务并发 insert 唯一键冲突"></a>案例一:事务并发 insert 唯一键冲突</h2><p>表结构如下所示:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_1.png"></p><p>测试用例如下:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_2.png"></p><p>日志分析如下:</p><ul><li><p>事务 T2 insert into t7(id,a) values (26,10) 语句 insert 成功，持有 a=10 的 排他行锁( Xlocks rec but no gap )</p></li><li><p>事务 T1 insert into t7(id,a) values (30,10), 因为T2的第一条 insert 已经插入 a=10 的记录,事务 T1 insert a=10 则发生唯一键冲突,需要申请对冲突的唯一索引加上S Next-key Lock( 即 lock mode S waiting ) 这是一个间隙锁会申请锁住(,10],(10,20]之间的 gap 区域。</p></li><li><p>事务 T2 insert into t7(id,a) values (40，9)该语句插入的 a=9 的值在事务 T1 申请的 gap 锁4-10之间， 故需事务 T2 的第二条 insert 语句要等待事务 T1 的 S-Next-key Lock 锁释放,在日志中显示 lock_mode X locks gap before rec insert intention waiting 。</p></li></ul><h2 id="案例二-先-update-再-insert-的并发死锁问题"><a href="#案例二-先-update-再-insert-的并发死锁问题" class="headerlink" title="案例二:先 update 再 insert 的并发死锁问题"></a>案例二:先 update 再 insert 的并发死锁问题</h2><p>表结构如下，无数据:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_3.png"></p><p>测试用例如下:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_4.png"></p><p>死锁分析:<br>可以看到两个事务 update 不存在的记录，先后获得间隙锁( gap 锁)，gap 锁之间是兼容的所以在update环节不会阻塞。</p><p>两者都持有 gap 锁，然后去竞争插入意向锁。当存在其他会话持有 gap 锁的时候，当前会话申请不了插入意向锁，导致死锁。</p><h1 id="如何尽可能避免死锁"><a href="#如何尽可能避免死锁" class="headerlink" title="如何尽可能避免死锁"></a>如何尽可能避免死锁</h1><ul><li><p>合理的设计索引，区分度高的列放到组合索引前面，使业务 SQL 尽可能通过索引定位更少的行，减少锁竞争。</p></li><li><p>调整业务逻辑 SQL 执行顺序， 避免 update/delete 长时间持有锁的 SQL 在事务前面。</p></li><li><p>避免大事务，尽量将大事务拆成多个小事务来处理，小事务发生锁冲突的几率也更小。</p></li><li><p>以固定的顺序访问表和行。比如两个更新数据的事务，事务 A 更新数据的顺序为 1，2;事务 B 更新数据的顺序为 2，1。这样更可能会造成死锁。</p></li><li><p>在并发比较高的系统中，不要显式加锁，特别是是在事务里显式加锁。如 select … for update 语句，如果是在事务里（运行了 start transaction 或设置了autocommit 等于0）,那么就会锁定所查找到的记录。</p></li><li><p>尽量按主键/索引去查找记录，范围查找增加了锁冲突的可能性，也不要利用数据库做一些额外额度计算工作。比如有的程序会用到 “select … where … order by rand();”这样的语句，由于类似这样的语句用不到索引，因此将导致整个表的数据都被锁住。</p></li><li><p>优化 SQL 和表设计，减少同时占用太多资源的情况。比如说，减少连接的表，将复杂 SQL 分解为多个简单的 SQL。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 死锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>批处理框架之SpringBatch快速入门实践</title>
      <link href="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
      <url>/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h3 id="什么是SpringBatch"><a href="#什么是SpringBatch" class="headerlink" title="什么是SpringBatch"></a>什么是SpringBatch</h3><p>一个轻量级，全面的<strong>批处理框架，不是一个 schuedling 的框架</strong>。</p><p>一个标准的批处理程序：</p><ul><li>通常会从数据库，文件或者队列中读取大量的数据和记录，</li><li>然后对获取的数据进行处理，</li><li>然后将修改后的格式写回到数据库中。</li></ul><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img.png"></p><p>通常 Spring Batch 在离线模式下进行工作，不需要用户干预就能自动进行基本的批处理迭代，进行类似事务方式的处理。批处理是大多数 IT 目的一个组成部分，而 Spring Batch<br>是唯一能够提供健壮的企业级扩展性的批处理开源框架。</p><h3 id="什么情况下需要用到SpringBatch"><a href="#什么情况下需要用到SpringBatch" class="headerlink" title="什么情况下需要用到SpringBatch"></a>什么情况下需要用到SpringBatch</h3><p>在大型企业中，由于业务复杂、数据量大、数据格式不同、数据交互格式繁杂，并非所有的操作都能通过交互界面进行处理。而有一些操作需要定期读取大批量的数据，然后进行一系列的后续处理。这样的过程就是“批处理”。</p><ul><li>数据量大，从数万到数百万甚至上亿不等；</li><li>整个过程全部自动化，并预留一定接口进行自定义配置；</li><li>这样的应用通常是周期性运行，比如按日、周、月运行；</li><li>对数据处理的准确性要求高，并且需要容错机制、回滚机制、完善的日志监控等。</li></ul><h3 id="SpringBatch提供了哪些功能"><a href="#SpringBatch提供了哪些功能" class="headerlink" title="SpringBatch提供了哪些功能"></a>SpringBatch提供了哪些功能</h3><ul><li>事务管理：全批次事务(因为可能有小数据量的批处理或存在存储过程/脚本中)</li><li>基于Web的管理员接口</li><li>分阶段的企业消息驱动处理</li><li>极高容量和高性能的基于块的处理过程(通过优化和分区技术)</li><li>按顺序处理任务依赖（使用工作流驱动的批处理插件）</li><li>声明式的输入/输出操作</li><li>启动、终止、（失败后的手动或定时）重启任务</li><li>重试/跳过任务，部分处理跳过记录（例如，回滚）<details><summary>具体使用场景</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在处理百万级的数据过程过程中难免会出现异常。如果一旦出现异常而导致整个批处理工作终止的话那么会导致后续的数据无法被处理。Spring Batch内置了Retry（重试）和Skip（跳过）机制帮助我们轻松处理各种异常。我 们需要将异常分为三种类型。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> 第一种是<span class="strong">**需要进行Retry的异常**</span>，它们的特点是该异常可能会随着时间推移而消失，比如数据库目前有锁无法写入、web服务当前不可用、web服务满载等。所以对它们适合配置Retry机制。</span><br><span class="line"><span class="bullet">*</span> 第二种是<span class="strong">**需要Skip的异常**</span>，比如解析文件的某条数据出现异常等，因为对这些异常即使执行Retry每次的结果也都是相同，但又不想由于某条数据出错而停止对后续数据的处理。</span><br><span class="line"><span class="bullet">*</span> 第三种异常是<span class="strong">**需要让整个Job立刻失败的异常**</span>，比如如果出现了OutOfMemory的异常，那么需要整个Job立刻终止运行。</span><br><span class="line"></span><br><span class="line">一般来说需要Retry的异常也要配置Skip选项，从而保证后续的数据能够被继续处理。我们也可以配置SkipLimit选项保证当Skip的数据条目达到一定数量后及时终止整个Job。</span><br></pre></td></tr></table></figure></details></li></ul><h3 id="SpringBatch整体架构"><a href="#SpringBatch整体架构" class="headerlink" title="SpringBatch整体架构"></a>SpringBatch整体架构</h3><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_1.png"></p><p>Spring batch框架有4个主要组件：JobLauncher、Job、Step和JobRepository。</p><ul><li>JobLauncher（任务启动器）：通过它启动任务，可以理解为程序的入口。</li><li>Job（任务）：一个具体的任务。<ul><li>由一个或多个step组成，</li><li>通过JobBuilderFactory实例创建Bean，</li><li>使用next指向下一个step,  可以按照指定的逻辑顺序组合 step,</li><li>提供了我们给所有 step 设置相同属性的方法（例如一些事件监听，跳过策略）;</li></ul></li><li>Step（步骤）：一个具体的执行步骤，一个Job中可以有多个Step。</li><li>JobRepository（任务仓库）：存储数据的仓库，在任务执行的时候，需要用它来记录任务状态信息，可以看做是一个数据库的接口。</li></ul><h4 id="JOB"><a href="#JOB" class="headerlink" title="JOB"></a>JOB</h4><p>Job 是一个封装整个批处理过程的一个概念。Job 在 spring batch 的体系当中只是一个最顶层的一个抽象概念，体现在代码当中则它只是一个最上层的接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Batch domain object representing a job. Job is an explicit abstraction</span></span><br><span class="line"><span class="comment"> * representing the configuration of a job specified by a developer. It should</span></span><br><span class="line"><span class="comment"> * be noted that restart policy is applied to the job as a whole and not to a</span></span><br><span class="line"><span class="comment"> * step.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"> <span class="function">String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">boolean</span> <span class="title">isRestartable</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecution execution)</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersIncrementer <span class="title">getJobParametersIncrementer</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersValidator <span class="title">getJobParametersValidator</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Job 这个接口当中定义了五个方法，它的实现类主要有两种类型的 job，一个是 simplejob，另一个是 flowjob。</p><p>Spring Batch 以 SimpleJob 类的形式提供了 Job 接口的默认简单实现，它在 Job 之上创建了一些标准功能。一个使用 java config 的例子代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job footballJob() &#123;</span><br><span class="line">    return this.jobBuilderFactory.get(&quot;footballJob&quot;)</span><br><span class="line">                     .start(playerLoad())</span><br><span class="line">                     .next(gameLoad())</span><br><span class="line">                     .next(playerSummarization())</span><br><span class="line">                     .end()</span><br><span class="line">                     .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="JobInstance"><a href="#JobInstance" class="headerlink" title="JobInstance"></a>JobInstance</h4><p>他是 Job 的更加底层的一个抽象，他的定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobInstance</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobInstance.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> instance id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getInstanceId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>他的方法很简单，一个是返回 Job 的 id，另一个是返回 Job 的名字。</p><p>JobInstance 指的是 job 运行当中，作业执行过程当中的概念。</p><p>比如说现在有一个批处理的 job，它的功能是在一天结束时执行行一次。我们假定这个批处理 job 的名字为’EndOfDay’。在这个情况下，那么每天就会有一个逻辑意义上的 JobInstance, 而我们必须记录 job 的每次运行的情况。</p><h4 id="JobParameters"><a href="#JobParameters" class="headerlink" title="JobParameters"></a>JobParameters</h4><p>JobParameters 对象包含一组用于启动批处理作业的参数，它可以在运行期间用于识别或甚至用作参考数据。</p><p>例如, 我们前面的’EndOfDay’的 job 现在已经有了两个实例，一个产生于 1 月 1 日，另一个产生于 1 月 2 日，那么我们就可以定义两个 JobParameter 对象：一个的参数是 01-01, 另一个的参数是 01-02。</p><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_2.png"></p><p>因此，我么可以通过 Jobparameter 来操作正确的 JobInstance</p><h4 id="JobExecution"><a href="#JobExecution" class="headerlink" title="JobExecution"></a>JobExecution</h4><p>JobExecution 指的是单次尝试运行一个我们定义好的 Job 的代码层面的概念。job 的一次执行可能以失败也可能成功。只有当执行成功完成时，给定的与执行相对应的 JobInstance 才也被视为完成。</p><p>还是以前面描述的 EndOfDay 的 job 作为示例，假设第一次运行 01-01-2019 的 JobInstance 结果是失败。那么此时如果使用与第一次运行相同的 Jobparameter 参数（即 01-01-2019）作业参数再次运行，那么就会创建一个对应于之前 jobInstance 的一个新的 JobExecution 实例, JobInstance 仍然只有一个。</p><p>JobExecution 的接口定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobExecution</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobExecution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> execution id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getExecutionId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get batch status of this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> batch status value.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> BatchStatus <span class="title">getBatchStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered STARTED status. </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getStartTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered end status: COMPLETED, STOPPED, FAILED </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getEndTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get execution exit status.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> exit status.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getExitStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was created.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getCreateTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was last updated updated.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getLastUpdatedTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job parameters for this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> job parameters  </span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Properties <span class="title">getJobParameters</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>JobExecution 当中提供了一个方法 getBatchStatus 用于获取一个 job 某一次特地执行的一个状态。BatchStatus 是一个代表 job 状态的枚举类，其定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">BatchStatus</span> </span>&#123;</span><br><span class="line">    STARTING, STARTED, STOPPING, STOPPED, FAILED, COMPLETED, ABANDONED</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h4><p>每一个 Step 对象都封装了批处理作业的一个独立的阶段。事实上，每一个 Job 本质上都是由一个或多个步骤组成。每一个 step 包含定义和控制实际批处理所需的所有信息。任何特定的内容都由编写 Job 的开发人员自行决定。</p><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_3.png"></p><p>StepExecution 表示一次执行 Step, 每次运行一个 Step 时都会创建一个新的 StepExecution，类似于 JobExecution。但是，某个步骤可能由于其之前的步骤失败而无法执行。且仅当 Step 实际启动时才会创建 StepExecution。</p><p>一次 step 执行的实例由 StepExecution 类的对象表示。每个 StepExecution 都包含对其相应步骤的引用以及 JobExecution 和事务相关的数据，例如提交和回滚计数以及开始和结束时间。</p><p>此外，每个步骤执行都包含一个 ExecutionContext，其中包含开发人员需要在批处理运行中保留的任何数据，例如重新启动所需的统计信息或状态信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job JobFlowDemo1()&#123;</span><br><span class="line">    return jobBuilderFactory.get(&quot;jobFlowDemo1&quot;)</span><br><span class="line">//                .start(step1())</span><br><span class="line">//                .next(step2())</span><br><span class="line">//                .next(step3())</span><br><span class="line">//                .build();</span><br><span class="line">                .start(step1())</span><br><span class="line">                .on(&quot;COMPLETED&quot;).to(step2())</span><br><span class="line">                .from(step2()).on(&quot;COMPLETED&quot;).to(step3())</span><br><span class="line">                .from(step3()).end()</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">当step1 成功执行完成后，返回COMPLETED， 才调用step2进行下一步处理。但是过多的step，不易于程序维护和复用</span><br></pre></td></tr></table></figure><h4 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h4><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_4.png"></p><p>由于我们一次 batch 的任务可能会有很多的数据读写操作，因此一条一条的处理并向数据库提交的话效率不会很高，因此 spring batch 提供了 chunk 这个概念，我们可以设定一个 chunk size，spring batch 将一条一条处理数据，但不提交到数据库，只有当处理的数据数量达到 chunk size 设定的值得时候，才一起去 commit.</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Spring Batch为我们提供了非常实用的功能，对批处理场景进行了完善的抽象，它不仅能实现小数据的迁移，也能应对大企业的大数据实践应用。它让我们开发批处理应用可以事半功倍。  </p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring生态 </tag>
            
            <tag> SpringBatch </tag>
            
            <tag> 批处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之Kafka重平衡机制简读</title>
      <link href="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/"/>
      <url>/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h3 id="什么是Rebalance"><a href="#什么是Rebalance" class="headerlink" title="什么是Rebalance"></a>什么是Rebalance</h3><p>如果对RocketMQ或者对消息中间件有所了解的话，消费端在进行消息消费时至少需要先进行队列（分区）的负载，即一个消费组内的多个消费者如何对订阅的主题中的队列进行负载均衡,当消费者新增或减少、队列增加或减少时能否自动重平衡，做到应用无感知，直接决定了程序伸缩性，其说明图如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img0.png"></p><p>Rebalance本质上是一种协议，规定了一个Consumer Group下的所有的Consumer如何达成一致来分配订阅Topic的每个Partition；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">比如某个group下有5个consumer，它订阅了一个具有10个分区的topic。正常情况下，Kafka平均会为每个consumer分配2个分区。这个分配的过程就叫rebalance。</span><br></pre></td></tr></table></figure><h3 id="Kafka消费端基本流程"><a href="#Kafka消费端基本流程" class="headerlink" title="Kafka消费端基本流程"></a>Kafka消费端基本流程</h3><p>在介绍kafka消费端重平衡机制之前，我们首先简单来看看消费者拉取消息的流程，从整个流程来看重平衡的触发时机、在整个消费流程中所起的重要作用，消费端拉取消息的简要流程如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img1.png"></p><p>主要的关键点如下：</p><ul><li>判断KafkaConsumer对象是否处在多线程环境中。注意：<strong>该对象是多线程不安全的，不能有多个线程持有该对象。</strong></li><li>消费组初始化，包含了队列负载(重平衡)</li><li>消息拉取</li><li>消息消费拦截器处理</li></ul><p>关于poll方法的核心无非就是两个：<strong>重平衡</strong>与<strong>消费拉取</strong>，本篇文章将重点剖析Kafka消费者的重平衡机制。</p><h3 id="消费者队列负载-重平衡-机制"><a href="#消费者队列负载-重平衡-机制" class="headerlink" title="消费者队列负载(重平衡)机制"></a>消费者队列负载(重平衡)机制</h3><p>通过对updateAssignmentMetadataIfNeeded方法的源码剖析，最终调用的核心方法为ConsumerCoordinator的poll方法，核心流程图如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img2.png"></p><p>消费者协调器的核心流程关键点：</p><ul><li>消费者协调器寻找组协调器</li><li>队列负载(重平衡)</li><li>提交位点</li></ul><p><strong>Some Question</strong>  </p><ul><li>重平衡会阻塞消息消费吗？</li><li>Kafka的加入组协议哪些变更能有效减少重平衡</li><li>Kafka与RocketMQ的重平衡机制上各有什么优劣势</li></ul><h4 id="消费者协调器"><a href="#消费者协调器" class="headerlink" title="消费者协调器"></a>消费者协调器</h4><p>在Kafka中，在客户端每一个消费者会对应一个消费者协调器(ConsumerCoordinator),在服务端每一个broker会启动一个组协调器。</p><p>接下来将对该过程进行源码级别的跟踪，根据源码提练工作机制，该部分对应上面流程图中的：ensureCoordinatorReady方法。</p><details>    <summary>protected synchronized boolean ensureCoordinatorReady(final Timer timer)</summary>    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">protected synchronized boolean ensureCoordinatorReady(final Timer timer) &#123;</span><br><span class="line">    if (!coordinatorUnknown())</span><br><span class="line">        return true;</span><br><span class="line"></span><br><span class="line">    do &#123;</span><br><span class="line">        final RequestFuture&lt;Void&gt; future = lookupCoordinator();</span><br><span class="line">        client.poll(future, timer);</span><br><span class="line"></span><br><span class="line">        if (!future.isDone()) &#123;</span><br><span class="line">            // ran out of time</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (future.failed()) &#123;</span><br><span class="line">            if (future.isRetriable()) &#123;</span><br><span class="line">                log.debug(&quot;Coordinator discovery failed, refreshing metadata&quot;);</span><br><span class="line">                client.awaitMetadataUpdate(timer);</span><br><span class="line">            &#125; else</span><br><span class="line">                throw future.exception();</span><br><span class="line">        &#125; else if (coordinator != null &amp;&amp; client.isUnavailable(coordinator)) &#123;</span><br><span class="line">            // we found the coordinator, but the connection has failed, so mark</span><br><span class="line">            // it dead and backoff before retrying discovery</span><br><span class="line">            markCoordinatorUnknown();</span><br><span class="line">            timer.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; while (coordinatorUnknown() &amp;&amp; timer.notExpired());</span><br><span class="line"></span><br><span class="line">    return !coordinatorUnknown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>该方法的关键点如下：</p><ul><li>首先判断一下当前消费者是否已找到broker端的组协调器，如果以感知，则返回true。</li><li>如果当前并没有感知组协调器，则向服务端(broker)寻找该消费组的组协调器。</li><li>寻找组协调器的过程是一个同步过程，如果出现异常，则会触发重试，但引入了重试间隔机制。</li><li>如果未超时并且没有获取组协调器，则再次尝试(do while)。</li></ul><p>核心要点为<strong>lookupCoordinator</strong>方法，该方法的核心是<strong>选择一台负载最小的broker</strong>,构建请求，向broker端查询消费组的组协调器，代码如下：</p><details>    <summary>private RequestFuture<Void> sendFindCoordinatorRequest(Node node)</Void></summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Discover the current coordinator for the group. Sends a GroupMetadata request to</span><br><span class="line"> * one of the brokers. The returned future should be polled to get the result of the request.</span><br><span class="line"> * @return A request future which indicates the completion of the metadata request</span><br><span class="line"> */</span><br><span class="line">private RequestFuture&lt;Void&gt; sendFindCoordinatorRequest(Node node) &#123;</span><br><span class="line">    // initiate the group metadata request</span><br><span class="line">    log.debug(&quot;Sending FindCoordinator request to broker &#123;&#125;&quot;, node);</span><br><span class="line">    FindCoordinatorRequest.Builder requestBuilder =</span><br><span class="line">            new FindCoordinatorRequest.Builder(</span><br><span class="line">                    new FindCoordinatorRequestData()</span><br><span class="line">                        .setKeyType(CoordinatorType.GROUP.id())</span><br><span class="line">                        .setKey(this.groupId));</span><br><span class="line">    return client.send(node, requestBuilder)</span><br><span class="line">            .compose(new FindCoordinatorResponseHandler());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>查询组协调器的请求，核心参数为：</p><ul><li><p>ApiKeys apiKey<br>  请求API，类比RocketMQ的RequestCode，根据该值很容易找到服务端对应的处理代码，这里为ApiKeys.FIND_COORDINATOR。</p></li><li><p>String coordinatorKey<br>  协调器key，取消费组名称。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka服务端每一台Broker会创建一个组协调器(GroupCoordinator),每一个组协调器可以协调多个消费组，但一个消费组只会被分配给一个组协调器，那这里负载机制是什么呢？服务端众多Broker如何竞争该消费组的控制权呢？</span><br></pre></td></tr></table></figure></li><li><p>coordinatorType<br>协调器类型，默认为GROUP,表示普通消费组。</p></li><li><p>short minVersion<br>版本。</p></li></ul><p>针对客户端端请求，服务端统一入口为KafkaApis.scala，可以根据ApiKeys快速找到其处理入口：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img.png"><br>具体的处理逻辑在KafkaApis的handleFindCoordinatorRequest中，如下图所示:<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_1.png"></p><p>服务端为消费组分配协调器的核心算法竟然非常简单：</p><ul><li>根据消费组的名称，取hashcode，</li><li>然后与kafka内部topic(__consumer_offsets)的分区个数取模，</li><li>然后返回该分区所在的物理broker作为消费组的分组协调器</li><li>即内部并没有复杂的选举机制，这样也能更好的说明，客户端在发送请求时可以挑选负载最低的broker进行查询的原因。</li></ul><p>客户端收到响应结果后更新ConsumerCoordinator的(Node coordinator)属性，这样再次调用coordinatorUnknown()方法，将会返回false,至此完成消费端协调器的查找。</p><h4 id="消费者加入消费组流程剖析"><a href="#消费者加入消费组流程剖析" class="headerlink" title="消费者加入消费组流程剖析"></a>消费者加入消费组流程剖析</h4><p>用一张时序图来说明协调者一端是如何处理新成员入组的:<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_21.png"></p><p>在消费者获取到协调器后，根据上文提到的协调器处理流程，接下来消费者需要加入到消费者组中，加入到消费组也是参与队列负载机制的前提，接下来我们从源码角度分析一下消费组加入消费组的流程，对应上文中的<strong>AbstractCoordinator的ensureActiveGroup</strong>方法。</p><details>    <summary>boolean ensureActiveGroup(final Timer timer)</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Ensure the group is active (i.e., joined and synced)</span><br><span class="line"> *</span><br><span class="line"> * @param timer Timer bounding how long this method can block</span><br><span class="line"> * @return true iff the group is active</span><br><span class="line"> */</span><br><span class="line">boolean ensureActiveGroup(final Timer timer) &#123;</span><br><span class="line">    // always ensure that the coordinator is ready because we may have been disconnected</span><br><span class="line">    // when sending heartbeats and does not necessarily require us to rejoin the group.</span><br><span class="line">    if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    startHeartbeatThreadIfNeeded();</span><br><span class="line">    return joinGroupIfNeeded(timer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>该方法的核心关键点：</p><ul><li>在加入消费组之前必须确保该消费者已经感知到组协调器。</li><li>启动心跳线程，当消费者加入到消费组后处于MemberState.STABLE后需要定时向协调器上报心跳，表示存活，否则将从消费组中移除。</li><li>加入消费组。</li></ul><p>心跳线程稍后会详细介绍，先跟踪一下加入消费组的核心流程，具体实现方法为</p><details><summary>joinGroupIfneeded</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Joins the group without starting the heartbeat thread.</span><br><span class="line"> *</span><br><span class="line"> * Visible for testing.</span><br><span class="line"> *</span><br><span class="line"> * @param timer Timer bounding how long this method can block</span><br><span class="line"> * @return true iff the operation succeeded</span><br><span class="line"> */</span><br><span class="line">boolean joinGroupIfNeeded(final Timer timer) &#123;</span><br><span class="line">    while (rejoinNeededOrPending()) &#123;</span><br><span class="line">        if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span><br><span class="line">        // time if the client is woken up before a pending rebalance completes. This must be called</span><br><span class="line">        // on each iteration of the loop because an event requiring a rebalance (such as a metadata</span><br><span class="line">        // refresh which changes the matched subscription set) can occur while another rebalance is</span><br><span class="line">        // still in progress.</span><br><span class="line">        if (needsJoinPrepare) &#123;</span><br><span class="line">            onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">            needsJoinPrepare = false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        final RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br><span class="line">        client.poll(future, timer);</span><br><span class="line">        if (!future.isDone()) &#123;</span><br><span class="line">            // we ran out of time</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (future.succeeded()) &#123;</span><br><span class="line">            // Duplicate the buffer in case `onJoinComplete` does not complete and needs to be retried.</span><br><span class="line">            ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line">            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br><span class="line"></span><br><span class="line">            // We reset the join group future only after the completion callback returns. This ensures</span><br><span class="line">            // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            needsJoinPrepare = true;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            final RuntimeException exception = future.exception();</span><br><span class="line">            if (exception instanceof UnknownMemberIdException ||</span><br><span class="line">                    exception instanceof RebalanceInProgressException ||</span><br><span class="line">                    exception instanceof IllegalGenerationException ||</span><br><span class="line">                    exception instanceof MemberIdRequiredException)</span><br><span class="line">                continue;</span><br><span class="line">            else if (!future.isRetriable())</span><br><span class="line">                throw exception;</span><br><span class="line"></span><br><span class="line">            timer.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>接下来对该方法进行分步解读：</p><ol><li><p>加入消费组之前必须先获取对应的组协调器，因为后续所有的请求都是需要发送到组协调器上。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>每一次执行重平衡之前调用其回调函数，我们可以看看ConsumerCoordinatory的实现</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span><br><span class="line">// time if the client is woken up before a pending rebalance completes. This must be called</span><br><span class="line">// on each iteration of the loop because an event requiring a rebalance (such as a metadata</span><br><span class="line">// refresh which changes the matched subscription set) can occur while another rebalance is</span><br><span class="line">// still in progress.</span><br><span class="line">if (needsJoinPrepare) &#123;</span><br><span class="line">    onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">    needsJoinPrepare = false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void onJoinPrepare(int generation, String memberId) &#123;</span><br><span class="line">    // commit offsets prior to rebalance if auto-commit enabled</span><br><span class="line">    maybeAutoCommitOffsetsSync(time.timer(rebalanceTimeoutMs));</span><br><span class="line"></span><br><span class="line">    // execute the user&#x27;s callback before rebalance</span><br><span class="line">    ConsumerRebalanceListener listener = subscriptions.rebalanceListener();</span><br><span class="line">    Set&lt;TopicPartition&gt; revoked = subscriptions.assignedPartitions();</span><br><span class="line">    log.info(&quot;Revoking previously assigned partitions &#123;&#125;&quot;, revoked);</span><br><span class="line">    try &#123;</span><br><span class="line">        listener.onPartitionsRevoked(revoked);</span><br><span class="line">    &#125; catch (WakeupException | InterruptException e) &#123;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        log.error(&quot;User provided listener &#123;&#125; failed on partition revocation&quot;, listener.getClass().getName(), e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    isLeader = false;</span><br><span class="line">    subscriptions.resetGroupSubscription();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>消费端协调器在进行重平衡(加入一个新组)之前通常会执行如下操作：</p><ul><li>如果开启了自动提交位点，进行一次位点提交。</li><li>执行重平衡相关的事件监听器。</li></ul></li><li><p>向消费组的组协调器发送加入请求，但加入消费组并不是目的，而是手段，最终要达成的目的是进行队列的负载均衡。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br></pre></td></tr></table></figure></li><li><p>调用onJoinComplete方法，通知消费端协调器队列负载的最终结果</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line">onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br></pre></td></tr></table></figure><ul><li>generationId</li><li>memberId 成员id</li><li>protocol 协议名称，这里是consumer。</li><li>memberAssignment 队列负载结果，包含了分配给当前消费者的队列信息，其序列后的结果如图所示<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_2.png"></li></ul></li></ol><p>故队列的负载机制蕴含在构建请求中，接下来深入分析一下客户端与服务端详细的交互流程。</p><h5 id="构建加入消费组请求"><a href="#构建加入消费组请求" class="headerlink" title="构建加入消费组请求"></a>构建加入消费组请求</h5><p>构建加入消费组代码见AbstractCoordinator的sendJoinGroupRequest,其代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_3.png"></p><p>发起一次组加入请求，请求体主要包含如下信息：</p><ul><li>消费组的名称</li><li>session timeout，会话超时时间，默认为10s</li><li>memberId 消费组成员id,第一次为null，后续服务端会为该消费者分配一个唯一的id,构成为客户端id + uuid。</li><li>protocolType 协议类型，消费者加入消费组固定为 consumer</li><li>消费端支持的所有队列负载算法</li></ul><p>收到服务端响应后将会调用JoinGroupResponseHandler回掉，稍后会详细介绍。</p><h5 id="服务端响应逻辑"><a href="#服务端响应逻辑" class="headerlink" title="服务端响应逻辑"></a>服务端响应逻辑</h5><p>服务端处理入口：KafkaApis的handleJoinGroupRequest方法，该方法为委托给GroupCoordinator。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_4.png"></p><p>通过这个入口，基本可以看到服务端处理加入请求的关键点：</p><ul><li>从客户端请求中提取客户端的memberId,如果为空，表示第一次加入消费组，还未分配memberId。</li><li>如果协调器中不存在该消费组的信息，表示第一次加入，创建一个，并执行doUnknownJoinGroup(第一次加入消费组逻辑)</li><li>如果协调器中已存在消费组的信息，判断一下是否已达到<strong>最大消费者个数限制</strong>(默认不限制)，超过则会抛出异常；然后根据消费者是否是第一次加入进行对应的逻辑处理。</li></ul><p><strong>组协调器会为每一个路由到的消费组维护一个组元信息(GroupMetadata)，存储在HashMap&lt; String, GroupMetadata&gt;，每一个消费组云信息中存储了当前的所有的消费者，由消费者主动加入，组协调器可以主动剔除消费者。</strong></p><p>接下来分情况处理，来看一下第一次加入(doUnknownJoinGroup)与重新加入(doJoinGroup)分别详细探讨。</p><h6 id="初次加入消费组"><a href="#初次加入消费组" class="headerlink" title="初次加入消费组"></a>初次加入消费组</h6><p>初次加入消费组的代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_5.png"></p><p>关键点如下：</p><ul><li><p>首先来看一下该方法的参数含义：</p><ul><li>GroupMetadata group: 消费组的元信息，并未持久化，存储在内存中，一个消费组当前消费者的信息。 </li><li>boolean requireKnownMemberId: 是否一定需要知道客户端id,如果客户端请求版本为4,在加入消费组时需要明确知道对方的memberId。</li><li>String clientId: 客户端ID,消息组的memberId生成规则为 clientId + uuid</li><li>String clientHost: 消费端端ip地址 </li><li>int rebalanceTimeoutMs: 重平衡超时时间，取自消费端参数max.poll.interval.ms，默认为5分钟。</li><li>int sessionTimeoutMs: 会话超时时间，默认为10s</li><li>String protocolType: 协议类型，默认为consumer</li><li>List protocols: 客户端支持的队列负载算法。</li></ul></li><li><p>对客户端进行状态验证，其校验如下：</p><ul><li>如果消费者状态为dead，则返回UNKNOWN_MEMBER_ID</li><li>如果当前消费组的负载算法协议不支持新客户端端队列负载协议，则抛出UNKNOWN_MEMBER_ID，并提示不一致的队列负载协议。</li></ul></li><li><p>Kafka 的加入请求版本4在加入消费端组时使用有明确的客户端memberId，消费组将创建的memberId加入到组的pendingMember中，并向客户端返回MEMBER_ID_REQUIRED，引导客户端重新加入，客户端会使用服务端生成的memberId，重新发起加入消费组。</p></li><li><p>调用addMemberAndRebalance方法加入消费组并触发重平衡。</p></li></ul><p>接下来继续探究加入消费组并触发重平衡的具体逻辑，具体实现见GroupCoordinator的addMemberAndRebalance。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_6.png"></p><p>核心要点如下：</p><ul><li>组协调器为每一个消费者创建一个MemberMetadata对象。</li><li>如果消费组的状态为PreparingRebalance(此状态表示正在等待消费组加入)，并将组的newMemberAdded设置为true，表示有新成员加入，后续需要触发重平衡。</li><li>将消费组添加到组中，这里会触发一次<strong>消费组选主</strong>,选主逻辑：<strong>该消费组的第一个加入的消费者成为该消费组中的Leader</strong>, Leader的职责是什么呢？<br>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_7.png"><br>总体而言： <strong>消费组Leader的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案</strong>。<ul><li>为每一个消费者创建一个DelayedHeartbeat对象，用于检测会话超时，组协调器如果检测会话超时，会将该消费者移除组，会重新触发重平衡，消费者为了避免被组协调器移除消费组，需要按间隔发送心跳包。</li><li>根据当前消费组的状态是否需要进行重平衡。</li></ul></li></ul><p>接下来继续深入跟踪maybePrepareRebalance方法，其实现如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_8.png"></p><p>根据状态机的驱动规则，判断是否可以进入到PrepareRebalance，其判断逻辑就是根据状态机的驱动，判断当前状态是否可以进入到该状态，其具体实现是为每一个状态存储了一个可以进入当前状态的前驱状态集合。</p><p>如果符合状态驱动流程，消费组将进入到PrepareRebalance，其具体实现如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_9.png"></p><ul><li>如果当前消费组的状态为CompletingRebalance，需要重置队列分配动作，并让消费组重新加入到消费组，即重新发送JOIN_GROUP请求。具体实现技巧：<br>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_10.png"><ul><li>将所有消费者已按分配算法分配到的队列信息置空</li><li>将空的分配结果返回给消费者，并且错误码为REBALANCE_IN_PROGRESS，客户端收到该错会重新加入消费组。</li></ul></li><li>如果当前没有消费者，则创建InitialDelayedJoin，否则则创建DelayedJoin<ul><li>值得注意的是这里有一个参数：group.initial.rebalance.delay.ms，用于设置消费组进入到PreparingRebalance真正执行其业务逻辑的延迟时间，其主要目的是等待更多的消费者进入。</li><li>驱动消费组状态为PreparingRebalance。</li><li>尝试执行initialDelayedJoin或DelayedJoin的tryComplete方法，如果没有完成，则创建watch，等待执行完成，最终执行的是组协调器的相关方法，其说明如下：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_11.png"><br>接下来看一下组协调器的tryCompleteJoin方法，其实现如下图所示：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_12.png"></li><li>*完成PreparingRebalance状态的条件是: 已知的消费组都成功加入到消费组**。该方法返回true后，onCompleteJoin方法将被执行。</li></ul></li></ul><p>接下来看一下GroupCoordinator的onCompleteJoin方法的实现。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_13.png"></p><p>核心的关键点如下：</p><ul><li>驱动消费组的状态转化为CompletingRebalance，将进入到重平衡的第二个阶段(队列负载)</li><li>为每一个成员构建对应JoinResponse对象，其中三个关键点<ul><li>generationId 消费组每一次状态变更，该值加一</li><li>subProtocol 当前消费者组中所有消费者都支持的队列负载算法</li><li>leaderId 消费组中的leader，一个消费组中第一个加入的消费者为leader</li></ul></li></ul><p>接下来，消费者协调器将根据服务端返回的响应结果，进行第二阶段的重平衡，即进入到队列负载算法。</p><h6 id="已知memberId加入消费组处理逻辑"><a href="#已知memberId加入消费组处理逻辑" class="headerlink" title="已知memberId加入消费组处理逻辑"></a>已知memberId加入消费组处理逻辑</h6><p>组协调在已知memberid处理加入请求的核心处理代码在GroupCoordinator的doJoinGroup中，即重新加入请求。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_14.png"></p><ol><li>首先进行相关的错误校验<ul><li>如果消费组状态为Dead，返回错误unknown_member_id错误。</li><li>如果当前消费者支持的队列负载算法消费组并不支持，返回错误inconsistent_group_protocol</li><li>如果当前的memberid处在pendingMember中，对于这种重新加入的消费者会接受并触发重平衡。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">值得注意的是，在Kafka JOIN_REQUEST版本为4后，首先会在服务端生成memberId,并加入到pendingMember中，并立即向客户端返回memberId,引导客户端重新加入。</span><br></pre></td></tr></table></figure></li><li>如果消费组不存在该成员，返回错误，说明消费组已经将该消费者移除。</li></ul></li><li>根据消费组的状态采取不同的行为<ul><li>如果当前状态为PreparingRebalance  更新成员的元信息，按照需要触发重平衡。  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_15.png">  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PreparingRebalance状态，消费组在等待消费组中的消费者加入。</span><br></pre></td></tr></table></figure></li><li>如果状态为CompletingRebalance<ul><li><p>如果收到join group请求，但其元信息并没有发生变化(队列负载算法)，只需将最新的信息返回给消费者；</p></li><li><p>如果状态发生变更，则会进行再次回到重平衡的第一阶段，消费组重新加入。</p></li></ul>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_16.png">  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">消费组如果处于CompletingRebalance状态，其实不希望再收到Join Group请求，因为处于CompletingRebalance状态的消费组，正在等待消费者Leader分配队列。</span><br></pre></td></tr></table></figure></li><li>如果消费组处于Stable状态  如果成员是leader并且支持的协议发生变化，则进行重平衡，否则只需要将元信息发生给客户端即可。  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_17.png"></li></ul></li></ol><h6 id="客户端处理组协调器的Join-Group响应包"><a href="#客户端处理组协调器的Join-Group响应包" class="headerlink" title="客户端处理组协调器的Join Group响应包"></a>客户端处理组协调器的Join Group响应包</h6><p>客户端对Join_Group的响应处理在：JoinGroupResponseHandler，其核心实现如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_18.png"></p><p>关键点：</p><ul><li>队列的负载算法是由Leader节点来分配，</li><li>将分配结果通过向组协调器发送SYNC_GROUP请求，</li><li>然后组协调器从Leader节点获取分配算法后，</li><li>再返回给所有的消费者，</li><li>从而开始进行消费。</li></ul><h4 id="心跳与离开"><a href="#心跳与离开" class="headerlink" title="心跳与离开"></a>心跳与离开</h4><p>消费者通过消费者协调器与组协调器交互完成消费组的加入，但如何退出呢？例如当消费者宕机，协调器如何感知呢？</p><p>原来在Kafka中，消费者协调器会引入心跳机制，即定时向组协调器发送心跳包，在指定时间内未收到客户端的心跳包，表示会话过期，过期时间通过参数session.timeout.ms设置，默认为10s。<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_22.png"><br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_23.png"></p><p>通过对ConsumerCoordinator的poll流程可知，消费者协调器在得知消费组的组协调器后，就会启动心跳线程，其代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_19.png"></p><p>启动心跳线程后，主要关注HeartbeatThread的run方法。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_20.png"></p><p>心跳线程的核心要点如下：</p><ul><li>如果距离上一次心跳超过了会话时间，会断开与GroupCoordinator断开链接，并设置为coordinatorUnknow 为true，需要重新寻找组协调器。</li><li>如果此次心跳发送时间距离上一次心跳发送时间超过了pollTimeout，客户端将发送LEAVE_GROUP，离开消费组，并在下一个poll方法调用时重新进入加入消费组的操作，会再次触发重平衡。</li><li>如果两次心跳时间超过了单次心跳发送间隔，将发送消息。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">温馨提示：尽管心跳包通常是定时类任务，但kafka的心跳机制另辟蹊径，使用了Object的wait与notify，心跳线程与消息拉取线程相互协助，**每一次消息拉取，都会进行判断是否应该发送心跳包**。</span><br></pre></td></tr></table></figure><p>关于消费组的离开，服务端端处理逻辑比较简单，就不在这一一介绍了。</p><h3 id="重平衡机制总结"><a href="#重平衡机制总结" class="headerlink" title="重平衡机制总结"></a>重平衡机制总结</h3><p>Kafka的重平衡其实包含两个非常重要的阶段：</p><ul><li>消费组加入阶段(PreparingRebalance)<ul><li>此阶段是消费者陆续加入消费组，该组第一个加入的消费者被推举为Leader</li><li>当该组所有已知memberId的消费者全部加入后，状态驱动到CompletingRebalance。</li></ul></li><li>队列负载(CompletingRebalance)<ul><li>PreparingRebalance状态完成后，如果消费者被推举为Leader，<strong>Leader会采用该消费组中都支持的队列负载算法进行队列分布</strong>，然后将结果回报给组协调器；</li><li>如果消费者的角色为非Leader，会向组协调器发送同步队列分区算法，组协调器会将Leader节点分配的结果分配给消费者。</li></ul></li></ul><p><strong>消费组如果在进行重平衡操作，将会暂停消息消费（STW），频繁的重平衡会导致队列消息消费的速度受到极大的影响。</strong></p><p>与重平衡相关的消费端参数：</p><ul><li><p><strong>max.poll.interval.ms</strong></p><p>  两次poll方法调用的最大间隔时间，单位毫秒，默认为5分钟。如果消费端在该间隔内没有发起poll操作，该消费者将被剔除，触发重平衡，将该消费者分配的队列分配给其他消费者。</p></li><li><p><strong>session.timeout.ms</strong></p><p>  消费者与broker的心跳超时时间,默认10s，broker在指定时间内没有收到心跳请求，broker端将会将该消费者移出，并触发重平衡。</p></li><li><p><strong>heartbeat.interval.ms</strong></p><p>  心跳间隔时间，消费者会以该频率向broker发送心跳，默认为3s，主要是确保session不会失效。</p></li></ul><h4 id="重平衡触发条件—消费群组或者topic分区出现变化时"><a href="#重平衡触发条件—消费群组或者topic分区出现变化时" class="headerlink" title="重平衡触发条件—消费群组或者topic分区出现变化时"></a>重平衡触发条件—消费群组或者topic分区出现变化时</h4><ul><li>消费组内成员个数发生变化(<strong>这种情况在实际情况中更加常见。因为订阅分区数、以及订阅 topic 数都是我们主动改变才会发生，而组内消费组成员个数发生变化，则是更加随机的。</strong>)<ul><li>有新的消费者加入Consumer Group,</li><li>由消费者主动退出，Consumer Group/调用unsubscribe()取消对某Topic的订阅,</li><li>有消费者崩溃，可能由于长时间未向GroupCoordinator(协调者)发送心跳，GroupCoordinator会认为其已下线；</li></ul></li><li>订阅的 Topic 分区数出现变化；</li><li>订阅的 Topic 个数发生变化:<br>一个 consumer group 如果之前只订阅了 A topic，那么其组内的 consumer 知会消费 A topic 的消息。而如果现在新增订阅了 B topic，那么 kafka 就需要把 B topic 的 partition 分配给组内的 consumer 进行消费。</li></ul><h3 id="线上环境频繁重平衡问题实例"><a href="#线上环境频繁重平衡问题实例" class="headerlink" title="线上环境频繁重平衡问题实例"></a>线上环境频繁重平衡问题实例</h3><h4 id="消息处理逻辑太重，超过max-poll-interval-ms限制"><a href="#消息处理逻辑太重，超过max-poll-interval-ms限制" class="headerlink" title="消息处理逻辑太重，超过max.poll.interval.ms限制"></a>消息处理逻辑太重，超过max.poll.interval.ms限制</h4><h5 id="问题原因："><a href="#问题原因：" class="headerlink" title="问题原因："></a>问题原因：</h5><p>kafkaConsumer调用一次轮询方法只是拉取一次消息。客户端为了不断拉取消息，会用一个外部循环不断调用消费者的轮询方法。每次轮询到消息，在处理完这一批消息后，才会继续下一次轮询。但如果一次轮询返回的结构没办法及时处理完成，会有什么后果呢？服务端约定了和客户端max.poll.interval.ms，两次poll最大间隔。如果客户端处理一批消息花费的时间超过了这个限制时间，服务端可能就会把消费者客户端移除掉，并触发rebalance。</p><h5 id="引发出的其他问题："><a href="#引发出的其他问题：" class="headerlink" title="引发出的其他问题："></a>引发出的其他问题：</h5><p>拉取偏移量与提交偏移量：kafka的偏移量(offset)是由消费者进行管理的，偏移量有两种，拉取偏移量(position)与提交偏移量(committed)。拉取偏移量代表当前消费者分区消费进度。每次消息消费后，需要提交偏移量。在提交偏移量时，kafka会使用拉取偏移量的值作为分区的提交偏移量发送给协调者。</p><p>如果没有提交偏移量，下一次消费者重新与broker连接后，会从当前消费者group已提交到broker的偏移量处开始消费。</p><p>所以，问题就在这里，当我们处理消息时间太长时,已经被broker剔除，提交偏移量又会报错。所以拉取偏移量没有提交到broker，分区又rebalance。</p><p>下一次重新分配分区时，消费者会从最新的已提交偏移量处开始消费。</p><p>这里就出现了<strong>重复消费</strong>的问题。</p><h5 id="处理方案："><a href="#处理方案：" class="headerlink" title="处理方案："></a>处理方案：</h5><ol><li>调大max.poll.interval.ms参数值或优化消息处理逻辑 <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">max.poll.interval.ms</span>=<span class="string">300</span></span><br></pre></td></tr></table></figure></li><li>设置分区拉取阈值<br>kafkaConsumer调用一次轮询方法只是拉取一次消息。客户端为了不断拉取消息，会用一个外部循环不断调用轮询方法poll()。每次轮询后，在处理完这一批消息后，才会继续下一次的轮询。<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">max.poll.records</span> = <span class="string">50</span></span><br></pre></td></tr></table></figure></li><li>poll到的消息，处理完一条就提交一条，当出现提交失败时，马上跳出循环，这时候kafka就会进行rebalance,下一次会继续从当前offset进行消费。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之Kafka消息拉取机制简读</title>
      <link href="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/"/>
      <url>/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>在详细介绍Kafka拉取之前，我们再来回顾一下消息拉取的整体流程：</p><p><img src="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img.png"></p><p>在消费者加入到消费组后，消费者Leader会根据当前在线消费者个数与分区的数量进行队列负载，每一个消费者获得一部分分区，接下来就是要从Broker服务端将数据拉取下来，提交给消费端进行消费，对应流程中的pollForFetches方法。</p><p>要正确写出优秀的Kafka端消费代码，详细了解其拉取模型是非常重要的一步。</p><h3 id="消息拉取详解"><a href="#消息拉取详解" class="headerlink" title="消息拉取详解"></a>消息拉取详解</h3><h4 id="消费端拉取流程详解"><a href="#消费端拉取流程详解" class="headerlink" title="消费端拉取流程详解"></a>消费端拉取流程详解</h4><p>消息拉取的实现入口为：KafkaConsumer的pollForFetches，接下来我们将详细剖析其流程，探讨kafka消息拉取模型，其实现如下所示：</p><p><img src="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_1.png"></p><p>整个消息拉取的核心步骤如下：</p><ol><li>获取本次拉取的超时时间，会取自用户设置的超时时间与一个心跳包的间隔之中的最小值。</li><li>从拉取缓存区中解析已异步拉取的消息。</li><li>向Broker发送拉取请求，该请求是一个异步请求。</li><li>通过ConsumerNetworkClient触发底层NIO通信。</li><li>再次尝试从缓存区中解析已拉起的消息。</li></ol><h4 id="Fetch的sendFetches详解"><a href="#Fetch的sendFetches详解" class="headerlink" title="Fetch的sendFetches详解"></a>Fetch的sendFetches详解</h4><p>经过队列负载算法分配到部分分区后，消费者接下来需要向Broker发送消息拉起请求，具体由sendFetches方法实现。</p><p><img src="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_2.png"></p><ol><li><p>通过调用preparefetchRequest，构建请求对象，其实现的核心要点如下：</p><ul><li><p>构建一个请求列表，这里采用了Build设计模式，最终生成的请求对象：Node为Key,FetchSessionHandler.FetchRequestData为Value的请求，我觉得这里有必要看一下FetchRequestData的数据结构：<br><img src="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_3.png"><br>其中ParitionData汇总包含了本次消息拉取的开始位点。</p></li><li><p>通过fetchablePartitions方法获取本次可拉取的队列，其核心实现要点如下：</p><ul><li>从队列负载结果中获取可拉取的分区信息，主要的判断标准：<strong>未被暂停与有正确位点信息</strong>。</li><li>nextInLineRecords？</li><li>去除掉拉取缓存区中的存在队列信息(completedFetches)，即<strong>如果缓存区中的数据未被消费端消费则不会继续拉取新的内容</strong>。</li><li>获取待拉取分区所在的leader信息，如果未找到，本次拉取将忽略该分区，但是会设置需要更新topic路由信息,在下次拉取之前会从Broker拉取最新的路由信息。</li><li><strong>如果客户端与待拉取消息的broker节点有待发送的网络请求(见代码@4)，则本次拉取任务将不会再发起新的拉取请求</strong>，待已有的请求处理完毕后才会拉取新的消息。</li><li>拉取消息时需要指定拉取消息偏移量，来自队列负载算法时指定，主要消费组的最新消费位点。<br><img src="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_4.png"></li></ul></li></ul></li><li><p>按Node依次构建请求节点，并通过client的send方法将请求异步发送，当收到请求结果后会调用对应的事件监听器，这里主要的是一次拉取最大的字节数50M。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">值得注意的是: 在Kafka中调用client的send方法并不会真正触发网络请求，而是将请求放到发送缓冲区中，Client的poll方法才会真正触发底层网络请求。</span><br></pre></td></tr></table></figure></li><li><p>当客户端收到服务端请求后会将原始结果放入到completedFetches中，等待客户端从中解析。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">本篇文章暂时不关注服务端对fetch请求的处理，等到详细剖析了Kafka的存储相关细节后再回过来看Fetch请求的响应。</span><br></pre></td></tr></table></figure></li></ol><h4 id="Fetcher的fetchedRecords方法详解"><a href="#Fetcher的fetchedRecords方法详解" class="headerlink" title="Fetcher的fetchedRecords方法详解"></a>Fetcher的fetchedRecords方法详解</h4><p>向服务端发送拉取请求异步返回后会将结果返回到一个completedFetches中，也可以理解为<strong>接收缓存区</strong>,接下来将从缓存区中将结果解析并返回给消费者消费。</p><p>从接收缓存区中解析数据的具体实现见Fetcher的fetchedRecords方法。</p><p><img src="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_5.png"></p><p>核心实现要点如下：</p><ul><li>首先说明一下nextInLineRecords的含义，接下来的fetchedRecords方法将从这里获取值，该参数主要是因为引入了maxPollRecords(默认为500)，一次拉取的消息条数，一次Fetch操作一次每一个分区最多返回50M数据，可能包含的消息条数大于maxPollRecords。  如果nextInLineRecords为空或者所有内容已被拉取，则从completedFetch中解析。</li><li>从completedFetch中解析解析成nextInlineRecords。</li><li>从nextInlineRecords中继续解析数据。</li></ul><p>关于将CompletedFetch中解析成PartitionRecords以及从PartitionRecords提取数据成Map&lt; TopicPartition, List&lt; ConsumerRecord&lt; K, V&gt;&gt;&gt;的最终供应用程序消费的数据结构，代码实现非常简单，这里就不再介绍。</p><p><strong>有关服务端响应SEND_FETCH的相关分析，将在详细分析Kafka存储相关机制时再介绍</strong>。在深入存储细节时，从消息拉取，消息写入为切入点是一个非常不错的选择。</p><h3 id="消息消费端模型"><a href="#消息消费端模型" class="headerlink" title="消息消费端模型"></a>消息消费端模型</h3><p>阅读源码是手段而不是目的，通过阅读源码，我们应该总结提炼一下Kafka消息拉取模型(特点)，以便更好的指导实践。</p><p>首先再强调一下消费端的三个重要参数：</p><ul><li><p>fetch.max.bytes</p><p>  客户端单个Fetch请求一次拉取的最大字节数，默认为50M，根据上面的源码分析得知，Kafka会按Broker节点为维度进行拉取， 即按照队列负载算法分配在同一个Broker上的多个队列进行聚合，同时尽量保证各个分区的拉取平衡，通过max.partition.fetch.bytes参数设置。</p></li><li><p>max.partition.fetch.bytes</p><p>  一次fetch拉取单个队列最大拉取字节数量，默认为1M。</p></li><li><p>max.poll.records</p><p>  调用一次KafkaConsumer的poll方法，返回的消息条数，默认为500条。</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">实践思考：fetch.max.bytes默认是max.partition.fetch.bytes的50倍，也就是默认情况一下，一个消费者一个Node节点上至少需要分配到50个队列，才能尽量满额拉取。但50个分区(队列)可以来源于这个消费组订阅的所有的topic。</span><br></pre></td></tr></table></figure><h4 id="Kafka消费线程拉取线程模型"><a href="#Kafka消费线程拉取线程模型" class="headerlink" title="Kafka消费线程拉取线程模型"></a>Kafka消费线程拉取线程模型</h4><p>KafkaConsumer并不是线程安全的，即KafkaConsumer的所有方法调用必须在同一个线程中，但消息拉取却是是并发的，线程模型说明如下图所示：</p><p><img src="/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_6.png"></p><p>其核心设计理念是KafkaConsumer在调用poll方法时，如果<strong>本地缓存区</strong>中(completedFeches)存在未拉取的消息，则直接从本地缓存区中拉取消息.</p><p>否则会调用client#send方法进行异步多线程并行发送拉取请求，发往不同的broker节点的请求是并发执行，执行完毕后，<strong>再将结果放入到poll方法所在线程中的缓存区，实现多个线程的协同</strong>。</p><h4 id="poll方法返回给消费端线程特点"><a href="#poll方法返回给消费端线程特点" class="headerlink" title="poll方法返回给消费端线程特点"></a>poll方法返回给消费端线程特点</h4><p>pol l方法会从缓存区中依次获取一个CompletedFetch对象，一次只从CompletedFetch对象中获取500条消息，一个CompletedFetch对象包含一个分区的数据，默认最大的消息体大小为1M，可通过max.partition.fetch.bytes改变默认值。</p><p>如果一个分区中消息超过500条，则KafkaConsumer的poll方法将只会返回1个分区的数据，这样在顺序消费时基于单分区的顺序性保证时如果采取与RocketMQ类似的机制，对分区加锁，则其并发度非常低，因为此时顺序消费的并发度取决于这500条消息包含的分区个数。</p><p><strong>Kafka顺序消费最佳实践</strong>：单分区中消息可以并发执行，但要保证同一个key的消息必须串行执行。因为在实践应用场景中，通常只需要同一个业务实体的不同消息顺序执行。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之Kafka消息发送者核心参数与工作机制</title>
      <link href="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/"/>
      <url>/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>本文将从Kafka Producer的配置属性为突破口，结合源码深入提炼出Kafka Producer的工作机制，方便大家更好使用Kafka Producer，并且胸有成竹的进行性能调优。</p><p>将Kafka Producer相关的参数分成如下几个类型：</p><ul><li>常规参数</li><li>工作原理(性能相关)参数(图解)</li></ul><p>本文会结合图解方式，重点阐述与Kafka生产者运作机制密切相关的参数。 </p><h3 id="Producer-核心流程一览"><a href="#Producer-核心流程一览" class="headerlink" title="Producer 核心流程一览"></a>Producer 核心流程一览</h3><p>producer也就是生产者，是kafka中消息的产生方，产生消息并提交给kafka集群完成消息的持久化。</p><h4 id="KafkaProducer构造方法"><a href="#KafkaProducer构造方法" class="headerlink" title="KafkaProducer构造方法"></a>KafkaProducer构造方法</h4><p>KafkaProducer构造方法主要是根据配置文件进行一些实例化操作</p><ol><li>解析clientId，若没有配置则由是producer-递增的数字</li><li>解析并实例化分区器partitioner</li><li>解析key、value的序列化方式并实例化</li><li>解析并实例化拦截器</li><li>解析并实例化RecordAccumulator</li><li>解析Broker地址</li><li>创建一个Sender线程并启动</li></ol><details><summary>一个KafkaProducer的小demo</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String[] args) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">        if (args.length != 2) &#123;</span><br><span class="line">            throw new IllegalArgumentException(&quot;usage: com.ding.KafkaProducerDemo bootstrap-servers topic-name&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        // kafka服务器ip和端口，多个用逗号分割</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, args[0]);</span><br><span class="line">        // 确认信号配置</span><br><span class="line">        // ack=0 代表producer端不需要等待确认信号，可用性最低</span><br><span class="line">        // ack=1 等待至少一个leader成功把消息写到log中，不保证follower写入成功，如果leader宕机同时follower没有把数据写入成功</span><br><span class="line">        // 消息丢失</span><br><span class="line">        // ack=all leader需要等待所有follower成功备份，可用性最高</span><br><span class="line">        props.put(&quot;ack&quot;, &quot;all&quot;);</span><br><span class="line">        // 重试次数</span><br><span class="line">        props.put(&quot;retries&quot;, 0);</span><br><span class="line">        // 批处理消息的大小，批处理可以增加吞吐量</span><br><span class="line">        props.put(&quot;batch.size&quot;, 16384);</span><br><span class="line">        // 延迟发送消息的时间</span><br><span class="line">        props.put(&quot;linger.ms&quot;, 1);</span><br><span class="line">        // 用来换出数据的内存大小</span><br><span class="line">        props.put(&quot;buffer.memory&quot;, 33554432);</span><br><span class="line">        // key 序列化方式</span><br><span class="line">        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        // value 序列化方式</span><br><span class="line">        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line"></span><br><span class="line">        // 创建KafkaProducer对象，创建时会启动Sender线程</span><br><span class="line">        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line">        for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">            // 往RecordAccumulator中写消息</span><br><span class="line">            Future&lt;RecordMetadata&gt; result = producer.send(new ProducerRecord&lt;&gt;(args[1], Integer.toString(i), Integer.toString(i)));</span><br><span class="line">            RecordMetadata rm = result.get();</span><br><span class="line">            System.out.println(&quot;topic: &quot; + rm.topic() + &quot;, partition: &quot; +  rm.partition() + &quot;, offset: &quot; + rm.offset());</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></details><p>相关参数:</p><ul><li><strong>bootstrap.servers</strong>: 配置Kafka broker的服务器地址列表，多个用英文逗号分开，可以不必写全，Kafka内部有自动感知Kafka broker的机制。</li><li><strong>key.serializer</strong>: 消息key的序列化策略，为org.apache.kafka.common.serialization接口的实现类。</li><li><strong>value.serializer</strong>: 消息体的序列化策略</li><li><strong>client.id</strong>: 客户端ID，如果不设置默认为producer-递增，<strong>强烈建议设置该值，尽量包含ip,port,pid</strong>。</li><li><strong>client.dns.lookup</strong>: 客户端寻找bootstrap地址的方式，支持如下两种方式：<ul><li><strong>resolve_canonical_bootstrap_servers_only</strong>: 这种方式，会依据bootstrap.servers提供的主机名(hostname)，根据主机上的名称服务返回其IP地址的数组(InetAddress.getAllByName)，然后依次获取inetAddress.getCanonicalHostName()，再建立tcp连接。<br><strong>一个主机可配置多个网卡，如果启用该功能，应该可以有效利用多网卡的优势，降低Broker的网络端负载压力。</strong></li><li><strong>use_all_dns_ips</strong>: 这种方式会直接使用bootstrap.servers中提供的hostname、port创建tcp连接，默认选项。</li></ul></li></ul><h4 id="KafkaProducer消息发送流程"><a href="#KafkaProducer消息发送流程" class="headerlink" title="KafkaProducer消息发送流程"></a>KafkaProducer消息发送流程</h4><p>Kafka将一条待发送的消息抽象为ProducerRecord对象，其数据结构是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic; <span class="comment">//目标topic</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition; <span class="comment">//目标partition</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;<span class="comment">//消息头信息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;   <span class="comment">//消息key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value; <span class="comment">//消息体</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp; <span class="comment">//消息时间戳</span></span><br><span class="line">    <span class="comment">//省略构造方法与成员方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>目前消息结构包括6个核心属性，分别是topic，partition，headers，key，value与timestamp，各属性含义如上也比较好理解，其中headers属性是Kafka 0.11.x 版本引入的，可以用它存储一些应用或业务相关的信息。</p><p>Kafka消息发送过程中主要涉及ProducerRecord对象的构建、分区选择、元数据的填充、ProducerRecord对象的序列化、进入消息缓冲池、完成消息的发送、接受broker的响应。</p><p>消息的发送入口是KafkaProducer.send方法，具体流程如下: </p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_3.png"></p><ol><li>确定topic信息</li><li>确定value信息</li><li>然后进行消息的序列化处理</li><li>由分区选择器确定对应的分区信息</li><li>将消息写入消息缓冲区</li><li>完成消息请求的发送</li><li>完成消息响应的处理</li></ol><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img.png"></p><p>总的来说，Kafka生产端发送数据过程涉及到序列化器Serializer、分区器Partitioner，消息缓存池Accumulator，还可能会涉及到拦截器Interceptor（这部分暂不做介绍）。</p><p>Kafka 的 Producer 发送消息采用的是异步发送的方式。</p><p>在消息发送的过程中，涉及到了 两个线程——<strong>main线程</strong>和 <strong>Sender线程</strong>，以及<strong>一个线程共享变量——RecordAccumulator。 main 线程将消息发送给 RecordAccumulator</strong>，Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka broker</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_4.png"></p><p>在消息发送端Kafka引入了批的概念，发送到服务端的消息通常不是一条一条发送，而是一批一批发送，一个批次对应源码层级为ProducerBatch对象。<br>相关参数：</p><ul><li><strong>batch.size</strong><br>该值用于设置每一个批次的内存大小,默认为16K,只有数据积累到 batch.size 之后，sender 才会发送数据。</li><li><strong>linger.ms</strong>:<br>Kafka希望一个批次一个批次去发送到Broker，应用程序往KafkaProducer中发送一条消息，首先会进入到内部缓冲区，具体是会进入到某一个批次中(ProducerBatch), 等待该批次堆满后一次发送到Broker，这样能提高消息的吞吐量，但其消息发送的延迟也会相应提高。<br>为了解决该问题，linger.ms参数应运而生。<br>它的作用是控制在缓存区中未积满时来控制消息发送线程的行为。 如果linger.ms 设置为 0表示立即发送，如果设置为大于0，则消息发送线程会等待这个值后才会向broker发送。有点类似于 TCP 领域的 Nagle 算法。.如果数据迟迟未达到 batch.size，sender 等待 linger.time 之后就会发送数据。</li></ul><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_1.png"></p><p>Kafka的每一个消息发送者，也就是KafkaProducer对象内部会有一块缓存区，缓冲区内存的组织会按照topic+parition构建双端队列。<br>相关参数：</p><ul><li><strong>buffer.memory</strong>:<br>指定缓存区大小，默认为32M</li><li><strong>delivery.timeout.ms</strong>:<br>默认为120s，该参数控制在双端队列中的过期时间，从进入双端队列开始计时，超过该值未被sender发送后会返回超时异常(TimeoutException)。</li></ul><p>队列中的每一个元素为一个ProducerBatch对象，表示一个消息发送批次，但发送线程将消息发送到Broker端时，一次可以包含多个批次。</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_2.png"></p><p>相关参数：</p><ul><li><p><strong>max.block.ms</strong>:<br>默认为60s，当消息发送者申请空闲内存时，如果在指定时间（包含发送端用于查找元信息的时间）内未申请到内存，消息发送端会直接报TimeoutException。</p></li><li><p><strong>max.request.size</strong>:<br>Send线程一次发送的最大字节数量，也就是Send线程向服务端一次消息发送请求的最大传输数据，默认为1M。</p></li><li><p><strong>request.timeout.ms</strong>:<br>请求的超时时间，主要是Kafka消息发送线程(Sender)与Broker端的网络通讯的请求超时时间。</p></li><li><p><strong>retries</strong>:<br>Kafka Sender线程从缓存区尝试发送到Broker端的重试次数，默认为Integer.MAX_VALUE。<br>为了避免无限重试，只针对可恢复的异常，例如Leader选举中这种异常就是可恢复的，重试最终是能解决问题的。</p></li><li><p><strong>max.in.flight.requests.per.connection</strong>:<br>设置每一个客户端与服务端连接，在应用层一个通道的积压消息数量，默认为5，有点类似Netty用高低水位线控制发送缓冲区中积压的多少，避免内存溢出。</p></li></ul><h5 id="RecordAccumulator"><a href="#RecordAccumulator" class="headerlink" title="RecordAccumulator"></a>RecordAccumulator</h5><p>RecordAccumulator是消息队列用于缓存消息，根据TopicPartition对消息分组</p><details><summary>RecordAccumulator源码解读</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Add a record to the accumulator, return the append result</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * The append result will contain the future metadata, and flag for whether the appended batch is full or a new batch is created</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> *</span><br><span class="line"> * @param tp The topic/partition to which this record is being sent</span><br><span class="line"> * @param timestamp The timestamp of the record</span><br><span class="line"> * @param key The key for the record</span><br><span class="line"> * @param value The value for the record</span><br><span class="line"> * @param headers the Headers for the record</span><br><span class="line"> * @param callback The user-supplied callback to execute when the request is complete</span><br><span class="line"> * @param maxTimeToBlock The maximum time in milliseconds to block for buffer memory to be available</span><br><span class="line"> */</span><br><span class="line">public RecordAppendResult append(TopicPartition tp,</span><br><span class="line">                                 long timestamp,</span><br><span class="line">                                 byte[] key,</span><br><span class="line">                                 byte[] value,</span><br><span class="line">                                 Header[] headers,</span><br><span class="line">                                 Callback callback,</span><br><span class="line">                                 long maxTimeToBlock) throws InterruptedException &#123;</span><br><span class="line">    // We keep track of the number of appending thread to make sure we do not miss batches in</span><br><span class="line">    // abortIncompleteBatches().</span><br><span class="line">    // ---记录进行applend的线程数---</span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    ByteBuffer buffer = null;</span><br><span class="line">    if (headers == null) headers = Record.EMPTY_HEADERS;</span><br><span class="line">    try &#123;</span><br><span class="line">        // check if we have an in-progress batch</span><br><span class="line">        // ---根据TopicPartition获取或新建Deque双端队列---</span><br><span class="line">        Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">        // ---尝试将消息加入到缓冲区中---</span><br><span class="line">        // ---加锁保证同一个TopicPartition写入有序---</span><br><span class="line">        synchronized (dq) &#123;</span><br><span class="line">            if (closed)</span><br><span class="line">                throw new KafkaException(&quot;Producer closed while send in progress&quot;);</span><br><span class="line">            // 尝试写入</span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            if (appendResult != null)</span><br><span class="line">                return appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // we don&#x27;t have an in-progress record batch try to allocate a new batch</span><br><span class="line">        byte maxUsableMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">        int size = Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line">        log.trace(&quot;Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;&quot;, size, tp.topic(), tp.partition());</span><br><span class="line">        // 尝试applend失败（返回null），会走到这里。如果tryApplend成功直接返回了</span><br><span class="line">        // 从BufferPool中申请内存空间，用于创建新的ProducerBatch</span><br><span class="line">        buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">        synchronized (dq) &#123;</span><br><span class="line">            // Need to check if producer is closed again after grabbing the dequeue lock.</span><br><span class="line">            if (closed)</span><br><span class="line">                throw new KafkaException(&quot;Producer closed while send in progress&quot;);</span><br><span class="line">            </span><br><span class="line">            // 注意这里，前面已经尝试添加失败了，且已经分配了内存，为何还要尝试添加？</span><br><span class="line">            // 因为可能已经有其他线程创建了ProducerBatch或者之前的ProducerBatch已经被Sender线程释放了一些空间，所以在尝试添加一次。这里如果添加成功，后面会在finally中释放申请的空间</span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            if (appendResult != null) &#123;</span><br><span class="line">                // Somebody else found us a batch, return the one we waited for! Hopefully this doesn&#x27;t happen often...</span><br><span class="line">                return appendResult;</span><br><span class="line">            &#125;</span><br><span class="line">            // 尝试添加失败了，新建ProducerBatch</span><br><span class="line">            MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">            ProducerBatch batch = new ProducerBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            incomplete.add(batch);</span><br><span class="line"></span><br><span class="line">            // 将buffer置为null,避免在finally汇总释放空间</span><br><span class="line">            // Don&#x27;t deallocate this buffer in the finally block as it&#x27;s being used in the record batch</span><br><span class="line">            buffer = null;</span><br><span class="line">            return new RecordAppendResult(future, dq.size() &gt; 1 || batch.isFull(), true);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 最后如果再次尝试添加成功，会释放之前申请的内存（为了新建ProducerBatch）</span><br><span class="line">        if (buffer != null)</span><br><span class="line">            free.deallocate(buffer);</span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers,</span><br><span class="line">                                     Callback callback, Deque&lt;ProducerBatch&gt; deque) &#123;</span><br><span class="line">    // 从双端队列的尾部取出ProducerBatch</span><br><span class="line">    ProducerBatch last = deque.peekLast();</span><br><span class="line">    if (last != null) &#123;</span><br><span class="line">        // 取到了，尝试添加消息</span><br><span class="line">        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, headers, callback, time.milliseconds());</span><br><span class="line">        // 空间不够，返回null</span><br><span class="line">        if (future == null)</span><br><span class="line">            last.closeForRecordAppends();</span><br><span class="line">        else</span><br><span class="line">            return new RecordAppendResult(future, deque.size() &gt; 1 || last.isFull(), false);</span><br><span class="line">    &#125;</span><br><span class="line">    // 取不到返回null</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br><span class="line">public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long now) &#123;</span><br><span class="line">    // 空间不够，返回null</span><br><span class="line">    if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) &#123;</span><br><span class="line">        return null;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 真正添加消息</span><br><span class="line">        Long checksum = this.recordsBuilder.append(timestamp, key, value, headers);</span><br><span class="line">        ...</span><br><span class="line">        FutureRecordMetadata future = ...</span><br><span class="line">        // future和回调callback进行关联    </span><br><span class="line">        thunks.add(new Thunk(callback, future));</span><br><span class="line">        ...</span><br><span class="line">        return future;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 将消息写入缓冲区</span><br><span class="line">RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey,serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line">if (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">    // 缓冲区满了或者新创建的ProducerBatch，唤起Sender线程</span><br><span class="line">    this.sender.wakeup();</span><br><span class="line">&#125;</span><br><span class="line">return result.future;</span><br></pre></td></tr></table></figure></details><h5 id="Sender"><a href="#Sender" class="headerlink" title="Sender"></a>Sender</h5><p>KafkaProducer的构造方法在实例化时启动一个KafkaThread线程来执行Sender</p><p>Sender主要流程如下： </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Sender.run</span><br><span class="line">Sender.runOnce</span><br><span class="line">Sender.sendProducerData</span><br><span class="line">// 获取集群信息</span><br><span class="line">Metadata.fetch</span><br><span class="line">// 获取可以发送消息的分区且已经获取到了leader分区的节点</span><br><span class="line">RecordAccumulator.ready</span><br><span class="line">// 根据准备好的节点信息从缓冲区中获取topicPartion对应的Deque队列中取出ProducerBatch信息</span><br><span class="line">RecordAccumulator.drain</span><br><span class="line">// 将消息转移到每个节点的生产请求队列中</span><br><span class="line">Sender.sendProduceRequests</span><br><span class="line">// 为消息创建生产请求队列</span><br><span class="line">Sender.sendProducerRequest</span><br><span class="line">KafkaClient.newClientRequest</span><br><span class="line">// 下面是发送消息</span><br><span class="line">KafkaClient.sent</span><br><span class="line">NetWorkClient.doSent</span><br><span class="line">Selector.send</span><br><span class="line">// 其实上面并不是真正执行I/O，只是写入到KafkaChannel中</span><br><span class="line">// poll 真正执行I/O</span><br><span class="line">KafkaClient.poll</span><br></pre></td></tr></table></figure><details><summary></summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// KafkaProducer构造方法启动Sender</span><br><span class="line">String ioThreadName = NETWORK_THREAD_PREFIX + &quot; | &quot; + clientId;</span><br><span class="line">this.ioThread = new KafkaThread(ioThreadName, this.sender, true);</span><br><span class="line">this.ioThread.start();</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// Sender-&gt;run()-&gt;runOnce()</span><br><span class="line">long currentTimeMs = time.milliseconds();</span><br><span class="line">// 发送生产的消息</span><br><span class="line">long pollTimeout = sendProducerData(currentTimeMs);</span><br><span class="line">// 真正执行I/O操作</span><br><span class="line">client.poll(pollTimeout, currentTimeMs);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 获取集群信息</span><br><span class="line">Cluster cluster = metadata.fetch();</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 获取准备好可以发送消息的分区且已经获取到leader分区的节点</span><br><span class="line">RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);</span><br><span class="line">// ReadyCheckResult 包含可以发送消息且获取到leader分区的节点集合、未获取到leader分区节点的topic集合</span><br><span class="line">public final Set&lt;Node&gt; 的节点;</span><br><span class="line">public final long nextReadyCheckDelayMs;</span><br><span class="line">public final Set&lt;String&gt; unknownLeaderTopics;</span><br></pre></td></tr></table></figure><p>ready方法主要是遍历在上面介绍RecordAccumulator添加消息的容器，Map&lt;TopicPartition, Deque&gt;，从集群信息中根据TopicPartition获取leader分区所在节点，找不到对应leader节点但有要发送的消息的topic添加到unknownLeaderTopics中。同时把那些根据TopicPartition可以获取leader分区且消息满足发送的条件的节点添加到的节点中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// 遍历batches</span><br><span class="line">for (Map.Entry&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; entry : this.batches.entrySet()) &#123;</span><br><span class="line">    TopicPartition part = entry.getKey();</span><br><span class="line">    Deque&lt;ProducerBatch&gt; deque = entry.getValue();</span><br><span class="line">    // 根据TopicPartition从集群信息获取leader分区所在节点</span><br><span class="line">    Node leader = cluster.leaderFor(part);</span><br><span class="line">    synchronized (deque) &#123;</span><br><span class="line">        if (leader == null &amp;&amp; !deque.isEmpty()) &#123;</span><br><span class="line">            // 添加未找到对应leader分区所在节点但有要发送的消息的topic</span><br><span class="line">            unknownLeaderTopics.add(part.topic());</span><br><span class="line">        &#125; else if (!readyNodes.contains(leader) &amp;&amp; !isMuted(part, nowMs)) &#123;</span><br><span class="line">....</span><br><span class="line">                if (sendable &amp;&amp; !backingOff) &#123;</span><br><span class="line">                    // 添加准备好的节点</span><br><span class="line">                    readyNodes.add(leader);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后对返回的unknownLeaderTopics进行遍历，将topic加入到metadata信息中，调用metadata.requestUpdate方法请求更新metadata信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for (String topic : result.unknownLeaderTopics)</span><br><span class="line">    this.metadata.add(topic);</span><br><span class="line">    result.unknownLeaderTopics);</span><br><span class="line">this.metadata.requestUpdate();</span><br></pre></td></tr></table></figure><p>对已经准备好的节点进行最后的检查，移除那些节点连接没有就绪的节点，主要根据KafkaClient.ready方法进行判断</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">long notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">while (iter.hasNext()) &#123;</span><br><span class="line">    Node node = iter.next();</span><br><span class="line">    // 调用KafkaClient.ready方法验证节点连接是否就绪</span><br><span class="line">    if (!this.client.ready(node, now)) &#123;</span><br><span class="line">        // 移除没有就绪的节点</span><br><span class="line">        iter.remove();</span><br><span class="line">        notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面开始创建生产消息的请求</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 从RecordAccumulator中取出TopicPartition对应的Deque双端队列，然后从双端队列头部取出ProducerBatch，作为要发送的信息</span><br><span class="line">Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);</span><br></pre></td></tr></table></figure><p>把消息封装成ClientRequest</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0,requestTimeoutMs, callback);</span><br></pre></td></tr></table></figure><p>调用KafkaClient发送消息（并非真正执行I/O），涉及到KafkaChannel。Kafka的通信采用的是NIO方式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// NetworkClient.doSent方法</span><br><span class="line">String destination = clientRequest.destination();</span><br><span class="line">RequestHeader header = clientRequest.makeHeader(request.version());</span><br><span class="line">...</span><br><span class="line">Send send = request.toSend(destination, header);</span><br><span class="line">InFlightRequest inFlightRequest = new InFlightRequest(clientRequest,header,isInternalRequest,request,send,now);</span><br><span class="line">this.inFlightRequests.add(inFlightRequest);</span><br><span class="line">selector.send(send);</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">// Selector.send方法    </span><br><span class="line">String connectionId = send.destination();</span><br><span class="line">KafkaChannel channel = openOrClosingChannelOrFail(connectionId);</span><br><span class="line">if (closingChannels.containsKey(connectionId)) &#123;</span><br><span class="line">    this.failedSends.add(connectionId);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        channel.setSend(send);</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>到这里，发送消息的工作准备的差不多了，调用KafkaClient.poll方法，真正执行I/O操作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.poll(pollTimeout, currentTimeMs);</span><br></pre></td></tr></table></figure></details><p>用一张图总结Sender线程的流程</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_6.png"></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>Kafka生产消息的主要流程，涉及到主线程往RecordAccumulator中写入消息，同时后台的Sender线程从RecordAccumulator中获取消息，使用NIO的方式把消息发送给Kafka，用一张图总结</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_5.png"></p><h3 id="Producer分区器"><a href="#Producer分区器" class="headerlink" title="Producer分区器"></a>Producer分区器</h3><p>分区器partitioner，可以实现自己的partitioner，比如根据key分区，可以保证相同key分到同一个分区，对保证顺序很有用。</p><p>相关参数：</p><ul><li><strong>partitioner.class</strong>:<br>消息发送队列负载算法，其默 DefaultPartitioner，路由算法如下：<ul><li>如果指定了 key，则使用 key 的 hashcode 与分区数取模。</li><li>如果未指定 key，则轮询所有的分区(用随机数对可用分区取模, counter值初始值是随机的，但后面都是递增的，所以可以算到roundrobin)。</li></ul></li></ul><h3 id="Producer-压缩算法"><a href="#Producer-压缩算法" class="headerlink" title="Producer 压缩算法"></a>Producer 压缩算法</h3><p>Kafka支持的压缩算法还是很可观的：GZIP、Snappy、LZ4，默认情况下不进行消息压缩，毕竟会消耗很大一部分cpu时间，导致send方法处理时间变慢。启动LZ4 进行消息压缩的producer的吞吐量是最高的。</p><p><strong>发送方与Broker 服务器采用相同的压缩类型，可有效避免在Broker服务端进行消息的压缩与解压缩，大大降低Broker的CPU使用压力</strong></p><p>相关参数：</p><ul><li><strong>compression.type</strong>:<br>消息的压缩算法，目前可选值：none、gzip、snappy、lz4、zstd，<strong>默认不压缩，建议与Kafka服务器配置的一样</strong>。</li></ul><p>当然Kafka服务端可以配置的压缩类型为 producer，即采用与发送方配置的压缩类型。</p><h3 id="Producer-interceptor"><a href="#Producer-interceptor" class="headerlink" title="Producer interceptor"></a>Producer interceptor</h3><p>拦截器是新版本才出现的一个特性，并且是非必须的。</p><p>interceptor 核心的函数有: </p><ul><li>onSend（在消息序列化计算分区之前就被调用）</li><li>onAcknowleagement（被应答前或者说在发送失败时，这个方法是运行在producer的I/O线程中的，所以说如果存在很多重逻辑的话会导致严重影响处理消息的速率）</li><li>close。通常是通过为clients定制一部分通用且简单的逻辑时才会使用的。</li></ul><p>相关参数: </p><ul><li><strong>interceptor.classes</strong>:<br>拦截器列表，kafka运行在消息真正发送到broker之前对消息进行拦截加工。</li></ul><h3 id="数据可靠性保证"><a href="#数据可靠性保证" class="headerlink" title="数据可靠性保证"></a>数据可靠性保证</h3><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后都需要向producer发送ack(acknowledgement 确认收到)，如果producer收到ack,就会进行下一轮的发送，否则重新发送数据。</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_7.png"></p><h4 id="副本数据同步策略"><a href="#副本数据同步策略" class="headerlink" title="副本数据同步策略"></a>副本数据同步策略</h4><table><thead><tr><th align="left">方案</th><th align="left">优点</th><th align="left">缺点</th></tr></thead><tbody><tr><td align="left">半数以上完成同步，就发送ack</td><td align="left">延迟低</td><td align="left">选举新的leader时，容忍n台节点故障，需要2n+1个副本</td></tr><tr><td align="left">全部完成同步，才发送ack</td><td align="left">选举新的leader时，容忍n台节点故障，需要n+1个副本</td><td align="left">延迟高</td></tr></tbody></table><p>Kafka选择了第二种方案，原因如下：</p><p>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1 个副本，而 Kafka 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</p><p>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</p><h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h4><p>采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据， 但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去， 直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p><p>Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集合。当 ISR 中的 follower 完成数据的同步之后，leader 就会给 follower 发送 ack。如果 follower 长时间未向 leader 同步数据 ， 则该 follower 将被踢出ISR ， 该时间阈值由replica.lag.time.max.ms 参数设定。Leader 发生故障之后，就会从 ISR 中选举新的 leader。</p><h4 id="ack-应答机制"><a href="#ack-应答机制" class="headerlink" title="ack 应答机制"></a>ack 应答机制</h4><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等 ISR 中的 follower 全部接收成功。</p><p>所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p><ul><li>0: 表示生产者不关心该条消息在 broker 端的处理结果，只要调用 KafkaProducer 的 send 方法返回后即认为成功，显然这种方式是最不安全的，因为 Broker 端可能压根都没有收到该条消息或存储失败。</li><li>1: 等待至少一个leader成功把消息写到log中，不保证follower写入成功，如果leader宕机同时follower没有把数据写入成功，数据丢失。</li><li>all 或 -1: 表示消息不仅需要 Leader 节点已存储该消息，并且要求其副本（准确的来说是 ISR 中的节点）全部存储才认为已提交，才向客户端返回提交成功。这是最严格的持久化保障，当然性能也最低。<ul><li>但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成数据重复。</li></ul></li></ul><p>相关参数:</p><ul><li><strong>acks</strong>:<br>ack应答级别</li></ul><h4 id="故障处理细节"><a href="#故障处理细节" class="headerlink" title="故障处理细节"></a>故障处理细节</h4><p>Log文件中的HW和LEO</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_8.png"></p><p>LEO：指的是每个副本最大的 offset；<br>HW：指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。</p><ul><li>follower 故障: follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘 记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。 等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重 新加入 ISR 了</li><li>leader 故障: leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader 同步数据。</li></ul><p><strong>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p><h3 id="消息队列投递语义"><a href="#消息队列投递语义" class="headerlink" title="消息队列投递语义"></a>消息队列投递语义</h3><ul><li>At Least Once 可以保证数据不丢失，但是不能保证数据不重复。</li><li>At Most Once 可以保证数据不重复，但是不能保证数据不丢失。</li><li>对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即 Exactly Once 语义。</li></ul><p>Kafka投递语义实现方案：</p><ul><li><p>将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 At Least Once 语义。</p></li><li><p>相对的，将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被 发送一次，即 At Most Once 语义。</p></li></ul><p>在 0.11 版本以前的 Kafka，对Exactly Once 语义是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。</p><p>对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11 版本的 Kafka，引入了一项重大特性：<strong>幂等性</strong>。</p><pre><code>所谓的幂等性就是指 Producer 不论向 Server 发送多少次重复数据，Server 端都只会持久化一条。</code></pre><p>幂等性结合 At Least Once 语义，就构成了 Kafka 的 Exactly Once 语义。即：</p><p><strong>At Least Once + 幂等性 = Exactly Once</strong></p><p>相关参数: </p><ul><li><strong>enable.idempotence</strong>: 是否开启发送端的幂等，默认为false。</li><li><strong>acks</strong>: all</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。 </span><br><span class="line">开启幂等性的 Producer 在初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。</span><br><span class="line">而 Broker 端会对做缓存，当具有相同主键的消息提交时，Broker 只会持久化一条。</span><br></pre></td></tr></table></figure><p>但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以<strong>幂等性无法保证分区跨会话的 Exactly Once</strong></p><h3 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h3><ul><li><strong>send.buffer.bytes</strong>: 网络通道(TCP)的发送缓存区大小，默认为128K。</li><li><strong>receive.buffer.bytes</strong>: 网络通道(TCP)的接收缓存区大小，默认为32K。</li><li><strong>reconnect.backoff.ms</strong>: 重新建立链接的等待时长，默认为50ms，属于底层网络参数，基本无需关注。</li><li><strong>reconnect.backoff.max.ms</strong>: 重新建立链接的最大等待时长，默认为1s，连续两次对同一个连接建立重连，等待时间会在reconnect.backoff.ms的初始值上成指数级递增，但超过max后，将不再指数级递增。</li><li><strong>transaction.timeout.ms</strong>: 事务协调器等待客户端的事务状态反馈的最大超时时间，默认为60s。</li><li><strong>transactional.id</strong>: 事务id,用于在一个事务中唯一标识一个客户端</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列之Kafka复制原理</title>
      <link href="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/"/>
      <url>/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/img.png"></p><h4 id="HW（High-Watermark）："><a href="#HW（High-Watermark）：" class="headerlink" title="HW（High Watermark）："></a>HW（High Watermark）：</h4><ul><li>在分区高水位以下的消息被认为是已提交消息，反之就是未提交消息；</li><li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的；</li><li>小于等于HW值的所有消息都被认为是“已备份”的（replicated）。</li></ul><h4 id="LEO（Log-End-Offset）"><a href="#LEO（Log-End-Offset）" class="headerlink" title="LEO（Log End Offset）"></a>LEO（Log End Offset）</h4><ul><li>记录了该副本底层日志(log)中下一条消息的位移值（注意是下一条消息！！）</li><li>数字 15 所在的方框是虚线，这就说明，这个副本当前只有 15 条消息，位移值是从 0 到 14，下一条新消息的位移是 15；</li></ul><h3 id="更新机制"><a href="#更新机制" class="headerlink" title="更新机制"></a>更新机制</h3><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/img_1.png"></p><p><strong>流程如下</strong></p><ol><li>生产者写入消息到leader副本</li><li>leader副本LEO值更新</li><li>follower副本尝试拉取消息，发现有消息可以拉取，更新自身LEO</li><li>follower副本继续尝试拉取消息，这时会更新remote副本LEO，同时会更新leader副本的HW</li><li>完成4步骤后，leader副本会将已更新过的HW发送给所有follower副本</li><li>follower副本接收leader副本HW，更新自身的HW</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kafka副本之间的数据复制既不是完全的同步复制，也不是单纯的异步复制；</span><br><span class="line">Leader副本的HW更新原则：取当前leader副本的LEO和所有remote副本的LEO的最小值</span><br><span class="line">Follower副本的HW更新原则：取leader副本发送的HW和自身的LEO中的最小值</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息中间件Kafka系列01之Kafka为什么这么快</title>
      <link href="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/"/>
      <url>/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/</url>
      
        <content type="html"><![CDATA[<ul><li>partition 并行处理</li><li>顺序写磁盘，充分利用磁盘特性</li><li>利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率</li><li>采用了零拷贝技术</li><li>Producer 生产的数据持久化到 broker，采用 mmap 文件映射，实现顺序的快速写入</li><li>Customer 从 broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer进行网络发送，减少 CPU 消耗</li></ul><h2 id="详细解读"><a href="#详细解读" class="headerlink" title="详细解读"></a>详细解读</h2><p>无论 kafka 作为 MQ 也好，作为存储层也罢，无非就是两个功能（好简单的样子），一是 Producer 生产的数据存到 broker，二是 Consumer 从 broker 读取数据。那 Kafka 的快也就体现在读写两个方面了，下面我们就聊聊 Kafka 快的原因。</p><h3 id="利用-Partition-实现并行处理"><a href="#利用-Partition-实现并行处理" class="headerlink" title="利用 Partition 实现并行处理"></a>利用 Partition 实现并行处理</h3><p>我们都知道 Kafka 是一个 Pub-Sub 的消息系统，无论是发布还是订阅，都要指定 Topic。</p><p>Topic 只是一个逻辑的概念。每个 Topic 都包含一个或多个 Partition，不同 Partition 可位于不同节点。</p><p>一方面，由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p><p>能并行处理，速度肯定会有提升，多个工人肯定比一个工人干的快。</p><h3 id="顺序写磁盘"><a href="#顺序写磁盘" class="headerlink" title="顺序写磁盘"></a>顺序写磁盘</h3><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img.png"><br>Kafka 中每个分区是一个有序的，不可变的消息序列，新的消息不断追加到 partition 的末尾，这个就是顺序写。</p><p>由于磁盘有限，不可能保存所有数据，实际上作为消息系统 Kafka 也没必要保存所有数据，需要删除旧的数据。</p><p>又由于顺序写入的原因，所以 Kafka 采用各种删除策略删除数据的时候，并非通过使用“读 - 写”模式去修改文件，而是将 Partition 分为多个 Segment，每个 Segment 对应一个物理文件，通过删除整个文件的方式去删除 Partition 内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。</p><h4 id="简单扯扯磁盘-IO-的那些事"><a href="#简单扯扯磁盘-IO-的那些事" class="headerlink" title="简单扯扯磁盘/IO 的那些事"></a>简单扯扯磁盘/IO 的那些事</h4><p>硬盘性能的制约因素是什么？如何根据磁盘I/O特性来进行系统设计？<br>硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。<br>实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img2.png"></p><p>由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示：</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img1.png"></p><p>影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。<br>机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。<br>在许多的开源框架如 Kafka、HBase 中，都通过追加写的方式来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。  </p><p>感兴趣的同学可以看看 <a href="https://link.zhihu.com/?target=https://tech.meituan.com/2017/05/19/about-desk-io.html">磁盘I/O那些事</a></p><p>磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。</p><h3 id="充分利用-Page-Cache"><a href="#充分利用-Page-Cache" class="headerlink" title="充分利用 Page Cache"></a>充分利用 Page Cache</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache。</span><br><span class="line">  每一个 Page Cache 包含若干 Buffer Cache。</span><br><span class="line">* Page Cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read/write 操作的时候。</span><br><span class="line">* Buffer Cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。</span><br></pre></td></tr></table></figure><p>使用 Page Cache 的好处：</p><ul><li>I/O Scheduler 会将连续的小块写组装成大块的物理写从而提高性能</li><li>I/O Scheduler 会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</li><li>充分利用所有空闲内存（非 JVM 内存）。如果使用应用层 Cache（即 JVM 堆内存），会增加 GC 负担</li><li>读操作可直接在 Page Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 Page Cache）交换数据</li><li>如果进程重启，JVM 内的 Cache 会失效，但 Page Cache 仍然可用</li></ul><p>Broker 收到数据后，写磁盘时只是将数据写入 Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache 内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由 Kafka 层面的 Replication 机制去解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。也正因如此，Kafka 虽然提供了 flush.messages 和 flush.ms 两个参数将 Page Cache 中的数据强制 Flush 到磁盘，但是 Kafka 并不建议使用。</p><h3 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h3><p>Kafka 中存在大量的网络数据持久化到磁盘（Producer 到 Broker）和磁盘文件通过网络发送（Broker 到 Consumer）的过程。这一过程的性能直接影响 Kafka 的整体吞吐量。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的权限。</span><br><span class="line">为了避免用户进程直接操作内核，保证内核安全，操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space），一部分是用户空间（User-space）。</span><br></pre></td></tr></table></figure><p>传统的 Linux 系统中，标准的 I/O 接口（例如read，write）都是基于数据拷贝操作的，即 I/O 操作会导致数据在内核地址空间的缓冲区和用户地址空间的缓冲区之间进行拷贝，所以标准 I/O 也被称作缓存 I/O。这样做的好处是，如果所请求的数据已经存放在内核的高速缓冲存储器中，那么就可以减少实际的 I/O 操作，但坏处就是数据拷贝的过程，会导致 CPU 开销。</p><p>我们把 Kafka 的生产和消费简化成如下两个过程来看：</p><ul><li>网络数据持久化到磁盘 (Producer 到 Broker)</li><li>磁盘文件通过网络发送（Broker 到 Consumer）</li></ul><h4 id="1-网络数据持久化到磁盘-Producer-到-Broker"><a href="#1-网络数据持久化到磁盘-Producer-到-Broker" class="headerlink" title="1) 网络数据持久化到磁盘 (Producer 到 Broker)"></a>1) 网络数据持久化到磁盘 (Producer 到 Broker)</h4><p>传统模式下，数据从网络传输到文件需要 4 次数据拷贝、4 次上下文切换和两次系统调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = socket.read()// 读取网络数据 </span><br><span class="line">File file = new File() </span><br><span class="line">file.write(data)// 持久化到磁盘 </span><br><span class="line">file.flush()</span><br></pre></td></tr></table></figure><p>这一过程实际上发生了四次数据拷贝：</p><ul><li>首先通过 DMA copy 将网络数据拷贝到内核态 Socket Buffer</li><li>然后应用程序将内核态 Buffer 数据读入用户态（CPU copy）</li><li>接着用户程序将用户态 Buffer 再拷贝到内核态（CPU copy）</li><li>最后通过 DMA copy 将数据拷贝到磁盘文件</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DMA（Direct Memory Access）：直接存储器访问。DMA 是一种无需 CPU 的参与，让外设和系统内存之间进行双向数据传输的硬件机制。使用 DMA 可以使系统 CPU 从实际的 I/O 数据传输过程中摆脱出来，从而大大提高系统的吞吐率。</span><br></pre></td></tr></table></figure><p>其中伴随着四次上下文切换，如图所示</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img3.png"></p><p>数据落盘通常都是非实时的，kafka 生产者数据持久化也是如此。Kafka 的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高 I/O 效率，就是上一节提到的 Page Cache。</p><p>对于 kafka 来说，Producer 生产的数据存到 broker，这个过程读取到 socket buffer 的网络数据，其实可以直接在内核空间完成落盘。并没有必要将 socket buffer 的网络数据，读取到应用进程缓冲区；在这里应用进程缓冲区其实就是 broker，broker 收到生产者的数据，就是为了持久化。</p><p><strong>在此特殊场景下</strong>：接收来自 socket buffer 的网络数据，应用进程不需要中间处理、直接进行持久化时。可以使用 <strong>mmpp</strong> 内存文件映射。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Memory Mapped Files：简称 mmap，也有叫 MMFile 的，使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射。从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程。它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。</span><br><span class="line">使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销。</span><br><span class="line">mmap 也有一个很明显的缺陷——不可靠，写到 mmap 中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。Kafka 提供了一个参数——producer.type 来控制是不是主动flush；如果 Kafka 写入到 mmap 之后就立即 flush 然后再返回 Producer 叫同步(sync)；写入 mmap 之后立即返回 Producer 不调用 flush 就叫异步(async)，默认是 sync。</span><br></pre></td></tr></table></figure><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img4.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。</span><br><span class="line">它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。</span><br><span class="line">目前零拷贝技术主要有三种类型：</span><br><span class="line">直接I/O：</span><br><span class="line">        数据直接跨过内核，在用户地址空间与I/O设备之间传递，内核只是进行必要的虚拟存储配置等辅助工作；</span><br><span class="line">避免内核和用户空间之间的数据拷贝：</span><br><span class="line">        当应用程序不需要对数据进行访问时，则可以避免将数据从内核空间拷贝到用户空间</span><br><span class="line">        * mmap</span><br><span class="line">        * sendfile</span><br><span class="line">        * splice &amp;&amp; tee</span><br><span class="line">        * sockmap</span><br><span class="line">copy on write：</span><br><span class="line">        写时拷贝技术，数据不需要提前拷贝，而是当需要修改的时候再进行部分拷贝。</span><br></pre></td></tr></table></figure><h4 id="2-磁盘文件通过网络发送（Broker-到-Consumer）"><a href="#2-磁盘文件通过网络发送（Broker-到-Consumer）" class="headerlink" title="2) 磁盘文件通过网络发送（Broker 到 Consumer）"></a>2) 磁盘文件通过网络发送（Broker 到 Consumer）</h4><p>传统方式实现：先读取磁盘、再用 socket 发送，实际也是进过四次 copy</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buffer = File.read</span><br><span class="line">Socket.send(buffer)</span><br></pre></td></tr></table></figure><p>这一过程可以类比上边的生产消息：</p><ul><li>首先通过系统调用将文件数据读入到内核态 Buffer（DMA 拷贝）</li><li>然后应用程序将内存态 Buffer 数据读入到用户态 Buffer（CPU 拷贝）</li><li>接着用户程序通过 Socket 发送数据时将用户态 Buffer 数据拷贝到内核态 Buffer（CPU 拷贝）</li><li>最后通过 DMA 拷贝将数据拷贝到 NIC Buffer </li></ul><p>Linux 2.4+ 内核通过 sendfile 系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件 - 网络发送由一个 sendfile 调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img5.png"></p><p>Kafka 在这里采用的方案是通过 NIO 的 transferTo/transferFrom 调用操作系统的 sendfile 实现零拷贝。总共发生 2 次内核数据拷贝、2 次上下文切换和一次系统调用，消除了 CPU 数据拷贝</p><h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>在很多情况下，系统的瓶颈不是 CPU 或磁盘，而是网络IO。</p><p>因此，除了操作系统提供的低级批处理之外，Kafka 的客户端和 broker 还会在通过网络发送数据之前，在一个批处理中累积多条记录 (包括读和写)。记录的批处理分摊了网络往返的开销，使用了更大的数据包从而提高了带宽利用率。</p><h3 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h3><p>Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQ </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库连接池之HikariCP实现详解</title>
      <link href="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/"/>
      <url>/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是数据库连接池，为什么需要数据库连接池"><a href="#什么是数据库连接池，为什么需要数据库连接池" class="headerlink" title="什么是数据库连接池，为什么需要数据库连接池"></a>什么是数据库连接池，为什么需要数据库连接池</h2><p>从根本上而言，数据库连接池和我们常用的线程池一样，都属于池化资源，它在程序初始化时创建一定数量的数据库连接对象并将其保存在一块内存区中。</p><p>它允许应用程序重复使用一个现有的数据库连接，当需要执行 SQL 时，我们是直接从连接池中获取一个连接，而不是重新建立一个数据库连接，当 SQL 执行完，也并不是将数据库连接真的关掉，而是将其归还到数据库连接池中。</p><p>我们可以通过配置连接池的参数来控制连接池中的初始连接数、最小连接、最大连接、最大空闲时间等参数，来保证访问数据库的数量在一定可控制的范围类，防止系统崩溃，同时保证用户良好的体验。</p><p>数据库连接池示意图如下所示：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img.png"></p><p>因为数据库连接是有限且代价昂贵，创建和释放数据库连接都非常耗时，频繁地进行这样的操作将占用大量的性能开销，进而导致网站的响应速度下降，甚至引起服务器崩溃。</p><p>因此使用数据库连接池的核心作用，就是<strong>避免数据库连接频繁创建和销毁，节省系统开销</strong>。</p><h3 id="常见数据库连接池对比分析"><a href="#常见数据库连接池对比分析" class="headerlink" title="常见数据库连接池对比分析"></a>常见数据库连接池对比分析</h3><p>这里详细总结了常见数据库连接池的各项功能比较，我们重点分析下当前主流的阿里巴巴Druid与HikariCP，HikariCP在性能上是完全优于Druid连接池的。</p><p>而Druid的性能稍微差点是由于锁机制的不同，并且Druid提供更丰富的功能，包括监控、sql拦截与解析等功能，两者的侧重点不一样，HikariCP追求极致的高性能。</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_1.png"></p><p>下面是官网提供的性能对比图，在性能上面这五种数据库连接池的排序如下：HikariCP&gt;druid&gt;tomcat-jdbc&gt;dbcp&gt;c3p0：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_2.png"></p><h3 id="一个简单的小问题"><a href="#一个简单的小问题" class="headerlink" title="一个简单的小问题"></a>一个简单的小问题</h3><pre><code>连接池本身的性能消耗在整个调用链路中通常占比不大，连接池的性能关键点是：连接是否LRU方式重用，是否支持PSCache（PreparedStatementCache）。</code></pre><h2 id="HikariCP数据库连接池简介"><a href="#HikariCP数据库连接池简介" class="headerlink" title="HikariCP数据库连接池简介"></a>HikariCP数据库连接池简介</h2><p>HikariCP 号称是史上性能最好的数据库连接池，SpringBoot 2.0将它设置为默认的数据源连接池。</p><p>Hikari相比起其它连接池的性能高了非常多，那么，这是怎么做到的呢？</p><p>通过查看HikariCP官网介绍，对于HikariCP所做优化总结如下：</p><ol><li><p><strong>字节码精简</strong> ：优化代码，编译后的字节码量极少，使得CPU缓存可以加载更多的程序代码；</p><p> HikariCP在优化并精简字节码上也下了功夫，使用第三方的Java字节码修改类库Javassist来生成委托实现动态代理.动态代理的实现在ProxyFactory类，速度更快，相比于JDK Proxy生成的字节码更少，精简了很多不必要的字节码。</p></li><li><p><strong>优化代理和拦截器</strong>：减少代码，例如HikariCP的Statement proxy只有100行代码，只有BoneCP的十分之一；</p></li><li><p><strong>自定义数组类型（FastStatementList）代替ArrayList</strong>：避免ArrayList每次get()都要进行range check，避免调用remove()时的从头到尾的扫描（由于连接的特点是后获取连接的先释放）；</p></li><li><p><strong>自定义集合类型（ConcurrentBag）</strong>：提高并发读写的效率；</p></li><li><p><strong>其他针对BoneCP缺陷的优化</strong>，比如对于耗时超过一个CPU时间片的方法调用的研究。</p></li></ol><h2 id="HikariCP详细设计之类图和流程图"><a href="#HikariCP详细设计之类图和流程图" class="headerlink" title="HikariCP详细设计之类图和流程图"></a>HikariCP详细设计之类图和流程图</h2><p>开始前先来了解下HikariCP获取一个连接时类间的交互流程，方便下面详细流程的阅读。</p><p>获取连接时的类间交互：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_3.png"></p><h2 id="HikariCP详细设计之流程源码解读"><a href="#HikariCP详细设计之流程源码解读" class="headerlink" title="HikariCP详细设计之流程源码解读"></a>HikariCP详细设计之流程源码解读</h2><h3 id="主流程1：获取连接流程"><a href="#主流程1：获取连接流程" class="headerlink" title="主流程1：获取连接流程"></a>主流程1：获取连接流程</h3><p>HikariCP获取连接时的入口是<code>HikariDataSource</code>里的<code>getConnection</code>方法，现在来看下该方法的具体流程：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_4.png"></p><p>上述为HikariCP获取连接时的流程图，由图可知:</p><ul><li>每个datasource对象里都会持有一个HikariPool对象，记为pool;</li><li>初始化后的datasource对象pool是空的，所以第一次getConnection的时候会进行实例化pool属性（参考主流程1），初始化的时候需要将当前datasource里的config属性传过去，用于pool的初始化，最终标记sealed;</li><li>然后根据pool对象调用getConnection方法（参考流程1.1），获取成功后返回连接对象。</li></ul><h4 id="流程1-1：通过HikariPool获取连接对象"><a href="#流程1-1：通过HikariPool获取连接对象" class="headerlink" title="流程1.1：通过HikariPool获取连接对象"></a>流程1.1：通过HikariPool获取连接对象</h4><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_6.png"></p><ul><li>从最开始的结构图可知，每个HikariPool里都维护一个ConcurrentBag对象，用于存放连接对象。</li><li>由上图可以看到，实际上HikariPool的getConnection就是从ConcurrentBag里获取连接的（调用其borrow方法获得，对应ConnectionBag主流程），</li><li>在长连接检查这块，与之前说的Druid不同，这里的长连接判活检查在连接对象没有被标记为“已丢弃”时，只要距离上次使用超过500ms每次取出都会进行检查（500ms是默认值，可通过配置<code>com.zaxxer.hikari.aliveBypassWindowMs</code>的系统参数来控制），也就是说HikariCP对长连接的活性检查很频繁，但是其并发性能依旧优于Druid，说明<strong>频繁的长连接检查并不是导致连接池性能高低的关键所在</strong>。<ul><li>这个其实是由于HikariCP的无锁实现，在高并发时对CPU的负载没有其他连接池那么高而产生的并发性能差异，后面会说HikariCP的具体做法；</li><li>即使是Druid，在获取连接、生成连接、归还连接时都进行了锁控制。</li><li>Druid里的连接池资源是多线程共享的，不可避免的会有锁竞争，有锁竞争意味着线程状态的变化会很频繁，线程状态变化频繁意味着CPU上下文切换也将会很频繁。</li></ul></li></ul><p>主体流程：</p><ul><li>如果拿到的连接为空，直接报错；</li><li>不为空则进行相应的检查<ul><li>如果检查通过，则包装成ConnectionProxy对象返回给业务方；</li><li>不通过则调用closeConnection方法关闭连接（对应流程1.1.2，该流程会触发ConcurrentBag的remove方法丢弃该连接，然后把实际的驱动连接交给closeConnectionExecutor线程池，异步关闭驱动连接）。</li></ul></li></ul><h5 id="流程1-1-1：连接判活"><a href="#流程1-1-1：连接判活" class="headerlink" title="流程1.1.1：连接判活"></a>流程1.1.1：连接判活</h5><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_7.png"></p><p>承接上面的<code>流程1.1</code>里的判活流程，来看下判活是如何做的</p><ul><li>首先说验证方法（注意这里该方法接受的这个connection对象不是poolEntry，而是poolEntry持有的实际驱动的连接对象），<ul><li>Druid是根据驱动程序里是否存在ping方法来判断是否启用ping的方式判断连接是否存活;</li><li>但是到了HikariCP则更加简单粗暴，仅根据是否配置了connectionTestQuery觉定是否启用ping：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.isUseJdbc4Validation = config.getConnectionTestQuery() == null;</span><br></pre></td></tr></table></figure></li><li>所以一般驱动如果不是特别低的版本，不建议配置该项，否则便会走createStatement+excute的方式，相比ping简单发送心跳数据，这种方式显然更低效。</li></ul></li><li>超时时间<ul><li>在刚进来还会通过驱动的连接对象重新给它设置一遍networkTimeout的值，使之变成validationTimeout，表示一次验证的超时时间；</li><li>因为在使用ping方法校验时，是没办法通过类似statement那样可以setQueryTimeout的，所以只能由网络通信的超时时间来控制，这个时间可以通过jdbc的连接参数socketTimeout来控制：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbc:mysql://127.0.0.1:3306/xxx?socketTimeout=250</span><br></pre></td></tr></table></figure></li><li>这个值最终会被赋值给HikariCP的networkTimeout字段，这就是为什么最后那一步使用这个字段来还原驱动连接超时属性的原因；</li><li>最后那里为啥要再次还原呢？这就很容易理解了，因为验证结束了，连接对象还存活的情况下，它的networkTimeout的值这时仍然等于validationTimeout（不合预期），显然在拿出去用之前，需要恢复成本来的值，也就是HikariCP里的networkTimeout属性。</li></ul></li></ul><h5 id="流程1-1-2：关闭连接对象"><a href="#流程1-1-2：关闭连接对象" class="headerlink" title="流程1.1.2：关闭连接对象"></a>流程1.1.2：关闭连接对象</h5><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_8.png"></p><p>这个流程简单来说就是把流程1.1.1中验证不通过的死连接，主动关闭的一个流程。</p><ul><li>首先会把这个连接对象从ConnectionBag里移除，</li><li>然后把实际的物理连接交给一个线程池去异步执行，这个线程池就是在主流程2里初始化池的时候初始化的线程池closeConnectionExecutor，</li><li>然后异步任务内开始实际的关连接操作，</li><li>因为主动关闭了一个连接相当于少了一个连接，所以还会触发一次扩充连接池（参考<code>主流程5</code>）操作。</li></ul><h3 id="主流程2：初始化池对象"><a href="#主流程2：初始化池对象" class="headerlink" title="主流程2：初始化池对象"></a>主流程2：初始化池对象</h3><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_5.png"></p><p>该流程用于初始化整个连接池，这个流程会给连接池内所有的属性做初始化的工作，其中比较主要的几个流程上图已经指出，简单概括一下：</p><ol><li>利用config初始化各种连接池属性，并且产生一个用于生产物理连接的数据源DriverDataSource</li><li>初始化存放连接对象的核心类connectionBag</li><li>初始化一个延时任务线程池类型的对象houseKeepingExecutorService，用于后续执行一些延时/定时类任务（比如连接泄漏检查延时任务，参考流程2.2以及<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B4%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%BC%A9%E5%AE%B9">主流程4：连接池缩容</a>，除此之外maxLifeTime后主动回收关闭连接也是交由该对象来执行的，这个过程可以参考主流程3）</li><li>预热连接池，HikariCP会在该流程的checkFailFast里初始化好一个连接对象放进池子内，当然触发该流程得保证initializationTimeout &gt; 0时（默认值1），这个配置属性表示留给预热操作的时间（默认值1在预热失败时不会发生重试）。与Druid通过initialSize控制预热连接对象数不一样的是，HikariCP仅预热进池一个连接对象。</li><li>初始化一个线程池对象addConnectionExecutor，用于后续扩充连接对象</li><li>初始化一个线程池对象closeConnectionExecutor，用于关闭一些连接对象，怎么触发关闭任务呢？可以参考流程1.1.2</li></ol><h4 id="流程2-1：HikariCP监控设置"><a href="#流程2-1：HikariCP监控设置" class="headerlink" title="流程2.1：HikariCP监控设置"></a>流程2.1：HikariCP监控设置</h4><p>不同于Druid那样监控指标那么多，HikariCP会把我们非常关心的几项指标暴露给我们，</p><p>比如当前连接池内闲置连接数、总连接数、一个连接被用了多久归还、创建一个物理连接花费多久等，</p><p>HikariCP的连接池的监控我们这一节专门详细的分解一下，首先找到HikariCP下面的metrics文件夹，这下面放置了一些规范实现的监控接口等，还有一些现成的实现（比如HikariCP自带对prometheus、micrometer、dropwizard的支持，不太了解后面两个，prometheus下文直接称为普罗米修斯）：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_9.png"></p><p>下面，来着重看下接口的定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这个接口的实现主要负责收集一些动作的耗时</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IMetricsTracker</span> <span class="keyword">extends</span> <span class="title">AutoCloseable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">//这个方法触发点在创建实际的物理连接时（主流程3），用于记录一个实际的物理连接创建所耗费的时间</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionCreatedMillis</span><span class="params">(<span class="keyword">long</span> connectionCreatedMillis)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点在getConnection时（主流程1），用于记录获取一个连接时实际的耗时</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionAcquiredNanos</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> elapsedAcquiredNanos)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点在回收连接时（主流程6），用于记录一个连接从被获取到被回收时所消耗的时间</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionUsageMillis</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> elapsedBorrowedMillis)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点也在getConnection时（主流程1），用于记录获取连接超时的次数，每发生一次获取连接超时，就会触发一次该方法的调用</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionTimeout</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>触发点都了解清楚后，再来看看MetricsTrackerFactory的接口定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//用于创建IMetricsTracker实例，并且按需记录PoolStats对象里的属性（这个对象里的属性就是类似连接池当前闲置连接数之类的线程池状态类指标）</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">MetricsTrackerFactory</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">//返回一个IMetricsTracker对象，并且把PoolStats传了过去</span></span><br><span class="line">    <span class="function">IMetricsTracker <span class="title">create</span><span class="params">(String poolName, PoolStats poolStats)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的接口用法见注释，针对新出现的PoolStats类，我们来看看它做了什么：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">PoolStats</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicLong reloadAt; <span class="comment">//触发下次刷新的时间（时间戳）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> timeoutMs; <span class="comment">//刷新下面的各项属性值的频率，默认1s，无法改变</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 总连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> totalConnections;</span><br><span class="line">    <span class="comment">// 闲置连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> idleConnections;</span><br><span class="line">    <span class="comment">// 活动连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> activeConnections;</span><br><span class="line">    <span class="comment">// 由于无法获取到可用连接而阻塞的业务线程数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> pendingThreads;</span><br><span class="line">    <span class="comment">// 最大连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> maxConnections;</span><br><span class="line">    <span class="comment">// 最小连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> minConnections;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PoolStats</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.timeoutMs = timeoutMs;</span><br><span class="line">        <span class="keyword">this</span>.reloadAt = <span class="keyword">new</span> AtomicLong();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这里以获取最大连接数为例，其他的跟这个差不多</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getMaxConnections</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (shouldLoad()) &#123; <span class="comment">//是否应该刷新</span></span><br><span class="line">            update(); <span class="comment">//刷新属性值，注意这个update的实现在HikariPool里，因为这些属性值的直接或间接来源都是HikariPool</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> maxConnections;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">()</span></span>; <span class="comment">//实现在↑上面已经说了</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldLoad</span><span class="params">()</span> </span>&#123; <span class="comment">//按照更新频率来决定是否刷新属性值</span></span><br><span class="line">        <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> now = currentTime();</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> reloadTime = reloadAt.get();</span><br><span class="line">            <span class="keyword">if</span> (reloadTime &gt; now) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (reloadAt.compareAndSet(reloadTime, plusMillis(now, timeoutMs))) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上这里就是这些属性获取和触发刷新的地方，那么这个对象是在哪里被生成并且丢给<code>MetricsTrackerFactory</code>的<code>create</code>方法的呢？这就是本节所需要讲述的要点：<code>主流程2</code>里的设置监控器的流程，来看看那里发生了什么事吧：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">//监控器设置方法（此方法在HikariPool中，metricsTracker属性就是HikariPool用来触发IMetricsTracker里方法调用的）</span><br><span class="line">public void setMetricsTrackerFactory(MetricsTrackerFactory metricsTrackerFactory) &#123;</span><br><span class="line">    if (metricsTrackerFactory != null) &#123;</span><br><span class="line">        //MetricsTrackerDelegate是包装类，是HikariPool的一个静态内部类，是实际持有IMetricsTracker对象的类，也是实际触发IMetricsTracker里方法调用的类</span><br><span class="line">        //这里首先会触发MetricsTrackerFactory类的create方法拿到IMetricsTracker对象，然后利用getPoolStats初始化PoolStat对象，然后也一并传给MetricsTrackerFactory</span><br><span class="line">        this.metricsTracker = new MetricsTrackerDelegate(metricsTrackerFactory.create(config.getPoolName(), getPoolStats()));</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        //不启用监控，直接等于一个没有实现方法的空类</span><br><span class="line">        this.metricsTracker = new NopMetricsTrackerDelegate();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private PoolStats getPoolStats() &#123;</span><br><span class="line">    //初始化PoolStats对象，并且规定1s触发一次属性值刷新的update方法</span><br><span class="line">    return new PoolStats(SECONDS.toMillis(1)) &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void update() &#123;</span><br><span class="line">            //实现了PoolStat的update方法，刷新各个属性的值</span><br><span class="line">            this.pendingThreads = HikariPool.this.getThreadsAwaitingConnection();</span><br><span class="line">            this.idleConnections = HikariPool.this.getIdleConnections();</span><br><span class="line">            this.totalConnections = HikariPool.this.getTotalConnections();</span><br><span class="line">            this.activeConnections = HikariPool.this.getActiveConnections();</span><br><span class="line">            this.maxConnections = config.getMaximumPoolSize();</span><br><span class="line">            this.minConnections = config.getMinimumIdle();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里HikariCP的监控器就算是注册进去了，所以要想实现自己的监控器拿到上面的指标，要经过如下步骤：</p><ol><li>新建一个类实现IMetricsTracker接口，我们这里将该类记为IMetricsTrackerImpl</li><li>新建一个类实现MetricsTrackerFactory接口，我们这里将该类记为MetricsTrackerFactoryImpl，并且将上面的IMetricsTrackerImpl在其create方法内实例化</li><li>将MetricsTrackerFactoryImpl实例化后调用HikariPool的setMetricsTrackerFactory方法注册到Hikari连接池。</li></ol><p>上面没有提到PoolStats里的属性怎么监控，这里来说下。</p><p>由于create方法是调用一次就没了，create方法只是接收了PoolStats对象的实例，如果不处理，那么随着create调用的结束，这个实例针对监控模块来说就失去持有了，所以这里如果想要拿到PoolStats里的属性，就需要开启一个守护线程，让其持有PoolStats对象实例，并且定时获取其内部属性值，然后push给监控系统，如果是<strong>普罗米修斯等使用pull方式获取监控数据的监控系统</strong>，可以效仿HikariCP原生普罗米修斯监控的实现，自定义一个Collector对象来接收PoolStats实例，这样普罗米修斯就可以定期拉取了，比如HikariCP根据普罗米修斯监控系统自己定义的<code>MetricsTrackerFactory</code>实现（对应<code>PrometheusMetricsTrackerFactory</code>类）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public IMetricsTracker create(String poolName, PoolStats poolStats) &#123;</span><br><span class="line">    getCollector().add(poolName, poolStats); //将接收到的PoolStats对象直接交给Collector，这样普罗米修斯服务端每触发一次采集接口的调用，PoolStats都会跟着执行一遍内部属性获取流程</span><br><span class="line">    return new PrometheusMetricsTracker(poolName, this.collectorRegistry); //返回IMetricsTracker接口的实现类</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//自定义的Collector</span><br><span class="line">private HikariCPCollector getCollector() &#123;</span><br><span class="line">    if (collector == null) &#123;</span><br><span class="line">        //注册到普罗米修斯收集中心</span><br><span class="line">        collector = new HikariCPCollector().register(this.collectorRegistry);</span><br><span class="line">    &#125;</span><br><span class="line">    return collector;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上面的解释可以知道在HikariCP中如何自定义一个自己的监控器，以及相比Druid的监控，有什么区别。 </p><h4 id="流程2-2：连接泄漏的检测与告警"><a href="#流程2-2：连接泄漏的检测与告警" class="headerlink" title="流程2.2：连接泄漏的检测与告警"></a>流程2.2：连接泄漏的检测与告警</h4><p>本节对应<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里的<a href="#%E6%B5%81%E7%A8%8B2.2%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B3%84%E6%BC%8F%E7%9A%84%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%91%8A%E8%AD%A6">子流程2.2</a>，在初始化池对象时，初始化了一个叫做<code>leakTaskFactory</code>的属性，本节来看下它具体是用来做什么的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个连接被拿出去使用时间超过leakDetectionThreshold（可配置，默认0）未归还的，会触发一个连接泄漏警告，通知业务方目前存在连接泄漏的问题。</span><br></pre></td></tr></table></figure><p><strong>过程详解</strong>:</p><p>该属性是<code>ProxyLeakTaskFactory</code>类型对象，且它还会持有<code>houseKeepingExecutorService</code>这个线程池对象，用于生产<code>ProxyLeakTask</code>对象，然后利用上面的<code>houseKeepingExecutorService</code>延时运行该对象里的run方法。</p><p>该流程的触发点在上面的<a href="#%E6%B5%81%E7%A8%8B1.1.1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%88%A4%E6%B4%BB">流程1.1</a>最后包装成ProxyConnection对象的那一步，来看看具体的流程图：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_10.png"></p><p>每次在<a href="#%E6%B5%81%E7%A8%8B1.1.1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%88%A4%E6%B4%BB">流程1.1</a>那里生成ProxyConnection对象时，都会触发上面的流程。</p><p>由流程图可以知道，ProxyConnection对象持有PoolEntry和ProxyLeakTask的对象，其中初始化ProxyLeakTask对象时就用到了leakTaskFactory对象，通过其schedule方法可以进行ProxyLeakTask的初始化，并将其实例传递给ProxyConnection进行初始化赋值</p><p><code>ps：由图知ProxyConnection在触发回收事件时，会主动取消这个泄漏检查任务，这也是ProxyConnection需要持有ProxyLeakTask对象的原因</code></p><p>只有在leakDetectionThreshold不等于0的时候才会生成一个带有实际延时任务的ProxyLeakTask对象，否则返回无实际意义的空对象。所以要想启用连接泄漏检查，首先要把leakDetectionThreshold配置设置上，这个属性表示经过该时间后借出去的连接仍未归还，则触发连接泄漏告警。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ProxyConnection之所以要持有ProxyLeakTask对象，是因为它可以监听到连接是否触发归还操作，如果触发，则调用cancel方法取消延时任务，防止误告。</span><br></pre></td></tr></table></figure><p>由此流程可以知道，跟Druid一样，HikariCP也有连接对象泄漏检查，与Druid主动回收连接相比，HikariCP实现更加简单，仅仅是在触发时打印警告日志，不会采取具体的强制回收的措施。</p><p>与Druid一样，默认也是关闭这个流程的，因为实际开发中一般使用第三方框架，框架本身会保证及时的close连接，防止连接对象泄漏，开启与否还是取决于业务是否需要，如果一定要开启，如何设置leakDetectionThreshold的大小也是需要考虑的一件事。</p><h3 id="主流程3：生成连接对象"><a href="#主流程3：生成连接对象" class="headerlink" title="主流程3：生成连接对象"></a>主流程3：生成连接对象</h3><p>本节来讲下<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里的<code>createEntry</code>方法，这个方法利用PoolBase里的DriverDataSource对象生成一个实际的连接对象（如果忘记DriverDatasource是哪里初始化的了，可以看下主流程2里PoolBase的initializeDataSource方法的作用），然后用PoolEntry类包装成PoolEntry对象：</p><details><summary>现在来看下这个包装类有哪些主要属性</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PoolEntry</span> <span class="keyword">implements</span> <span class="title">IConcurrentBagEntry</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(PoolEntry.class);</span><br><span class="line">    <span class="comment">//通过cas来修改state属性</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> AtomicIntegerFieldUpdater stateUpdater;</span><br><span class="line"></span><br><span class="line">    Connection connection; <span class="comment">//实际的物理连接对象</span></span><br><span class="line">    <span class="keyword">long</span> lastAccessed; <span class="comment">//触发回收时刷新该时间，表示“最近一次使用时间”</span></span><br><span class="line">    <span class="keyword">long</span> lastBorrowed; <span class="comment">//getConnection里borrow成功后刷新该时间，表示“最近一次借出的时间”</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;FieldCanBeLocal&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state = <span class="number">0</span>; <span class="comment">//连接状态，枚举值：IN_USE（使用中）、NOT_IN_USE（闲置中）、REMOVED（已移除）、RESERVED（标记为保留中）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> evict; <span class="comment">//是否被标记为废弃，很多地方用到（比如流程1.1靠这个判断连接是否已被废弃，再比如主流程4里时钟回拨时触发的直接废弃逻辑）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> ScheduledFuture&lt;?&gt; endOfLife; <span class="comment">//用于在超过连接生命周期（maxLifeTime）时废弃连接的延时任务，这里poolEntry要持有该对象，主要是因为在对象主动被关闭时（意味着不需要在超过maxLifeTime时主动失效了），需要cancel掉该任务</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> FastList openStatements; <span class="comment">//当前该连接对象上生成的所有的statement对象，用于在回收连接时主动关闭这些对象，防止存在漏关的statement</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> HikariPool hikariPool; <span class="comment">//持有pool对象</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isReadOnly; <span class="comment">//是否为只读</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isAutoCommit; <span class="comment">//是否存在事务</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面就是整个<code>PoolEntry</code>对象里所有的属性，这里再说下<em><strong>endOfLife</strong></em>对象。</p><p>它是一个利用houseKeepingExecutorService这个线程池对象做的延时任务，这个延时任务一般在创建好连接对象后maxLifeTime左右的时间触发</p><details><summary>具体来看下createEntry代码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">private PoolEntry createPoolEntry() &#123;</span><br><span class="line"></span><br><span class="line">        final PoolEntry poolEntry = newPoolEntry(); //生成实际的连接对象</span><br><span class="line"></span><br><span class="line">        final long maxLifetime = config.getMaxLifetime(); //拿到配置好的maxLifetime</span><br><span class="line">        if (maxLifetime &gt; 0) &#123; //&lt;=0的时候不启用主动过期策略</span><br><span class="line">            // 计算需要减去的随机数</span><br><span class="line">            // 源注释：variance up to 2.5% of the maxlifetime</span><br><span class="line">            final long variance = maxLifetime &gt; 10_000 ? ThreadLocalRandom.current().nextLong(maxLifetime / 40) : 0;</span><br><span class="line">            final long lifetime = maxLifetime - variance; //生成实际的延时时间</span><br><span class="line">            poolEntry.setFutureEol(houseKeepingExecutorService.schedule(</span><br><span class="line">                    () -&gt; &#123; //实际的延时任务，这里直接触发softEvictConnection，而softEvictConnection内则会标记该连接对象为废弃状态，然后尝试修改其状态为STATE_RESERVED，若成功，则触发closeConnection（对应流程1.1.2）</span><br><span class="line">                        if (softEvictConnection(poolEntry, &quot;(connection has passed maxLifetime)&quot;, false /* not owner */)) &#123;</span><br><span class="line">                            addBagItem(connectionBag.getWaitingThreadCount()); //回收完毕后，连接池内少了一个连接，就会尝试新增一个连接对象</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    lifetime, MILLISECONDS)); //给endOfLife赋值，并且提交延时任务，lifetime后触发</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return poolEntry;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //触发新增连接任务</span><br><span class="line">    public void addBagItem(final int waiting) &#123;</span><br><span class="line">        //前排提示：addConnectionQueue和addConnectionExecutor的关系和初始化参考主流程2</span><br><span class="line"></span><br><span class="line">        //当添加连接的队列里已提交的任务超过那些因为获取不到连接而发生阻塞的线程个数时，就进行提交连接新增连接的任务</span><br><span class="line">        final boolean shouldAdd = waiting - addConnectionQueue.size() &gt;= 0; // Yes, &gt;= is intentional.</span><br><span class="line">        if (shouldAdd) &#123;</span><br><span class="line">            //提交任务给addConnectionExecutor这个线程池，PoolEntryCreator是一个实现了Callable接口的类，下面将通过流程图的方式介绍该类的call方法</span><br><span class="line">            addConnectionExecutor.submit(poolEntryCreator);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></details></details><p>可以知道，HikariCP一般通过createEntry方法来新增一个连接入池，每个连接被包装成PoolEntry对象，在创建好对象时，同时会提交一个延时任务来关闭废弃该连接，这个时间就是我们配置的maxLifeTime，为了保证不在同一时间失效，HikariCP还会利用maxLifeTime减去一个随机数作为最终的延时任务延迟时间，然后在触发废弃任务时，还会触发addBagItem，进行连接添加任务（因为废弃了一个连接，需要往池子里补充一个），该任务则交给由<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里定义好的addConnectionExecutor线程池执行，那么，现在来看下这个异步添加连接对象的任务流程：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_11.png"></p><p>这个流程就是往连接池里加连接用的，跟<code>createEntry</code>结合起来说是因为这俩流程是紧密相关的，除此之外，<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B5%EF%BC%9A%E6%89%A9%E5%85%85%E8%BF%9E%E6%8E%A5%E6%B1%A0">主流程5：扩充连接池</a>也会触发该任务。</p><h3 id="主流程4：连接池缩容"><a href="#主流程4：连接池缩容" class="headerlink" title="主流程4：连接池缩容"></a>主流程4：连接池缩容</h3><p>HikariCP会按照 <strong>minIdle</strong> 定时清理闲置过久的连接，这个定时任务在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2：初始化池对象</a>时被启用，跟上面的流程一样，也是利用 <strong>houseKeepingExecutorService</strong> 这个线程池对象做该定时任务的执行器。</p><details><summary>来看下主流程2里是怎么启用该任务的</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//housekeepingPeriodMs的默认值是30s，所以定时任务的间隔为30s</span><br><span class="line">this.houseKeeperTask = houseKeepingExecutorService.scheduleWithFixedDelay(new HouseKeeper(), 100L, housekeepingPeriodMs, MILLISECONDS);</span><br></pre></td></tr></table></figure></details><p>那么本节主要来说下HouseKeeper这个类，该类实现了Runnable接口，回收逻辑主要在其run方法内，来看看run方法的逻辑流程图：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_12.png"></p><p>上面的流程就是HouseKeeper的run方法里具体做的事情，由于系统时间回拨会导致该定时任务回收一些连接时产生误差。<br>因此存在如下判断：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//now就是当前系统时间，previous就是上次触发该任务时的时间，housekeepingPeriodMs就是隔多久触发该任务一次</span><br><span class="line">//也就是说plusMillis(previous, housekeepingPeriodMs)表示当前时间</span><br><span class="line">//如果系统时间没被回拨，那么plusMillis(now, 128)一定是大于当前时间的，如果被系统时间被回拨</span><br><span class="line">//回拨的时间超过128ms，那么下面的判断就成立，否则永远不会成立</span><br><span class="line">if (plusMillis(now, 128) &lt; plusMillis(previous, housekeepingPeriodMs))</span><br></pre></td></tr></table></figure><p>这是hikariCP在解决系统时钟被回拨时做出的一种措施，通过流程图可以看到，它是直接把池子里所有的连接对象取出来挨个儿的标记成废弃，并且尝试把状态值修改为<code>STATE_RESERVED</code>（后面会说明这些状态，这里先不深究）。</p><p>如果系统时钟没有发生改变（绝大多数情况会命中这一块的逻辑），由图知，会把当前池内所有处于<code>闲置状态(STATE_NOT_IN_USE)</code>的连接拿出来，然后计算需要检查的范围，然后循环着修改连接的状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//拿到所有处于闲置状态的连接</span><br><span class="line">final List notInUse = connectionBag.values(STATE_NOT_IN_USE);</span><br><span class="line">//计算出需要被检查闲置时间的数量，简单来说，池内需要保证最小minIdle个连接活着，所以需要计算出超出这个范围的闲置对象进行检查</span><br><span class="line">int toRemove = notInUse.size() - config.getMinIdle();</span><br><span class="line">for (PoolEntry entry : notInUse) &#123;</span><br><span class="line">  //在检查范围内，且闲置时间超出idleTimeout，然后尝试将连接对象状态由STATE_NOT_IN_USE变为STATE_RESERVED成功</span><br><span class="line">  if (toRemove &gt; 0 &amp;&amp; elapsedMillis(entry.lastAccessed, now) &gt; idleTimeout &amp;&amp; connectionBag.reserve(entry)) &#123;</span><br><span class="line">    closeConnection(entry, &quot;(connection has passed idleTimeout)&quot;); //满足上述条件，进行连接关闭</span><br><span class="line">    toRemove--;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">fillPool(); //因为可能回收了一些连接，所以要再次触发连接池扩充流程检查下是否需要新增连接。</span><br></pre></td></tr></table></figure><p>上面的代码就是流程图里对应的没有回拨系统时间时的流程逻辑。</p><p>该流程在<code>idleTimeout大于0（默认等于0）并且minIdle小于maxPoolSize</code>的时候才会启用，默认是不启用的，若需要启用，可以按照条件来配置。</p><h3 id="主流程5：扩充连接池"><a href="#主流程5：扩充连接池" class="headerlink" title="主流程5：扩充连接池"></a>主流程5：扩充连接池</h3><p>这个流程主要依附<code>HikariPool</code>里的<code>fillPool</code>方法，这个方法已经在上面很多流程里出现过了，它的作用就是<strong>在触发连接废弃、连接池连接不够用时，发起扩充连接数的操作</strong>。</p><details><summary>下面看下源码（为了使代码结构更加清晰，对源码做了细微改动）</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// PoolEntryCreator关于call方法的实现流程在主流程3里已经看过了，但是这里却有俩PoolEntryCreator对象，</span><br><span class="line">// 这是个较细节的地方，用于打日志用，不再说这部分，为了便于理解，只需要知道这俩对象执行的是同一块call方法即可</span><br><span class="line">private final PoolEntryCreator poolEntryCreator = new PoolEntryCreator(null);</span><br><span class="line">private final PoolEntryCreator postFillPoolEntryCreator = new PoolEntryCreator(&quot;After adding &quot;);</span><br><span class="line"></span><br><span class="line">private synchronized void fillPool() &#123;</span><br><span class="line">  // 这个判断就是根据当前池子里相关数据，推算出需要扩充的连接数，</span><br><span class="line">  // 判断方式就是利用最大连接数跟当前连接总数的差值，与最小连接数与当前池内闲置的连接数的差值，取其最小的那一个得到</span><br><span class="line">  int needAdd = Math.min(maxPoolSize - connectionBag.size(),</span><br><span class="line">  minIdle - connectionBag.getCount(STATE_NOT_IN_USE));</span><br><span class="line"></span><br><span class="line">  //减去当前排队的任务，就是最终需要新增的连接数</span><br><span class="line">  final int connectionsToAdd = needAdd - addConnectionQueue.size();</span><br><span class="line">  for (int i = 0; i &lt; connectionsToAdd; i++) &#123;</span><br><span class="line">    //一般循环的最后一次会命中postFillPoolEntryCreator任务，其实就是在最后一次会打印一次日志而已（可以忽略该干扰逻辑）</span><br><span class="line">    addConnectionExecutor.submit((i &lt; connectionsToAdd - 1) ? poolEntryCreator : postFillPoolEntryCreator);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>最终这个新增连接的任务也是交由<code>addConnectionExecutor线程池</code>来处理的，而任务的主题也是<code>PoolEntryCreator</code>，这个流程可以参考<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B3%EF%BC%9A%E7%94%9F%E6%88%90%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1">主流程3：生成连接对象</a>.</p><p>然后needAdd的推算：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Math.min(最大连接数 - 池内当前连接总数, 最小连接数 - 池内闲置的连接数)</span><br></pre></td></tr></table></figure><p>根据这个方式判断，可以保证池内的连接数永远不会超过maxPoolSize，也永远不会低于minIdle。在连接吃紧的时候，可以保证每次触发都以minIdle的数量扩容。</p><p><code>因此如果在maxPoolSize跟minIdle配置的值一样的话，在池内连接吃紧的时候，就不会发生任何扩容了。</code></p><h3 id="主流程6：连接回收"><a href="#主流程6：连接回收" class="headerlink" title="主流程6：连接回收"></a>主流程6：连接回收</h3><p>最开始说过，最终真实的物理连接对象会被包装成PoolEntry对象，存放进ConcurrentBag，然后获取时，PoolEntry对象又会被再次包装成ProxyConnection对象暴露给使用方的，那么触发连接回收，实际上就是触发ProxyConnection里的close方法：</p><details><summary>查看源码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public final void close() throws SQLException &#123;</span><br><span class="line">  // 原注释：Closing statements can cause connection eviction, so this must run before the conditional below</span><br><span class="line">  closeStatements(); //此连接对象在业务方使用过程中产生的所有statement对象，进行统一close，防止漏close的情况</span><br><span class="line">  if (delegate != ClosedConnection.CLOSED_CONNECTION) &#123;</span><br><span class="line">    leakTask.cancel(); //取消连接泄漏检查任务，参考流程2.2</span><br><span class="line">    try &#123;</span><br><span class="line">      if (isCommitStateDirty &amp;&amp; !isAutoCommit) &#123; //在存在执行语句后并且还打开了事务，调用close时需要主动回滚事务</span><br><span class="line">        delegate.rollback(); //回滚</span><br><span class="line">        lastAccess = currentTime(); //刷新&quot;最后一次使用时间&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">      delegate = ClosedConnection.CLOSED_CONNECTION;</span><br><span class="line">      poolEntry.recycle(lastAccess); //触发回收</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>它最终会调用PoolEntry的recycle方法进行回收，除此之外，连接对象的最后一次使用时间也是在这个时候刷新的，该时间是个很重要的属性，可以用来判断一个连接对象的闲置时间.</p><details><summary>来看下PoolEntry的recycle方法</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void recycle(final long lastAccessed) &#123;</span><br><span class="line">  if (connection != null) &#123;</span><br><span class="line">    this.lastAccessed = lastAccessed; //刷新最后使用时间</span><br><span class="line">    hikariPool.recycle(this); //触发HikariPool的回收方法，把自己传过去</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>之前有说过，每个PoolEntry对象都持有HikariPool的对象，方便触发连接池的一些操作，由上述代码可以看到，最终还是会触发HikariPool里的recycle方法：</p><details><summary>再来看下HikariPool的recycle方法</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void recycle(final PoolEntry poolEntry) &#123;</span><br><span class="line">  metricsTracker.recordConnectionUsage(poolEntry); //监控指标相关，忽略</span><br><span class="line">  connectionBag.requite(poolEntry); //最终触发connectionBag的requite方法归还连接，该流程参考ConnectionBag主流程里的requite方法部分</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h3 id="ConcurrentBag主流程"><a href="#ConcurrentBag主流程" class="headerlink" title="ConcurrentBag主流程"></a>ConcurrentBag主流程</h3><p>当前主流数据库连接池实现方式，大都用两个阻塞队列来实现。一个用于保存空闲数据库连接的队列 idle，另一个用于保存忙碌数据库连接的队列 busy；获取连接时将空闲的数据库连接从 idle 队列移动到 busy 队列，而关闭连接时将数据库连接从 busy 移动到 idle。这种方案将并发问题委托给了阻塞队列，实现简单，但是性能并不是很理想。因为 Java SDK 中的阻塞队列是用锁实现的，而高并发场景下锁的争用对性能影响很大。</p><p>HiKariCP 并没有使用 Java SDK 中的阻塞队列，而是自己实现了一个叫做 ConcurrentBag 的并发容器，在连接池（多线程数据交互）的实现上具有比LinkedBlockingQueue和LinkedTransferQueue更优越的性能。</p><p>ConcurrentBag 中的关键属性</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 存放共享元素，用于存储所有的数据库连接</span><br><span class="line">private final CopyOnWriteArrayList&lt;T&gt; sharedList;</span><br><span class="line">// 在 ThreadLocal 缓存线程本地的数据库连接，避免线程争用</span><br><span class="line">private final ThreadLocal&lt;List&lt;Object&gt;&gt; threadList;</span><br><span class="line">// 等待数据库连接的线程数</span><br><span class="line">private final AtomicInteger waiters;</span><br><span class="line">// 接力队列，用来分配数据库连接</span><br><span class="line">private final SynchronousQueue&lt;T&gt; handoffQueue;</span><br></pre></td></tr></table></figure><p>这个类用来存放最终的PoolEntry类型的连接对象，提供了基本的增删查的功能，被HikariPool持有，上面那么多的操作，几乎都是在HikariPool中完成的，HikariPool用来管理实际的连接生产动作和回收动作，实际操作的却是ConcurrentBag类，梳理下上面所有流程的触发点：</p><ul><li>流程1.1：通过HikariPool获取连接时，通过调用<strong>ConcurrentBag.borrow</strong>拿到一个连接对象。</li><li>流程1.1.2：触发关闭连接时，会通过<strong>ConcurrentBag.remove</strong>移除连接对象，由前面的流程可知关闭连接触发点为：连接超过最大生命周期maxLifeTime主动废弃、健康检查不通过主动废弃、连接池缩容。</li><li>主流程2：初始化HikariPool时初始化ConcurrentBag（构造方法），预热时通过createEntry拿到连接对象，调用<strong>ConcurrentBag.add</strong>添加连接到ConcurrentBag。</li><li>主流程3：通过异步添加连接时，通过调用<strong>ConcurrentBag.add</strong>添加连接到ConcurrentBag，由前面的流程可知添加连接触发点为：连接超过最大生命周期maxLifeTime主动废弃连接后、连接池扩容。</li><li>主流程4：连接池缩容任务，通过调用<strong>ConcurrentBag.values</strong>筛选出需要的做操作的连接对象，然后再通过<strong>ConcurrentBag.reserve</strong>完成对连接对象状态的修改，然后会通过流程1.1.2触发关闭和移除连接操作。</li><li>主流程6：通过<strong>ConcurrentBag.requite</strong>归还一个连接。</li></ul><p>通过触发点整理，可以知道该结构里的主要方法，就是上面触发点里整理的部分。</p><details><summary>具体看下该类的基本定义和主要方法</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcurrentBag</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">IConcurrentBagEntry</span>&gt; <span class="keyword">implements</span> <span class="title">AutoCloseable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CopyOnWriteArrayList&lt;T&gt; sharedList; <span class="comment">//最终存放PoolEntry对象的地方，它是一个CopyOnWriteArrayList</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> weakThreadLocals; <span class="comment">//默认false，为true时可以让一个连接对象在下方threadList里的list内处于弱引用状态，防止内存泄漏（参见备注1）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ThreadLocal&lt;List&lt;Object&gt;&gt; threadList; <span class="comment">//线程级的缓存，从sharedList拿到的连接对象，会被缓存进当前线程内，borrow时会先从缓存中拿，从而达到池内无锁实现</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IBagStateListener listener; <span class="comment">//内部接口，HikariPool实现了该接口，主要用于ConcurrentBag主动通知HikariPool触发添加连接对象的异步操作（也就是主流程3里的addConnectionExecutor所触发的流程）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger waiters; <span class="comment">//当前因为获取不到连接而发生阻塞的业务线程数，这个在之前的流程里也出现过，比如主流程3里addBagItem就会根据该指标进行判断是否需要新增连接</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> closed; <span class="comment">//标记当前ConcurrentBag是否已被关闭</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SynchronousQueue&lt;T&gt; handoffQueue; <span class="comment">//这是个即产即销的队列，用于在连接不够用时，及时获取到add方法里新创建的连接对象，详情可以参考下面borrow和add的代码</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//内部接口，PoolEntry类实现了该接口</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IConcurrentBagEntry</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//连接对象的状态，前面的流程很多地方都已经涉及到了，比如主流程4的缩容</span></span><br><span class="line">        <span class="keyword">int</span> STATE_NOT_IN_USE = <span class="number">0</span>; <span class="comment">//闲置</span></span><br><span class="line">        <span class="keyword">int</span> STATE_IN_USE = <span class="number">1</span>; <span class="comment">//使用中</span></span><br><span class="line">        <span class="keyword">int</span> STATE_REMOVED = -<span class="number">1</span>; <span class="comment">//已废弃</span></span><br><span class="line">        <span class="keyword">int</span> STATE_RESERVED = -<span class="number">2</span>; <span class="comment">//标记保留，介于闲置和废弃之间的中间状态，主要由缩容那里触发修改</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">int</span> expectState, <span class="keyword">int</span> newState)</span></span>; <span class="comment">//尝试利用cas修改连接对象的状态值</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setState</span><span class="params">(<span class="keyword">int</span> newState)</span></span>; <span class="comment">//设置状态值</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">int</span> <span class="title">getState</span><span class="params">()</span></span>; <span class="comment">//获取状态值</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//参考上面listener属性的解释</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IBagStateListener</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">addBagItem</span><span class="params">(<span class="keyword">int</span> waiting)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">borrow</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">final</span> TimeUnit timeUnit)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//回收连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requite</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//添加连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//移除连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//根据连接状态值获取当前池子内所有符合条件的连接集合</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List <span class="title">values</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取当前池子内所有的连接</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List <span class="title">values</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//利用cas把传入的连接对象的state从 STATE_NOT_IN_USE 变为 STATE_RESERVED</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">reserve</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取当前池子内符合传入状态值的连接数量</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>ConcurrentBag 实现采用了queue-stealing的机制获取元素：首先尝试从ThreadLocal中获取属于当前线程的元素来避免锁竞争，如果没有可用元素则再次从共享的CopyOnWriteArrayList中获取。此外，ThreadLocal和CopyOnWriteArrayList在ConcurrentBag中都是成员变量，线程间不共享，避免了伪共享(false sharing)的发生。同时因为线程本地存储中的连接是可以被其他线程窃取的，在共享队列中获取空闲连接，所以需要用 CAS 方法防止重复分配。</p><details><summary>ConcurrentBag具体方法详细阅读</summary><h4 id="borrow"><a href="#borrow" class="headerlink" title="borrow"></a>borrow</h4><p>这个方法用来获取一个可用的连接对象，触发点为流程1.1，HikariPool就是利用该方法获取连接的。</p><details><summary>下面来看下该方法做了什么</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">public T borrow(long timeout, final TimeUnit timeUnit) throws InterruptedException &#123;</span><br><span class="line">    // 源注释：Try the thread-local list first</span><br><span class="line">    final List&lt;Object&gt; list = threadList.get(); //首先从当前线程的缓存里拿到之前被缓存进来的连接对象集合</span><br><span class="line">    for (int i = list.size() - 1; i &gt;= 0; i--) &#123;</span><br><span class="line">        final Object entry = list.remove(i); //先移除，回收方法那里会再次add进来</span><br><span class="line">        final T bagEntry = weakThreadLocals ? ((WeakReference&lt;T&gt;) entry).get() : (T) entry; //默认不启用弱引用</span><br><span class="line">        // 获取到对象后，通过cas尝试把其状态从STATE_NOT_IN_USE 变为 STATE_IN_USE，注意，这里如果其他线程也在使用这个连接对象，</span><br><span class="line">        // 并且成功修改属性，那么当前线程的cas会失败，那么就会继续循环尝试获取下一个连接对象</span><br><span class="line">        if (bagEntry != null &amp;&amp; bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">            return bagEntry; //cas设置成功后，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 源注释：Otherwise, scan the shared list ... then poll the handoff queue</span><br><span class="line">    final int waiting = waiters.incrementAndGet(); //如果缓存内找不到一个可用的连接对象，则认为需要“回源”，waiters+1</span><br><span class="line">    try &#123;</span><br><span class="line">        for (T bagEntry : sharedList) &#123;</span><br><span class="line">            //循环sharedList，尝试把连接状态值从STATE_NOT_IN_USE 变为 STATE_IN_USE</span><br><span class="line">            if (bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">                // 源注释：If we may have stolen another waiter&#x27;s connection, request another bag add.</span><br><span class="line">                if (waiting &gt; 1) &#123; //阻塞线程数大于1时，需要触发HikariPool的addBagItem方法来进行添加连接入池，这个方法的实现参考主流程3</span><br><span class="line">                    listener.addBagItem(waiting - 1);</span><br><span class="line">                &#125;</span><br><span class="line">                return bagEntry; //cas设置成功，跟上面的逻辑一样，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //走到这里说明不光线程缓存里的列表竞争不到连接对象，连sharedList里也找不到可用的连接，这时则认为需要通知HikariPool，该触发添加连接操作了</span><br><span class="line">        listener.addBagItem(waiting);</span><br><span class="line"></span><br><span class="line">        timeout = timeUnit.toNanos(timeout); //这时候开始利用timeout控制获取时间</span><br><span class="line">        do &#123;</span><br><span class="line">            final long start = currentTime();</span><br><span class="line">            //尝试从handoffQueue队列里获取最新被加进来的连接对象（一般新入的连接对象除了加进sharedList之外，还会被offer进该队列）</span><br><span class="line">            final T bagEntry = handoffQueue.poll(timeout, NANOSECONDS);</span><br><span class="line">            //如果超出指定时间后仍然没有获取到可用的连接对象，或者获取到对象后通过cas设置成功，这两种情况都不需要重试，直接返回对象</span><br><span class="line">            if (bagEntry == null || bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">                return bagEntry;</span><br><span class="line">            &#125;</span><br><span class="line">            //走到这里说明从队列内获取到了连接对象，但是cas设置失败，说明又该对象又被其他线程率先拿去用了，若时间还够，则再次尝试获取</span><br><span class="line">            timeout -= elapsedNanos(start); //timeout减去消耗的时间，表示下次循环可用时间</span><br><span class="line">        &#125; while (timeout &gt; 10_000); //剩余时间大于10s时才继续进行，一般情况下，这个循环只会走一次，因为timeout很少会配的比10s还大</span><br><span class="line"></span><br><span class="line">        return null; //超时，仍然返回null</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        waiters.decrementAndGet(); //这一步出去后，HikariPool收到borrow的结果，算是走出阻塞，所以waiters-1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>仔细看下注释，该过程大致分成三个主要步骤：</p><ol><li>从线程缓存获取连接</li><li>获取不到再从sharedList里获取</li><li>都获取不到则触发添加连接逻辑，并尝试从队列里获取新生成的连接对象</li></ol><h4 id="add"><a href="#add" class="headerlink" title="add"></a>add</h4><p>这个流程会添加一个连接对象进入bag，通常由<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B3%EF%BC%9A%E7%94%9F%E6%88%90%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1">主流程3：生成连接对象</a>里的addBagItem方法通过addConnectionExecutor异步任务触发添加操作，该方法主流程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public void add(final T bagEntry) &#123;</span><br><span class="line"></span><br><span class="line">    sharedList.add(bagEntry); //直接加到sharedList里去</span><br><span class="line"></span><br><span class="line">    // 源注释：spin until a thread takes it or none are waiting</span><br><span class="line">    // 参考borrow流程，当存在线程等待获取可用连接，并且当前新入的这个连接状态仍然是闲置状态，且队列里无消费者等待获取时，发起一次线程调度</span><br><span class="line">    while (waiters.get() &gt; 0 &amp;&amp; bagEntry.getState() == STATE_NOT_IN_USE &amp;&amp; !handoffQueue.offer(bagEntry)) &#123; //注意这里会offer一个连接对象入队列</span><br><span class="line">        yield();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结合borrow来理解的话，这里在存在等待线程时会添加一个连接对象入队列，可以让borrow里发生等待的地方更容易poll到这个连接对象。</p><h4 id="requite"><a href="#requite" class="headerlink" title="requite"></a>requite</h4><p>这个流程会回收一个连接，该方法的触发点在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B6%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%9B%9E%E6%94%B6">主流程6：连接回收</a></p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public void requite(final T bagEntry) &#123;</span><br><span class="line">    bagEntry.setState(STATE_NOT_IN_USE); //回收意味着使用完毕，更改state为STATE_NOT_IN_USE状态</span><br><span class="line"></span><br><span class="line">    for (int i = 0; waiters.get() &gt; 0; i++) &#123; //如果存在等待线程的话，尝试传给队列，让borrow获取</span><br><span class="line">        if (bagEntry.getState() != STATE_NOT_IN_USE || handoffQueue.offer(bagEntry)) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        else if ((i &amp; 0xff) == 0xff) &#123;</span><br><span class="line">            parkNanos(MICROSECONDS.toNanos(10));</span><br><span class="line">        &#125;</span><br><span class="line">        else &#123;</span><br><span class="line">            yield();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    final List&lt;Object&gt; threadLocalList = threadList.get();</span><br><span class="line">    if (threadLocalList.size() &lt; 50) &#123; //线程内连接集合的缓存最多50个，这里回收连接时会再次加进当前线程的缓存里，方便下次borrow获取</span><br><span class="line">        threadLocalList.add(weakThreadLocals ? new WeakReference&lt;&gt;(bagEntry) : bagEntry); //默认不启用弱引用，若启用的话，则缓存集合里的连接对象没有内存泄露的风险</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h4><p>这个负责从池子里移除一个连接对象，触发点在流程1.1.2。</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public boolean remove(final T bagEntry) &#123;</span><br><span class="line">    // 下面两个cas操作，都是从其他状态变为移除状态，任意一个成功，都不会走到下面的warn log</span><br><span class="line">    if (!bagEntry.compareAndSet(STATE_IN_USE, STATE_REMOVED) &amp;&amp; !bagEntry.compareAndSet(STATE_RESERVED, STATE_REMOVED) &amp;&amp; !closed) &#123;</span><br><span class="line">        LOGGER.warn(&quot;Attempt to remove an object from the bag that was not borrowed or reserved: &#123;&#125;&quot;, bagEntry);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 直接从sharedList移除掉</span><br><span class="line">    final boolean removed = sharedList.remove(bagEntry);</span><br><span class="line">    if (!removed &amp;&amp; !closed) &#123;</span><br><span class="line">        LOGGER.warn(&quot;Attempt to remove an object from the bag that does not exist: &#123;&#125;&quot;, bagEntry);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return removed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>移除时仅仅移除了sharedList里的对象，各个线程内缓存的那一份集合里对应的对象并没有被移除，这个时候会不会存在该连接再次从缓存里拿到呢？</p><p>会的，但是不会返回出去，而是直接remove掉了，仔细看borrow的代码发现状态不是闲置状态的时候，取出来时就会remove掉，然后也拿不出去，自然也不会触发回收方法。</p><h4 id="values"><a href="#values" class="headerlink" title="values"></a>values</h4><p>该方法存在重载方法，用于返回当前池子内连接对象的集合，触发点在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B4%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%BC%A9%E5%AE%B9">主流程4：连接池缩容</a>，代码如下：</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public List values(final int state) &#123;</span><br><span class="line">    //过滤出来符合状态值的对象集合逆序后返回出去</span><br><span class="line">    final List list = sharedList.stream().filter(e -&gt; e.getState() == state).collect(Collectors.toList());</span><br><span class="line">    Collections.reverse(list);</span><br><span class="line">    return list;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public List values() &#123;</span><br><span class="line">    //返回全部连接对象（注意下方clone为浅拷贝）</span><br><span class="line">    return (List) sharedList.clone();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="reserve"><a href="#reserve" class="headerlink" title="reserve"></a>reserve</h4><p>该方法单纯将连接对象的状态值由STATE_NOT_IN_USE修改为STATE_RESERVED，触发点仍然是主流程4，缩容时使用：</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public boolean reserve(final T bagEntry)&#123;</span><br><span class="line">   return bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_RESERVED);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="getCount"><a href="#getCount" class="headerlink" title="getCount"></a>getCount</h4><p>该方法用于返回池内符合某个状态值的连接的总数量，触发点为主流程5，扩充连接池时用于获取闲置连接总数。</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public int getCount(final int state)&#123;</span><br><span class="line">   int count = 0;</span><br><span class="line">   for (IConcurrentBagEntry e : sharedList) &#123;</span><br><span class="line">      if (e.getState() == state) &#123;</span><br><span class="line">         count++;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   return count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details></details><h2 id="基于FastList的性能优化"><a href="#基于FastList的性能优化" class="headerlink" title="基于FastList的性能优化"></a>基于FastList的性能优化</h2><p>首先我们来看一下执行数据库操作规范化的操作步骤：</p><ol><li>通过数据源获取一个数据库连接；</li><li>创建 Statement；</li><li>执行 SQL；</li><li>通过 ResultSet 获取 SQL 执行结果；</li><li>释放 ResultSet；</li><li>释放 Statement；</li><li>释放数据库连接。</li></ol><p>当前所有数据库连接池都是严格地根据这个顺序来进行数据库操作的，为了防止最后的释放操作，各类数据库连接池都会把创建的 Statement 保存在数组 ArrayList 里，来保证当关闭连接的时候，可以依次将数组中的所有 Statement 关闭。</p><p>HiKariCP 在处理这一步骤中，认为 ArrayList 的某些方法操作存在优化空间，因此对List接口的精简实现，针对List接口中核心的几个方法进行优化，其他部分与ArrayList基本一致。</p><ul><li>首先是get()方法<ul><li>ArrayList每次调用get()方法时都会进行rangeCheck检查索引是否越界，FastList的实现中去除了这一检查，是因为数据库连接池满足索引的合法性，能保证不会越界，此时rangeCheck就属于无效的计算开销，所以不用每次都进行越界检查。省去频繁的无效操作，可以明显地减少性能消耗。</li></ul></li><li>其次是remove方法<ul><li>当通过 conn.createStatement() 创建一个 Statement 时，需要调用 ArrayList 的 add() 方法加入到 ArrayList 中，这个是没有问题的；但是当通过 stmt.close() 关闭 Statement 的时候，需要调用 ArrayList 的 remove() 方法来将其从 ArrayList 中删除，而ArrayList的remove(Object)方法是从头开始遍历数组，而FastList是从数组的尾部开始遍历，因此更为高效。</li><li>相比于ArrayList的 remove()代码， FastList 去除了检查范围 和 从头到尾遍历检查元素的步骤，其性能更快。</li></ul></li></ul><p>总体而言，FastList 的优化点还是很简单的。相比ArrayList仅仅是去掉了rage检查，扩容优化等细节处，删除时数组从后往前遍历查找元素等微小的调整，从而追求性能极致。</p><p>当然FastList 对于 ArrayList 的优化，我们不能说ArrayList不好。所谓定位不同、追求不同，ArrayList作为通用容器，更追求安全、稳定，操作前rangeCheck检查，对非法请求直接抛出异常，更符合 fail-fast(快速失败)机制，而FastList追求的是性能极致。</p><h2 id="通过字节码修改类库Javassist完成字节码精简"><a href="#通过字节码修改类库Javassist完成字节码精简" class="headerlink" title="通过字节码修改类库Javassist完成字节码精简"></a>通过字节码修改类库Javassist完成字节码精简</h2><p>待补充，具体实现参考文章<a href="https://mp.weixin.qq.com/s?__biz=MzUzNTY4NTYxMA==&mid=2247483812&idx=1&sn=0fa3e648f853b840ed8a1c2f19468d6d&chksm=fa80f121cdf778379c70219665ef9c36d66dd0d6c6547add55a8fd920d523c6738835af308f7&scene=21#wechat_redirect">HikariCP源码分析之字节码修改类库Javassist委托实现动态代理</a></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring生态 </tag>
            
            <tag> 池化设计 </tag>
            
            <tag> 数据库连接池 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式协调组件之Zookeeper基础概念入门</title>
      <link href="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"/>
      <url>/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式协调组件"><a href="#什么是分布式协调组件" class="headerlink" title="什么是分布式协调组件"></a>什么是分布式协调组件</h2><p>讲Zookeeper之前，首先我们了解下什么是”分布式协调组件“。</p><p>所谓的“分布式协调组件”，就是我们在分布式应用开发中，为了协调分布式系统中各个机器协同运行而使用到的“公共组件”。比如Zookeeper、Redis等，都可以看作是“分布式协调组件”。</p><p>这里很容易可以看到，分布式环境中的“分布式协调组件”，和单机环境中的“多线程协调组件”（比如Java多线程并发工具包），其实是类似的东西。</p><p>不同的是: </p><ul><li>多线程协调组件是在同一台机器的内存中；而分布式协调组件的调用则是需要通过网络通信的，“网络不可达”的不确定性，就加大了使用分布式协调组件的使用难度</li><li>可用性：多线程协调组件是单机应用中的一部分，完全不需要担心某个并发变量会“挂掉”；而分布式协调组件一般是独立运行的，如何保障分布式协调组件的高可用，是一个很复杂的命题。比如一般会通过集群保障高可用，而集群里的机器之间如何保障数据一致性，则又是一个更加复杂的命题</li><li>分布式协调组件还需要考虑性能问题、可扩展性等</li></ul><h3 id="常用的分布式协调组件"><a href="#常用的分布式协调组件" class="headerlink" title="常用的分布式协调组件"></a>常用的分布式协调组件</h3><p><strong>全局功能数据存储/有功能的组件</strong>：</p><ul><li>K-V类：redis、memcache</li><li>Zookeeper</li><li>消息队列</li><li>配置中心：Spring Cloud Config等</li></ul><p><strong>持久数据存储</strong>：</p><ul><li>MySQL</li><li>MongoDB</li></ul><h3 id="分布式协调组件应用场景"><a href="#分布式协调组件应用场景" class="headerlink" title="分布式协调组件应用场景"></a>分布式协调组件应用场景</h3><ul><li>分布式session</li><li>分布式计数器</li><li>分布式锁</li><li>分布式队列：<ul><li>先入先出队列</li><li>要等所有队列元素聚集之后才能统一安排执行的Barrier模型队列</li></ul></li><li>分布式配置</li><li>分布式协调 / 通知</li><li>数据发布、订阅</li><li>软负载均衡：域名 -&gt; IP和端口号配置</li><li>命名服务：在分布式环境中，上层应用需要一个全局唯一的名字，类似于数据库中的主键</li><li>集群管理：<ul><li>集群监控（进群运行时状态收集）</li><li>集群控制（对集群进行操作和控制）</li></ul></li><li>Master选举</li></ul><h2 id="分布式协调组件Zookeeper概览"><a href="#分布式协调组件Zookeeper概览" class="headerlink" title="分布式协调组件Zookeeper概览"></a>分布式协调组件Zookeeper概览</h2><h3 id="ZooKeeper-实现了什么"><a href="#ZooKeeper-实现了什么" class="headerlink" title="ZooKeeper 实现了什么"></a>ZooKeeper 实现了什么</h3><p>ZooKeeper 是一个开源的分布式协调服务，它的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。</p><p><strong>原语</strong>： 操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。具有不可分割性·即原语的执行必须是连续的，在执行过程中不允许被中断。</p><p>ZooKeeper为我们提供了高可用、高性能、稳定的分布式数据一致性解决方案，通常被用于实现诸如<strong>数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列</strong>等功能。</p><p>另外，ZooKeeper 将<strong>数据保存在内存</strong>中，性能是非常棒的。</p><ul><li>在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。</li></ul><p><code>“读”多于“写”是协调服务的典型场景</code></p><h3 id="ZooKeeper-特点"><a href="#ZooKeeper-特点" class="headerlink" title="ZooKeeper 特点"></a>ZooKeeper 特点</h3><ul><li><p><strong>顺序一致性</strong>： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。</p></li><li><p><strong>原子性</strong>： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。</p></li><li><p><strong>单一系统映像</strong>： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。</p></li><li><p><strong>可靠性</strong>： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。</p></li></ul><h3 id="ZooKeeper-典型应用场景"><a href="#ZooKeeper-典型应用场景" class="headerlink" title="ZooKeeper 典型应用场景"></a>ZooKeeper 典型应用场景</h3><ul><li><p><strong>分布式锁</strong>： 通过创建唯一节点获得分布式锁，当获得锁的一方执行完相关代码或者是挂掉之后就释放锁。</p></li><li><p><strong>命名服务</strong>： 可以通过 ZooKeeper 的顺序节点生成全局唯一 ID</p></li><li><p><strong>数据发布/订阅</strong>：通过 Watcher 机制可以很方便地实现数据发布/订阅。当你将数据发布到 ZooKeeper 被监听的节点上，其他机器可通过监听 ZooKeeper 上节点的变化来实现配置的动态更新。</p></li></ul><h2 id="Zookeeper重要概念"><a href="#Zookeeper重要概念" class="headerlink" title="Zookeeper重要概念"></a>Zookeeper重要概念</h2><h3 id="Data-model（数据模型）"><a href="#Data-model（数据模型）" class="headerlink" title="Data model（数据模型）"></a>Data model（数据模型）</h3><p>ZooKeeper 数据模型采用层次化的多叉树形结构，每个节点上都可以存储数据，这些数据可以是数字、字符串或者是二级制序列。并且。每个节点还可以拥有 N 个子节点，最上层是根节点以“/”来代表。每个数据节点在 ZooKeeper 中被称为 znode，它是 ZooKeeper 中数据的最小单元。并且，每个 znode 都一个唯一的路径标识。</p><p>强调一句：ZooKeeper 主要是用来协调服务的，而不是用来存储业务数据的，所以<strong>不要放比较大的数据在znode上</strong>，ZooKeeper 给出的上限是每个结点的数据大小最大是 1M。</p><p>ZooKeeper 节点路径标识方式和 Unix 文件系统路径非常相似，都是由一系列使用斜杠”/“进行分割的路径表示，开发员可以向这个节点中写人数据，也可以在节点下面创建子节点。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/b26842dad2872eb0498fdf2bb1471cee.jpeg#pic_center"></p><h3 id="znode（数据节点）"><a href="#znode（数据节点）" class="headerlink" title="znode（数据节点）"></a>znode（数据节点）</h3><h4 id="znode节点分类"><a href="#znode节点分类" class="headerlink" title="znode节点分类"></a>znode节点分类</h4><ul><li><p>持久（PERSISTENT）节点： 一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。</p></li><li><p>临时（EPHEMERAL）节点： 临时节点的生命周期是与客户端会话（session）绑定的，会话消失则节点消失。并且，临时节点只能做叶子节点，不能创建子节点。</p></li><li><p>持久顺序（PERSISTENT_SEQUENTIAL）节点：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如/node1/app0000000001 、/node1/app0000000002 。</p></li><li><p>临时顺序（EPHEMERAL_SEQUENTIAL）节点：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。</p></li></ul><h4 id="znode-数据结构"><a href="#znode-数据结构" class="headerlink" title="znode 数据结构"></a>znode 数据结构</h4><p>每个 znode 由 2 部分组成:</p><ul><li>stat ：状态信息</li><li>data ： 节点存放的数据的具体内容</li></ul><p>Stat 类中包含了一个数据节点的所有状态信息的字段，包括事务 ID-cZxid、节点创建时间-ctime 和子节点个数-numChildren 等等，详细信息参考下表。</p><table><thead><tr><th>znode 状态信息</th><th>解释</th></tr></thead><tbody><tr><td>cZxid</td><td>create ZXID，即该数据节点被创建时的事务 id</td></tr><tr><td>ctime</td><td>create time，即该节点的创建时间</td></tr><tr><td>mZxid</td><td>modified ZXID，即该节点最终一次更新时的事务 id</td></tr><tr><td>mtime</td><td>modified time，即该节点最后一次的更新时间</td></tr><tr><td>pZxid</td><td>该节点的子节点列表最后一次修改时的事务 id，只有子节点列表变更才会更新 pZxid，子节点内容变更不会更新</td></tr><tr><td>cversion</td><td>子节点版本号，当前节点的子节点每次变化时值增加 1</td></tr><tr><td>dataVersion</td><td>数据节点内容版本号，节点创建时为 0，每更新一次节点内容(不管内容有无变化)该版本号的值增加 1</td></tr><tr><td>aclVersion</td><td>节点的 ACL 版本号，表示该节点 ACL 信息变更次数</td></tr><tr><td>ephemeralOwner</td><td>创建该临时节点的会话的 sessionId；如果当前节点为持久节点，则 ephemeralOwner=0</td></tr><tr><td>dataLength</td><td>数据节点内容长度</td></tr><tr><td>numChildren</td><td>当前节点的子节点个数</td></tr></tbody></table><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>前面我们已经提到，对应于每个 znode，ZooKeeper 都会为其维护一个叫作 <strong>Stat</strong>的数据结构，Stat 中记录了这个 znode 的三个相关的版本：</p><ul><li><p>  <strong>dataVersion</strong> ：当前 znode 节点的版本号</p></li><li><p>  <strong>cversion</strong> ： 当前 znode 子节点的版本</p></li><li><p>  <strong>aclVersion</strong> ： 当前 znode 的 ACL 的版本。</p></li></ul><h3 id="ACL（权限控制）"><a href="#ACL（权限控制）" class="headerlink" title="ACL（权限控制）"></a><strong>ACL（权限控制）</strong></h3><p>ZooKeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。</p><p>对于 znode 操作的权限，ZooKeeper 提供了以下 5 种：</p><ul><li><p>  <strong>CREATE</strong> : 能创建子节点</p></li><li><p>  <strong>READ</strong> ：能获取节点数据和列出其子节点</p></li><li><p>  <strong>WRITE</strong> : 能设置/更新节点数据</p></li><li><p>  <strong>DELETE</strong> : 能删除子节点</p></li><li><p>  <strong>ADMIN</strong> : 能设置节点 ACL 的权限</p></li></ul><p>其中尤其需要注意的是，<strong>CREATE</strong>和<strong>DELETE</strong>这两种权限都是针对<strong>子节点</strong>的权限控制。</p><p>对于身份认证，提供了以下几种方式：</p><ul><li><p>  <strong>world</strong> ： 默认方式，所有用户都可无条件访问。</p></li><li><p>  <strong>auth</strong>: 不使用任何 id，代表任何已认证的用户。</p></li><li><p>  <strong>digest</strong>: 用户名:密码认证方式： <em>username:password</em> 。</p></li><li><p>  <strong>ip</strong>: 对指定 ip 进行限制。</p></li></ul><h3 id="Watcher"><a href="#Watcher" class="headerlink" title="Watcher"></a><strong>Watcher</strong></h3><p>Watcher（事件监听器），是 ZooKeeper 中的一个很重要的特性。ZooKeeper允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper实现分布式协调服务的重要特性。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/be40875cd45d92900b44c4d39dedcb57.jpeg"></p><p><em>用到 ZooKeeper 基本离不开 Watcher（事件监听器）机制。</em></p><h3 id="会话（Session）"><a href="#会话（Session）" class="headerlink" title="会话（Session）"></a><strong>会话（Session）</strong></h3><p>Session 可以看作是 ZooKeeper 服务器与客户端的之间的一个 TCP 长连接，通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的 Watcher 事件通知。</p><p>Session 有一个属性叫做：sessionTimeout ，sessionTimeout代表会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。</p><p>另外，在为客户端创建会话之前，服务端首先会为每个客户端都分配一个 sessionID。由于 sessionID是 ZooKeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。</p><h2 id="ZooKeeper-集群"><a href="#ZooKeeper-集群" class="headerlink" title="ZooKeeper 集群"></a>ZooKeeper 集群</h2><p>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的，通常 3 台服务器就可以构成一个 ZooKeeper 集群了。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/8de274eb6351bdf85a64e4ce1a4b9f65.png"></p><p>上图中每一个 Server 代表一个安装 ZooKeeper 服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 ZAB 协议（ZooKeeper Atomic Broadcast）来保持数据的一致性。</p><p><strong>最典型集群模式： Master/Slave 模式（主备模式）</strong>。</p><p>在这种模式中，通常 Master 服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。</p><h3 id="ZooKeeper-集群角色"><a href="#ZooKeeper-集群角色" class="headerlink" title="ZooKeeper 集群角色"></a>ZooKeeper 集群角色</h3><table><thead><tr><th><strong>角色</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>Leader</td><td>为客户端提供读和写的服务，负责投票的发起和决议，更新系统状态。</td></tr><tr><td>Follower</td><td>为客户端提供读服务，如果是写服务则转发给 Leader。在选举过程中参与投票。</td></tr><tr><td>Observer</td><td>为客户端提供读服务器，如果是写服务则转发给 Leader。不参与选举过程中的投票，也不参与“过半写成功”策略。在不影响写性能的情况下提升集群的读性能。此角色于 ZooKeeper3.3 系列新增的角色。</td></tr></tbody></table><h3 id="Zookeeper-Leader选举"><a href="#Zookeeper-Leader选举" class="headerlink" title="Zookeeper Leader选举"></a>Zookeeper Leader选举</h3><p>当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，就会进入 Leader 选举过程，这个过程会选举产生新的 Leader 服务器。</p><p>这个过程大致是这样的：</p><ol><li><p> <strong>Leader election（选举阶段）</strong>: 节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。</p></li><li><p> <strong>Discovery（发现阶段）</strong>: 在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。</p></li><li><p> <strong>Synchronization（同步阶段）</strong>: 同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。</p></li><li><p> <strong>Broadcast（广播阶段）</strong>: 到了这个阶段，ZooKeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。</p></li></ol><h3 id="ZooKeeper-集群中的服务器状态"><a href="#ZooKeeper-集群中的服务器状态" class="headerlink" title="ZooKeeper 集群中的服务器状态"></a><strong>ZooKeeper 集群中的服务器状态</strong></h3><ul><li><p>  <strong>LOOKING</strong>: 寻找 Leader。</p></li><li><p>  <strong>LEADING</strong>: Leader 状态，对应的节点为 Leader。</p></li><li><p>  <strong>FOLLOWING</strong>: Follower 状态，对应的节点为 Follower。</p></li><li><p>  <strong>OBSERVING</strong>: Observer 状态，对应节点为 Observer，该节点不参与 Leader 选举。</p></li></ul><h3 id="ZooKeeper-集群为啥最好奇数台"><a href="#ZooKeeper-集群为啥最好奇数台" class="headerlink" title="ZooKeeper 集群为啥最好奇数台"></a><strong>ZooKeeper 集群为啥最好奇数台</strong></h3><p>ZooKeeper 集群在宕掉几个 ZooKeeper 服务器之后，如果剩下的 ZooKeeper 服务器个数大于宕掉的个数的话整个 ZooKeeper 才依然可用。假如我们的集群中有 n 台 ZooKeeper 服务器，那么也就是剩下的服务数必须大于 n/2。先说一下结论，2n 和 2n-1 的容忍度是一样的，都是n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。 比如假如我们有 3 台，那么最大允许宕掉 1 台 ZooKeeper 服务器，如果我们有 4 台的的时候也同样只允许宕掉 1 台。 假如我们有 5 台，那么最大允许宕掉 2 台ZooKeeper 服务器，如果我们有 6 台的的时候也同样只允许宕掉 2 台。</p><h2 id="ZAB-协议和Paxos-算法"><a href="#ZAB-协议和Paxos-算法" class="headerlink" title="ZAB 协议和Paxos 算法"></a>ZAB 协议和Paxos 算法</h2><p>Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像Paxos算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。</p><h3 id="ZAB-协议介绍"><a href="#ZAB-协议介绍" class="headerlink" title="ZAB 协议介绍"></a><strong>ZAB 协议介绍</strong></h3><p>ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。</p><p><strong>ZAB 协议两种基本的模式：崩溃恢复和消息广播</strong></p><p>ZAB 协议包括两种基本的模式，分别是</p><ul><li><p><strong>崩溃恢复</strong>：当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。<br>  其中，<strong>所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致</strong>。</p></li><li><p><strong>消息广播</strong>：<strong>当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。</strong><br>  当一台同样遵守ZAB协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。</p></li></ul><p>具体ZAB协议介绍可参考 <a href="https://dbaplus.cn/news-141-1875-1.html">实例详解ZooKeeper ZAB协议、分布式锁与领导选举</a></p><h2 id="Zookeeper总结"><a href="#Zookeeper总结" class="headerlink" title="Zookeeper总结"></a>Zookeeper总结</h2><ol><li><p>ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。</p></li><li><p>为了保证高可用，最好是以集群形态来部署ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么ZooKeeper 本身仍然是可用的。</p></li><li><p>ZooKeeper 将数据保存在内存中，这也就保证了高吞吐量和低延迟</p></li></ol><ul><li>但是内存限制了能够存储的容量不太大，此限制也是保持 znode 中存储的数据量较小的进一步原因。</li></ul><ol start="4"><li><p>ZooKeeper 是高性能的。<br>在“读”多于“写”的应用程序中尤其地明显，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</p></li><li><p>ZooKeeper 有临时节点的概念。  </p></li></ol><ul><li>当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。  </li><li>持久节点是指一旦这个 znode 被创建了，除非主动进行 znode 的移除操作，否则这个 znode 将一直保存在 ZooKeeper 上。</li></ul><ol start="6"><li>ZooKeeper 底层其实只提供了两个功能：</li></ol><ul><li>管理（存储、读取）用户程序提交的数据；</li><li>为用户程序提供数据节点监听服务。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ZOOKEEPER </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统00之如何设计一个高并发系统</title>
      <link href="/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/"/>
      <url>/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p>为啥会有高并发？为啥高并发就很牛逼？</p><p>很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。<br>所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。</p><p>设计一个高并发系统可以简单分为以下 6 点：</p><ul><li>系统拆分</li><li>缓存</li><li>MQ</li><li>分库分表</li><li>读写分离</li><li>ElasticSearch</li></ul><p><img src="/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/img_1.png"></p><h3 id="系统拆分"><a href="#系统拆分" class="headerlink" title="系统拆分"></a>系统拆分</h3><p>将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存，必须得用缓存。大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。</p><h3 id="MQ"><a href="#MQ" class="headerlink" title="MQ"></a>MQ</h3><p>MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。</p><h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h3><p>分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 sql 跑的性能。</p><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。</p><h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>Elasticsearch，简称 ES。</p><p>ES 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 设计理念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统03之高并发三大利器之降级</title>
      <link href="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%8D%E7%BA%A7/"/>
      <url>/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%8D%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h3 id="什么是服务降级"><a href="#什么是服务降级" class="headerlink" title="什么是服务降级"></a>什么是服务降级</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。</span><br></pre></td></tr></table></figure><p>服务降级主要用于当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，将一些 不重要 或 不紧急 的服务或任务进行服务的 <strong>延迟使用</strong> 或 <strong>暂停使用</strong>。</p><p>降级就是为了解决资源不足和访问量增加的矛盾。</p><h3 id="服务降级方式"><a href="#服务降级方式" class="headerlink" title="服务降级方式"></a>服务降级方式</h3><ul><li><strong>延迟服务</strong>：定时任务处理、或者mq延时处理。比如新用户注册送多少优惠券可以提示用户优惠券会24小时到达用户账号中，我们可以选择再凌晨流量较小的时候，批量去执行送券</li><li><strong>页面降级</strong>：页面点击按钮全部置灰，或者页面调整成为一个静态页面显示“系统正在维护中，。。。。”。</li><li><strong>关闭非核心服务</strong>：比如电商关闭推荐服务、关闭运费险、退货退款等。保证主流程的核心服务下单付款就好。</li><li><strong>写降级</strong>：比如秒杀抢购，我们可以只进行Cache的更新返回，然后通过mq异步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。</li><li><strong>读降级</strong>：比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景。</li></ul><h3 id="服务熔断"><a href="#服务熔断" class="headerlink" title="服务熔断"></a>服务熔断</h3><h4 id="服务雪崩"><a href="#服务雪崩" class="headerlink" title="服务雪崩"></a>服务雪崩</h4><p>多个微服务之间调用的时候，比如A服务调用了B服务，B服务调用了C服务，然后C服务由于机器宕机或者网略故障， 然后就会导致B服务调用C服务的时候超时，然后A服务调用B服务也会超时，最终整个链路都不可用了，导致整个系统不可用就跟雪蹦一样。</p><h4 id="雪崩效应产生的几种场景"><a href="#雪崩效应产生的几种场景" class="headerlink" title="雪崩效应产生的几种场景"></a>雪崩效应产生的几种场景</h4><p><strong>突增流量</strong>：比如一大波爬虫，或者黑客攻击等。<br><strong>程序bug</strong>：代码死循环，或者资源未释放等。<br><strong>硬件原因</strong>：机器宕机、机房断电、光纤被挖断等。  </p><h4 id="服务熔断-1"><a href="#服务熔断-1" class="headerlink" title="服务熔断"></a>服务熔断</h4><p>熔断机制是应对雪崩效应的一种微服务链路保护机制，在互联网系统中当下游的服务因为某种原因突然变得不可用或响应过慢，上游服务为了保证自己整体服务的可用性，暂时不再继续调用目标服务，直接快速返回，快速释放资源。如果目标服务情况好转则恢复调用。</p><h3 id="熔断和降级的比较"><a href="#熔断和降级的比较" class="headerlink" title="熔断和降级的比较"></a>熔断和降级的比较</h3><h4 id="共性"><a href="#共性" class="headerlink" title="共性"></a>共性</h4><ul><li>目的很一致：都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段，都是为了保证系统的稳定。</li><li>最终表现类似:对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用；</li><li>粒度一般都是服务级别:当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）；</li><li>自治性要求很高: 熔断模式一般都是服务基于策略的自动触发，比如</li><li>降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段；</li></ul><h4 id="差异性"><a href="#差异性" class="headerlink" title="差异性"></a>差异性</h4><ul><li>触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；</li><li>管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）熔断是降级方式的一种体现。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 降级 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统02之高并发三大利器之缓存</title>
      <link href="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/"/>
      <url>/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/</url>
      
        <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h2 id="缓存分类"><a href="#缓存分类" class="headerlink" title="缓存分类"></a>缓存分类</h2><ul><li>分布式缓存： 如redis、memcached等</li><li>本地（进程内）缓存： 如ehcache、GuavaCache、Caffeine等</li></ul><h2 id="缓存特性"><a href="#缓存特性" class="headerlink" title="缓存特性"></a>缓存特性</h2><h3 id="命中率"><a href="#命中率" class="headerlink" title="命中率"></a>命中率</h3><p>命中率=命中数/（命中数+没有命中数）当某个请求能够通过访问缓存而得到响应时，称为缓存命中。缓存命中率越高，缓存的利用率也就越高。</p><h3 id="最大空间"><a href="#最大空间" class="headerlink" title="最大空间"></a>最大空间</h3><p>缓存中可以容纳最大元素的数量。当缓存存放的数据超过最大空间时，就需要根据淘汰算法来淘汰部分数据存放新到达的数据。</p><h3 id="淘汰算法"><a href="#淘汰算法" class="headerlink" title="淘汰算法"></a>淘汰算法</h3><p>缓存的存储空间有限制，当缓存空间被用满时，如何保证在稳定服务的同时有效提升命中率？这就由缓存淘汰算法来处理，设计适合自身数据特征的淘汰算法能够有效提升缓存命中率。<br>常见的淘汰算法有：</p><ul><li><p>FIFO(first in first out)「先进先出」<br>最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。「适用于保证高频数据有效性场景，优先保障最新数据可用」。</p></li><li><p>LFU(less frequently used)「最少使用」<br>无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。「适用于保证高频数据有效性场景」。</p></li><li><p>LRU(least recently used)「最近最少使用」<br>无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。「比较适用于热点数据场景，优先保证热点数据的有效性。」</p></li></ul><h2 id="本地缓存"><a href="#本地缓存" class="headerlink" title="本地缓存"></a>本地缓存</h2><p>常见本地缓存有以下几种实现方式：</p><p><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/img.png"></p><p>其中性能最佳的是Caffeine，了解更详细信息参考： <a href="https://mp.weixin.qq.com/s?__biz=MzIyMjQwMTgyNA==&mid=2247483811&idx=1&sn=9d0b207044b5fe447169d630a7f77aab&scene=21#wechat_redirect">本地缓存性能之王</a></p><h2 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h2><p>分布式缓存详细信息参考redis系列文章</p><h2 id="缓存更新方案"><a href="#缓存更新方案" class="headerlink" title="缓存更新方案"></a>缓存更新方案</h2><p>我们一般的缓存更新主要有以下几种更新策略：</p><ul><li>先更新缓存，再更新数据库</li><li>先更新数据库，再更新缓存</li><li>先删除缓存，再更新数据库</li><li>先更新数据源库，再删除缓存</li></ul><p>至于选择哪种更新策略的话，没有绝对的选择，可以根据自己的业务情况来选择适合自己的。<br>不过一般推荐的话是选择 「<strong>先更新数据源库，再删除缓存</strong>」。</p><h2 id="缓存常见问题"><a href="#缓存常见问题" class="headerlink" title="缓存常见问题"></a>缓存常见问题</h2><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>大量查询数据库不存在数据，缓存无数据，大量无效请求落库。</p><p>解决方案</p><ul><li>数据库不存在数据写空值入缓存</li></ul><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>大规模缓存崩溃，大量请求落库。</p><p>解决方案</p><ul><li>事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。</li><li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li><li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>热点key失效瞬间大量请求落库。</p><p>解决方案</p><ul><li>基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>更新不频繁且更新时间段，加互斥锁保证少量请求重建缓存。</li><li>数据更新频繁或更新时间长，定时线程主动重建缓存。</li></ul><h3 id="缓存双写一致性"><a href="#缓存双写一致性" class="headerlink" title="缓存双写一致性"></a>缓存双写一致性</h3><p>缓存使用方法：<br>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。<br>更新的时候，先更新数据库，然后再删除缓存。</p><p>不一致解决方案</p><ul><li>初级：先删除缓存，再更新数据库。</li><li>高并发：使用队列做轻异步，多个并发更新请求阻塞过滤。（必须压测防止长时间阻塞积压）</li></ul><h3 id="redis并发竞争"><a href="#redis并发竞争" class="headerlink" title="redis并发竞争"></a>redis并发竞争</h3><p>多客户端同时并发写key，后来的数据先改。</p><p>解决方案：</p><ul><li>Redis存在CAS方案</li><li>实现分布式锁</li><li>写前判断版本号</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高并发系统01之高并发三大利器之限流</title>
      <link href="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/"/>
      <url>/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/</url>
      
        <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h2 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h2><h3 id="快速失败-–-滑动时间窗口"><a href="#快速失败-–-滑动时间窗口" class="headerlink" title="快速失败 – 滑动时间窗口"></a>快速失败 – 滑动时间窗口</h3><p>滑动窗口算法是将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期<br><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/%E6%BB%91%E5%8A%A8%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3.png"></p><h3 id="排队等待-漏桶算法"><a href="#排队等待-漏桶算法" class="headerlink" title="排队等待 - 漏桶算法"></a>排队等待 - 漏桶算法</h3><p>漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。<br><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/%E6%BC%8F%E6%A1%B6%E7%AE%97%E6%B3%95.png"></p><p>首先，我们有一个固定容量的桶，有水流进来，也有水流出去。对于流进来的水来说，我们无法预计一共有多少水会流进来，也无法预计水流的速度。但是对于流出去的水来说，这个桶可以固定水流出的速率。而且，当桶满了之后，多余的水将会溢出。</p><p>我们将算法中的水换成实际应用中的请求，我们可以看到漏桶算法天生就限制了请求的速度。当使用了漏桶算法，我们可以保证接口会以一个常速速率来处理请求。所以漏桶算法天生不会出现临界问题。<br>漏桶算法可以粗略的认为就是注水漏水过程，往桶中<strong>以一定速率流出水，以任意速率流入水</strong>，当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。</p><h3 id="Warm-Up-令牌桶算法"><a href="#Warm-Up-令牌桶算法" class="headerlink" title="Warm Up - 令牌桶算法"></a>Warm Up - 令牌桶算法</h3><p>首先，我们有一个固定容量的桶，桶里存放着令牌（token）。<br>桶一开始是空的，token以 一个固定的速率r往桶里填充，直到达到桶的容量，多余的令牌将会被丢弃。<br>每当一个请求过来时，就会尝试从桶里移除一个令牌，如果没有令牌的话，请求无法通过。</p><p><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/aegar-6o1hz.png"></p><h4 id="解决问题："><a href="#解决问题：" class="headerlink" title="解决问题："></a>解决问题：</h4><ul><li>Warm Up（冷启动/预热）：通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。</li></ul><h3 id="各算法适用场景"><a href="#各算法适用场景" class="headerlink" title="各算法适用场景"></a>各算法适用场景</h3><ul><li>计数法用于简单粗暴的连接池数量等。</li><li>令牌桶可以用来保护自己，主要用来对调用者频率进行限流，为的是让自己不被打垮。所以如果自己本身有处理能力的时候，如果流量突发（实际消费能力强于配置的流量限制），那么实际处理速率可以超过配置的限制。</li><li>漏桶算法，这是用来保护他人，也就是保护他所调用的系统。主要场景是，当调用的第三方系统本身没有保护机制，或者有流量限制的时候，我们的调用速度不能超过他的限制，由于我们不能更改第三方系统，所以只有在主调方控制。这个时候，即使流量突发，也必须舍弃。因为消费能力是第三方决定的。</li></ul><p>** 简单粗暴场景用计数法。如果要让自己的系统不被打垮，用令牌桶。如果保证别人的系统不被打垮，用漏桶。**</p><h2 id="流量控制组件对比"><a href="#流量控制组件对比" class="headerlink" title="流量控制组件对比"></a>流量控制组件对比</h2><p><img src="/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/stickPicture.png"></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.cnblogs.com/xuwc/p/9123078.html">高并发系统限流-漏桶算法和令牌桶算法</a></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 限流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>状态机系列之SpringStatusMachine详解</title>
      <link href="/2020/07/15/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/"/>
      <url>/2020/07/15/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是状态机"><a href="#什么是状态机" class="headerlink" title="什么是状态机"></a>什么是状态机</h2><p>有限状态机是一种用来进行对象行为建模的工具，其作用主要是描述对象在它的生命周期内所经历的状态序列，以及如何响应来自外界的各种事件。</p><p>在电商场景（订单、物流、售后）、社交（IM消息投递）、分布式集群管理（分布式计算平台任务编排）等场景都有大规模的使用。</p><h3 id="状态机的要素"><a href="#状态机的要素" class="headerlink" title="状态机的要素"></a>状态机的要素</h3><ul><li><strong>现态</strong>：指当前所处的状态</li><li><strong>条件</strong>：又称“事件”，当一个条件被满足，将会触发一个动作，或者执行一次状态的迁移</li><li><strong>动作</strong>：条件满足后执行的动作。动作执行完毕后，可以迁移到新的状态，也可以仍旧保持原状态。动作不是必须的，当条件满足后，也可以不执行任何动作，直接迁移到新的状态。<ul><li>进入动作：在进入状态时进行</li><li>退出动作：在退出状态时进行</li><li>输入动作：依赖于当前状态和输入条件进行</li><li>转移动作：在进行特定转移时进行</li></ul></li><li><strong>次态</strong>：条件满足后要迁往的新状态。“次态”是相对于“现态”而言的，“次态”一旦被激活，就转换成“现态”。</li></ul><h3 id="什么时候需要用到状态机"><a href="#什么时候需要用到状态机" class="headerlink" title="什么时候需要用到状态机"></a>什么时候需要用到状态机</h3><p>Spring文档指出，在以下情况下，项目很适合使用状态机：</p><ul><li>您可以将应用程序或其结构的一部分表示为状态。</li><li>您想将复杂的逻辑拆分为更小的可管理任务。</li><li>应用程序已经遇到了（例如）异步发生的并发问题。</li></ul><p>如果满足以下条件，您已经在尝试实现状态机 ：  </p><ul><li>使用布尔标志或枚举对情况进行建模。</li><li>具有仅对应用程序生命周期的一部分有意义的变量。</li><li>遍历if / else结构并检查是否设置了特定的标志或枚举，然后进一步对当标志和枚举的某些组合存在或不存在时的处理方式作进一步的例外。</li></ul><h4 id="使用状态机的优缺点"><a href="#使用状态机的优缺点" class="headerlink" title="使用状态机的优缺点"></a>使用状态机的优缺点</h4><p><strong>优点</strong></p><ul><li>状态及转换与业务解耦；</li><li>代码的可维护性增强；</li><li>对于流程复杂易变的业务场景能大减轻维护和测试的难度。</li></ul><p><strong>缺点</strong></p><ul><li>事务不好控制；</li><li>增加更多的类。<h3 id="状态机对比"><a href="#状态机对比" class="headerlink" title="状态机对比"></a>状态机对比</h3></li></ul><table><thead><tr><th>状态机</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>stateless4j</td><td>轻量级<br>支持基本事件迁移<br>二次开发难度低</td><td>不支持持久化和上下文传参</td></tr><tr><td>squirrel-foundation</td><td>功能齐全<br>StatueMachine精简版</td><td>—</td></tr><tr><td>Spring StatusMachine</td><td>功能齐全<br>&ensp; 状态：初始终止、历史状态、连接交并；<br>&ensp; 延迟事件;<br>&ensp; Guard;<br>&ensp; 持久化;<br>&ensp; JPA<br>使用方便<br>&ensp; 配置+注解，文档齐全</td><td>学习成本较高<br>状态机已捕获异常，需要手动编码处理异常，单个状态机可以被共享，需要builder多个实例<br>同时使用多个状态机事务需要手工控制</td></tr></tbody></table><h3 id="Spring-StatusMachine使用案例"><a href="#Spring-StatusMachine使用案例" class="headerlink" title="Spring StatusMachine使用案例"></a>Spring StatusMachine使用案例</h3><p>假设在一个业务系统中，有这样一个对象，它有三个状态：草稿、待发布、发布完成，针对这三个状态的业务动作也比较简单，分别是：上线、发布、回滚。该业务状态机如下图所示。<br><img src="/2020/07/15/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/img.png"></p><p>创建一个基础的Spring Boot工程，在主pom文件中加入Spring StateMachine的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--加入spring statemachine的依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.statemachine<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-statemachine-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.3.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>定义状态枚举和事件枚举，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 状态枚举</span></span><br><span class="line"><span class="comment">**/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">States</span> </span>&#123;</span><br><span class="line">    DRAFT,</span><br><span class="line">    PUBLISH_TODO,</span><br><span class="line">    PUBLISH_DONE,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 事件枚举</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Events</span> </span>&#123;</span><br><span class="line">  ONLINE,</span><br><span class="line">  PUBLISH,</span><br><span class="line">  ROLLBACK</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成状态机的配置，包括：（1）状态机的初始状态和所有状态；（2）状态之间的转移规则</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="comment">// @EnableStateMachine批注时，它将在应用程序启动时自动创建默认状态机。</span></span><br><span class="line"><span class="meta">@EnableStateMachine</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StateMachineConfig</span> <span class="keyword">extends</span> <span class="title">EnumStateMachineConfigurerAdapter</span>&lt;<span class="title">States</span>, <span class="title">Events</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(StateMachineStateConfigurer&lt;States, Events&gt; states)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        states.withStates().initial(States.DRAFT).states(EnumSet.allOf(States.class));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(StateMachineTransitionConfigurer&lt;States, Events&gt; transitions)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        transitions.withExternal()</span><br><span class="line">            .source(States.DRAFT).target(States.PUBLISH_TODO)</span><br><span class="line">            .event(Events.ONLINE)</span><br><span class="line">            .and()</span><br><span class="line">            .withExternal()</span><br><span class="line">            .source(States.PUBLISH_TODO).target(States.PUBLISH_DONE)</span><br><span class="line">            .event(Events.PUBLISH)</span><br><span class="line">            .and()</span><br><span class="line">            .withExternal()</span><br><span class="line">            .source(States.PUBLISH_DONE).target(States.DRAFT)</span><br><span class="line">            .event(Events.ROLLBACK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个测试业务对象，状态机的状态转移都会反映到该业务对象的状态变更上</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WithStateMachine</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BizBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@see</span> States</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String status = States.DRAFT.name();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;PUBLISH_TODO&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">online</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作上线，待发布. target status:&#123;&#125;&quot;</span>, States.PUBLISH_TODO.name());</span><br><span class="line">        setStatus(States.PUBLISH_TODO.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;PUBLISH_DONE&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">publish</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作发布,发布完成. target status:&#123;&#125;&quot;</span>, States.PUBLISH_DONE.name());</span><br><span class="line">        setStatus(States.PUBLISH_DONE.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;DRAFT&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rollback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作回滚,回到草稿状态. target status:&#123;&#125;&quot;</span>, States.DRAFT.name());</span><br><span class="line">        setStatus(States.DRAFT.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编写测试用例，这里我们使用CommandLineRunner接口代替，定义了一个StartupRunner，在该类的run方法中启动状态机、发送不同的事件，通过日志验证状态机的流转过程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StartupRunner</span> <span class="keyword">implements</span> <span class="title">CommandLineRunner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    StateMachine&lt;States, Events&gt; stateMachine;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(String... args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        stateMachine.start();</span><br><span class="line">        stateMachine.sendEvent(Events.ONLINE);</span><br><span class="line">        stateMachine.sendEvent(Events.PUBLISH);</span><br><span class="line">        stateMachine.sendEvent(Events.ROLLBACK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>使用步骤总结：</strong></p><ul><li>定义状态枚举和事件枚举</li><li>定义状态机的初始状态和所有状态</li><li>定义状态之间的转移规则</li><li>在业务对象中使用状态机，编写响应状态变化的监听器方法</li></ul><p>使用Spring StateMachine的好处在于自己无需关心状态机的实现细节，只需要关心业务有什么状态、它们之间的转移规则是什么、每个状态转移后真正要进行的业务操作。</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>Spring State Machine可以做的事情还很多。 </p><ul><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#statemachine-config-states">状态可以嵌套</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-security">可以配置为检查是否允许过渡的防护措施</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-extendedstate">允许定义选择状态，接合状态等的伪状态</a> </li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-triggers">事件可以由操作或在计时器上触发</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-persist">状态机可以持久化以提高性能</a> </li></ul><p>要浏览所有内容，您需要研究 <a href="https://docs.spring.io/spring-statemachine/docs/current/reference/">Spring StateMachine文档</a> 并确定适合您的特定情况的文档。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 状态机 </tag>
            
            <tag> Spring生态 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码规范之BigDecimal的equals方法等值比较引坑</title>
      <link href="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/"/>
      <url>/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/</url>
      
        <content type="html"><![CDATA[<p>BigDecimal，相信对于很多人来说都不陌生，很多人都知道他的用法，这是一种java.math包中提供的一种可以用来进行精确运算的类型。</p><p>很多人都知道，在进行金额表示、金额计算等场景，不能使用double、float等类型，而是要使用对精度支持的更好的BigDecimal。</p><p>所以，很多支付、电商、金融等业务中，BigDecimal的使用非常频繁。而且不得不说这是一个非常好用的类，其内部自带了很多方法，如加，减，乘，除等运算方法都是可以直接调用的。</p><p>除了需要用BigDecimal表示数字和进行数字运算以外，代码中还经常需要对于数字进行相等判断。</p><p>关于BigDecimal等值判断的这个知识点，在最新版的《阿里巴巴Java开发手册》中也有说明：<br><img src="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_1.png"></p><p>那么，为什么会有这样的要求呢？背后的思考是什么呢？</p><p>其实，我在之前的CodeReview中，看到过以下这样的低级错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(bigDecimal == bigDecimal1)&#123;</span><br><span class="line">    // 两个数相等</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种错误，相信聪明的读者一眼就可以看出问题，因为BigDecimal是对象，所以不能用==来判断两个数字的值是否相等。</p><p>以上这种问题，在有一定的经验之后，还是可以避免的，但是聪明的读者，看一下以下这行代码，你觉得他有问题吗：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(bigDecimal.equals(bigDecimal1))&#123;</span><br><span class="line">    // 两个数相等</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以明确的告诉大家，以上这种写法，可能得到的结果和你预想的不一样！</p><p>先来做个实验，运行以下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal bigDecimal = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal1 = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal.equals(bigDecimal1));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal2 = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal3 = new BigDecimal(1.0);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal2.equals(bigDecimal3));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal4 = new BigDecimal(&quot;1&quot;);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal5 = new BigDecimal(&quot;1.0&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal4.equals(bigDecimal5));</span><br></pre></td></tr></table></figure><p>以上代码，输出结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">true</span><br><span class="line"></span><br><span class="line">true</span><br><span class="line"></span><br><span class="line">false</span><br></pre></td></tr></table></figure><h3 id="BigDecimal的equals原理"><a href="#BigDecimal的equals原理" class="headerlink" title="BigDecimal的equals原理"></a>BigDecimal的equals原理</h3><p>通过以上代码示例，我们发现，在使用BigDecimal的equals方法对1和1.0进行比较的时候，有的时候是true（当使用int、double定义BigDecimal时），有的时候是false（当使用String定义BigDecimal时）。</p><p>那么，为什么会出现这样的情况呢，我们先来看下BigDecimal的equals方法。</p><p>在BigDecimal的JavaDoc中其实已经解释了其中原因：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Compares this  BigDecimal with the specified Object for equality.  Unlike compareTo, this method considers two BigDecimal objects equal only if they are equal in value and scale (thus 2.0 is not equal to 2.00 when compared by  this method)</span><br></pre></td></tr></table></figure><p>大概意思就是，equals方法和compareTo并不一样，equals方法会比较两部分内容，分别是<strong>值(value)<strong>和</strong>标度(scale)</strong></p><p><img src="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_2.png"></p><p>到这里，我们大概解释清楚了，之所以equals比较bigDecimal4和bigDecimal5的结果是false，是因为标度不同。</p><p>那么，为什么标度不同呢？为什么bigDecimal2和bigDecimal3的标度是一样的（当使用int、double定义BigDecimal时），而bigDecimal4和bigDecimal5却不一样（当使用String定义BigDecimal时）呢？</p><h3 id="为什么标度不同"><a href="#为什么标度不同" class="headerlink" title="为什么标度不同"></a>为什么标度不同</h3><p>这个就涉及到BigDecimal的标度问题了，这个问题其实是比较复杂的，由于不是本文的重点，这里面就简单介绍一下吧。</p><p>首先，BigDecimal一共有以下4个构造方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal(int)</span><br><span class="line"></span><br><span class="line">BigDecimal(double) </span><br><span class="line"></span><br><span class="line">BigDecimal(long) </span><br><span class="line"></span><br><span class="line">BigDecimal(String)</span><br></pre></td></tr></table></figure><p>以上四个方法，创建出来的的BigDecimal的标度是不同的。</p><ul><li><p><strong>BigDecimal(long) 和BigDecimal(int)</strong><br>首先，最简单的就是BigDecimal(long) 和BigDecimal(int)，<strong>因为是整数，所以标度就是0</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public BigDecimal(int val) &#123;</span><br><span class="line">  this.intCompact = val;</span><br><span class="line">  this.scale = 0;</span><br><span class="line">  this.intVal = null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public BigDecimal(long val) &#123;</span><br><span class="line">  this.intCompact = val;</span><br><span class="line">  this.intVal = (val == INFLATED) ? INFLATED_BIGINT : null;</span><br><span class="line">  this.scale = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>BigDecimal(double)</strong><br>而对于BigDecimal(double), 当我们使用new BigDecimal(0.1)创建一个BigDecimal 的时候，其实创建出来的值并不是正好等于0.1的，而是0.1000000000000000055511151231257827021181583404541015625 。这是因为doule自身表示的只是一个近似值。</p><p>那么，无论我们使用new BigDecimal(0.1)还是new BigDecimal(0.10)定义，他的近似值都是0.1000000000000000055511151231257827021181583404541015625这个，那么他的标度就是这个数字的位数，即55。</p><p><img src="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_3.png"> </p><p>其他的浮点数也同样的道理。对于new BigDecimal(1.0)这样的形式来说，因为他本质上也是个整数，所以他创建出来的数字的标度就是0。</p><p>所以，因为BigDecimal(1.0)和BigDecimal(1.00)的标度是一样的，所以在使用equals方法比较的时候，得到的结果就是true。</p></li><li><p><strong>BigDecimal(string)</strong><br>而对于BigDecimal(double) ，当我们使用new BigDecimal(“0.1”)创建一个BigDecimal 的时候，其实创建出来的值正好就是等于0.1的。那么他的标度也就是1。</p><p>如果使用new BigDecimal(“0.10000”)，那么创建出来的数就是0.10000，标度也就是5。</p></li></ul><p>所以，因为BigDecimal(“1.0”)和BigDecimal(“1.00”)的标度不一样，所以在使用equals方法比较的时候，得到的结果就是false。</p><h3 id="如何比较BigDecimal"><a href="#如何比较BigDecimal" class="headerlink" title="如何比较BigDecimal"></a>如何比较BigDecimal</h3><p>前面，我们解释了BigDecimal的equals方法，其实不只是会比较数字的值，还会对其标度进行比较。</p><p>所以，当我们使用equals方法判断判断两个数是否相等的时候，是极其严格的。</p><p>那么，如果我们只想判断两个BigDecimal的值是否相等，那么该如何判断呢？</p><p><strong>BigDecimal中提供了compareTo方法，这个方法就可以只比较两个数字的值，如果两个数相等，则返回0。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal bigDecimal4 = new BigDecimal(&quot;1&quot;);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal5 = new BigDecimal(&quot;1.0000&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal4.compareTo(bigDecimal5));</span><br></pre></td></tr></table></figure><p>以上代码，输出结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0</span><br></pre></td></tr></table></figure><p>其源码如下：</p><p><img src="/2020/06/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_4.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>BigDecimal是一个非常好用的表示高精度数字的类，其中提供了很多丰富的方法。</p><p>但是，他的equals方法使用的时候需要谨慎，因为他在比较的时候，不仅比较两个数字的值，还会比较他们的标度，只要这两个因素有一个是不相等的，那么结果也是false</p><p>如果读者想要对两个BigDecimal的数值进行比较的话，可以使用compareTo方法。</p>]]></content>
      
      
      <categories>
          
          <category> 代码规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代码规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统04之分布式锁</title>
      <link href="/2020/06/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>/2020/06/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁"></a>什么是分布式锁</h2><ul><li>分布式模型下，数据只有一份，需要锁技术控制某一时刻修改数据的进程数。 </li><li>不仅需要保证进程可见，还需要考虑进程与锁的网络问题 </li><li>可以将标记存在内存，但是内存不是进程分配而是公共内存（redis、zk）,保证标记互斥。</li></ul><h2 id="Java分布式锁需求"><a href="#Java分布式锁需求" class="headerlink" title="Java分布式锁需求"></a>Java分布式锁需求</h2><ul><li>同一个方法在同一时间只能被一台机器上一个线程执行。</li><li>可重入（避免死锁）</li><li>阻塞锁（业务需求） </li><li>公平锁（业务需求） </li><li>高可用、高性能获取/释放锁</li></ul><h2 id="Java分布式锁解决方案"><a href="#Java分布式锁解决方案" class="headerlink" title="Java分布式锁解决方案"></a>Java分布式锁解决方案</h2><h3 id="基于数据库"><a href="#基于数据库" class="headerlink" title="基于数据库"></a>基于数据库</h3><p>基于表主键唯一做分布式锁</p><h3 id="基于redis"><a href="#基于redis" class="headerlink" title="基于redis"></a>基于redis</h3><h4 id="基于-redis-的-SETNX-、EXPIRE-方法做分布式锁"><a href="#基于-redis-的-SETNX-、EXPIRE-方法做分布式锁" class="headerlink" title="基于 redis 的 SETNX()、EXPIRE() 方法做分布式锁"></a>基于 redis 的 SETNX()、EXPIRE() 方法做分布式锁</h4><p>使用步骤：</p><ul><li>setnx(lockkey, 1) 返回1，占位成功</li><li>expire()对lockkey设置超时时间，避免死锁</li><li>执行完业务后，delete命令删除key</li></ul><p>在 expire() 命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题。</p><h4 id="基于-redis-的-setnx-、get-和-getset-方法来实现分布式锁。"><a href="#基于-redis-的-setnx-、get-和-getset-方法来实现分布式锁。" class="headerlink" title="基于 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。"></a>基于 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。</h4><p>使用步骤</p><ul><li>setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。</li><li>get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。</li><li>计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。</li><li>判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</li><li>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</li></ul><h4 id="分布式锁Redlock"><a href="#分布式锁Redlock" class="headerlink" title="分布式锁Redlock"></a>分布式锁Redlock</h4><p>解决问题：<br>解决redis分布式锁的单点故障问题</p><p>使用步骤：</p><ul><li>获取当前时间（毫秒数）。</li><li>按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败，比如该Redis节点不可用，或者该Redis节点上的锁已经被其它客户端持有（注：Redlock原文中这里只提到了Redis节点不可用的情况，但也应该包含其它的失败情况）。</li><li>计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。</li><li>如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。</li><li>如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的Redis Lua脚本）。</li></ul><h4 id="基于-REDISSON-做分布式锁"><a href="#基于-REDISSON-做分布式锁" class="headerlink" title="基于 REDISSON 做分布式锁"></a>基于 REDISSON 做分布式锁</h4><p>redis 官方的分布式锁组件，解决超时时间设置不合理问题。每获得一个锁时，只设置一个很短的超时时间，同时起一个线程在每次快要到超时时间时去刷新锁的超时时间。在释放锁的同时结束这个线程。</p><h3 id="zookeeper实现分布式锁"><a href="#zookeeper实现分布式锁" class="headerlink" title="zookeeper实现分布式锁"></a>zookeeper实现分布式锁</h3><p>其实基于ZooKeeper，就是使用它的临时有序节点来实现的分布式锁。</p><p><img src="/2020/06/19/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/img_1.png"><br>当某客户端要进行逻辑的加锁时，就在zookeeper上的某个指定节点的目录下，去生成一个唯一的临时有序节点， 然后判断自己是否是这些有序节点中序号最小的一个。</p><ul><li>如果是，则算是获取了锁。</li><li>如果不是，则说明没有获取到锁，那么就需要在序列中找到比自己小的那个节点，并对其调用exist()方法，对其注册事件监听，当监听到这个节点被删除了，那就再去判断一次自己当初创建的节点是否变成了序列中最小的。<ul><li>如果是，则获取锁，如果不是，则重复上述步骤。</li></ul></li></ul><p>当释放锁的时候，只需将这个临时节点删除即可。</p><h2 id="redis分布式锁和zookeeper分布式锁的区别"><a href="#redis分布式锁和zookeeper分布式锁的区别" class="headerlink" title="redis分布式锁和zookeeper分布式锁的区别"></a>redis分布式锁和zookeeper分布式锁的区别</h2><h3 id="优缺点对比"><a href="#优缺点对比" class="headerlink" title="优缺点对比"></a>优缺点对比</h3><p>对于redis的分布式锁而言：</p><ul><li><p>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</p></li><li><p>redis的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮</p><ul><li>即便使用redlock算法来实现，在某些复杂场景下，也无法保证其实现100%没有问题，关于redlock的讨论可以看How to do distributed locking</li></ul></li></ul><p>但是另一方面使用redis实现分布式锁在很多企业中非常常见，而且大部分情况下都不会遇到所谓的“极端复杂场景”</p><p>所以使用redis作为分布式锁也不失为一种好的方案，最重要的一点是redis的性能很高，可以支撑高并发的获取、释放锁操作。</p><p>对于zk分布式锁而言:</p><ul><li><p>zookeeper天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</p></li><li><p>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</p></li></ul><p>但是zk也有其缺点：如果有较多的客户端频繁的申请加锁、释放锁，对于zk集群的压力会比较大。</p><h3 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h3><p>就个人而言的话，我<strong>比较推崇zk实现的锁</strong>：</p><p>因为redis是有可能存在隐患的，可能会导致数据不对的情况。但是，怎么选用要看具体在公司的场景了。</p><p>如果公司里面有zk集群条件，优先选用zk实现，但是如果说公司里面只有redis集群，没有条件搭建zk集群。</p><p>那么其实用redis来实现也可以，另外还可能是系统设计者考虑到了系统已经有redis，但是又不希望再次引入一些外部依赖的情况下，可以选用redis。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 锁 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于JVMTI技术的Jar包字节码加密技术初探</title>
      <link href="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%9F%BA%E4%BA%8EJVMTI%E6%8A%80%E6%9C%AF%E7%9A%84Jar%E5%8C%85%E5%AD%97%E8%8A%82%E7%A0%81%E5%8A%A0%E5%AF%86%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/"/>
      <url>/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%9F%BA%E4%BA%8EJVMTI%E6%8A%80%E6%9C%AF%E7%9A%84Jar%E5%8C%85%E5%AD%97%E8%8A%82%E7%A0%81%E5%8A%A0%E5%AF%86%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="JVMTI的定义及原理"><a href="#JVMTI的定义及原理" class="headerlink" title="JVMTI的定义及原理"></a>JVMTI的定义及原理</h2><p>在介绍JVMTI之前，需要先了解下Java平台调试体系JPDA（Java PlatformDebugger Architecture）。它是Java虚拟机为调试和监控虚拟机专门提供的一套接口。</p><p>如下图所示，JPDA被抽象为三层实现。其中JVMTI就是JVM对外暴露的接口。 JDI是实现了JDWP通信协议的客户端，调试器通过它和JVM中被调试程序通信。</p><p>JVMTI 本质上是在JVM内部的许多事件进行了埋点。通过这些埋点可以给外部提供当前上下文的一些信息。甚至可以接受外部的命令来改变下一步的动作。外部程序一般利用C/C++实现一个JVMTIAgent，在Agent里面注册一些JVM事件的回调。当事件发生时JVMTI调用这些回调方法。Agent可以在回调方法里面实现自己的逻辑。</p><p>JVMTIAgent是以动态链接库的形式被虚拟机加载的。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%9F%BA%E4%BA%8EJVMTI%E6%8A%80%E6%9C%AF%E7%9A%84Jar%E5%8C%85%E5%AD%97%E8%8A%82%E7%A0%81%E5%8A%A0%E5%AF%86%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/img.png"></p><h2 id="JVMTI的历史"><a href="#JVMTI的历史" class="headerlink" title="JVMTI的历史"></a>JVMTI的历史</h2><p>JVMTI 的前身是JVMDI（Java Virtual Machine Debug Interface）和 JVMPI（Java Virtual Machine Profiler Interface），它们原来分别被用于提供调试 Java 程序以及 Java 程序调节性能的功能。</p><p>在 J2SE 5.0 之后 JDK 取代了JVMDI 和 JVMPI 这两套接口，JVMDI 在最新的 Java SE 6 中已经不提供支持，而 JVMPI 也计划在 Java SE 7 后被彻底取代。</p><h2 id="JVMTI的功能"><a href="#JVMTI的功能" class="headerlink" title="JVMTI的功能"></a>JVMTI的功能</h2><p>JVMTI处于整个JPDA 体系的最底层，所有调试功能本质上都需要通过 JVMTI 来提供。</p><p>从大的方面来说，JVMTI 提供了可用于 debug 和profiler 的接口；同时，在 Java 5/6 中，虚拟机接口也增加了监听（Monitoring），线程分析（Thread analysis）以及覆盖率分析（Coverage Analysis）等功能。</p><p>从小的方面来说包含了虚拟机中线程、内存、堆、栈、类、方法、变量，事件、定时器处理等等诸多功能。 具体可以参考<a href="https://docs.oracle.com/javase/1.5.0/docs/guide/jvmti/jvmti.html">oracle的文档</a></p><p>通过这些接口，开发人员不仅可以调试在该虚拟机上运行的 Java 程序，还能查看它们运行的状态，设置回调函数，控制某些环境变量，从而优化程序性能。</p><h2 id="基于JVMTI的项目加解密实现"><a href="#基于JVMTI的项目加解密实现" class="headerlink" title="基于JVMTI的项目加解密实现"></a>基于JVMTI的项目加解密实现</h2><p><strong>参考DEMO中jvmti-encrypt模块项目实现</strong></p><h2 id="Agent加载与回调函数的执行分析"><a href="#Agent加载与回调函数的执行分析" class="headerlink" title="Agent加载与回调函数的执行分析"></a>Agent加载与回调函数的执行分析</h2><h3 id="Agent启动"><a href="#Agent启动" class="headerlink" title="Agent启动"></a>Agent启动</h3><p>Agent 是在 Java 虚拟机启动之时加载的，这个加载处于虚拟机初始化的早期。</p><p>在这个时间点上：</p><ul><li>所有的 Java 类都未被初始化；</li><li>所有的对象实例都未被创建；</li><li>因而，没有任何 Java 代码被执行；</li></ul><p>但在这个时候，我们已经可以：</p><ul><li>操作 JVMTI 的 Capability 参数；</li><li>使用系统参数</li></ul><p>动态库被加载之后，虚拟机会先寻找一个 Agent 入口函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JNIEXPORT jint JNICALL Agent_OnLoad(JavaVM *vm, char *options, void *reserved)</span><br></pre></td></tr></table></figure><p>在这个函数中，虚拟机传入了一个 JavaVM 指针，以及命令行的参数。</p><p>通过 JavaVM，我们可以获得 JVMTI 的指针，并获得 JVMTI 函数的使用能力，所有的 JVMTI 函数都通过这个 jvmtiEnv 获取，不同的虚拟机实现提供的函数细节可能不一样，但是使用的方式是统一的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jint ret = vm-&gt;GetEnv((void **)&amp;jvmti, JVMTI_VERSION);</span><br></pre></td></tr></table></figure><p>这里传入的版本信息参数很重要，不同的 JVMTI 环境所提供的功能以及处理方式都可能有所不同，不过它在同一个虚拟机中会保持不变。</p><p>命令行参数事实上就是上面启动命令行中的 options 部分，在 Agent 实现中需要进行解析并完成后续处理工作。参数传入的字符串仅仅在 Agent_OnLoad 函数里有效。</p><p>需要强调的是，这个时候由于虚拟机并未完成初始化工作，并不是所有的 JVMTI 函数都可以被使用。</p><p>Agent 还可以在运行时加载。具体说来，虚拟机会在运行时监听并接受 Agent 的加载，在这个时候，它会使用 Agent 的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JNIEXPORT jint JNICALL Agent_OnAttach(JavaVM* vm, char *options, void *reserved);</span><br></pre></td></tr></table></figure><p>同样的在这个初始化阶段，不是所有的 JVMTI 的 Capability 参数都处于可操作状态，而且 options 这个 char 数组在这个函数运行之后就会被丢弃，如果需要，需要做好保留工作。</p><p>Agent 的主要功能是通过一系列的在虚拟机上设置的回调（callback）函数完成的，一旦某些事件发生，Agent 所设置的回调函数就会被调用，来完成特定的需求。</p><h3 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h3><p>最后，Agent 完成任务，或者虚拟机关闭的时候，虚拟机都会调用一个类似于类析构函数的方法来完成最后的清理任务，注意这个函数和虚拟机自己的 VM_DEATH 事件是不同的。</p><h3 id="执行逻辑分析"><a href="#执行逻辑分析" class="headerlink" title="执行逻辑分析"></a>执行逻辑分析</h3><p><a href="https://www.jianshu.com/p/8775c1542b52">参考文档</a></p>]]></content>
      
      
      <categories>
          
          <category> 实用工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVMTI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA线上故障排查全套路</title>
      <link href="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/"/>
      <url>/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<p>线上故障主要会包括cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。</p><p>同时例如jstack、jmap等工具也是不囿于一个方面的问题的，基本上出问题就是df、free、top 三连，然后依次jstack、jmap伺候，具体问题具体分析即可。</p><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><p>一般来讲我们首先会排查cpu方面的问题。cpu异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁gc以及上下文切换过多。而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用jstack来分析对应的堆栈情况。</p><h3 id="使用jstack分析cpu问题"><a href="#使用jstack分析cpu问题" class="headerlink" title="使用jstack分析cpu问题"></a>使用jstack分析cpu问题</h3><p>我们先用ps命令找到对应进程的pid(如果你有好几个目标进程，可以先用top看一下哪个占用比较高)。<br>接着用top -H -p pid来找到cpu使用率比较高的一些线程<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img.png"><br>然后将占用最高的pid转换为16进制printf ‘%x\n’ pid得到nid<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_1.png"><br>接着直接在jstack中找到相应的堆栈信息jstack pid |grep ‘nid’ -C5 –color<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_2.png"><br>可以看到我们已经找到了nid为0x42的堆栈信息，接着只要仔细分析一番即可。</p><p>当然更常见的是我们对整个jstack文件进行分析，通常我们会比较关注WAITING和TIMED_WAITING的部分，BLOCKED就不用说了。我们可以使用命令cat jstack.log | grep “java.lang.Thread.State” | sort -nr | uniq -c来对jstack的状态有一个整体的把握，如果WAITING之类的特别多，那么多半是有问题啦。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_3.png"></p><h3 id="频繁gc"><a href="#频繁gc" class="headerlink" title="频繁gc"></a>频繁gc</h3><p>当然我们还是会使用jstack来分析问题，但有时候我们可以先确定下gc是不是太频繁，使用<strong>jstat -gc pid 1000</strong>命令来对gc分代变化情况进行观察，</p><ul><li>1000表示采样间隔(ms)</li><li>S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU分别代表两个Survivor区、Eden区、老年代、元数据区的容量和使用量。</li><li>YGC/YGT、FGC/FGCT、GCT则代表YoungGc、FullGc的耗时和次数以及总耗时。</li></ul><p>如果看到gc比较频繁，再针对gc方面做进一步分析，具体可以参考一下gc章节的描述。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_4.png"></p><h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>针对频繁上下文问题，我们可以使用vmstat命令来进行查看<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_5.png"><br>cs(context switch)一列则代表了上下文切换的次数。<br>如果我们希望对特定的pid进行监控那么可以使用 pidstat -w pid命令，cswch和nvcswch表示自愿及非自愿切换。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_6.png"></p><h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><p>磁盘问题和cpu一样是属于比较基础的。首先是磁盘空间方面，我们直接使用<strong>df -hl</strong>来查看文件系统状态<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_7.png"><br>更多时候，磁盘问题还是性能上的问题。我们可以通过iostatiostat -d -k -x来进行分析<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_8.png"><br>最后一列%util可以看到每块磁盘写入的程度，而rrqpm/s以及wrqm/s分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。</p><p>另外我们还需要知道是哪个进程在进行读写，一般来说开发自己心里有数，或者用iotop命令来进行定位文件读写的来源。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_9.png"><br>不过这边拿到的是tid，我们要转换成pid，可以通过readlink来找到pidreadlink -f /proc/*/task/tid/../..。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_10.png"><br>找到pid之后就可以看这个进程具体的读写情况cat /proc/pid/io<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_11.png"><br>我们还可以通过lsof命令来确定具体的文件读写情况lsof -p pid<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_12.png"></p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><p>内存问题排查起来相对比CPU麻烦一些，场景也比较多。主要包括OOM、GC问题和堆外内存。一般来讲，我们会先用free命令先来检查一发内存的各种情况。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_13.png"></p><h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>内存问题大多还都是堆内内存问题。表象上主要分为OOM和StackOverflow。</p><h4 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h4><p><strong>Exception in thread “main” java.lang.OutOfMemoryError: unable to create new native thread</strong></p><p>这个意思是没有足够的内存空间给线程分配java栈，基本上还是线程池代码写的有问题，比如说忘记shutdown，所以说应该首先从代码层面来寻找问题，使用jstack或者jmap。如果一切都正常，JVM方面可以通过指定Xss来减少单个thread stack的大小。另外也可以在系统层面，可以通过修改/etc/security/limits.confnofile和nproc来增大os对线程的限制<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_14.png"></p><p><strong>Exception in thread “main” java.lang.OutOfMemoryError: Java heap space</strong></p><p>这个意思是堆的内存占用已经达到-Xmx设置的最大值，应该是最常见的OOM错误了。解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过jstack和jmap去定位问题。如果说一切都正常，才需要通过调整Xmx的值来扩大内存。</p><p><strong>Caused by: java.lang.OutOfMemoryError: Meta space</strong></p><p>这个意思是元数据区的内存占用已经达到XX:MaxMetaspaceSize设置的最大值，排查思路和上面的一致，参数方面可以通过XX:MaxPermSize来进行调整(这里就不说1.8以前的永久代了)。</p><h4 id="Stack-Overflow"><a href="#Stack-Overflow" class="headerlink" title="Stack Overflow"></a>Stack Overflow</h4><p>栈内存溢出，这个大家见到也比较多。</p><p><strong>Exception in thread “main” java.lang.StackOverflowError</strong></p><p>表示线程栈需要的内存大于Xss值，同样也是先进行排查，参数方面通过Xss来调整，但调整的太大可能又会引起OOM。</p><h4 id="使用JMAP定位代码内存泄漏"><a href="#使用JMAP定位代码内存泄漏" class="headerlink" title="使用JMAP定位代码内存泄漏"></a>使用JMAP定位代码内存泄漏</h4><p>上述关于OOM和StackOverflow的代码排查方面，我们一般使用JMAPjmap -dump:format=b,file=filename pid来导出dump文件<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_15.png"></p><p>通过mat(Eclipse Memory Analysis Tools)导入dump文件进行分析，内存泄漏问题一般我们直接选Leak Suspects即可，mat给出了内存泄漏的建议。另外也可以选择Top Consumers来查看最大对象报告。和线程相关的问题可以选择thread overview进行分析。除此之外就是选择Histogram类概览来自己慢慢分析，大家可以搜搜mat的相关教程。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_16.png"></p><p>日常开发中，代码产生内存泄漏是比较常见的事，并且比较隐蔽，需要开发者更加关注细节。比如说每次请求都new对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发gc；ByteBuffer缓存分配不合理等都会造成代码OOM。</p><p>另一方面，我们可以在启动参数中指定-XX:+HeapDumpOnOutOfMemoryError来保存OOM时的dump文件。</p><h4 id="gc问题和线程"><a href="#gc问题和线程" class="headerlink" title="gc问题和线程"></a>gc问题和线程</h4><p>gc问题除了影响cpu也会影响内存，排查思路也是一致的。一般先使用jstat来查看分代变化情况，比如youngGC或者fullGC次数是不是太多呀；EU、OU等指标增长是不是异常呀等。</p><p>线程的话太多而且不被及时gc也会引发oom，大部分就是之前说的unable to create new native thread。除了jstack细细分析dump文件外，我们一般先会看下总体线程，通过pstreee -p pid |wc -l。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_17.png"></p><p>或者直接通过查看/proc/pid/task的数量即为线程数量。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_18.png"></p><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>如果碰到堆外内存溢出，那可真是太不幸了。首先堆外内存溢出表现就是物理常驻内存增长快，报错的话视使用方式都不确定，如果由于使用Netty导致的，那错误日志里可能会出现OutOfDirectMemoryError错误，如果直接是DirectByteBuffer，那会报OutOfMemoryError: Direct buffer memory。</p><p>堆外内存溢出往往是和NIO的使用相关，一般我们先通过pmap来查看下进程占用的内存情况pmap -x pid | sort -rn -k3 | head -30，这段意思是查看对应pid倒序前30大的内存段。这边可以再一段时间后再跑一次命令看看内存增长情况，或者和正常机器比较可疑的内存段在哪里。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_19.png"></p><p>我们如果确定有可疑的内存端，需要通过gdb来分析gdb –batch –pid {pid} -ex “dump memory filename.dump {内存起始地址} {内存起始地址+内存块大小}”</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_20.png"></p><p>获取dump文件后可用heaxdump进行查看hexdump -C filename | less，不过大多数看到的都是二进制乱码。</p><p>NMT是Java7U40引入的HotSpot新特性，配合jcmd命令我们就可以看到具体内存组成了。需要在启动参数中加入 -XX:NativeMemoryTracking=summary 或者 -XX:NativeMemoryTracking=detail，会有略微性能损耗。</p><p>一般对于堆外内存缓慢增长直到爆炸的情况来说，可以先设一个基线jcmd pid VM.native_memory baseline。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_21.png"></p><p>然后等放一段时间后再去看看内存增长的情况，通过jcmd pid VM.native_memory detail.diff(summary.diff)做一下summary或者detail级别的diff。</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_22.png"><br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_23.png"></p><p>可以看到jcmd分析出来的内存十分详细，包括堆内、线程以及gc(所以上述其他内存异常其实都可以用nmt来分析)，这边堆外内存我们重点关注Internal的内存增长，如果增长十分明显的话那就是有问题了。</p><p>detail级别的话还会有具体内存段的增长情况，如下图。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_24.png"></p><p>此外在系统层面，我们还可以使用strace命令来监控内存分配 strace -f -e “brk,mmap,munmap” -p pid</p><p>这边内存分配信息主要包括了pid和内存地址。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_25.png"><br>不过其实上面那些操作也很难定位到具体的问题点，关键还是要看错误日志栈，找到可疑的对象，搞清楚它的回收机制，然后去分析对应的对象。比如DirectByteBuffer分配内存的话，是需要full GC或者手动system.gc来进行回收的(所以最好不要使用-XX:+DisableExplicitGC)。那么其实我们可以跟踪一下DirectByteBuffer对象的内存情况，通过jmap -histo:live pid手动触发fullGC来看看堆外内存有没有被回收。如果被回收了，那么大概率是堆外内存本身分配的太小了，通过-XX:MaxDirectMemorySize进行调整。如果没有什么变化，那就要使用jmap去分析那些不能被gc的对象，以及和DirectByteBuffer之间的引用关系了。</p><h3 id="GC问题"><a href="#GC问题" class="headerlink" title="GC问题"></a>GC问题</h3><p>堆内内存泄漏总是和GC异常相伴。不过GC问题不只是和内存问题相关，还有可能引起CPU负载、网络问题等系列并发症，只是相对来说和内存联系紧密些，所以我们在此单独总结一下GC相关问题。</p><p>我们在cpu章介绍了使用jstat来获取当前GC分代变化信息。而更多时候，我们是通过GC日志来排查问题的，在启动参数中加上-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps来开启GC日志。</p><p>常见的Young GC、Full GC日志含义在此就不做赘述了。</p><p>针对gc日志，我们就能大致推断出youngGC与fullGC是否过于频繁或者耗时过长，从而对症下药。我们下面将对G1垃圾收集器来做分析，这边也建议大家使用G1-XX:+UseG1GC。</p><h4 id="youngGC过频繁"><a href="#youngGC过频繁" class="headerlink" title="youngGC过频繁"></a>youngGC过频繁</h4><p>youngGC频繁一般是短周期小对象较多，先考虑是不是Eden区/新生代设置的太小了，看能否通过调整-Xmn、-XX:SurvivorRatio等参数设置来解决问题。如果参数正常，但是young gc频率还是太高，就需要使用Jmap和MAT对dump文件进行进一步排查了</p><h4 id="youngGC耗时过长"><a href="#youngGC耗时过长" class="headerlink" title="youngGC耗时过长"></a>youngGC耗时过长</h4><p>耗时过长问题就要看GC日志里耗时耗在哪一块了。以G1日志为例，可以关注Root Scanning、Object Copy、Ref Proc等阶段。Ref Proc耗时长，就要注意引用相关的对象。Root Scanning耗时长，就要注意线程数、跨代引用。Object Copy则需要关注对象生存周期。而且耗时分析它需要横向比较，就是和其他项目或者正常时间段的耗时比较。比如说图中的Root Scanning和正常时间段比增长较多，那就是起的线程太多了。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_26.png"></p><h4 id="触发fullGC"><a href="#触发fullGC" class="headerlink" title="触发fullGC"></a>触发fullGC</h4><p>G1中更多的还是mixedGC，但mixedGC可以和youngGC思路一样去排查。触发fullGC了一般都会有问题，G1会退化使用Serial收集器来完成垃圾的清理工作，暂停时长达到秒级别，可以说是半跪了。</p><p>fullGC的原因可能包括以下这些，以及参数调整方面的一些思路：</p><ul><li><p>并发阶段失败：在并发标记阶段，MixGC之前老年代就被填满了，那么这时候G1就会放弃标记周期。这种情况，可能就需要增加堆大小，或者调整并发标记线程数-XX:ConcGCThreads。</p></li><li><p>晋升失败：在GC的时候没有足够的内存供存活/晋升对象使用，所以触发了Full GC。这时候可以通过-XX:G1ReservePercent来增加预留内存百分比，减少-XX:InitiatingHeapOccupancyPercent来提前启动标记，-XX:ConcGCThreads来增加标记线程数也是可以的。</p></li><li><p>大对象分配失败：大对象找不到合适的region空间进行分配，就会进行fullGC，这种情况下可以增大内存或者增大-XX:G1HeapRegionSize。</p></li><li><p>程序主动执行System.gc()：不要随便写就对了。</p></li></ul><p>另外，我们可以在启动参数中配置-XX:HeapDumpPath=/xxx/dump.hprof来dump fullGC相关的文件，并通过jinfo来进行gc前后的dump</p><p>jinfo -flag +HeapDumpBeforeFullGC pid</p><p>jinfo -flag +HeapDumpAfterFullGC pid</p><p>这样得到2份dump文件，对比后主要关注被gc掉的问题对象来定位问题。</p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>涉及到网络层面的问题一般都比较复杂，场景多，定位难，成为了大多数开发的噩梦，应该是最复杂的了。这里会举一些例子，并从tcp层、应用层以及工具的使用等方面进行阐述。</p><h3 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h3><p>超时错误大部分处在应用层面，所以这块着重理解概念。超时大体可以分为连接超时和读写超时，某些使用连接池的客户端框架还会存在获取连接超时和空闲连接清理超时。</p><ul><li><p>读写超时。readTimeout/writeTimeout，有些框架叫做so_timeout或者socketTimeout，均指的是数据读写超时。注意这边的超时大部分是指逻辑上的超时。soa的超时指的也是读超时。读写超时一般都只针对客户端设置。</p></li><li><p>连接超时。connectionTimeout，客户端通常指与服务端建立连接的最大时间。服务端这边connectionTimeout就有些五花八门了，jetty中表示空闲连接清理时间，tomcat则表示连接维持的最大时间。</p></li><li><p>其他。包括连接获取超时connectionAcquireTimeout和空闲连接清理超时idleConnectionTimeout。多用于使用连接池或队列的客户端或服务端框架。</p></li></ul><p>我们在设置各种超时时间中，需要确认的是尽量保持客户端的超时小于服务端的超时，以保证连接正常结束。</p><p>在实际开发中，我们关心最多的应该是接口的读写超时了。</p><p>如何设置合理的接口超时是一个问题。如果接口超时设置的过长，那么有可能会过多地占用服务端的tcp连接。而如果接口设置的过短，那么接口超时就会非常频繁。</p><p>服务端接口明明rt降低，但客户端仍然一直超时又是另一个问题。这个问题其实很简单，客户端到服务端的链路包括网络传输、排队以及服务处理等，每一个环节都可能是耗时的原因。</p><h3 id="TCP队列溢出"><a href="#TCP队列溢出" class="headerlink" title="TCP队列溢出"></a>TCP队列溢出</h3><p>tcp队列溢出是个相对底层的错误，它可能会造成超时、rst等更表层的错误。因此错误也更隐蔽，所以我们单独说一说。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_27.png"></p><p>如上图所示，这里有两个队列：syns queue(半连接队列）、accept queue（全连接队列）。三次握手，在server收到client的syn后，把消息放到syns queue，回复syn+ack给client，server收到client的ack，如果这时accept queue没满，那就从syns queue拿出暂存的信息放入accept queue中，否则按tcp_abort_on_overflow指示的执行。</p><p>tcp_abort_on_overflow 0表示如果三次握手第三步的时候accept queue满了那么server扔掉client发过来的ack。tcp_abort_on_overflow 1则表示第三步的时候如果全连接队列满了，server发送一个rst包给client，表示废掉这个握手过程和这个连接，意味着日志里可能会有很多connection reset / connection reset by peer。</p><p>那么在实际开发中，我们怎么能快速定位到tcp队列溢出呢？</p><p><strong>netstat命令，执行netstat -s | egrep “listen|LISTEN”</strong><br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_28.png"><br>如上图所示，overflowed表示全连接队列溢出的次数，sockets dropped表示半连接队列溢出的次数。</p><p><strong>ss命令，执行ss -lnt=</strong><br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_29.png"><br>上面看到Send-Q 表示第三列的listen端口上的全连接队列最大为5，第一列Recv-Q为全连接队列当前使用了多少。</p><p>接着我们看看怎么设置全连接、半连接队列大小吧：</p><p>全连接队列的大小取决于min(backlog, somaxconn)。backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数。而半连接队列的大小取决于max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog)。</p><p>在日常开发中，我们往往使用servlet容器作为服务端，所以我们有时候也需要关注容器的连接队列大小。在tomcat中backlog叫做acceptCount，在jetty里面则是acceptQueueSize。</p><h3 id="RST异常"><a href="#RST异常" class="headerlink" title="RST异常"></a>RST异常</h3><p>RST包表示连接重置，用于关闭一些无用的连接，通常表示异常关闭，区别于四次挥手。</p><p>在实际开发中，我们往往会看到connection reset / connection reset by peer错误，这种情况就是RST包导致的。</p><h3 id="端口不存在"><a href="#端口不存在" class="headerlink" title="端口不存在"></a>端口不存在</h3><p>如果像不存在的端口发出建立连接SYN请求，那么服务端发现自己并没有这个端口则会直接返回一个RST报文，用于中断连接。</p><h3 id="主动代替FIN终止连接"><a href="#主动代替FIN终止连接" class="headerlink" title="主动代替FIN终止连接"></a>主动代替FIN终止连接</h3><p>一般来说，正常的连接关闭都是需要通过FIN报文实现，然而我们也可以用RST报文来代替FIN，表示直接终止连接。实际开发中，可设置SO_LINGER数值来控制，这种往往是故意的，来跳过TIMED_WAIT，提供交互效率，不闲就慎用。</p><h3 id="客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接"><a href="#客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接" class="headerlink" title="客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接"></a>客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接</h3><p>我们上面讲的tcp队列溢出发送RST包其实也是属于这一种。这种往往是由于某些原因，一方无法再能正常处理请求连接了(比如程序崩了，队列满了)，从而告知另一方关闭连接。</p><p>接收到的TCP报文不在已知的TCP连接内</p><p>比如，一方机器由于网络实在太差TCP报文失踪了，另一方关闭了该连接，然后过了许久收到了之前失踪的TCP报文，但由于对应的TCP连接已不存在，那么会直接发一个RST包以便开启新的连接。</p><h3 id="一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文"><a href="#一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文" class="headerlink" title="一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文"></a>一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文</h3><p>这种大多也和网络环境相关了，网络环境差可能会导致更多的RST报文。</p><p>之前说过RST报文多会导致程序报错，在一个已关闭的连接上读操作会报connection reset，而在一个已关闭的连接上写操作则会报connection reset by peer。通常我们可能还会看到broken pipe错误，这是管道层面的错误，表示对已关闭的管道进行读写，往往是在收到RST，报出connection reset错后继续读写数据报的错，这个在glibc源码注释中也有介绍。</p><p>我们在排查故障时候怎么确定有RST包的存在呢？当然是使用tcpdump命令进行抓包，并使用wireshark进行简单分析了。tcpdump -i en0 tcp -w xxx.cap，en0表示监听的网卡。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_30.png"></p><p>接下来我们通过wireshark打开抓到的包，可能就能看到如下图所示，红色的就表示RST包了。<br><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_31.png"></p><h3 id="TIME-WAIT和CLOSE-WAIT"><a href="#TIME-WAIT和CLOSE-WAIT" class="headerlink" title="TIME_WAIT和CLOSE_WAIT"></a>TIME_WAIT和CLOSE_WAIT</h3><p>TIME_WAIT和CLOSE_WAIT是啥意思相信大家都知道。<br>在线上时，我们可以直接用命令netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’来查看time-wait和close_wait的数量</p><p>用ss命令会更快ss -ant | awk ‘{++S[$1]} END {for(a in S) print a, S[a]}’</p><p><img src="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_32.png"></p><h3 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT"></a>TIME_WAIT</h3><p>time_wait的存在一是为了丢失的数据包被后面连接复用，二是为了在2MSL的时间范围内正常关闭连接。它的存在其实会大大减少RST包的出现。</p><p>过多的time_wait在短连接频繁的场景比较容易出现。这种情况可以在服务端做一些内核参数调优:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br></pre></td></tr></table></figure><p>当然我们不要忘记在NAT环境下因为时间戳错乱导致数据包被拒绝的坑了，另外的办法就是改小tcp_max_tw_buckets，超过这个数的time_wait都会被干掉，不过这也会导致报time wait bucket table overflow的错。</p><h3 id="CLOSE-WAIT"><a href="#CLOSE-WAIT" class="headerlink" title="CLOSE_WAIT"></a>CLOSE_WAIT</h3><p>close_wait往往都是因为应用程序写的有问题，没有在ACK后再次发起FIN报文。close_wait出现的概率甚至比time_wait要更高，后果也更严重。往往是由于某个地方阻塞住了，没有正常关闭连接，从而渐渐地消耗完所有的线程。</p><p>想要定位这类问题，最好是通过jstack来分析线程堆栈来排查问题，具体可参考上述章节。这里仅举一个例子。</p><p>开发同学说应用上线后CLOSE_WAIT就一直增多，直到挂掉为止，jstack后找到比较可疑的堆栈是大部分线程都卡在了countdownlatch.await方法，找开发同学了解后得知使用了多线程但是确没有catch异常，修改后发现异常仅仅是最简单的升级sdk后常出现的class not found。</p>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线上问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统03之分布式事务</title>
      <link href="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
      <url>/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式事务"><a href="#什么是分布式事务" class="headerlink" title="什么是分布式事务"></a>什么是分布式事务</h2><p>分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。</p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。</p><h2 id="分布式系统一致性基础算法"><a href="#分布式系统一致性基础算法" class="headerlink" title="分布式系统一致性基础算法"></a>分布式系统一致性基础算法</h2><h3 id="Paxos算法"><a href="#Paxos算法" class="headerlink" title="Paxos算法"></a>Paxos算法</h3><p>Paxos 算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一，其解决的问题就是在分布式系统中如何就某个值（决议）达成一致 。</p><p>在 Paxos 中主要有三个角色，分别为 Proposer提案者、Acceptor表决者、Learner学习者。Paxos 算法和 2PC 一样，也有两个阶段，分别为 Prepare 和 accept 阶段。  </p><ul><li>prepare 阶段<ul><li>Proposer提案者：负责提出 proposal，每个提案者在提出提案时都会首先获取到一个 具有全局唯一性的、递增的提案编号N，即在整个集群中是唯一的编号 N，然后将该编号赋予其要提出的提案，在第一阶段是只将提案编号发送给所有的表决者。  </li><li>Acceptor表决者：每个表决者在 accept 某提案后，会将该提案编号N记录在本地，这样每个表决者中保存的已经被 accept 的提案中会存在一个编号最大的提案，其编号假设为 maxN。每个表决者仅会 accept 编号大于自己本地 maxN 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 Proposer。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_1.png"></li></ul></li><li>accept 阶段<br>当一个提案被 Proposer 提出后，如果 Proposer 收到了超过半数的 Acceptor 的批准（Proposer 本身同意），那么此时 Proposer 会给所有的 Acceptor 发送真正的提案（你可以理解为第一阶段为试探），这个时候 Proposer 就会发送提案的内容和提案编号。<br>表决者收到提案请求后会再次比较本身已经批准过的最大提案编号和该提案编号，如果该提案编号 大于等于 已经批准过的最大提案编号，那么就 accept 该提案（此时执行提案内容但不提交），随后将情况返回给 Proposer 。如果不满足则不回应或者返回 NO 。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_2.png"><br>当 Proposer 收到超过半数的 accept ，那么它这个时候会向所有的 acceptor 发送提案的提交请求。需要注意的是，因为上述仅仅是超过半数的 acceptor 批准执行了该提案内容，其他没有批准的并没有执行该提案内容，所以这个时候需要向未批准的 acceptor 发送提案内容和提案编号并让它无条件执行和提交，而对于前面已经批准过该提案的 acceptor 来说 仅仅需要发送该提案的编号 ，让 acceptor 执行提交就行了。<br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_3.png"><br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。</li></ul><h4 id="Paxos算法的死循环问题"><a href="#Paxos算法的死循环问题" class="headerlink" title="Paxos算法的死循环问题"></a>Paxos算法的死循环问题</h4><p>其实就有点类似于两个人吵架，小明说我是对的，小红说我才是对的，两个人据理力争的谁也不让谁🤬🤬。<br>比如说，此时提案者 P1 提出一个方案 M1，完成了 Prepare 阶段的工作，这个时候 acceptor 则批准了 M1，但是此时提案者 P2 同时也提出了一个方案 M2，它也完成了 Prepare 阶段的工作。然后 P1 的方案已经不能在第二阶段被批准了（因为 acceptor 已经批准了比 M1 更大的 M2），所以 P1 自增方案变为 M3 重新进入 Prepare 阶段，然后 acceptor ，又批准了新的 M3 方案，它又不能批准 M2 了，这个时候 M2 又自增进入 Prepare 阶段。<br>就这样无休无止的永远提案下去，这就是 paxos 算法的死循环问题。<br>那么如何解决呢？很简单，人多了容易吵架，我现在 就允许一个能提案 就行了。</p><h3 id="Raft-算法"><a href="#Raft-算法" class="headerlink" title="Raft 算法"></a>Raft 算法</h3><h2 id="分布式事务解决方案"><a href="#分布式事务解决方案" class="headerlink" title="分布式事务解决方案"></a>分布式事务解决方案</h2><h3 id="XA规范-协议"><a href="#XA规范-协议" class="headerlink" title="XA规范/协议"></a>XA规范/协议</h3><p>X/Open组织（现在的Open Group）定义了一套DTP（Distributed Transaction Processing）分布式事务处理模型，主要包含以下四部分：</p><ul><li>AP（应用程序） </li><li>TM（事务管理器）：交易中间件</li><li>RM（资源管理器）：数据库</li><li>CRM（通信资源管理器）：消息中间件</li></ul><p><strong>XA规范</strong>则是DTP模型定义TM和RM之间通讯的接口规范。  </p><p>XA接口函数由数据库厂商提供。<br>TM用它来通知数据库事务的开始、结束、提交、回滚。<br>基于XA规范衍生出下面的二阶段提交（2PC）、三阶段提交（3PC）。  </p><p>XA规范包括两套函数，以xa_开头的及以ax_开头的。<br>以下的函数使事务管理器可以对资源管理器进行的操作：</p><ul><li>xa_open,xa_close：建立和关闭与资源管理器的连接。</li><li>xa_start,xa_end：开始和结束一个本地事务。</li><li>xa_prepare,xa_commit,xa_rollback：预提交、提交、回滚一个本地事务。</li><li>xa_recover：回滚一个已进行预提交的事务。</li><li>ax_开头的函数使资源管理器可以动态地在事务管理器中进行注册，并可以对XID(TRANSACTION IDS)进行操作。</li><li>ax_reg,ax_unreg；允许一个资源管理器在一个TMS(TRANSACTION MANAGER SERVER)中动态注册或撤消注册。<br>XA的一些问题：</li><li>性能（阻塞、响应时间增加、死锁）；</li><li>依赖于独立的J2EE中间件，Weblogic、Jboss，后期轻量级的Atomikos、Narayana、Bitronix；</li><li>不是所有资源(RM)都支持XA协议；</li></ul><h4 id="JTA（Java-Transaction-API）"><a href="#JTA（Java-Transaction-API）" class="headerlink" title="JTA（Java Transaction API）"></a>JTA（Java Transaction API）</h4><p>即Java的事务API，基于XA实现，也就是RM需要支持XA，所以也有JTA(XA)的说法，JTA仅定义了接口。主要包括javax.sql.XADataResource、javax.sql.XAConnection、javax.sql.XAException、javax.transaction.xa.XAResource、javax.transaction.Xid。 目下JTA的实现有几种形式：</p><ul><li>J2EE容器提供的JTA实现（Weblogic、JBoss ）；</li><li>JOTM（Java Open Transaction Manager）、Atomikos，可独立于J2EE容器的环境下实现JTA；</li></ul><h4 id="二阶段提交（2PC）"><a href="#二阶段提交（2PC）" class="headerlink" title="二阶段提交（2PC）"></a>二阶段提交（2PC）</h4><p>2PC就是分布式事务中将事务分为两步进行提交。基于数据库的XA协议完成事务本质上就是二阶段提交（XA、JTA/JTS）。</p><ul><li><p>协调者（Coordinater）：事务管理器（TM）</p></li><li><p>参与者（participants）：资源管理器（RM）<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_4.png"></p></li><li><p><strong>准备阶段</strong>：  </p><ul><li>协调者向参与者发送prepare信息，以询问参与者是否能够提交事务；</li><li>参与者在收到prepare信息后，进行本地事务的预处理，但不提交。并根据处理结果返回，失败not commit or 成功ready ；</li></ul></li><li><p><strong>提交阶段</strong>：  </p><ul><li>如协调者收到参与者的失败消息，则向每个参与者发送rollback消息进行回滚；</li><li>所有参与者都返回ready，则向每个参与者发送提交commit消息，通知参与者进行事务提交；</li></ul></li></ul><p>两阶段提交的一些问题:</p><ul><li>同步阻塞，事务执行过程中所有参与者都是阻塞型的，第三方参与者访问参与者占有的资源时会被阻塞；</li><li>单点故障，协调者一旦发生故障，参与者会被阻塞。尤其在提交阶段，所有参与者都处于锁定资源状态中，无法完成事务操作；（可以选择新的协调者，但无法解决参与者被阻塞的问题）；</li><li>数据不一致，提交阶段协调者向参与者发送commit信息，发生局部网络故障，会导致存在参与者未收到commit信息无法提交事务情况，导致出现数据不一致现象；</li></ul><h4 id="三阶段提交（3PC）"><a href="#三阶段提交（3PC）" class="headerlink" title="三阶段提交（3PC）"></a>三阶段提交（3PC）</h4><p>相比于2PC，3PC把2PC的准备阶段再次进行拆分，并且3PC引入了参与者超时机制。</p><ul><li>canCommit：协调者询问参与者，是否具备执行事务的条件，参与者进行自身事务必要条件的检查；</li><li>preCommit：协调者通知参与者进行事务的预提交；</li><li>doCommit：协调者根据preCommit阶段参与者的反馈结果通知参与者是否进行事务提交或是进行事务回滚。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_5.png"></li></ul><h4 id="TCC事务补偿方案"><a href="#TCC事务补偿方案" class="headerlink" title="TCC事务补偿方案"></a>TCC事务补偿方案</h4><p>TCC的核心思想就是校验、资源锁定、补偿，对每个操作（Try）都提供确认（Confirm）和取消（cancel）的操作，这样根据操作的结果，来确认是进行Confirm还是Cancel。<br>可以看出XA的两阶段提交是基于资源层面的，而TCC也是一种两阶段提交，但它是基于应用层面的。</p><ul><li>Try：主要负责对业务进行数据检查和资源预留，例如：对资金进行冻结；对状态更改为处理中；</li><li>Confirm：确认执行业务的操作，例如：进行实际资金扣除；更改状态为最终结果；</li><li>Cancel：取消执行业务的操作，例如：解冻资金；更改状态为未处理；</li></ul><p>TCC存在的一些问题：</p><ul><li>业务操作的是不同服务的Try来进行资源预留，每个Try都是独立完成本地事务，因此不会对资源一直加锁。</li><li>业务服务需要提供try、confirm、cancel，业务侵入性强，如不适用三方框架要做到对各阶段状态的感知，比较麻烦。</li><li>Confirm/Cancel要做幂等性设计。</li></ul><p>常用TCC框架：<br>tcc-transaction、ByteTCC、spring-cloud-rest-tcc、Himly</p><p>常见的微服务系统大部分接口调用是同步的，这时候使用TCC来保证一致性是比较合适的。</p><h4 id="SAGA"><a href="#SAGA" class="headerlink" title="SAGA"></a>SAGA</h4><p>Saga的核心是补偿，与TCC不同的是Saga不需要Try，而是直接进行confirm、cancel操作。  </p><ul><li>Confirm：依次按顺序依次执行资源操作，各个资源直接处理本地事务，如无问题，二阶段什么都不用做；</li><li>Cancel：异常情况下需要调用的补偿事务（逆操作）来保证数据的一致性。</li></ul><p>可以看出，Saga和TCC有些类似，都是补偿型事务</p><p>优势：</p><ul><li>一阶段提交本地事务，无锁，高性能；</li><li>事件驱动模式，参与者可异步执行，高吞吐；</li><li>应用成本低，补偿服务易于实现；</li></ul><p>劣势：</p><ul><li>无法保证隔离性（脏写）</li></ul><h4 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h4><p>有一些情况，服务间调用时异步的，服务A将消息发送到MQ，服务B进行消息的消费。这时我们就需要用到可靠消息最终一致性来解决分布式事务问题</p><ul><li>可靠消息：即这个消息一定是可靠的，并且最终一定需要被消费的。 </li><li>最终一致性：过程中数据存在一定时间内的不一致，但超过限定时间后，需要最终会保持一致。</li></ul><p>保证以上两点的情况下，可以通过消息中间件（RocketMQ）来完成分布式事务处理，因为RocketMQ支持事务消息，可以方便的让我们进行分布式事务控制。</p><p>RocketMQ的事务消息的原理：<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_6.png"></p><p>half message：半消息，此时消息不能被consumer所发现和消费，需producer进行二次消息确认。</p><ul><li>producer发送half message给MQ Server；</li><li>producer根据MQ Server应答结果判断half message是否发送成功；</li><li>producer处理本地事务；</li><li>producer发送最终确认消息commit / rollback；</li><li>commit：consumer对消息可见并进行消费；</li><li>rollback：discard抛弃消息，consumer无法进行消息消费；</li></ul><p>如遇异常情况下step4最终确认消息为达到MQ Server，MQ Server会定期查询当前处于半消息状态下的消息，主动进行消息回查来询问producer该消息的最终状态；</p><ul><li>producer检查本地事务执行的最终结果；</li><li>producer根据检查到的结果，再次提交确认消息，MQ Server仍然按照step4进行后续操作。</li></ul><p>事务消息发送对应步骤1、2、3、4，事务消息回查对应步骤5、6、7。<br>由以上步骤可以看出通过事务性消息的两步操作，避免了消息直接投递所产生一些问题。最终投递到MQ Server的消息，是真实可靠且必须被消费的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="分布式事务设计权衡点"><a href="#分布式事务设计权衡点" class="headerlink" title="分布式事务设计权衡点"></a>分布式事务设计权衡点</h3><ul><li>实现复杂度：事务模式与当前业务结合，实施成本是否过高；</li><li>业务侵入性：基于注解、XML、补偿逻辑； </li><li>TC/TM部署：独立部署、与应用部署；</li><li>性能：回滚概率、回滚所付出的代价、响应时间、吞吐量；</li><li>高可用：数据库、注册中心、配置中心</li><li>持久化：文件、数据库；</li><li>同步/异步：分布式事务执行过程中是否阻塞，还是非阻塞；</li></ul><h3 id="分布式事务解决方案对比"><a href="#分布式事务解决方案对比" class="headerlink" title="分布式事务解决方案对比"></a>分布式事务解决方案对比</h3><p>分布式系统中，基于不同的一致性需求产生了不同的分布式事务解决方案，追求强一致的两阶段提交、追求最终一致性的柔性事务和事务消息等等。  </p><p>我们综合对比下几种分布式事务解决方案：  </p><ul><li>一致性保证：XA &gt; TCC = SAGA &gt; 事务消息  </li><li>业务友好性：XA &gt; 事务消息 &gt; SAGA &gt; TCC  </li><li>性 能 损 耗：XA &gt; TCC &gt; SAGA = 事务消息</li></ul><p>在柔性事务解决方案中，虽然SAGA和TCC看上去可以保证数据的最终一致性，但分布式系统的生产环境复杂多变，某些情况是可以导致柔性事务机制失效的，所以无论使用那种方案，都需要最终的兜底策略，人工校验，修复数据。</p><h3 id="分布式事务框架Seata"><a href="#分布式事务框架Seata" class="headerlink" title="分布式事务框架Seata"></a>分布式事务框架Seata</h3><p>阿里开源的Seata 是一款分布式事务解决方案，提供了 AT、TCC、SAGA 和 XA 事务模式。</p><p>Seata架构的亮点主要有几个:</p><ul><li>应用层基于SQL解析实现了自动补偿，从而最大程度的降低业务侵入性；</li><li>将分布式事务中TC（事务协调者）独立部署，负责事务的注册、回滚（支持多种注册中心形式以及本地文件形式）；</li><li>通过全局锁实现了写隔离与读隔离。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 事务 </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统02之分布式ID解决方案</title>
      <link href="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么需要分布式ID"><a href="#为什么需要分布式ID" class="headerlink" title="为什么需要分布式ID"></a>为什么需要分布式ID</h2><p>在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如数据量太大之后，往往需要对进行对数据进行分库分表，分库分表后需要有一个唯一 ID 来标识一条数据或消息，数据库的自增 ID 显然不能满足需求。</p><h2 id="分布式ID生成方案"><a href="#分布式ID生成方案" class="headerlink" title="分布式ID生成方案"></a>分布式ID生成方案</h2><p><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/img_1.png"></p><h3 id="数据库自增ID"><a href="#数据库自增ID" class="headerlink" title="数据库自增ID"></a>数据库自增ID</h3><p>需要一个单独的Mysql实例，虽然可行，但是基于性能与可靠性来考虑的话都不够，业务系统每次需要一个ID时，都需要请求数据库获取，性能低，并且如果此数据库实例下线了，那么将影响所有的业务系统。</p><h3 id="数据库多主模式"><a href="#数据库多主模式" class="headerlink" title="数据库多主模式"></a>数据库多主模式</h3><p>多个数据库主节点实例，单独设置步长防止产生相同ID，或者使用号段模式每个节点生产部分号段的ID</p><h3 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h3><p>核心思想是：分布式ID固定是一个long型的数字，一个long型占8个字节，也就是64个bit，原始snowflake算法中对于bit的分配如下图：<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/img.png"></p><ul><li>第一个bit位是标识部分，在java中由于long的最高位是符号位，正数是0，负数是1，一般生成的ID为正数，所以固定为0。</li><li>时间戳部分占41bit，这个是毫秒级的时间，一般实现上不会存储当前的时间戳，而是时间戳的差值（当前时间-固定的开始时间），这样可以使产生的ID从更小值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69年</li><li>工作机器id占10bit，这里比较灵活，比如，可以使用前5位作为数据中心机房标识，后5位作为单机房机器标识，可以部署1024个节点。</li><li>序列号部分占12bit，支持同一毫秒内同一个节点可以生成4096个ID</li><li>备注： 工作机器ID可以通过某种改造自动生成。</li></ul><h3 id="Redis自增ID"><a href="#Redis自增ID" class="headerlink" title="Redis自增ID"></a>Redis自增ID</h3><p>使用Redis来生成分布式ID，其实和利用Mysql自增ID类似，可以利用Redis中的incr命令来实现原子性的自增与返回，比如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set seq_id 1 // 初始化自增ID为1 OK </span><br><span class="line">127.0.0.1:6379&gt; incr seq_id // 增加1，并返回 (integer) 2 </span><br><span class="line">127.0.0.1:6379&gt; incr seq_id // 增加1，并返回</span><br><span class="line">备注：使用redis需要考虑持久化问题,RDB&amp;AOF。</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统01之分布式系统理论</title>
      <link href="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"/>
      <url>/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><h3 id="名词解析"><a href="#名词解析" class="headerlink" title="名词解析"></a>名词解析</h3><p>CAP理论作为分布式系统的基础理论,它描述的是一个分布式系统在以下三个特性中：</p><ul><li><strong>一致性（Consistency）</strong><ul><li>所有节点访问同一份最新的数据副本</li></ul></li><li><strong>可用性（Availability）</strong><ul><li>非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。</li></ul></li><li><strong>分区容错性（Partition tolerance）</strong><ul><li>分布式系统出现网络分区（多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域）的时候，仍然能够对外提供服务。<br>最多满足其中的两个特性。 </li></ul></li></ul><p>也就是下图所描述的。分布式系统要么满足CA,要么CP，要么AP。无法同时满足CAP。<br><img src="/2020/06/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/img.png"></p><h3 id="CAP三者不可兼得，该如何取舍："><a href="#CAP三者不可兼得，该如何取舍：" class="headerlink" title="CAP三者不可兼得，该如何取舍："></a>CAP三者不可兼得，该如何取舍：</h3><ul><li><strong>CA</strong>: 优先保证一致性和可用性，放弃分区容错。 这也意味着放弃系统的扩展性，系统不再是分布式的，有违设计的初衷。<ul><li>当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。</li><li><strong>因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。</strong></li></ul></li><li><strong>CP</strong>: 优先保证一致性和分区容错性，放弃可用性。 在<strong>数据一致性要求比较高的场合</strong>(譬如:zookeeper,Hbase) 是比较常见的做法，一旦发生网络故障或者消息丢失，就会牺牲用户体验，等恢复之后用户才逐渐能访问。</li><li><strong>AP</strong>: 优先保证可用性和分区容错性，放弃一致性。 NoSQL中的Cassandra 就是这种架构。跟CP一样，放弃一致性不是说一致性就不保证了，而是逐渐的变得一致。</li></ul><h3 id="实际应用案例–注册中心"><a href="#实际应用案例–注册中心" class="headerlink" title="实际应用案例–注册中心"></a>实际应用案例–注册中心</h3><p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos…。 </p><ul><li>ZooKeeper 保证的是 CP。<br>任何时刻对 ZooKeeper 的读请求都能得到一致性的结果。<br>但是， ZooKeeper 不保证每次请求的可用性，比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。</li><li>Eureka 保证的则是 AP。<br>Eureka 在设计的时候就是优先保证 A （可用性）。<br>在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。<br>因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。<br>Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。   </li><li>Nacos 不仅支持 CP 也支持 AP。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等。<br>如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”（网络连接通信正常）的话，我们要思考如何保证 CA。</p><h2 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h2><h3 id="BASE理论名词解析"><a href="#BASE理论名词解析" class="headerlink" title="BASE理论名词解析"></a>BASE理论名词解析</h3><ul><li><strong>基本可用（Basically Available）</strong><br>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。<br>什么叫允许损失部分可用性呢？ <ul><li>响应时间上的损失: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。 </li><li>系统功能上的损失：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。</li></ul></li><li><strong>软状态（Soft State）</strong><br>软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</li><li><strong>最终一致性（Eventually Consistent）</strong><br>虽然允许软状态，但是系统不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。<br>实际工程实践中，最终一致性分为5种：<ul><li>因果一致性（Causal consistency）<br>如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。</li><li>读己之所写（Read your writes）<br>节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。</li><li>会话一致性（Session consistency）<br>系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</li><li>单调读一致性（Monotonic read consistency）<br>如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。</li><li>单调写一致性（Monotonic write consistency）<br>一个系统要能够保证来自同一个节点的写操作被顺序的执行。</li></ul></li></ul><h3 id="系统一致性说明"><a href="#系统一致性说明" class="headerlink" title="系统一致性说明"></a>系统一致性说明</h3><ul><li><strong>强一致性</strong>：系统写入了什么，读出来的就是什么。 </li><li><strong>弱一致性</strong>：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</li><li><strong>最终一致性</strong>：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</li></ul><h3 id="BASE理论的核心思想"><a href="#BASE理论的核心思想" class="headerlink" title="BASE理论的核心思想"></a>BASE理论的核心思想</h3><p>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</span><br></pre></td></tr></table></figure><p>CAP的3选2实际是个伪命题，实际上，系统没有发生P(分区)的话，必须在C（一致性）和A（可用性）之间任选其一。<br>分区的情况很少出现，CAP在大多时间能够同时满足C和A。<br>对于分区存在或者探知其影响的情况下，需要提供一种预备策略做出处理：</p><ul><li>探知分区的发生；</li><li>进入显示的分区模式，限制某些操作；</li><li>启动恢复过程，恢复数据一致性，补偿分区发生期间的错误。</li></ul><p>因此，AP方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。<br>在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。</p><h2 id="ACID本地事务四大特性"><a href="#ACID本地事务四大特性" class="headerlink" title="ACID本地事务四大特性"></a>ACID本地事务四大特性</h2><ul><li><strong>原子性（atomicity）</strong><br>一个事务中的所有操作，不可分割，要么全部成功，要么全部失败；</li><li><strong>一致性（consistency）</strong><br>一个事务执行前与执行后数据的完整性必须保持一致；</li><li><strong>隔离性（isolation）</strong><br>一个事务的执行，不能被其他事务干扰，多并发时事务之间要相互隔离；</li><li><strong>持久性（durability）</strong><br>一个事务一旦被提交，它对数据库中数据的改变是永久性的。</li></ul><h2 id="幂等性设计"><a href="#幂等性设计" class="headerlink" title="幂等性设计"></a>幂等性设计</h2><p>幂等（Idempotent）是一个数学与计算机学中的概念。f(n) = 1^n // 无论n等于多少，f(n)永远值等于1；在程序中，使用相同参数执行同一个方法，每一次执行结果都是相同的，即具有幂等性。</p><h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><ul><li>ACID 是数据库事务完整性的理论，</li><li>CAP 是分布式系统设计理论，</li><li>BASE 是 CAP 理论中 AP 方案的延伸。</li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 设计理念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式系统00之什么是分布式系统</title>
      <link href="/2020/06/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
      <url>/2020/06/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是分布式系统"><a href="#什么是分布式系统" class="headerlink" title="什么是分布式系统"></a>什么是分布式系统</h2><p>分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。</p><p>分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是<strong>利用更多的机器，处理更多的数据</strong>。</p><p>首先需要明确的是，只有</p><ul><li>单个节点的处理能力无法满足日益增长的计算、存储任务</li><li>且硬件的提升（加内存、加磁盘、使用更好的CPU）高昂到得不偿失</li><li>应用程序也不能进一步优化  </li></ul><p>我们才需要考虑分布式系统。</p><p>因为，分布式系统要解决的问题本身就是和单机系统一样的，而由于分布式系统多节点、通过网络通信的拓扑结构，会引入很多单机系统没有的问题，为了解决这些问题又会引入更多的机制、协议，带来更多的问题。</p><p>分布式系统怎么将任务分发到这些计算机节点呢，很简单的思想，分而治之，即分片（partition）。对于计算，那么就是对计算任务进行切换，每个节点算一些，最终汇总就行了，这就是MapReduce的思想；对于存储，更好理解一下，每个节点存一部分数据就行了。当数据规模变大的时候，Partition是唯一的选择，同时也会带来一些好处：</p><ul><li>提升性能和并发，操作被分发到不同的分片，相互独立</li><li>提升系统的可用性，即使部分分片不能用，其他分片不会受到影响</li></ul><p>理想的情况下，有分片就行了，但事实的情况却不大理想。</p><p>原因在于，分布式系统中有大量的节点，且通过网络通信。单个节点的故障（进程crash、断电、磁盘损坏）是个小概率事件，但整个系统的故障率会随节点的增加而指数级增加，网络通信也可能出现断网、高延迟的情况。在这种一定会出现的“异常”情况下，分布式系统还是需要继续稳定的对外提供服务，即需要较强的容错性。最简单的办法，就是冗余或者复制集（Replication），即多个节点负责同一个任务，最为常见的就是分布式存储中，多个节点复杂存储同一份数据，以此增强可用性与可靠性。同时，Replication也会带来性能的提升，比如数据的locality可以减少用户的等待时间。</p><p><img src="/2020/06/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/img.png"></p><p>Partition和Replication是解决分布式系统问题的一记组合拳，很多具体的问题都可以用这个思路去解决。但这并不是银弹，往往是为了解决一个问题，会引入更多的问题，比如为了可用性与可靠性保证，引用了冗余（复制集）。有了冗余，各个副本间的一致性问题就变得很头疼，一致性在系统的角度和用户的角度又有不同的等级划分。如果要保证强一致性，那么会影响可用性与性能，在一些应用（比如电商、搜索）是难以接受的。如果是最终一致性，那么就需要处理数据冲突的情况。CAP、FLP这些理论告诉我们，在分布式系统中，没有最佳的选择，都是需要权衡，做出最合适的选择。</p><h2 id="分布式系统面临的挑战"><a href="#分布式系统面临的挑战" class="headerlink" title="分布式系统面临的挑战"></a>分布式系统面临的挑战</h2><ul><li><p>异构的机器与网络：</p><p>  分布式系统中的机器，配置不一样，其上运行的服务也可能由不同的语言、架构实现，因此处理能力也不一样；节点间通过网络连接，而不同网络运营商提供的网络的带宽、延时、丢包率又不一样。怎么保证大家齐头并进，共同完成目标，这四个不小的挑战。</p></li><li><p>普遍的节点故障：</p><p>  虽然单个节点的故障概率较低，但节点数目达到一定规模，出故障的概率就变高了。分布式系统需要保证故障发生的时候，系统仍然是可用的，这就需要监控节点的状态，在节点故障的情况下将该节点负责的计算、存储任务转移到其他节点</p></li><li><p>不可靠的网络：</p><p>  节点间通过网络通信，而网络是不可靠的。可能的网络问题包括：网络分割、延时、丢包、乱序。</p><p>  相比单机过程调用，网络通信最让人头疼的是超时：节点A向节点B发出请求，在约定的时间内没有收到节点B的响应，那么B是否处理了请求，这个是不确定的，这个不确定会带来诸多问题，最简单的，是否要重试请求，节点B会不会多次处理同一个请求。</p></li></ul><p>总而言之，分布式的挑战来自<strong>不确定性</strong>，不确定计算机什么时候crash、断电，不确定磁盘什么时候损坏，不确定每次网络通信要延迟多久，也不确定通信对端是否处理了发送的消息。而分布式的规模放大了这个不确定性，不确定性是令人讨厌的，所以有诸多的分布式理论、协议来保证在这种不确定性的情况下，系统还能继续正常工作。</p><h2 id="分布式系统特性与衡量标准"><a href="#分布式系统特性与衡量标准" class="headerlink" title="分布式系统特性与衡量标准"></a>分布式系统特性与衡量标准</h2><ul><li><p><strong>透明性</strong><br>使用分布式系统的用户并不关心系统是怎么实现的，也不关心读到的数据来自哪个节点，对用户而言，分布式系统的最高境界是用户根本感知不到这是一个分布式系统。</p></li><li><p><strong>可扩展性</strong><br>分布式系统的根本目标就是为了处理单个计算机无法处理的任务，当任务增加的时候，分布式系统的处理能力需要随之增加。简单来说，要比较方便的通过增加机器来应对数据量的增长，同时，当任务规模缩减的时候，可以撤掉一些多余的机器，达到动态伸缩的效果</p></li><li><p><strong>可用性与可靠性</strong><br>一般来说，分布式系统是需要长时间甚至7*24小时提供服务的。可用性是指系统在各种情况对外提供服务的能力，简单来说，可以通过不可用时间与正常服务时间的必知来衡量；而可靠性而是指计算结果正确、存储的数据不丢失。</p></li><li><p><strong>高性能</strong><br>不管是单机还是分布式系统，大家都非常关注性能。不同的系统对性能的衡量指标是不同的，最常见的：高并发，单位时间内处理的任务越多越好；低延迟：每个任务的平均时间越少越好。这个其实跟操作系统CPU的调度策略很像</p></li><li><p><strong>一致性</strong><br>分布式系统为了提高可用性可靠性，一般会引入冗余（复制集）。那么如何保证这些节点上的状态一致，这就是分布式系统不得不面对的一致性问题。一致性有很多等级，一致性越强，对用户越友好，但会制约系统的可用性；一致性等级越低，用户就需要兼容数据不一致的情况，但系统的可用性、并发性很高很多。</p></li></ul><h2 id="一个简化的架构图"><a href="#一个简化的架构图" class="headerlink" title="一个简化的架构图"></a>一个简化的架构图</h2><p><img src="/2020/06/08/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/img_2.png"></p><h3 id="概念及其实现"><a href="#概念及其实现" class="headerlink" title="概念及其实现"></a>概念及其实现</h3><p>负载均衡：<br>Nginx：高性能、高并发的web服务器；功能包括负载均衡、反向代理、静态内容缓存、访问控制；工作在应用层</p><p>LVS： Linux virtual server，基于集群技术和Linux操作系统实现一个高性能、高可用的服务器；工作在网络层</p><p>webserver：<br>Java：Tomcat，Apache，Jboss</p><p>Python：gunicorn、uwsgi、twisted、webpy、tornado</p><p>service：<br>SOA、微服务、spring boot，django</p><p>容器：<br>docker，kubernetes</p><p>cache：<br>memcache、redis等</p><p>协调中心：<br>zookeeper、etcd等</p><p>zookeeper使用了Paxos协议Paxos是强一致性，高可用的去中心化分布式。zookeeper的使用场景非常广泛，之后细讲。</p><p>rpc框架：<br>grpc、dubbo、brpc</p><p>dubbo是阿里开源的Java语言开发的高性能RPC框架，在阿里系的诸多架构中，都使用了dubbo + spring boot</p><p>消息队列：<br>kafka、rabbitMQ、rocketMQ、QSP</p><p>消息队列的应用场景：异步处理、应用解耦、流量削锋和消息通讯</p><p>实时数据平台：<br>storm、akka</p><p>离线数据平台：<br>hadoop、spark</p><p>PS: spark、akka、kafka都是scala语言写的，看到这个语言还是很牛逼的</p><p>dbproxy：<br>cobar也是阿里开源的，在阿里系中使用也非常广泛，是关系型数据库的sharding + replica 代理</p><p>db：<br>mysql、oracle、MongoDB、HBase</p><p>搜索：<br>elasticsearch、solr</p><p>日志：<br>rsyslog、elk、flume</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 设计理念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之分布式定时调度Elastic-Job解析</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Elastic-Job%E8%A7%A3%E6%9E%90/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Elastic-Job%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>待完善，具体信息参考： </p><p><a href="http://www.iocoder.cn/categories/Elastic-Job-Lite/?vip&architect-awesome">Elastic-Job-Lite 源码解析</a></p><p><a href="http://www.iocoder.cn/categories/Elastic-Job-Cloud/?vip&architect-awesome">Elastic-Job-Cloud 源码解析</a></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之分布式定时调度Quartz集群基本实现原理</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="Quartz集群架构"><a href="#Quartz集群架构" class="headerlink" title="Quartz集群架构"></a>Quartz集群架构</h3><p>一个Quartz集群中的每个节点是一个独立的Quartz应用，它又管理着其他的节点。这就意味着你必须对每个节点分别启动或停止。Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的，如图2.1所示。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img.png"></p><h3 id="Quartz集群相关数据库表"><a href="#Quartz集群相关数据库表" class="headerlink" title="Quartz集群相关数据库表"></a>Quartz集群相关数据库表</h3><p>因为Quartz集群依赖于数据库，所以必须首先创建Quartz数据库表，Quartz发布包中包括了所有被支持的数据库平台的SQL脚本。这些SQL脚本存放于<quartz_home>/docs/dbTables 目录下。</quartz_home></p><p>这里采用的Quartz 1.8.4版本，总共12张表，不同版本，表个数可能不同。数据库为mysql，用tables_mysql.sql创建数据库表。</p><p>Quartz 1.8.4在mysql数据库中生成的表：<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img_1.png"></p><p>Quartz数据表简介：<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img_2.png"></p><h3 id="Quartz-Scheduler在集群中的启动流程"><a href="#Quartz-Scheduler在集群中的启动流程" class="headerlink" title="Quartz Scheduler在集群中的启动流程"></a>Quartz Scheduler在集群中的启动流程</h3><p>Quartz Scheduler自身是察觉不到被集群的，只有配置给Scheduler的JDBC JobStore才知道。<br>当Quartz Scheduler启动时，它调用JobStore的schedulerStarted()方法，它告诉JobStore Scheduler已经启动了。<br>schedulerStarted() 方法是在JobStoreSupport类中实现的。<br>JobStoreSupport类会根据<strong>quartz.properties</strong>文件中的设置来确定Scheduler实例是否参与到集群中。<br>假如配置了集群，一个新的ClusterManager类的实例就被创建、初始化并启动。<br>ClusterManager是在JobStoreSupport类中的一个内嵌类，继承了java.lang.Thread，它会定期运行，并对Scheduler实例执行检入的功能。<br>Scheduler也要查看是否有任何一个别的集群节点失败了。检入操作执行周期在quartz.properties中配置。</p><h4 id="侦测失败的Scheduler节点"><a href="#侦测失败的Scheduler节点" class="headerlink" title="侦测失败的Scheduler节点"></a>侦测失败的Scheduler节点</h4><p>当一个Scheduler实例执行检入时，它会查看是否有其他的Scheduler实例在到达他们所预期的时间还未检入。这是通过检查SCHEDULER_STATE表中Scheduler记录在LAST_CHEDK_TIME列的值是否早于org.quartz.jobStore.clusterCheckinInterval来确定的。如果一个或多个节点到了预定时间还没有检入，那么运行中的Scheduler就假定它(们) 失败了。</p><h4 id="从故障实例中恢复Job"><a href="#从故障实例中恢复Job" class="headerlink" title="从故障实例中恢复Job"></a>从故障实例中恢复Job</h4><p>当一个Sheduler实例在执行某个Job时失败了，有可能由另一正常工作的Scheduler实例接过这个Job重新运行。要实现这种行为，配置给JobDetail对象的Job可恢复属性必须设置为true（job.setRequestsRecovery(true)）。如果可恢复属性被设置为false(默认为false)，当某个Scheduler在运行该job失败时，它将不会重新运行；而是由另一个Scheduler实例在下一次触发时间触发。Scheduler实例出现故障后多快能被侦测到取决于每个Scheduler的检入间隔（即2.3中提到的org.quartz.jobStore.clusterCheckinInterval）。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><h4 id="时间同步问题"><a href="#时间同步问题" class="headerlink" title="时间同步问题"></a>时间同步问题</h4><p>Quartz实际并不关心你是在相同还是不同的机器上运行节点。当集群放置在不同的机器上时，称之为水平集群。节点跑在同一台机器上时，称之为垂直集群。对于垂直集群，存在着单点故障的问题。这对高可用性的应用来说是无法接受的，因为一旦机器崩溃了，所有的节点也就被终止了。对于水平集群，存在着时间同步问题。</p><p>节点用时间戳来通知其他实例它自己的最后检入时间。假如节点的时钟被设置为将来的时间，那么运行中的Scheduler将再也意识不到那个结点已经宕掉了。另一方面，如果某个节点的时钟被设置为过去的时间，也许另一节点就会认定那个节点已宕掉并试图接过它的Job重运行。最简单的同步计算机时钟的方式是使用某一个Internet时间服务器(Internet Time Server ITS)。</p><h4 id="节点争抢Job问题"><a href="#节点争抢Job问题" class="headerlink" title="节点争抢Job问题"></a>节点争抢Job问题</h4><p>因为Quartz使用了一个随机的负载均衡算法， Job以随机的方式由不同的实例执行。Quartz官网上提到当前，还不存在一个方法来指派(钉住) 一个 Job 到集群中特定的节点。</p><h4 id="从集群获取Job列表问题"><a href="#从集群获取Job列表问题" class="headerlink" title="从集群获取Job列表问题"></a>从集群获取Job列表问题</h4><p>当前，如果不直接进到数据库查询的话，还没有一个简单的方式来得到集群中所有正在执行的Job列表。请求一个Scheduler实例，将只能得到在那个实例上正运行Job的列表。Quartz官网建议可以通过写一些访问数据库JDBC代码来从相应的表中获取全部的Job信息。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
            <tag> Quartz </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之分布式定时调度优秀国产调度系统</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h3 id="opencron"><a href="#opencron" class="headerlink" title="opencron"></a>opencron</h3><p>opencron 是一个功能完善且通用的开源定时任务调度系统，拥有先进可靠的自动化任务管理调度功能，提供可操作的 web 图形化管理满足多种场景下各种复杂的定时任务调度，同时集成了 linux 实时监控、webssh 等功能特性。</p><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img.png"></p><h3 id="LTS"><a href="#LTS" class="headerlink" title="LTS"></a>LTS</h3><p>LTS，light-task-scheduler，是一款分布式任务调度框架, 支持实时任务、定时任务和 Cron 任务。有较好的伸缩性和扩展性，提供对 Spring 的支持（包括 Xml 和注解），提供业务日志记录器。支持节点监控、任务执行监、JVM 监控，支持动态提交、更改、停止任务。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_1.png"></p><h3 id="XXL-JOB"><a href="#XXL-JOB" class="headerlink" title="XXL-JOB"></a>XXL-JOB</h3><p>XXL-JOB 是一个轻量级分布式任务调度框架，支持通过 Web 页面对任务进行 CRUD 操作，支持动态修改任务状态、暂停/恢复任务，以及终止运行中任务，支持在线配置调度任务入参和在线查看调度结果。</p><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_2.png"></p><h3 id="Elastic-Job"><a href="#Elastic-Job" class="headerlink" title="Elastic-Job"></a>Elastic-Job</h3><p>Elastic-Job 是一个分布式调度解决方案，由两个相互独立的子项目 Elastic-Job-Lite 和 Elastic-Job-Cloud 组成。定位为轻量级无中心化解决方案，使用 jar 包的形式提供分布式任务的协调服务。支持分布式调度协调、弹性扩容缩容、失效转移、错过执行作业重触发、并行调度、自诊断和修复等等功能特性。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_3.png"></p><h3 id="Uncode-Schedule"><a href="#Uncode-Schedule" class="headerlink" title="Uncode-Schedule"></a>Uncode-Schedule</h3><p>Uncode-Schedule 是基于 ZooKeeper + Quartz / spring task 的分布式任务调度组件，确保每个任务在集群中不同节点上不重复的执行。支持动态添加和删除任务，支持添加 ip 黑名单，过滤不需要执行任务的节点。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_4.png"></p><h3 id="Antares"><a href="#Antares" class="headerlink" title="Antares"></a>Antares</h3><p>Antares 是一款基于 Quartz 机制的分布式任务调度管理平台，内部重写执行逻辑，一个任务仅会被服务器集群中的某个节点调度。用户可通过对任务预分片，有效提升任务执行效率；也可通过控制台 antares-tower 对任务进行基本操作，如触发，暂停，监控等。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_5.png"></p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之单机定时调度Quartz使用总结及原理解析</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="Quartz可以用来做什么？"><a href="#Quartz可以用来做什么？" class="headerlink" title="Quartz可以用来做什么？"></a>Quartz可以用来做什么？</h2><p>在某一个有规律的时间点干某件事。<br>并且时间的触发的条件可以非常复杂（比如每月最后一个工作日的17:50），复杂到需要一个专门的框架来干这个事。<br>Quartz就是来干这样的事，你给它一个触发条件的定义，它负责到了时间点，触发相应的Job起来干活。</p><h2 id="Quartz使用总结"><a href="#Quartz使用总结" class="headerlink" title="Quartz使用总结"></a>Quartz使用总结</h2><h3 id="从简单示例看Quartz核心设计"><a href="#从简单示例看Quartz核心设计" class="headerlink" title="从简单示例看Quartz核心设计"></a>从简单示例看Quartz核心设计</h3><h4 id="一个简单的Demo程序"><a href="#一个简单的Demo程序" class="headerlink" title="一个简单的Demo程序"></a>一个简单的Demo程序</h4><p>这里面的所有例子都是基于Quartz 2.2.1</p><details><summary>点击展开/收起</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.quartz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DateBuilder.newDate;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.JobBuilder.newJob;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.SimpleScheduleBuilder.simpleSchedule;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.TriggerBuilder.newTrigger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.GregorianCalendar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Scheduler;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Trigger;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.StdSchedulerFactory;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.calendar.AnnualCalendar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuartzTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//创建scheduler</span></span><br><span class="line">            Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义一个Trigger</span></span><br><span class="line">            Trigger trigger = newTrigger().withIdentity(<span class="string">&quot;trigger1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//定义name/group</span></span><br><span class="line">                .startNow()<span class="comment">//一旦加入scheduler，立即生效</span></span><br><span class="line">                .withSchedule(simpleSchedule() <span class="comment">//使用SimpleTrigger</span></span><br><span class="line">                    .withIntervalInSeconds(<span class="number">1</span>) <span class="comment">//每隔一秒执行一次</span></span><br><span class="line">                    .repeatForever()) <span class="comment">//一直执行，奔腾到老不停歇</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义一个JobDetail</span></span><br><span class="line">            JobDetail job = newJob(HelloQuartz.class) <span class="comment">//定义Job类为HelloQuartz类，这是真正的执行逻辑所在</span></span><br><span class="line">                .withIdentity(<span class="string">&quot;job1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//定义name/group</span></span><br><span class="line">                .usingJobData(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;quartz&quot;</span>) <span class="comment">//定义属性</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//加入这个调度</span></span><br><span class="line">            scheduler.scheduleJob(job, trigger);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//启动之</span></span><br><span class="line">            scheduler.start();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//运行一段时间后关闭</span></span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            scheduler.shutdown(<span class="keyword">true</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.quartz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.quartz.DisallowConcurrentExecution;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Job;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionContext;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloQuartz</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        JobDetail detail = context.getJobDetail();</span><br><span class="line">        String name = detail.getJobDataMap().getString(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;say hello to &quot;</span> + name + <span class="string">&quot; at &quot;</span> + <span class="keyword">new</span> Date());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="Quartz核心元素："><a href="#Quartz核心元素：" class="headerlink" title="Quartz核心元素："></a>Quartz核心元素：</h4><ul><li><p>Scheduler：调度器。<br>负责整个定时系统的调度，内部通过线程池进行调度。</p></li><li><p>Trigger： 定义触发的条件。<br>主要有四种类型：SimpleTrigger、CronTrigger、DataIntervalTrigger、NthIncludedTrigger，在项目中常用的为：SimpleTrigger和CronTrigger。。</p></li><li><p>JobDetail：定义任务数据。<br>记录Job的名字、组及任务执行的具体类和任务执行所需要的参数</p></li><li><p>Job： 真正的执行逻辑。  </p></li></ul><p>为什么设计成JobDetail + Job，不直接使用Job？<br>这是因为任务是有可能并发执行，如果Scheduler直接使用Job，就会存在对同一个Job实例并发访问的问题。<br>而JobDetail &amp; Job 方式，sheduler每次执行，都会根据JobDetail创建一个新的Job实例，这样就可以规避并发访问的问题。</p><h4 id="核心元素之间的关系"><a href="#核心元素之间的关系" class="headerlink" title="核心元素之间的关系"></a>核心元素之间的关系</h4><ul><li>先由SchedulerFactory创建Scheduler调度器</li><li>由调度器去调取即将执行的Trigger</li><li>执行时获取到对于的JobDetail信息</li><li>找到对应的Job类执行业务逻辑</li></ul><h3 id="Quartz-API"><a href="#Quartz-API" class="headerlink" title="Quartz API"></a>Quartz API</h3><p>Quartz的API的风格在2.x以后，采用的是DSL风格（通常意味着fluent interface风格），就是示例中newTrigger()那一段东西。它是通过Builder实现的，就是以下几个。（** 下面大部分代码都要引用这些Builder ** )</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//job相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.JobBuilder.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">//trigger相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.TriggerBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.SimpleScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.CronScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DailyTimeIntervalScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.CalendarIntervalScheduleBuilder.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">//日期相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DateBuilder.*;</span><br></pre></td></tr></table></figure><p>DSL风格写起来会更加连贯，畅快，而且由于不是使用setter的风格，语义上会更容易理解一些。对比一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JobDetail jobDetail=new JobDetailImpl(&quot;jobDetail1&quot;,&quot;group1&quot;,HelloQuartz.class);</span><br><span class="line">jobDetail.getJobDataMap().put(&quot;name&quot;, &quot;quartz&quot;);</span><br><span class="line"></span><br><span class="line">SimpleTriggerImpl trigger=new SimpleTriggerImpl(&quot;trigger1&quot;,&quot;group1&quot;);</span><br><span class="line">trigger.setStartTime(new Date());</span><br><span class="line">trigger.setRepeatInterval(1);</span><br><span class="line">trigger.setRepeatCount(-1);</span><br></pre></td></tr></table></figure><h3 id="关于name和group"><a href="#关于name和group" class="headerlink" title="关于name和group"></a>关于name和group</h3><p>JobDetail和Trigger都有name和group。</p><p>name是它们在这个sheduler里面的唯一标识。如果我们要更新一个JobDetail定义，只需要设置一个name相同的JobDetail实例即可。</p><p>group是一个组织单元，sheduler会提供一些对整组操作的API，比如 scheduler.resumeJobs()。</p><h3 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a>Trigger</h3><h4 id="StartTime-amp-EndTime"><a href="#StartTime-amp-EndTime" class="headerlink" title="StartTime &amp; EndTime"></a>StartTime &amp; EndTime</h4><p>startTime和endTime指定的Trigger会被触发的时间区间。在这个区间之外，Trigger是不会被触发的。</p><p>** 所有Trigger都会包含这两个属性 **</p><h4 id="优先级（Priority）"><a href="#优先级（Priority）" class="headerlink" title="优先级（Priority）"></a>优先级（Priority）</h4><p>当scheduler比较繁忙的时候，可能在同一个时刻，有多个Trigger被触发了，但资源不足（比如线程池不足）。那么这个时候比剪刀石头布更好的方式，就是设置优先级。优先级高的先执行。</p><p>需要注意的是，优先级只有在同一时刻执行的Trigger之间才会起作用，如果一个Trigger是9:00，另一个Trigger是9:30。那么无论后一个优先级多高，前一个都是先执行。</p><p>优先级的值默认是5，当为负数时使用默认值。最大值似乎没有指定，但建议遵循Java的标准，使用1-10，不然鬼才知道看到【优先级为10】是时，上头还有没有更大的值。</p><h4 id="Misfire-错失触发）策略"><a href="#Misfire-错失触发）策略" class="headerlink" title="Misfire(错失触发）策略"></a>Misfire(错失触发）策略</h4><p>类似的Scheduler资源不足的时候，或者机器崩溃重启等，有可能某一些Trigger在应该触发的时间点没有被触发，也就是Miss Fire了。这个时候Trigger需要一个策略来处理这种情况。每种Trigger可选的策略各不相同。</p><p>这里有两个点需要重点注意：</p><ul><li>MisFire的触发是有一个阀值，这个阀值是配置在JobStore的。比RAMJobStore是org.quartz.jobStore.misfireThreshold。只有超过这个阀值，才会算MisFire。小于这个阀值，Quartz是会全部重新触发。</li></ul><p>所有MisFire的策略实际上都是解答两个问题：</p><ul><li>已经MisFire的任务还要重新触发吗？</li><li>如果发生MisFire，要调整现有的调度时间吗？</li></ul><details><summary>比如SimpleTrigger的MisFire策略有</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>IGNORE<span class="emphasis">_MISFIRE_</span>POLICY</span><br><span class="line"></span><br><span class="line"><span class="code">    这个不是忽略已经错失的触发的意思，而是说忽略MisFire策略。它会在资源合适的时候，重新触发所有的MisFire任务，并且不会影响现有的调度时间。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    比如，SimpleTrigger每15秒执行一次，而中间有5分钟时间它都MisFire了，一共错失了20个，5分钟后，假设资源充足了，并且任务允许并发，它会被一次性触发。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    这个属性是所有Trigger都适用。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>FIRE<span class="emphasis">_NOW</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  忽略已经MisFire的任务，并且立即执行调度。这通常只适用于只执行一次的任务。</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">* MISFIRE_</span>INSTRUCTION<span class="emphasis">_RESCHEDULE_</span>NOW<span class="emphasis">_WITH_</span>EXISTING<span class="emphasis">_REPEAT_</span>COUNT</span><br><span class="line"></span><br><span class="line">  将startTime设置当前时间，立即重新调度任务，包括的MisFire的</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NOW_</span>WITH<span class="emphasis">_REMAINING_</span>REPEAT<span class="emphasis">_COUNT</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  类似MISFIRE_</span>INSTRUCTION<span class="emphasis">_RESCHEDULE_</span>NOW<span class="emphasis">_WITH_</span>EXISTING<span class="emphasis">_REPEAT_</span>COUNT，区别在于会忽略已经MisFire的任务</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_EXISTING_</span>COUNT</span><br><span class="line"></span><br><span class="line">  在下一次调度时间点，重新开始调度任务，包括的MisFire的</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_REMAINING_</span>COUNT</span><br><span class="line"></span><br><span class="line">  类似于MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_EXISTING_</span>COUNT，区别在于会忽略已经MisFire的任务。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>SMART<span class="emphasis">_POLICY</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  所有的Trigger的MisFire默认值都是这个，大致意思是“把处理逻辑交给聪明的Quartz去决定”。基本策略是，</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  * 如果是只执行一次的调度，使用MISFIRE_</span>INSTRUCTION<span class="emphasis">_FIRE_</span>NOW</span><br><span class="line"><span class="bullet">  *</span> 如果是无限次的调度(repeatCount是无限的)，使用MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_REMAINING_</span>COUNT</span><br><span class="line"><span class="bullet">  *</span> 否则，使用MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NOW_</span>WITH<span class="emphasis">_EXISTING_</span>REPEAT<span class="emphasis">_COUNT</span></span><br></pre></td></tr></table></figure></details><h4 id="Calendar"><a href="#Calendar" class="headerlink" title="Calendar"></a>Calendar</h4><p>这里的Calendar不是jdk的java.util.Calendar，不是为了计算日期的。它的作用是在于补充Trigger的时间。可以排除或加入某一些特定的时间点。</p><p>以”每月25日零点自动还卡债“为例，我们想排除掉每年的2月25号零点这个时间点（因为有2.14，所以2月一定会破产）。这个时间，就可以用Calendar来实现。</p><details><summary>例子</summary><pre><code>AnnualCalendar cal = new AnnualCalendar(); //定义一个每年执行Calendar，精度为天，即不能定义到2.25号下午2:00java.util.Calendar excludeDay = new GregorianCalendar();excludeDay.setTime(newDate().inMonthOnDay(2, 25).build());cal.setDayExcluded(excludeDay, true);  //设置排除2.25这个日期scheduler.addCalendar("FebCal", cal, false, false); //scheduler加入这个Calendar//定义一个TriggerTrigger trigger = newTrigger().withIdentity("trigger1", "group1").startNow()//一旦加入scheduler，立即生效.modifiedByCalendar("FebCal") //使用Calendar !!.withSchedule(simpleSchedule().withIntervalInSeconds(1).repeatForever()).build();</code></pre></details><p>Quartz体贴地为我们提供以下几种Calendar，注意，所有的Calendar既可以是排除，也可以是包含，取决于：</p><ul><li>HolidayCalendar。指定特定的日期，比如20140613。精度到天。</li><li>DailyCalendar。指定每天的时间段（rangeStartingTime, rangeEndingTime)，格式是HH:MM[:SS[:mmm]]。也就是最大精度可以到毫秒。</li><li>WeeklyCalendar。指定每星期的星期几，可选值比如为java.util.Calendar.SUNDAY。精度是天。</li><li>MonthlyCalendar。指定每月的几号。可选值为1-31。精度是天</li><li>AnnualCalendar。 指定每年的哪一天。使用方式如上例。精度是天。</li><li>CronCalendar。指定Cron表达式。精度取决于Cron表达式，也就是最大精度可以到秒。</li></ul><h4 id="其他属性"><a href="#其他属性" class="headerlink" title="其他属性"></a>其他属性</h4><ul><li><p>Durability(耐久性？)</p><p>如果一个任务不是durable，那么当没有Trigger关联它的时候，它就会被自动删除。</p></li><li><p>RequestsRecovery</p><p>如果一个任务是”requests recovery”，那么当任务运行过程非正常退出时（比如进程崩溃，机器断电，但不包括抛出异常这种情况），Quartz再次启动时，会重新运行一次这个任务实例。</p><p>可以通过JobExecutionContext.isRecovering()查询任务是否是被恢复的。</p></li></ul><h4 id="Trigger实现类"><a href="#Trigger实现类" class="headerlink" title="Trigger实现类"></a>Trigger实现类</h4><h5 id="SimpleTrigger"><a href="#SimpleTrigger" class="headerlink" title="SimpleTrigger"></a>SimpleTrigger</h5><p>指定从某一个时间开始，以一定的时间间隔（单位是毫秒）执行的任务。</p><p>它适合的任务类似于：9:00 开始，每隔1小时，执行一次。</p><p>它的属性有：</p><ul><li>repeatInterval 重复间隔</li><li>repeatCount 重复次数。实际执行次数是 repeatCount+1。因为在startTime的时候一定会执行一次。<strong>下面有关repeatCount 属性的都是同理</strong></li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">simpleSchedule()</span><br><span class="line">        .withIntervalInHours(1) //每小时执行一次</span><br><span class="line">        .repeatForever() //次数不限</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">simpleSchedule()</span><br><span class="line">    .withIntervalInMinutes(1) //每分钟执行一次</span><br><span class="line">    .withRepeatCount(10) //次数为10次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="CalendarIntervalTrigger"><a href="#CalendarIntervalTrigger" class="headerlink" title="CalendarIntervalTrigger"></a>CalendarIntervalTrigger</h5><p>类似于SimpleTrigger，指定从某一个时间开始，以一定的时间间隔执行的任务。<br>但是不同的是SimpleTrigger指定的时间间隔为毫秒，没办法指定每隔一个月执行一次（每月的时间间隔不是固定值），而CalendarIntervalTrigger支持的间隔单位有秒，分钟，小时，天，月，年，星期。</p><p>相较于SimpleTrigger有两个优势：1、更方便，比如每隔1小时执行，你不用自己去计算1小时等于多少毫秒。 2、支持不是固定长度的间隔，比如间隔为月和年。但劣势是精度只能到秒。</p><p>它适合的任务类似于：9:00 开始执行，并且以后每周 9:00 执行一次</p><p>它的属性有:</p><ul><li>interval 执行间隔</li><li>intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）</li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">calendarIntervalSchedule()</span><br><span class="line">    .withIntervalInDays(1) //每天执行一次</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">calendarIntervalSchedule()</span><br><span class="line">    .withIntervalInWeeks(1) //每周执行一次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="DailyTimeIntervalTrigger"><a href="#DailyTimeIntervalTrigger" class="headerlink" title="DailyTimeIntervalTrigger"></a>DailyTimeIntervalTrigger</h5><p>指定每天的某个时间段内，以一定的时间间隔执行任务。并且它可以支持指定星期。</p><p>它适合的任务类似于：指定每天9:00 至 18:00 ，每隔70秒执行一次，并且只要周一至周五执行。</p><p>它的属性有:</p><ul><li>startTimeOfDay 每天开始时间</li><li>endTimeOfDay 每天结束时间</li><li>daysOfWeek 需要执行的星期</li><li>interval 执行间隔</li><li>intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）</li><li>repeatCount 重复次数</li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dailyTimeIntervalSchedule()</span><br><span class="line">    .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始</span><br><span class="line">    .endingDailyAt(TimeOfDay.hourAndMinuteOfDay(16, 0)) //16：00 结束 </span><br><span class="line">    .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行</span><br><span class="line">    .withIntervalInHours(1) //每间隔1小时执行一次</span><br><span class="line">    .withRepeatCount(100) //最多重复100次（实际执行100+1次）</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">dailyTimeIntervalSchedule()</span><br><span class="line">    .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始</span><br><span class="line">    .endingDailyAfterCount(10) //每天执行10次，这个方法实际上根据 startTimeOfDay+interval*count 算出 endTimeOfDay</span><br><span class="line">    .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行</span><br><span class="line">    .withIntervalInHours(1) //每间隔1小时执行一次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="CronTrigger"><a href="#CronTrigger" class="headerlink" title="CronTrigger"></a>CronTrigger</h5><p>适合于更复杂的任务，它支持类型于Linux Cron的语法（并且更强大）。基本上它覆盖了以上三个Trigger的绝大部分能力（但不是全部）—— 当然，也更难理解。</p><p>它适合的任务类似于：每天0:00,9:00,18:00各执行一次。</p><p>它的属性只有:</p><p>Cron表达式。但这个表示式本身就够复杂了。</p><h3 id="JobDetail-amp-Job"><a href="#JobDetail-amp-Job" class="headerlink" title="JobDetail &amp; Job"></a>JobDetail &amp; Job</h3><p>JobDetail是任务的定义，而Job是任务的执行逻辑。在JobDetail里会引用一个Job Class定义。</p><details><summary>一个最简单的例子</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JobTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> SchedulerException, IOException </span>&#123;</span><br><span class="line">           JobDetail job=newJob()</span><br><span class="line">               .ofType(DoNothingJob.class) <span class="comment">//引用Job Class</span></span><br><span class="line">               .withIdentity(<span class="string">&quot;job1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//设置name/group</span></span><br><span class="line">               .withDescription(<span class="string">&quot;this is a test job&quot;</span>) <span class="comment">//设置描述</span></span><br><span class="line">               .usingJobData(<span class="string">&quot;age&quot;</span>, <span class="number">18</span>) <span class="comment">//加入属性到ageJobDataMap</span></span><br><span class="line">               .build();</span><br><span class="line"></span><br><span class="line">           job.getJobDataMap().put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;quertz&quot;</span>); <span class="comment">//加入属性name到JobDataMap</span></span><br><span class="line"></span><br><span class="line">           <span class="comment">//定义一个每秒执行一次的SimpleTrigger</span></span><br><span class="line">           Trigger trigger=newTrigger()</span><br><span class="line">                   .startNow()</span><br><span class="line">                   .withIdentity(<span class="string">&quot;trigger1&quot;</span>)</span><br><span class="line">                   .withSchedule(simpleSchedule()</span><br><span class="line">                       .withIntervalInSeconds(<span class="number">1</span>)</span><br><span class="line">                       .repeatForever())</span><br><span class="line">                   .build();</span><br><span class="line"></span><br><span class="line">           Scheduler sche=StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line">           sche.scheduleJob(job, trigger);</span><br><span class="line"></span><br><span class="line">           sche.start();</span><br><span class="line"></span><br><span class="line">           System.in.read();</span><br><span class="line"></span><br><span class="line">           sche.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DoNothingJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;do nothing&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>从上例我们可以看出，要定义一个任务，需要干几件事：</p><ul><li>创建一个org.quartz.Job的实现类，并实现实现自己的业务逻辑。比如上面的DoNothingJob。</li><li>定义一个JobDetail，引用这个实现类</li><li>加入scheduleJob</li></ul><p>Quartz调度一次任务，会干如下的事：</p><ul><li>JobClass jobClass=JobDetail.getJobClass()</li><li>Job jobInstance=jobClass.newInstance()。所以Job实现类，必须有一个public的无参构建方法。</li><li>jobInstance.execute(JobExecutionContext context)。JobExecutionContext是Job运行的上下文，可以获得Trigger、Scheduler、JobDetail的信息。</li></ul><p>也就是说，每次调度都会创建一个新的Job实例，这样的好处是有些任务并发执行的时候，不存在对临界资源的访问问题——当然，如果需要共享JobDataMap的时候，还是存在临界资源的并发访问的问题。</p><h4 id="JobDataMap"><a href="#JobDataMap" class="headerlink" title="JobDataMap"></a>JobDataMap</h4><p>每一个JobDetail都会有一个JobDataMap。JobDataMap本质就是一个Map的扩展类，只是提供了一些更便捷的方法，比如getString()之类的。</p><p>我们可以在定义JobDetail，加入属性值，方式有二：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">newJob().usingJobData(&quot;age&quot;, 18) //加入属性到ageJobDataMap</span><br><span class="line"></span><br><span class="line"> or</span><br><span class="line"></span><br><span class="line">job.getJobDataMap().put(&quot;name&quot;, &quot;quertz&quot;); //加入属性name到JobDataMap</span><br></pre></td></tr></table></figure><p>然后在Job中可以获取这个JobDataMap的值，方式同样有二：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloQuartz</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        JobDetail detail = context.getJobDetail();</span><br><span class="line">        JobDataMap map = detail.getJobDataMap(); <span class="comment">//方法一：获得JobDataMap</span></span><br><span class="line">        System.out.println(<span class="string">&quot;say hello to &quot;</span> + name + <span class="string">&quot;[&quot;</span> + map.getInt(<span class="string">&quot;age&quot;</span>) + <span class="string">&quot;]&quot;</span> + <span class="string">&quot; at &quot;</span></span><br><span class="line">                           + <span class="keyword">new</span> Date());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//方法二：属性的setter方法，会将JobDataMap的属性自动注入</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123; </span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于同一个JobDetail实例，执行的多个Job实例，是共享同样的JobDataMap，也就是说，如果你在任务里修改了里面的值，会对其他Job实例（并发的或者后续的）造成影响。</p><p>除了JobDetail，Trigger同样有一个JobDataMap，共享范围是所有使用这个Trigger的Job实例。</p><h4 id="Job并发"><a href="#Job并发" class="headerlink" title="Job并发"></a>Job并发</h4><p>Job是有可能并发执行的，比如一个任务要执行10秒中，而调度算法是每秒中触发1次，那么就有可能多个任务被并发执行。</p><p>有时候我们并不想任务并发执行，比如这个任务要去”获得数据库中所有未发送邮件的名单“，如果是并发执行，就需要一个数据库锁去避免一个数据被多次处理。这个时候一个@DisallowConcurrentExecution解决这个问题。</p><p>就是这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DoNothingJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="meta">@DisallowConcurrentExecution</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;do nothing&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，@DisallowConcurrentExecution是对JobDetail实例生效，也就是如果你定义两个JobDetail，引用同一个Job类，是可以并发执行的。</p><h4 id="JobExecutionException"><a href="#JobExecutionException" class="headerlink" title="JobExecutionException"></a>JobExecutionException</h4><p>Job.execute()方法是不允许抛出除JobExecutionException之外的所有异常的（包括RuntimeException)，所以编码的时候，最好是try-catch住所有的Throwable，小心处理。</p><h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>Scheduler就是Quartz的大脑，所有任务都是由它来设施。</p><p>Schduelr包含一个两个重要组件: JobStore和ThreadPool。</p><p>JobStore是会来存储运行时信息的，包括Trigger,Schduler,JobDetail，业务锁等。它有多种实现RAMJob(内存实现)，JobStoreTX(JDBC，事务由Quartz管理），JobStoreCMT(JDBC，使用容器事务)，ClusteredJobStore(集群实现)、TerracottaJobStore(什么是Terractta)。</p><p>ThreadPool就是线程池，Quartz有自己的线程池实现。所有任务的都会由线程池执行。</p><h4 id="SchedulerFactory"><a href="#SchedulerFactory" class="headerlink" title="SchedulerFactory"></a>SchedulerFactory</h4><p>SchdulerFactory，顾名思义就是来用创建Schduler了，有两个实现：DirectSchedulerFactory和 StdSchdulerFactory。前者可以用来在代码里定制你自己的Schduler参数。后者是直接读取classpath下的quartz.properties（不存在就都使用默认值）配置来实例化Schduler。通常来讲，我们使用StdSchdulerFactory也就足够了。</p><p>SchdulerFactory本身是支持创建RMI stub的，可以用来管理远程的Scheduler，功能与本地一样，可以远程提交个Job什么的。</p><p>DirectSchedulerFactory的创建接口</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Same as</span><br><span class="line">     * &#123;@link DirectSchedulerFactory#createScheduler(ThreadPool threadPool, JobStore jobStore)&#125;,</span><br><span class="line">     * with the addition of specifying the scheduler name and instance ID. This</span><br><span class="line">     * scheduler can only be retrieved via</span><br><span class="line">     * &#123;@link DirectSchedulerFactory#getScheduler(String)&#125;</span><br><span class="line">     *</span><br><span class="line">     * @param schedulerName</span><br><span class="line">     *          The name for the scheduler.</span><br><span class="line">     * @param schedulerInstanceId</span><br><span class="line">     *          The instance ID for the scheduler.</span><br><span class="line">     * @param threadPool</span><br><span class="line">     *          The thread pool for executing jobs</span><br><span class="line">     * @param jobStore</span><br><span class="line">     *          The type of job store</span><br><span class="line">     * @throws SchedulerException</span><br><span class="line">     *           if initialization failed</span><br><span class="line">     */</span><br><span class="line">    public void createScheduler(String schedulerName,</span><br><span class="line">            String schedulerInstanceId, ThreadPool threadPool, JobStore jobStore)</span><br><span class="line">        throws SchedulerException;</span><br></pre></td></tr></table></figure><p>StdSchdulerFactory的配置例子，更多配置，参考<a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/">Quartz配置指南</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">org.quartz.scheduler.instanceName = DefaultQuartzScheduler</span><br><span class="line">org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool</span><br><span class="line">org.quartz.threadPool.threadCount = 10 </span><br><span class="line">org.quartz.threadPool.threadPriority = 5</span><br><span class="line">org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true</span><br><span class="line">org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore</span><br></pre></td></tr></table></figure><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>JobStore <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-09">介绍</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/">配置</a></li></ul></li><li>集群: <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-11">介绍</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/ConfigJDBCJobStoreClustering">配置</a></li></ul></li><li>RMI</li><li>监听器 <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-07">TriggerListeners and JobListeners</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-08">SchedulerListeners</a></li></ul></li><li>插件</li></ul><p>主要的资料来自<a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/">官方文档</a>，这里有教程，例子，配置等，非常详细</p><h2 id="Quartz源码解析"><a href="#Quartz源码解析" class="headerlink" title="Quartz源码解析"></a>Quartz源码解析</h2><h3 id="Quartz启动流程"><a href="#Quartz启动流程" class="headerlink" title="Quartz启动流程"></a>Quartz启动流程</h3><p>当服务器启动时，Spring就加载相关的bean。<br>SchedulerFactoryBean实现了InitializingBean接口，因此在初始化bean的时候，会执行afterPropertiesSet方法，该方法将会调用SchedulerFactory(DirectSchedulerFactory 或者 StdSchedulerFactory，通常用StdSchedulerFactory)创建Scheduler。==<br>我们在SchedulerFactoryBean配置类中配了相关的配置及配置文件参数，所以会读取配置文件参数，初始化各个组件。  </p><p>关键组件如下：</p><ul><li><strong>ThreadPool</strong>：一般是使用SimpleThreadPool(线程数量固定的线程池),SimpleThreadPool创建了一定数量的WorkerThread实例来使得Job能够在线程中进行处理。WorkerThread是定义在SimpleThreadPool类中的内部类，它实质上就是一个线程。<br>在SimpleThreadPool中有三个list：workers-存放池中所有的线程引用，availWorkers-存放所有空闲的线程，busyWorkers-存放所有工作中的线程；配置如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool</span><br><span class="line">org.quartz.threadPool.threadCount=3</span><br><span class="line">org.quartz.threadPool.threadPriority=5</span><br></pre></td></tr></table></figure></li><li><strong>JobStore</strong>： 初始化定时任务的数据存储方式，分为两种：<ul><li>存储在内存的RAMJobStore<br>存取速度非常快，但是由于其在系统被停止后所有的数据都会丢失，所以在集群应用中，必须使用JobStoreSupport</li><li>存储在数据库的JobStoreSupport(包括JobStoreTX和JobStoreCMT两种实现，JobStoreCMT是依赖于容器来进行事务的管理，而JobStoreTX是自己管理事务） </li></ul></li><li><strong>QuartzSchedulerThread</strong>： 初始化调度线程，在初始化的时候paused=true,halted=false,虽然线程开始运行了，但是paused=true，线程会一直等待，直到start方法将paused置为false；SchedulerFactoryBean还实现了SmartLifeCycle接口，因此初始化完成后，会执行start()方法，该方法将主要会执行以下的几个动作：<ul><li>创建ClusterManager线程并启动线程:该线程用来进行集群故障检测和处理</li><li>创建MisfireHandler线程并启动线程:该线程用来进行misfire任务的处理</li><li>置QuartzSchedulerThread的paused=false，调度线程才真正开始调度</li></ul>整个启动流程图如下：<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img.png"><br>流程图简要说明：<ol><li>先读取配置文件</li><li>初始化SchedulerFactoryBean</li><li>初始化SchedulerFactory</li><li>实例化执行线程池（TheadPool）</li><li>实例化数据存储</li><li>初始化QuartzScheduler(为Scheduler的简单实现，包括调度作业、注册JobListener实例等方法。)</li><li>new一个QuartzSchedulerThread调度线程（负责执行在QuartzScheduler中注册的触发触发器的线程。），并开始运行</li><li>调度开始，注册监听器，注册Job和Trigger</li><li>SchedulerFactoryBean初始化完成后执行start()方法</li><li>创建ClusterManager线程并启动线程</li><li>创建MisfireHandler线程并启动线程</li><li>置QuartzSchedulerThread的paused=false，调度线程真正开始调度，开始执行run方法</li></ol></li></ul><h3 id="Quartz-线程视图"><a href="#Quartz-线程视图" class="headerlink" title="Quartz 线程视图"></a>Quartz 线程视图</h3><p>在Quartz中，有两类线程，Scheduler调度线程和任务执行线程，其中任务执行线程通常使用一个线程池维护一组线程。<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_3.png"></p><p>Scheduler调度线程主要有两个：执行常规调度的线程，和执行misfiredtrigger的线程。  </p><ul><li>常规调度线程轮询存储的所有trigger，如果有需要触发的trigger，即到达了下一次触发的时间，则从任务执行线程池获取一个空闲线程，执行与该trigger关联的任务。<br>— Misfire线程是扫描所有的trigger，查看是否有misfiredtrigger，如果有的话根据misfire的策略分别处理(fire now OR wait for the next fire)。</li></ul><h3 id="QuartzSchedulerThread逻辑具体介绍"><a href="#QuartzSchedulerThread逻辑具体介绍" class="headerlink" title="QuartzSchedulerThread逻辑具体介绍"></a>QuartzSchedulerThread逻辑具体介绍</h3><p>类中主要的方法就是run方法，下面主要对run方法进行介绍：</p><details><summary>源码解析</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//只有当Quartzscheduler执行start方法时被调用</span><br><span class="line">void togglePause(boolean pause) &#123;</span><br><span class="line">    synchronized(this.sigLock) &#123;</span><br><span class="line">        this.paused = pause;</span><br><span class="line">        if (this.paused) &#123;</span><br><span class="line">          this.signalSchedulingChange(0L);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          this.sigLock.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">public void run() &#123;</span><br><span class="line">    boolean lastAcquireFailed = false;</span><br><span class="line">    label214:</span><br><span class="line">    //此处判断调度器是否终止</span><br><span class="line">    while(!this.halted.get()) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            synchronized(this.sigLock) &#123;</span><br><span class="line">                //此处判断调度器是否终止或是否暂停，由于我们在初始化的时候</span><br><span class="line">                //将paused=true，那么调度线程此时不会真正开始执行只会在不断循环阻塞</span><br><span class="line">                //只有当Quartzscheduler执行start方法时调用togglePause开始将</span><br><span class="line">                //paused置为false,run方法开始真正运行</span><br><span class="line">                while(this.paused &amp;&amp; !this.halted.get()) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        this.sigLock.wait(1000L);</span><br><span class="line">                    &#125; catch (InterruptedException var23) &#123;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                if (this.halted.get()) &#123;</span><br><span class="line">                    break;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            //取出执行线程池中空闲的线程数量</span><br><span class="line">            int availThreadCount = this.qsRsrcs.getThreadPool().blockForAvailableThreads();</span><br><span class="line">            if (availThreadCount &gt; 0) &#123;</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">            //如果可用线程数量足够那么查看30秒内需要触发的触发器。如果没有的</span><br><span class="line">            //话那么就是30后再次扫描，其中方法中三个参数idleWaitTime为如果</span><br><span class="line">            //没有的再次扫描的时间，第二个为最多取几个，最后一个参数</span><br><span class="line">            //batchTimeWindow，这个参数默认是0，同样是一个时间范围，如果</span><br><span class="line">            //有两个任务只差一两秒，而执行线程数量满足及batchTimeWindow时间</span><br><span class="line">            //也满足的情况下就会两个都取出来</span><br><span class="line"></span><br><span class="line">            triggers = this.qsRsrcs.getJobStore().acquireNextTriggers(now + this.idleWaitTime, Math.min(availThreadCount, this.qsRsrcs.getMaxBatchSize()), this.qsRsrcs.getBatchTimeWindow());</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">            //trigger列表是以下次执行时间排序查出来的</span><br><span class="line">            //在列表不为空的时候进行后续操作</span><br><span class="line">            if (triggers != null &amp;&amp; !triggers.isEmpty()) &#123;</span><br><span class="line">            now = System.currentTimeMillis();</span><br><span class="line">            //取出集合中最早执行的触发器</span><br><span class="line">            long triggerTime = ((OperableTrigger)triggers.get(0)).getNextFireTime().getTime();</span><br><span class="line">            //判断距离执行时间是否大于两毫秒</span><br><span class="line">            for(long timeUntilTrigger = triggerTime - now; timeUntilTrigger &gt; 2L; timeUntilTrigger = triggerTime - now) &#123;</span><br><span class="line">                synchronized(this.sigLock) &#123;</span><br><span class="line">                    if (this.halted.get()) &#123;</span><br><span class="line">                        break;</span><br><span class="line">                    &#125;</span><br><span class="line">                    //判断是否还有更早的trigger</span><br><span class="line">                    if (!this.isCandidateNewTimeEarlierWithinReason(triggerTime, false)) &#123;</span><br><span class="line">                    //没有的话进行简单的阻塞，到时候再执行</span><br><span class="line">                        try &#123;</span><br><span class="line">                            now = System.currentTimeMillis();</span><br><span class="line">                            timeUntilTrigger = triggerTime - now;</span><br><span class="line">                            if (timeUntilTrigger &gt;= 1L) &#123;</span><br><span class="line">                                this.sigLock.wait(timeUntilTrigger);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; catch (InterruptedException var22) &#123;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //开始根据需要执行的trigger从数据库中获取相应的JobDetail</span><br><span class="line">                 if (goAhead) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        List&lt;TriggerFiredResult&gt; res = this.qsRsrcs.getJobStore().triggersFired(triggers);</span><br><span class="line">                        if (res != null) &#123;</span><br><span class="line">                            bndles = res;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; catch (SchedulerException var24) &#123;</span><br><span class="line">                        this.qs.notifySchedulerListenersError(&quot;An error occurred while firing triggers &#x27;&quot; + triggers + &quot;&#x27;&quot;, var24);</span><br><span class="line">                        int i = 0;</span><br><span class="line"></span><br><span class="line">                        while(true) &#123;</span><br><span class="line">                            if (i &gt;= triggers.size()) &#123;</span><br><span class="line">                                continue label214;</span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                            ++i;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //将查询到的结果封装成为 TriggerFiredResult</span><br><span class="line">                 for(int i = 0; i &lt; ((List)bndles).size(); ++i) &#123;</span><br><span class="line">                    TriggerFiredResult result = (TriggerFiredResult)((List)bndles).get(i);</span><br><span class="line">                    TriggerFiredBundle bndle = result.getTriggerFiredBundle();</span><br><span class="line">                    Exception exception = result.getException();</span><br><span class="line">                    if (exception instanceof RuntimeException) &#123;</span><br><span class="line">                        this.getLog().error(&quot;RuntimeException while firing trigger &quot; + triggers.get(i), exception);</span><br><span class="line">                        this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                    &#125; else if (bndle == null) &#123;</span><br><span class="line">                        this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        JobRunShell shell = null;</span><br><span class="line"></span><br><span class="line">                        try &#123;</span><br><span class="line">                        //把任务封装成JobRunShell线程任务，然后放到线程池中跑动。</span><br><span class="line">                            shell = this.qsRsrcs.getJobRunShellFactory().createJobRunShell(bndle);</span><br><span class="line">                            shell.initialize(this.qs);</span><br><span class="line">                        &#125; catch (SchedulerException var27) &#123;</span><br><span class="line">                            this.qsRsrcs.getJobStore().triggeredJobComplete((OperableTrigger)triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR);</span><br><span class="line">                            continue;</span><br><span class="line">                        &#125;</span><br><span class="line">                        //runInThread方法加Job放入对应的工作线程进行执行Job</span><br><span class="line">                        if (!this.qsRsrcs.getThreadPool().runInThread(shell)) &#123;</span><br><span class="line">                            this.getLog().error(&quot;ThreadPool.runInThread() return false!&quot;);</span><br><span class="line">                            this.qsRsrcs.getJobStore().triggeredJobComplete((OperableTrigger)triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure></details><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_1.png"></p><p>总结下来:</p><ol><li>先获取线程池中的可用线程数量（若没有可用的会阻塞，直到有可用的）；</li><li>获取30m内要执行的trigger(即acquireNextTriggers)获取trigger的锁，通过select …for update方式实现；获取30m内（可配置）要执行的triggers（需要保证集群节点的时间一致），若@ConcurrentExectionDisallowed且列表存在该条trigger则跳过，否则更新trigger状态为ACQUIRED(刚开始为WAITING)；插入firedTrigger表，状态为ACQUIRED;（注意：在RAMJobStore中，有个timeTriggers，排序方式是按触发时间nextFireTime排的；JobStoreSupport从数据库取出triggers时是按照nextFireTime排序）;</li><li>待直到获取的trigger中最先执行的trigger在2ms内；</li><li>triggersFired：<ol><li>更新firedTrigger的status=EXECUTING;</li><li>更新trigger下一次触发的时间; </li><li>更新trigger的状态：无状态的trigger-&gt;WAITING，有状态的trigger-&gt;BLOCKED，若nextFireTime==null -&gt;COMPLETE；</li><li>commit connection,释放锁；</li></ol></li><li>针对每个要执行的trigger，创建JobRunShell，并放入线程池执行：<ol><li>execute:执行job</li><li>获取TRIGGER_ACCESS锁</li><li>若是有状态的job：更新trigger状态：BLOCKED-&gt;WAITING,PAUSED_BLOCKED-&gt;BLOCKED</li><li>若@PersistJobDataAfterExecution，则updateJobData</li><li>删除firedTrigger</li><li>commit connection，释放锁</li></ol></li></ol><h3 id="misfireHandler线程"><a href="#misfireHandler线程" class="headerlink" title="misfireHandler线程"></a>misfireHandler线程</h3><p>下面这些原因可能造成 misfired job:</p><ol><li>系统因为某些原因被重启。在系统关闭到重新启动之间的一段时间里，可能有些任务会被 misfire；</li><li>Trigger 被暂停（suspend）的一段时间里，有些任务可能会被 misfire；</li><li>线程池中所有线程都被占用，导致任务无法被触发执行，造成 misfire；</li><li>有状态任务在下次触发时间到达时，上次执行还没有结束；为了处理 misfired job，Quartz 中为 trigger定义了处理策略，主要有下面两种：MISFIRE_INSTRUCTION_FIRE_ONCE_NOW：针对 misfired job马上执行一次；MISFIRE_INSTRUCTION_DO_NOTHING：忽略 misfired job，等待下次触发；默认是MISFIRE_INSTRUCTION_SMART_POLICY，该策略在CronTrigger中=MISFIRE_INSTRUCTION_FIRE_ONCE_NOW线程默认1分钟执行一次；在一个事务中，默认一次最多recovery 20个；</li></ol><p>执行流程：<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_2.png"></p><ol><li>若配置(默认为true，可配置)成获取锁前先检查是否有需要recovery的trigger，先获取misfireCount；</li><li>获取TRIGGER_ACCESS锁；</li><li>hasMisfiredTriggersInState：获取misfired的trigger，默认一个事务里只能最大20个misfired trigger（可配置），misfired判断依据：status=waiting,next_fire_time &lt; current_time-misfirethreshold(可配置，默认1min)</li><li>notifyTriggerListenersMisfired</li><li>updateAfterMisfire:获取misfire策略(默认是MISFIRE_INSTRUCTION_SMART_POLICY，该策略在CronTrigger中=MISFIRE_INSTRUCTION_FIRE_ONCE_NOW)，根据策略更新nextFireTime；</li><li>将nextFireTime等更新到trigger表；</li><li>commit connection，释放锁8.如果还有更多的misfired，sleep短暂时间(为了集群负载均衡)，否则sleep misfirethreshold时间，后继续轮询；</li></ol>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
            <tag> Quartz </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>定时调度系列之单机定时调度Linux定时任务cron</title>
      <link href="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/"/>
      <url>/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/</url>
      
        <content type="html"><![CDATA[<p>实现linux定时任务有：cron、anacron、at,使用最多的是cron任务</p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul><li>cron–服务名；</li><li>crond–linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似；</li><li>crontab–是定制好的计划任务表，一个设置cron的工具</li></ul><h2 id="软件包安装"><a href="#软件包安装" class="headerlink" title="软件包安装"></a>软件包安装</h2><p>要使用cron服务，先要安装vixie-cron软件包和crontabs软件包，两个软件包作用如下：</p><ul><li>vixie-cron软件包是cron的主程序。<ul><li>查看是否安装了cron软件包: rpm -qa|grep vixie-cron</li></ul></li><li>crontabs软件包是用来安装、卸装、或列举用来驱动 cron 守护进程的表格的程序。<ul><li>查看是否安装了crontabs软件包:rpm -qa|grep crontabs</li></ul></li></ul><p>如果没有安装，则执行如下命令安装软件包(软件包必须存在)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh vixie-cron-4.1-54.FC5*</span><br><span class="line">rpm -ivh crontabs*</span><br></pre></td></tr></table></figure><p>如果本地没有安装包，在能够连网的情况下可以在线安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install vixie-cron</span><br><span class="line">yum install crontabs</span><br></pre></td></tr></table></figure><h3 id="查看crond服务是否运行"><a href="#查看crond服务是否运行" class="headerlink" title="查看crond服务是否运行"></a>查看crond服务是否运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pgrep crond 或 </span><br><span class="line">/sbin/service crond status 或 </span><br><span class="line">ps -elf|grep crond|grep -v &quot;grep&quot;</span><br></pre></td></tr></table></figure><h3 id="crond服务操作命令"><a href="#crond服务操作命令" class="headerlink" title="crond服务操作命令"></a>crond服务操作命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/sbin/service crond start //启动服务  </span><br><span class="line">/sbin/service crond stop //关闭服务  </span><br><span class="line">/sbin/service crond restart //重启服务  </span><br><span class="line">/sbin/service crond reload //重新载入配置</span><br></pre></td></tr></table></figure><h2 id="配置定时任务"><a href="#配置定时任务" class="headerlink" title="配置定时任务"></a>配置定时任务</h2><p>cron有两个配置文件，一个是一个全局配置文件（/etc/crontab），是针对系统任务的；一组是crontab命令生成的配置文件（/var/spool/cron下的文件），是针对某个用户的.定时任务配置到任意一个中都可以。</p><p>查看全局配置文件配置情况: <code>cat /etc/crontab</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">　---------------------------------------------</span><br><span class="line">　　SHELL=/bin/bash</span><br><span class="line">　　PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">　　MAILTO=root</span><br><span class="line">　　HOME=/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">　　#</span><span class="bash"> run-parts</span></span><br><span class="line">　　01 * * * * root run-parts /etc/cron.hourly</span><br><span class="line">　　02 4 * * * root run-parts /etc/cron.daily</span><br><span class="line">　　22 4 * * 0 root run-parts /etc/cron.weekly</span><br><span class="line">　　42 4 1 * * root run-parts /etc/cron.monthly</span><br><span class="line">　　----------------------------------------------</span><br></pre></td></tr></table></figure><p>查看用户下的定时任务:crontab -l或cat /var/spool/cron/用户名</p><h3 id="crontab任务配置基本格式"><a href="#crontab任务配置基本格式" class="headerlink" title="crontab任务配置基本格式"></a>crontab任务配置基本格式</h3><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-----------------------------------------------------------------------</span><br><span class="line">*   *　 *　 *　 *　　command</span><br><span class="line">分钟(0-59)　小时(0-23)　日期(1-31)　月份(1-12)　星期(0-6,0代表星期天)　 命令</span><br><span class="line">第1列表示分钟1～59 每分钟用*或者 */1表示</span><br><span class="line">第2列表示小时1～23（0表示0点）</span><br><span class="line">第3列表示日期1～31</span><br><span class="line">第4列表示月份1～12</span><br><span class="line">第5列标识号星期0～6（0表示星期天）</span><br><span class="line">第6列要运行的命令</span><br><span class="line"></span><br><span class="line">-----------------------------------------------------------------------</span><br><span class="line">在以上任何值中，星号（*）可以用来代表所有有效的值。譬如，月份值中的星号意味着在满足其它制约条件后每月都执行该命令。</span><br><span class="line">整数间的短线（-）指定一个整数范围。譬如，1-4 意味着整数 1、2、3、4。</span><br><span class="line">用逗号（,）隔开的一系列值指定一个列表。譬如，3, 4, 6, 8 标明这四个指定的整数。</span><br><span class="line">正斜线（/）可以用来指定间隔频率。在范围后加上 /&lt;integer&gt; 意味着在范围内可以跳过 integer。譬如，0-59/2 可以用来在分钟字段定义每两分钟。间隔频率值还可以和星号一起使用。例如，*/3 的值可以用在月份字段中表示每三个月运行一次任务。</span><br><span class="line">开头为井号（#）的行是注释，不会被处理</span><br><span class="line">-----------------------------------------------------------------------</span><br></pre></td></tr></table></figure><details><summary>使用实例</summary><pre><code>实例1：每1分钟执行一次command命令：* * * * * command<p>实例2：每小时的第3和第15分钟执行<br>命令：3,15 * * * * command</p><p>实例3：在上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 * * * command</p><p>实例4：每隔两天的上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 */2 * * command</p><p>实例5：每个星期一的上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 * * 1 command</p><p>实例6：每晚的21:30重启smb<br>命令：30 21 * * * /etc/init.d/smb restart</p><p>实例7：每月1、10、22日的4 : 45重启smb<br>命令：45 4 1,10,22 * * /etc/init.d/smb restart</p><p>实例8：每周六、周日的1 : 10重启smb<br>命令：10 1 * * 6,0 /etc/init.d/smb restart</p><p>实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb<br>命令：0,30 18-23 * * * /etc/init.d/smb restart</p><p>实例10：每星期六的晚上11 : 00 pm重启smb<br>命令：0 23 * * 6 /etc/init.d/smb restart</p><p>实例11：每一小时重启smb<br>命令：* */1 * * * /etc/init.d/smb restart</p><p>实例12：晚上11点到早上7点之间，每隔一小时重启smb<br>命令：* 23-7/1 * * * /etc/init.d/smb restart</p><p>实例13：每月的4号与每周一到周三的11点重启smb<br>命令：0 11 4 * mon-wed /etc/init.d/smb restart</p><p>实例14：一月一号的4点重启smb<br>命令：0 4 1 jan * /etc/init.d/smb restart</p><p>实例15：每小时执行/etc/cron.hourly目录内的脚本<br>命令：01   *   *   *   *     root run-parts /etc/cron.hourly<br>说明：<br>run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了</p></code></pre><p></p></details><h2 id="cron实现原理"><a href="#cron实现原理" class="headerlink" title="cron实现原理"></a>cron实现原理</h2><h3 id="基本原理图解"><a href="#基本原理图解" class="headerlink" title="基本原理图解"></a>基本原理图解</h3><p>fork 进程 + sleep 轮询<br><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img_1.png"><br>Cron每分钟做一次检查，看看哪个命令可执行。</p><p>从上图可以看到，有4次fork，这4次fork分别是：</p><ul><li>第一个fork，让Cron自己成为Daemon进程，即成为守护进程；</li><li>第二个fork，当Cron检查到有命令需要执行时被创建，但注意它并不执行命令，执行命令由它的子进程来做；</li><li>第三个fork，有些版本调用的是vfork，但有些版本却是fork，它是负责执行Cron命令的进程，即会调用execle()的进程；</li><li>第四个fork不是必须的，只有为Cron命令配置了标准输入才会用：<br><code>*/1 * * * * /tmp/X/x%1234567890</code><br>像上面有个百分符“%”，后面跟一串，则会有第四个fork，它的作用是将“%”后面的内容作为标准输入传递给第三个fork出来的进程。</li></ul><p>注意fork出来的进程没有忽略(ignore)管道信号(SIGPIPE)，所以如果遇到SIGPIPE，则会导致进程无声无息的退出，比如标准输主输出重定向管道的读端被关闭了，写时就会触发SIGPIPE。</p><p>实践中，可能会遇到child_process()在做上述所说的第三个fork前因SIGPIPE信号退出，导致难以理解的问题。其中一个现象 是：Cron命令被执行了若干次，但之后再也不执行了，原因在于第二个fork出来的进程因SIGPIPE退出了，导致没有进行第三个fork，因此 Cron命令没有被调用(总是由execle()调用)。</p><p><img src="/2020/03/14/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img_2.png"></p><h3 id="一个诡异的问题"><a href="#一个诡异的问题" class="headerlink" title="一个诡异的问题"></a>一个诡异的问题</h3><p>你有可能遇到这样的情况，假设在cron中有如下一条配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo hello &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>观察到它正常运行几次后，就不再运行了，或者一次也不能，但确认无其它问题，因此十分诡异。</p><p>这个问题的原因，有可能是因为有共享库Hook了cron，共享库代码触发了SIGPIPE，导致了第二个fork出的进程退出，没来得及执行vfork。</p><p>fork出来的子进程，没有对SIGPIPE进行任何处理，默认行为是悄悄退出进程。通过修改/etc/ld.so.preload，可以将共享库注入到非关联的进程中，可通过ldd观察到这种依赖，使用LD_PRELOAD也可以达到同样的效果。</p><h3 id="crontab编辑后cron异常"><a href="#crontab编辑后cron异常" class="headerlink" title="crontab编辑后cron异常"></a>crontab编辑后cron异常</h3><p>使用crontab编辑后，cron卡住不动(不是指进程卡住了，而是指命令没有被调用)，原因可能是因为“tcb table full”，最简单的办法是重启cron。</p><p>建议避免写下面这样的嵌套命令语句，它有可能导致cron不能正常工作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo &quot;`date +%H:%M:%S` hello&quot; &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>“echo”中嵌套了“date”，可以改成脚本调用，或者不嵌套命令，如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo &quot;hello&quot; &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>一个现象是有一个cron子进程(如下述的14786)不退出了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ps -ef|grep cron</span></span><br><span class="line"></span><br><span class="line">root     10325     1  0 15:08 ?        00:00:00 /usr/sbin/cron</span><br><span class="line">root     14786 10325  0 15:13 ?        00:00:00 /usr/sbin/cron</span><br></pre></td></tr></table></figure><p>gdb看到的调用栈为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">0  0xffffe410 <span class="keyword">in</span> __kernel_vsyscall ()</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1  0xb7e88a63 <span class="keyword">in</span> __read_nocancel () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">2  0xb7e38e38 <span class="keyword">in</span> _IO_file_read_internal () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">3  0xb7e3a0bb <span class="keyword">in</span> _IO_new_file_underflow () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">4  0xb7e3a7fb <span class="keyword">in</span> _IO_default_uflow_internal () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">5  0xb7e3bb2d <span class="keyword">in</span> __uflow () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">6  0xb7e35b7b <span class="keyword">in</span> getc () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">7  0x80005d73 <span class="keyword">in</span> ?? () from /usr/sbin/cron</span></span><br></pre></td></tr></table></figure><p>strace看到如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> strace -f -p 14786</span></span><br><span class="line"></span><br><span class="line">Process 14786 attached</span><br><span class="line">read(7,</span><br></pre></td></tr></table></figure><p>借助lsof可以看到：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cron    14786 root    7r  FIFO        0,6         117960708 pipe</span><br></pre></td></tr></table></figure><p>为一个管道，read()挂住的原因可能是因为管道另一端所在进程调用_exit()退出而不是调用exit()退出。</p><p>这个时候只有人工kill这个挂起的cron子进程。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 定时调度 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>标签</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
