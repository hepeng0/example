<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>沉默者</title>
  
  <subtitle>路漫漫其修远兮，吾将上下而求索</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-08-12T10:29:21.512Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>何鹏 [smile.hepeng@qq.com]</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>JVM基础系列之运行时内存分配模型</title>
    <link href="http://example.com/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/"/>
    <id>http://example.com/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/</id>
    <published>2021-08-12T08:32:34.000Z</published>
    <updated>2021-08-12T10:29:21.512Z</updated>
    
    <content type="html"><![CDATA[<h3 id="JVM是什么"><a href="#JVM是什么" class="headerlink" title="JVM是什么"></a>JVM是什么</h3><p>而对于不同的操作系统，系统操作指令集（CPU原语）往往是不同的。JVM即Java虚拟机，是基于C/C++开发的一种抽象计算机，它对不同平台的系统指令集进行封装，对外提供了一套固定的指令集，在运行时操作各种内存区域，使JAVA成为可以跨平台的语言。</p><p><code>一般来说，使用特定编译器编译的程序只能在对应的平台运行，这里也可以说编译器是与平台相关的，编译后的文件也是与平台相关的。我们说的语言跨平台是编译后的文件跨平台，而不是源程序跨平台。</code></p><p>虚拟机有很多种，不同厂商提供了不同实现，只要遵循虚拟机规范即可，目前我们所说的虚拟机一般指的是Hot Spot。</p><p>JVM对Java语言一无所知，只知道一种特定的二进制格式，即类文件格式，我们写好的程序最终交给JVM执行的时候会被编译成二进制格式，JVM只认识二进制格式，所以任何语言只要编译后的格式符合要求，都可以在JVM上运行。</p><p><strong>JVM 组成部分</strong></p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img.png"></p><ul><li>类加载器，在 JVM 启动时或者类运行时将需要的 class 加载到 JVM 中。</li><li>内存区，将内存划分成若干个区以模拟实际机器上的存储、记录和调度功能模块，如实际机器上的各种功能的寄存器或者 PC 指针的记录器等。</li><li>执行引擎，执行引擎的任务是负责执行 class 文件中包含的字节码指令，相当于实际机器上的 CPU 。</li><li>本地方法调用，调用 C 或 C++ 实现的本地方法的代码返回结果。</li></ul><p>一个Java类在经过编译好类加载之后，会将加载后的数据放入运行时数据区域，这样我们在运行程序时就可以直接从运行时数据区域中读取信息。</p><h3 id="JVM运行时数据区域详解"><a href="#JVM运行时数据区域详解" class="headerlink" title="JVM运行时数据区域详解"></a>JVM运行时数据区域详解</h3><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_1.png"></p><p>JVM 内存布局规定了 Java 在运行过程中内存申请、分配、管理的策略 ，保证了 JVM 的高效稳定运行。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_8.png"></p><p>如果按照线程是否共享来分类的话，如下图所示：</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_9.png"></p><h4 id="线程私有"><a href="#线程私有" class="headerlink" title="线程私有"></a>线程私有</h4><h5 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h5><ul><li>字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。</li><li>在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储。<code>由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，CPU 只有把数据装载到寄存器才能够运行。寄存器存储指令相关的现场信息，由于CPU 时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。</code><ul><li>每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器用来存放执行指令的偏移量和行号指示器等，线程执行或恢复都要依赖程序计数器。</li></ul></li><li>如果该方法不是Native方法，即PC寄存器会记录当前正在执行的java虚拟机指令的地址; 如果线程当前执行的方法是本地的，那么java虚拟机的PC寄存器的值就是Undefined。</li><li><strong>唯一不会发生OOM的区</strong>，随线程创建而创建、随线程死亡而死亡，因此不需要进行 GC。</li></ul><h5 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h5><ul><li><p>Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：<strong>局部变量表、操作数栈、动态链接、方法出口信息</strong>。</p></li><li><p>局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用</p><ul><li><p>存放方法参数和方法内部定义的局部变量</p><p><code>所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</code> </p><ul><li><p>如果局部变量是Java的8种基本基本数据类型，则存在局部变量表中，如果是引用类型。如new出来的String，局部变量表中存的是引用，而实例在堆中。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_10.png"></p></li></ul></li></ul></li><li><p>操作数栈</p><ul><li>操作数栈（Operand Stack）看名字可以知道是一个栈结构。</li><li>Java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。</li><li>当JVM为方法创建栈帧的时候，在栈帧中为方法创建一个操作数栈，保证方法内指令可以完成工作。</li></ul><details><summary>用实操理解一下</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* <span class="doctag">@author</span> Richard_yyf</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OperandStackTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> a + b;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译生成.class文件之后，再反汇编查看汇编指令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">javac OperandStackTest.java</span><br><span class="line">javap -v OperandStackTest.class &gt; 1.txt</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public int sum(int, int);</span><br><span class="line">  descriptor: (II)I</span><br><span class="line">  flags: ACC_PUBLIC</span><br><span class="line">  Code:</span><br><span class="line">    stack=2, locals=3, args_size=3 // 最大栈深度为2 局部变量个数为3</span><br><span class="line">       0: iload_1 // 局部变量1 压栈</span><br><span class="line">       1: iload_2 // 局部变量2 压栈</span><br><span class="line">       2: iadd    // 栈顶两个元素相加，计算结果压栈</span><br><span class="line">       3: ireturn</span><br><span class="line">    LineNumberTable:</span><br><span class="line">      line 10: 0</span><br></pre></td></tr></table></figure></details></li><li><p>动态链接</p><ul><li>每个栈帧中包含一个在常量池中<strong>对当前方法的引用</strong>， 目的是<strong>支持方法调用过程的动态连接</strong>。</li></ul></li><li><p>方法返回地址</p><p>方法执行时有两种退出情况：</p><ul><li>正常退出，即正常执行到任何方法的返回字节码指令，如 RETURN、IRETURN、ARETURN等</li><li>异常退出</li></ul><p>无论何种退出情况，都将返回至方法当前被调用的位置。方法退出的过程相当于弹出当前栈帧，退出可能有三种方式：</p><ul><li>返回值压入上层调用栈帧</li><li>异常信息抛给能够处理的栈帧</li><li>PC 计数器指向方法调用后的下一条指令</li></ul><p>扩展阅读： <a href="https://link.juejin.cn/?target=https://louluan.blog.csdn.net/article/details/50412126">JVM机器指令集图解</a></p></li><li><p>为执行字节码服务</p></li><li><p>StackOverFlowError（不允许动态扩展，栈深度大于虚拟机允许的栈深度） 和 OutOfMemoryError （允许动态扩展，内存不足）</p></li><li><p>方法执行时入栈，方法执行完出栈，入栈出栈的时机很明确，所以这块区域不需要进行 GC。<br><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img4.png"></p></li><li><p>扩展阅读： <a href="https://www.cnblogs.com/noKing/p/8167700.html">栈帧</a></p></li><li><p>扩展阅读： <a href="https://www.pianshen.com/article/9519386034/">逃逸分析-栈上分配-TLAB</a>, 对于开启逃逸分析的程序而言，不会逃逸的对象也会分配在栈上。</p></li></ul><h5 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h5><ul><li>与虚拟机栈相似，为执行Native服务。</li><li>本地方法栈和虚拟机栈在有的虚拟机是合在一起的，例如Hot Spot虚拟机。</li></ul><h4 id="线程共享"><a href="#线程共享" class="headerlink" title="线程共享"></a>线程共享</h4><h5 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h5><ul><li><p>所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放<strong>对象实例和数组</strong>，<em>几乎</em> 所有的对象实例以及数组都在这里分配内存(随着JIT编译器的发展和逃逸分析技术的成熟，这个说法也不是那么绝对)。</p><p>  <img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/cb25f0d4c52a9ffca1925e9694c6954d.jpg" alt="java堆空间"></p></li><li><p>java8后永久代已移除。</p></li><li><p>堆中的对象永远不会被显式释放，必须由GC回收。GC主要区域，也叫GC堆，采用分代垃圾收集算法（年轻代&amp;老年代）。</p></li><li><p>Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。</p><p><code>值得注意的是，在通常情况下，服务器在运行过程中，堆空间不断地扩容与回缩，会形成不必要的系统压力 所以在线上生产环境中 JVM的Xms和 Xmx会设置成同样大小，避免在GC 后调整堆大小时带来的额外压力。</code></p></li></ul><h5 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h5><ul><li>方法区也是所有线程共享。主要用于存储<strong>类的信息、常量池、方法数据、方法代码</strong>等。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”。</li><li>JDK 1.8中移除整个永久代，取而代之的是一个叫元空间（Metaspace）的区域, 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。  空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。</li><li>如果方法区的内存无法满足分配请求时也会抛出OutOfMemoryError</li><li>扩展阅读：<a href="https://www.cnblogs.com/paddix/p/5309550.html">Java8内存模型—永久代(PermGen)和元空间(Metaspace)</a></li></ul><p><em>运行时常量池</em></p><p>方法区的一部分，用于存储编译生成的字面量（基本数据类型或被final修饰的常量或字符串）和符号引用，类或接口的运行时常量池是在java虚拟机创建类或接口时创建的。</p><ul><li>jdk1.6及之前: Java中的字符串是放在方法区中的运行时常量池内，</li><li>jdk1.7以后: 将字符串常量池拿出来放在了堆中。</li></ul><details><summary>一个有趣的例子</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GcDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String [] args)</span> </span>&#123;</span><br><span class="line">        String str = <span class="keyword">new</span> String(<span class="string">&quot;lonely&quot;</span>)+<span class="keyword">new</span> String(<span class="string">&quot;wolf&quot;</span>);</span><br><span class="line">        System.out.println(str == str.intern());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码在jdk1.6中打印false，在jdk1.7和jdk1.8中打印true。 关于intern()方法：</p><ul><li>JDK1.6：调用String.intern()方法，会先去检查常量池中是否存在该字符串，如果不存在，则会在方法区中创建一个字符串，而new String()创建的字符串在堆中，两个字符串的地址当然不相等。</li><li>JDK1.8：字符串常量池从方法区的运行时常量池移到了堆中，调用String.intern()方法，首先会检查常量池是否存在，如果不存在，那么就会创建一个常量，并将引用指向堆，也就是说不会再重新创建一个字符串对象了，两者都会指向堆中的对象，所以返回true。</li></ul><p>只有一个new String()，产生两个对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GcDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String [] args)</span> </span>&#123;</span><br><span class="line">        String str = <span class="keyword">new</span> String(<span class="string">&quot;lonely&quot;</span>);</span><br><span class="line">        System.out.println(str == str.intern());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只有一个new String()，在jdk1.7和jdk1.8也会返回false，我们假设一开始字符串常量池没有任何字符串，执行一个new String(“lonely”)会产生两个对象，一个在堆，一个在字符串常量池。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_5.png"></p><p>String.intern()先检查字符串常量池，发现存在”lonely”的字符串，所以直接返回，这时候两个地址不一样，所以返回false。</p><ul><li><p>new String(“lonely”)+new String(“wolf”)会产生5个对象，2个在字符串常量池，3个在堆。</p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_6.png" class title="img.png"><ul><li>如果在1.7和1.8中会检查字符串常量池，发现没有lonelywolf的字符串，所以会在字符串常量池创建一个，指向堆中的字符串。</li><li>JDK1.6中不会指向堆，会重新创建一个lonelywolf的字符串放到字符串常量池，所以才会产生不同的结果。</li></ul></li></ul></details><h5 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h5><ul><li>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。</li><li>使用Native函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。  这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。</li><li>Java8后<strong>方法区的实现-元空间就在使用了直接内存实现</strong>（不进行GC进而提高了性能）</li><li>Code Cache<ul><li><strong>JVM代码缓存是JVM将其字节码存储为本机代码的区域</strong>。我们将可执行本机代码的每个块称为 nmethod 。该 nmethod可能是一个完整的或内联Java方法。</li><li>实时（JIT）编译器是代码缓存区域的最大消费者。这就是为什么一些开发人员将此内存称为JIT代码缓存的原因。 </li><li>一般情况下我们是不会关心这部分区域的且大部分开发人员对这块区域也不熟悉。如果这块区域OOM了，在日志里面就会看到 java.lang.OutOfMemoryError code cache。</li><li>扩展阅读: <a href="https://link.juejin.cn/?target=https://www.baeldung.com/jvm-code-cache">Introduction to JVM Code Cache</a></li></ul></li><li>也可能导致 OutOfMemoryError 异常出现。</li><li>扩展阅读：<a href="https://link.juejin.cn/?target=https://www.jianshu.com/p/35cf0f348275">堆外内存回收</a></li></ul><h3 id="从进程与线程的角度理解JVM运行时数据区设计原理"><a href="#从进程与线程的角度理解JVM运行时数据区设计原理" class="headerlink" title="从进程与线程的角度理解JVM运行时数据区设计原理"></a>从进程与线程的角度理解JVM运行时数据区设计原理</h3><p>首先，我们回顾一下进程与线程的区别与联系:</p><p><strong>进程 = 线程+内存+文件/网络句柄</strong></p><ul><li>这里的内存是逻辑内存，指的是内存的寻址空间。每个进程的内存是相互独立的。</li><li>文件/网络句柄是所有的进程所共有的，例如打开同一个文件，去抢同一个网络的端口这样的操作是被允许的</li></ul><p><strong>线程 = 栈+PC+TLS</strong></p><ul><li>通常都是说调用堆栈，调用堆栈就是调用栈的意思(这里的堆是没有含义的)。每次调用的时候，会把所有的参数和返回地址压入到栈中。</li><li>Program Counter: 程序计数器，我们的进程只是一个容器。PC就是指向当前的指令，而这个指令是放在内存中。每个线程都有一串自己的指针，去指向自己当前所在内存的指针。</li><li>thread local storage: 线程独立的内存就是TLS，可以用来存储我们线程所独有的数据。</li></ul><p><strong>总结如下</strong></p><ol><li>线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；</li><li>一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线；</li><li>进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见；</li><li>调度和切换：线程上下文切换比进程上下文切换要快得多。</li></ol><p>线程与进程关系的示意图：</p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_2.png" class><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_3.png" class><p><strong>对于一个JAVA进程而言</strong>：</p><ul><li>JAVA进程间的内存分配保持独立</li><li>JAVA同进程的多线程间共享代码段（方法区）、数据集（堆）</li><li>JAVA各线程分别维护自己的寄存器（程序计数器）和方法栈（分为本地方法栈和虚拟机栈）</li></ul><h3 id="从操作系统层面理解JVM内存区域"><a href="#从操作系统层面理解JVM内存区域" class="headerlink" title="从操作系统层面理解JVM内存区域"></a>从操作系统层面理解JVM内存区域</h3><h4 id="系统进程占用的物理内存高于-Xmx"><a href="#系统进程占用的物理内存高于-Xmx" class="headerlink" title="系统进程占用的物理内存高于-Xmx"></a>系统进程占用的物理内存高于-Xmx</h4><p>在实际运行过程中，我们通常会发现: 系统进程占用的物理内存(Res/Rss)会大于设置的Xmx值</p><p>实际上，-Xmx和-Xms参数实际上只是Java堆对象将会占用的内存，而堆只是影响Java程序占用内存数量的一个因素。</p><p>除了堆，影响Java程序所占用内存的因素还包括: 栈、永生代、JVM本身、NIO中的DirectBuffer等。</p><p>因此，一般使用Xmx分配给JVM的，肯定不能太多。</p><p>而且，在操作系统上，运行的不仅仅是JVM应用，还会有其他一些守护进程，比如各种日志收集工具、监控工具、安全工具等。它们虽然占用的内存不是很多，但累加起来还是比较可观的。JVM内存和操作系统的剩余内存是一个此消彼长的关系，这些小内存挤占了JVM的发挥空间，就容易出问题。</p><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/img_7.png"></p><p>JVM是我们的主体，所以要把它放在主人公的位置。这种划分方式，就可以把整个内存搞成JVM内存、操作系统物理内存、SWAP三个部分。</p><p>当JVM和其他程序占满了物理内存，接着占满了SWAP内存（交换分区一般不开，此处不展开），当在需要申请内存空间的时候，操作系统发现没有可用的内存空间了。</p><p>这个时候，Linux会启动oom-killer，杀死占用内存最大的进程，这个时候大概率我们的JVM进程。</p><p>由于这个OOM为操作系统本身的OOM，这个时候会出现的现象为: <strong>java进程死了，但是没有留下任何日志</strong></p><p><code>此日志可以通过dmesg命令找到，属于操作系统范畴</code></p><h4 id="对内存做一些更细致的划分"><a href="#对内存做一些更细致的划分" class="headerlink" title="对内存做一些更细致的划分"></a>对内存做一些更细致的划分</h4><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/%E5%86%85%E5%AD%98.png"></p><ul><li>堆内内存: 是我们平常打交道最多的地方，因为我们大部分Java对象，都是在堆上分配的。<ul><li>一旦有溢出问题，使用jmap + mat等一系列猛如虎的操作，就可以方便快捷的发现问题。</li></ul></li><li>堆外内存<ul><li>元空间<ul><li>jdk8以后才加入的，用来替换原来的永久代，用于存储那些变动很少的数据，稳定为主。</li><li>比如我们在jvm启动时，加载的那些class文件；以及在运行时，动态生成的代理类。</li><li>默认是没有上限的，极端情况下，会一直挤占操作系统的剩余内存。</li></ul></li><li>CodeCache<ul><li>JIT是JVM一个非常重要的特性，CodeCahe存放的，就是即时编译器所生成的二进制代码。</li><li>当然，JNI的代码也是放在这里的。</li><li>在不同的平台，大小都是不一样的，但一般够用了。<code>调的非常小的情况下，JVM不会溢出，这个区域也不会溢出，但是会退化成解释型执行模式，速度和JIT不可同日而语，慢个数量级也是可能的</code></li></ul></li><li>本地内存<ul><li>网络内存<ul><li>可以认为它是操作系统内核所占用的内存，也可以认为是JVM进程占用的内存</li><li>如果你的系统并发非常高，这部分内存的占用也是比较多的。因为连接一般对应着网卡的数据缓冲区，还有文件句柄的耗费。</li></ul></li><li>线程内存<ul><li>如果你造的线程非常多，JVM除了占用Thread对象本身很小的一部分堆内存，大部分是以轻量级进程的方式存在于操作系统。</li><li>这同样是一个积少成多的内存区域，但一般不会发生问题</li></ul></li><li>JNI内存<ul><li>上面谈到CodeCache存放的JNI代码，JNI内存就是指的这部分代码所malloc的具体内存。 </li><li>比如Java的zip库，就不是在JVM的堆里完成的，而是开辟了一个堆外的缓冲池进行运算。</li></ul></li><li>直接内存<ul><li>指的是使用了Java的直接内存API，进行操作的内存。</li><li>这部分内存可以受到JVM的管控，比如ByteBuffer类所做的事情。</li><li>ByteBuffer底层是用的unsafe, 但unsafe是不受直接内存的管控的，因此并不会造成JVM直接内存溢出，反而会造成操作系统内存溢出。。</li></ul></li></ul></li></ul></li></ul><h4 id="如何排查操作系统内存"><a href="#如何排查操作系统内存" class="headerlink" title="如何排查操作系统内存"></a>如何排查操作系统内存</h4><p>linux下有一个命令lsof，可以看到JVM进程所关联的所有句柄信息，一般可作为参考。</p><p>近一步，使用pmap函数，即可观测到具体的内存分布。但是不要怕，有很多是共享内存。</p><p>具体排查思路可以参考 <a href="/2020/06/18/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/" title="JAVA线上故障排查全套路">JAVA线上故障排查全套路</a> 中的堆外内存溢出。</p><h4 id="内存区域控制参数"><a href="#内存区域控制参数" class="headerlink" title="内存区域控制参数"></a>内存区域控制参数</h4><p><img src="/2021/08/12/JAVA%E5%9F%BA%E7%A1%80/JVM%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E5%8F%82%E6%95%B0.png"></p><ul><li>堆  <code>-Xmx  -Xms</code></li><li>元空间 <code>-XX:MaxMetaspaceSize  -XX:MetaspaceSize</code></li><li>栈 <code>-Xss</code></li><li>直接内存  <code>-XX:MaxDirectMemorySize</code></li><li>JIT编译后代码存放 <code>-XX:ReservedCodeCacheSize</code></li><li>其他堆外内存 <code>无法控制！随缘吧</code></li></ul><p>可以看到，堆外内存的占用，其实还是比较多的。如果你太贪婪，整个内存很容易就玩玩。</p><p>一般的，我们使用操作系统的2/3作为堆空间，是比较合理的。这是一个经验值。比如6GB的内存，你分配给JVM的，最好不要超过4GB。</p><p>还有，我们上面谈到的swap交换分区，在高并发应用中，一般是关掉的。因为它会造成频繁的页交换，在GC的时候，会引起严重的卡顿。</p><p>但要辩证的思维看待问题。对于低频的，对内存大小有非常大的依赖的情况下，SWAP不仅要开，还要开的大一些。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;JVM是什么&quot;&gt;&lt;a href=&quot;#JVM是什么&quot; class=&quot;headerlink&quot; title=&quot;JVM是什么&quot;&gt;&lt;/a&gt;JVM是什么&lt;/h3&gt;&lt;p&gt;而对于不同的操作系统，系统操作指令集（CPU原语）往往是不同的。JVM即Java虚拟机，是基于C/C++开发</summary>
      
    
    
    
    <category term="JAVA基础" scheme="http://example.com/categories/JAVA%E5%9F%BA%E7%A1%80/"/>
    
    
    <category term="JVM" scheme="http://example.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>代码实用小套路之Java 性能优化的一些细节</title>
    <link href="http://example.com/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BJava-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82/"/>
    <id>http://example.com/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BJava-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82/</id>
    <published>2021-08-12T01:40:24.000Z</published>
    <updated>2021-08-12T02:48:03.858Z</updated>
    
    <content type="html"><![CDATA[<p>在JAVA程序中，性能问题的大部分原因并不在于JAVA语言，而是程序本身。养成良好的编码习惯非常重要，能够显著地提升程序性能。</p><ol><li><p>尽量在合适的场合使用单例</p><p> 使用单例可以减轻加载的负担，缩短加载的时间，提高加载的效率，但并不是所有地方都适用于单例</p><p> 简单来说，单例主要适用于以下三个方面：</p><ul><li>控制资源的使用，通过线程同步来控制资源的并发访问；</li><li>控制实例的产生，以达到节约资源的目的；</li><li>控制数据共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信。</li></ul></li><li><p>尽量避免随意使用静态变量</p><p> 当某个对象被定义为static变量所引用，那么GC通常是不会回收这个对象所占有的内存，如:</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> B b = <span class="keyword">new</span> B();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时静态变量 b 的生命周期与A类同步，如果A类不会卸载，那么b对象会常驻内存，直到程序终止。</p></li><li><p>尽量避免过多过常地创建Java对象</p><p>尽量避免在经常调用的方法，循环中new对象，由于系统不仅要花费时间来创建对象，而且还要花时间对这些对象进行垃圾回收和处理。</p><p>在我们可以控制的范围内，最大限度地重用对象，最好能用基本的数据类型或数组来替代对象。</p></li><li><p>尽量使用final修饰符</p><p>带有final修饰符的类是不可派生的。在JAVA核心API中，有许多应用final的例子，例如java、lang、String，为String类指定final防止了使用者覆盖length()方法。</p><p>另外，如果一个类是final的，则该类所有方法都是final的。java编译器会寻找机会内联（inline）所有的final方法（这和具体的编译器实现有关），此举能够使性能平均提高50%。</p><p>如：让访问实例内变量的getter/setter方法变成”final：简单的getter/setter方法应该被置成final，这会告诉编译器，这个方法不会被重载，所以，可以变成”inlined”,例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MAF</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSize</span> <span class="params">(<span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">     _size = size;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> _size;</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"><span class="comment">// 更正</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DAF_fixed</span> </span>&#123;</span><br><span class="line">   <span class="function"><span class="keyword">final</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSize</span> <span class="params">(<span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">     _size = size;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> _size;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>尽量使用局部变量</p><p>调用方法时传递的参数以及在调用中创建的临时变量都保存在栈（Stack）中，速度较快；其他变量，如静态变量、实例变量等，都在堆（Heap）中创建，速度较慢。</p></li><li><p>尽量处理好包装类型和基本类型两者的使用场所</p><p>虽然包装类型和基本类型在使用过程中是可以相互转换，但它们两者所产生的内存区域是完全不同的</p><ul><li><p>基本类型数据产生和处理都在栈中处理，包装类型作为对象是在堆中产生实例（开启逃逸分析小对象也在栈上分配?）。</p></li><li><p>在集合类对象，有对象方面需要的处理适用包装类型，其他的处理提倡使用基本类型。</p></li></ul></li><li><p>慎用synchronized，尽量减小synchronize的方法</p><p>都知道，实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。</p><p>synchronize方法被调用时，直接会把当前对象锁了，在方法执行完之前其他线程无法调用当前对象的其他方法。</p><p>所以，synchronize的方法尽量减小，并且应<strong>尽量使用方法同步代替代码块同步</strong>。</p></li><li><p>尽量不要使用finalize方法</p><p>实际上，将资源清理放在finalize方法中完成是非常不好的选择</p><p>由于GC的工作量很大，尤其是回收Young代内存时，大都会引起应用程序暂停，所以再选择使用finalize方法进行资源清理，会导致GC负担更大，程序运行效率更差。</p></li><li><p>尽量使用基本数据类型代替对象</p><p>String str = “hello”;</p><p>上面这种方式会创建一个“hello”字符串，而且JVM的字符缓存池还会缓存这个字符串；</p><p>String str = new String(“hello”);</p><p>此时程序除创建字符串外，str所引用的String对象底层还包含一个char[]数组，这个char[]数组依次存放了h,e,l,l,o</p></li><li><p>多线程在未发生线程安全前提下应尽量使用HashMap、ArrayList</p></li></ol><p>   HashTable、Vector等使用了同步机制，降低了性能。</p><ol start="11"><li>尽量合理的创建HashMap</li></ol><p>   当你要创建一个比较大的hashMap时，充分利用这个构造函数</p><p>   public HashMap(int initialCapacity, float loadFactor);</p><p>   避免HashMap多次进行了hash重构,扩容是一件很耗费性能的事</p><p>   在默认中initialCapacity只有16，而loadFactor是 0.75，需要多大的容量，你最好能准确的估计你所需要的最佳大小，同样的Hashtable，Vectors也是一样的道理。</p><ol start="12"><li>尽量减少对变量的重复计算</li></ol><p>   如：</p><p>   <code>for(int i=0;i&lt;list.size();i++)</code></p><p>   应该改为：<br>   <code>for(int i=0,len=list.size();i&lt;len;i++)</code></p><p>   并且在循环中应该避免使用复杂的表达式，在循环中，循环条件会被反复计算，如果不使用复杂表达式，而使循环条件值不变的话，程序将会运行的更快。</p><ol start="13"><li>尽量避免不必要的创建</li></ol><p>   如：</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A a = new A();</span><br><span class="line">if(i==1)&#123;</span><br><span class="line">   list.add(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>   应该改为：</p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if(i==1)&#123;</span><br><span class="line">   A a = new A();</span><br><span class="line">   list.add(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="14"><li>尽量在finally块中释放资源</li></ol><p>   程序中使用到的资源应当被释放，以避免资源泄漏，这最好在finally块中去做。不管程序执行的结果如何，finally块总是会执行的，以确保资源的正确关闭。</p><ol start="15"><li>尽量使用移位来代替’a/b’或者’a*b’的操作</li></ol><p>   “/“和”*”是一个代价很高的操作，使用移位的操作将会更快和更有效</p><p>   如：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int num = a / 4;</span><br><span class="line">int num = a / 8;</span><br><span class="line">int num = a * 4;</span><br><span class="line">int num = a * 8;</span><br></pre></td></tr></table></figure></p><p>   应该改为：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int num = a &gt;&gt; 2;</span><br><span class="line">int num = a &gt;&gt; 3;</span><br><span class="line">int num = a &lt;&lt; 2;</span><br><span class="line">int num = a &lt;&lt; 3;</span><br></pre></td></tr></table></figure></p><p>   但注意的是<strong>使用移位应添加注释</strong>，因为移位操作不直观，比较难理解。</p><ol start="16"><li>尽量确定StringBuffer的容量</li></ol><p>   StringBuffer 的构造器会创建一个默认大小（通常是16）的字符数组。</p><p>   在使用中，如果超出这个大小，就会重新分配内存，创建一个更大的数组，并将原先的数组复制过来，再丢弃旧的数组。</p><p>   在大多数情况下，你可以在创建 StringBuffer的时候指定大小，这样就避免了在容量不够的时候自动增长，以提高性能。如：</p><p>   StringBuffer buffer = new StringBuffer(1000);</p><ol start="17"><li>尽量早释放无用对象的引用</li></ol><p>   大部分时，方法局部引用变量所引用的对象会随着方法结束而变成垃圾，因此，大部分时候程序无需将局部，引用变量显式设为null。例如：</p><p>   Java代码<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Public void test()&#123;</span><br><span class="line">   Object obj = new Object();</span><br><span class="line">   ……</span><br><span class="line">   Obj = null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>   上面这个就没必要了，随着方法test()的执行完成，程序中obj引用变量的作用域就结束了。</p><p>   但是如果是改成下面：<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Public void test()&#123;</span><br><span class="line">   Object obj = new Object();</span><br><span class="line">   ……</span><br><span class="line">   Obj = null;</span><br><span class="line">   //执行耗时，耗内存操作；或调用耗时，耗内存的方法</span><br><span class="line">   ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>   这时候就有必要将obj赋值为null，可以尽早的释放对Object对象的引用。</p><ol start="18"><li>尽量避免使用二维数组</li></ol><p>   二维数据占用的内存空间比一维数组多得多，大概10倍以上。</p><ol start="19"><li>尽量避免使用split</li></ol><p>   除非是必须的，否则应该避免使用split，split由于支持正则表达式，所以效率比较低</p><p>   如果是频繁的几十，几百万的调用将会耗费大量资源，如果确实需要频繁的调用split，可以考虑使用apache的StringUtils.split(string,char)，频繁split的可以缓存结果</p><ol start="20"><li>ArrayList &amp; LinkedList</li></ol><p>   一个是线性表，一个是链表，一句话，随机查询尽量使用ArrayList，ArrayList优于LinkedList，LinkedList还要移动指针，添加删除的操作LinkedList优于ArrayList，ArrayList还要移动数据</p><p>   不过这是理论性分析，事实未必如此，重要的是理解好2者得数据结构，对症下药。</p><ol start="21"><li>尽量使用System.arraycopy ()代替通过来循环复制数组</li></ol><p>   System.arraycopy() 要比通过循环来复制数组快的多。</p><ol start="22"><li>尽量缓存经常使用的对象</li></ol><p>   尽可能将经常使用的对象进行缓存，可以使用数组，或HashMap的容器来进行缓存，但这种方式可能导致系统占用过多的缓存，性能下降</p><p>   推荐可以使用一些第三方的开源工具，如EhCache，Oscache进行缓存，他们基本都实现了FIFO/FLU等缓存算法。</p><ol start="23"><li>尽量避免非常大的内存分配</li></ol><p>   有时候问题不是由当时的堆状态造成的，而是因为分配失败造成的。分配的内存块都必须是连续的，而随着堆越来越满，找到较大的连续块越来越困难。</p><ol start="24"><li>慎用异常</li></ol><p>   当创建一个异常时，需要收集一个栈跟踪(stack track)，这个栈跟踪用于描述异常是在何处创建的。</p><p>   构建这些栈跟踪时需要为运行时栈做一份快照，正是这一部分开销很大。</p><p>   当需要创建一个 Exception 时，JVM 不得不说：先别动，我想就您现在的样子存一份快照，所以暂时停止入栈和出栈操作。栈跟踪不只包含运行时栈中的一两个元素，而是包含这个栈中的每一个元素。</p><p>   如果您创建一个 Exception ，就得付出代价，好在捕获异常开销不大，因此可以使用 try-catch 将核心内容包起来。</p><p>   从技术上讲，你甚至可以随意地抛出异常，而不用花费很大的代价。招致性能损失的并不是 throw 操作——尽管在没有预先创建异常的情况下就抛出异常是有点不寻常。</p><p>   真正要花代价的是创建异常，幸运的是，好的编程习惯已教会我们，不应该不管三七二十一就抛出异常。异常是为异常的情况而设计的，使用时也应该牢记这一原则。</p><ol start="25"><li>尽量重用对象</li></ol><p>   特别是String对象的使用中，出现字符串连接情况时应使用StringBuffer代替，由于系统不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理。因此生成过多的对象将会给程序的性能带来很大的影响。</p><ol start="26"><li>不要重复初始化变量</li></ol><p>   默认情况下，调用类的构造函数时，java会把变量初始化成确定的值，所有的对象被设置成null，整数变量设置成0，float和double变量设置成0.0，逻辑值设置成false。</p><p>   当一个类从另一个类派生时，这一点尤其应该注意，因为用new关键字创建一个对象时，构造函数链中的所有构造函数都会被自动调用。</p><p>   这里有个注意，给成员变量设置初始值但需要调用其他方法的时候，最好放在一个方法。比如initXXX()中，因为直接调用某方法赋值可能会因为类尚未初始化而抛空指针异常，如：public int state = this.getState()。</p><ol start="27"><li><p>在java+Oracle的应用系统开发中，java中内嵌的SQL语言应尽量使用大写形式，以减少Oracle解析器的解析负担。</p></li><li><p>在java编程过程中，进行数据库连接，I/O流操作，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销。</p></li><li><p>过分的创建对象会消耗系统的大量内存，严重时，会导致内存泄漏</p></li></ol><p>   因此，保证过期的对象的及时回收具有重要意义。JVM的GC并非十分智能，因此建议在对象使用完毕后，手动设置成null。</p><ol start="30"><li>不要在循环中使用Try/Catch语句，应把Try/Catch放在循环最外层</li></ol><p>   Error是获取系统错误的类，或者说是虚拟机错误的类。不是所有的错误Exception都能获取到的，虚拟机报错Exception就获取不到，必须用Error获取。</p><ol start="31"><li>array(数组)和ArrayList的使用</li></ol><p>   array 数组效率最高，但容量固定，无法动态改变，ArrayList容量可以动态增长，但牺牲了效率。</p><ol start="32"><li><p>单线程应尽量使用 HashMap, ArrayList,除非必要，否则不推荐使用HashTable,Vector，它们使用了同步机制，而降低了性能。</p></li><li><p>考虑使用静态方法，如果你没有必要去访问对象的外部，那么就使你的方法成为静态方法。它会被更快地调用，因为它不需要一个虚拟函数导向表。</p></li></ol><p>   这同时也是一个很好的实践，因为它告诉你如何区分方法的性质，调用这个方法不会改变对象的状态。</p><p>34.避免枚举，浮点数的使用。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在JAVA程序中，性能问题的大部分原因并不在于JAVA语言，而是程序本身。养成良好的编码习惯非常重要，能够显著地提升程序性能。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;尽量在合适的场合使用单例&lt;/p&gt;
&lt;p&gt; 使用单例可以减轻加载的负担，缩短加载的时间，提高加载的效率，但并不是所有</summary>
      
    
    
    
    <category term="代码规范" scheme="http://example.com/categories/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
    
    <category term="代码规范" scheme="http://example.com/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>代码实用小套路之Effective Java阅读笔记</title>
    <link href="http://example.com/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BEffective-Java%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2021/08/12/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%94%A8%E5%B0%8F%E5%A5%97%E8%B7%AF%E4%B9%8BEffective-Java%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2021-08-12T01:38:29.000Z</published>
    <updated>2021-08-12T02:49:57.953Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://jiapengcai.gitbooks.io/effective-java/content/">《Effective Java》第三版中文版</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://jiapengcai.gitbooks.io/effective-java/content/&quot;&gt;《Effective Java》第三版中文版&lt;/a&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="代码规范" scheme="http://example.com/categories/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
    
    <category term="代码规范" scheme="http://example.com/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>数据库版本管理之Flyway使用指南</title>
    <link href="http://example.com/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://example.com/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</id>
    <published>2021-08-11T02:13:23.000Z</published>
    <updated>2021-08-12T09:57:21.109Z</updated>
    
    <content type="html"><![CDATA[<p>对于数据库版本管理，我们已经介绍过一款类似工具<a href="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" title="数据库版本管理之Liquibase使用指南">数据库版本管理之Liquibase使用指南</a></p><p>本文将介绍另一种数据库版本管理工具flyway.</p><p>老规矩，首先上<a href="https://flywaydb.org/documentation">官网</a></p><h3 id="Flyway是如何工作的"><a href="#Flyway是如何工作的" class="headerlink" title="Flyway是如何工作的"></a>Flyway是如何工作的</h3><p>flyway 工作原理与 Liquibase 基本一致，其工作流程如下:</p><ol><li>项目启动，应用程序完成数据库连接池的建立后，Flyway自动运行。</li><li>初次使用时，Flyway会创建一个flyway_schema_history表，用于记录sql执行记录。</li><li>Flyway会扫描项目指定路径下(默认是classpath:db/migration)的所有sql脚本，与flyway_schema_history表脚本记录进行比对。如果数据库记录执行过的脚本记录，与项目中的sql脚本不一致，Flyway会报错并停止项目执行。</li><li>如果校验通过，则根据表中的sql记录最大版本号，忽略所有版本号不大于该版本的脚本。再按照版本号从小到大，逐个执行其余脚本。</li></ol><h3 id="在SpringBoot项目使用Flyway"><a href="#在SpringBoot项目使用Flyway" class="headerlink" title="在SpringBoot项目使用Flyway"></a>在SpringBoot项目使用Flyway</h3><ol><li>初始化一个SpringBoot项目，引入MySQL数据库驱动依赖等，并且需要引入Flyway依赖：</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--引入flyway--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.flywaydb<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flyway-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>6.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li><p>添加Flyway配置</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring</span>:<span class="string"></span></span><br><span class="line"><span class="comment">  # 数据库连接配置</span></span><br><span class="line">  <span class="attr">datasource</span>:<span class="string"></span></span><br><span class="line">    <span class="meta">driver-class-name</span>: <span class="string">com.mysql.cj.jdbc.Driver</span></span><br><span class="line">    <span class="attr">url</span>: <span class="string">jdbc:mysql://localhost:3306/ssm-demo?characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=GMT%2B8</span></span><br><span class="line">    <span class="attr">username</span>: <span class="string">xxx</span></span><br><span class="line">    <span class="attr">password</span>: <span class="string">xxx</span></span><br><span class="line">  <span class="attr">flyway</span>:<span class="string"></span></span><br><span class="line"><span class="comment">    # 是否启用flyway</span></span><br><span class="line">    <span class="attr">enabled</span>: <span class="string">true</span></span><br><span class="line"><span class="comment">    # 编码格式，默认UTF-8</span></span><br><span class="line">    <span class="attr">encoding</span>: <span class="string">UTF-8</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件存放路径，默认db/migration</span></span><br><span class="line">    <span class="attr">locations</span>: <span class="string">classpath:db/migration</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的前缀，默认V</span></span><br><span class="line">    <span class="meta">sql-migration-prefix</span>: <span class="string">V</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的分隔符，默认2个下划线__</span></span><br><span class="line">    <span class="meta">sql-migration-separator</span>: <span class="string">__</span></span><br><span class="line"><span class="comment">    # 迁移sql脚本文件名称的后缀</span></span><br><span class="line">    <span class="meta">sql-migration-suffixes</span>: <span class="string">.sql</span></span><br><span class="line"><span class="comment">    # 迁移时是否进行校验，默认true</span></span><br><span class="line">    <span class="meta">validate-on-migrate</span>: <span class="string">true</span></span><br><span class="line"><span class="comment">    # 当迁移发现数据库非空且存在没有元数据的表时，自动执行基准迁移，新建schema_version表</span></span><br><span class="line">    <span class="meta">baseline-on-migrate</span>: <span class="string">true</span></span><br></pre></td></tr></table></figure></li><li><p>根据在配置文件的脚本存放路径的配置，在resource目录下建立文件夹db/migration</p></li><li><p>添加需要运行的sql脚本。sql脚本的命名规范为：V+版本号(版本号的数字间以”.“或”_“分隔开)+双下划线(用来分隔版本号和描述)+文件描述+后缀名，例如：V20201100__create_user.sql。如图所示：<br> <img src="/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BFlyway%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/img.png"></p></li><li><p>启动项目。启动成功后，在数据库中可以看到已按照定义好的脚本，完成数据库变更，并在flyway_schema_history表插入了sql执行记录。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;对于数据库版本管理，我们已经介绍过一款类似工具&lt;a href=&quot;/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E</summary>
      
    
    
    
    <category term="实用工具" scheme="http://example.com/categories/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="数据库版本管理" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>数据库版本管理之Liquibase使用指南</title>
    <link href="http://example.com/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://example.com/2021/08/11/%E6%9D%82%E9%A1%B9%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E4%B9%8BLiquibase%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</id>
    <published>2021-08-11T02:12:37.000Z</published>
    <updated>2021-08-11T06:26:12.262Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么需要数据库版本管理"><a href="#为什么需要数据库版本管理" class="headerlink" title="为什么需要数据库版本管理"></a>为什么需要数据库版本管理</h3><p>研发过程中经常涉及到数据库变更，对表结构的修复及对数据的修改，为了保证各环境都能正确的进行变更我们可能需要维护一个数据库升级文档来保存这些记录，有需要升级的环境按文档进行升级。</p><p>这样手工维护有几个缺点：</p><ul><li>无法保证每个环境都按要求执行</li><li>遇到问题不一定有相对的回滚语句</li><li>无法自动化</li></ul><p>为了解决这些问题，我们进行了一些调研，主要调研对象是Liquibase和Flyway，我们希望通过数据库版本管理工具实现以下几个目标：</p><ul><li>数据库升级</li><li>数据库回滚</li><li>版本标记</li></ul><h3 id="数据库版本管理工具Liquibase简介"><a href="#数据库版本管理工具Liquibase简介" class="headerlink" title="数据库版本管理工具Liquibase简介"></a>数据库版本管理工具Liquibase简介</h3><p>首先，上<a href="https://docs.liquibase.com/home.html">官方文档</a></p><h4 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h4><p>首先，Liquibase是用于管理数据库版本的，所以就会有这些概念：</p><ul><li>版本号<ul><li>它的版本号由开发人员来维护，使用 author + id(由ChangeSet定义)</li></ul></li><li>管理的数据</li><li>差异比较</li><li>版本回滚</li></ul><p>提交数据，比较差异，版本回滚 可以使用命令行 或者 maven ，ant 等构建工具来完成</p><h5 id="Changelog-文件"><a href="#Changelog-文件" class="headerlink" title="Changelog 文件"></a>Changelog 文件</h5><p>开发人员将数据库更改存储在其本地开发计算机上基于文本的文件中，并将其应用于其本地数据库。Changelog文件可以任意嵌套，以便更好地管理。</p><p>所有Liquibase更改的根源是更改日志文件, Liquibase使用更改日志按顺序列出对数据库所做的所有更改。</p><p>它是一个包含所有数据库更改记录的文件（变更集s）, Liquibase使用此更改日志记录审核您的数据库并执行尚未应用于您的数据库的任何更改。</p><p><strong>可用属性</strong></p><ul><li>logicalFilePath: 用于在创建changeSet的唯一标识符时覆盖文件名和路径。移动或重命名change logs时是必需的。</li></ul><p><strong>可用的子标签</strong></p><ul><li><p>preConditions: 执行更改日志所需的先决条件。<a href="http://www.liquibase.org/documentation/preconditions.html">read more</a></p><ul><li>记录更改日志的编写者在创建changelog时的假设。</li><li>强制使运行change log的用户不会违反这些假设</li><li>在执行不可恢复的更改（如 drop_Table）之前执行数据检查</li><li>根据数据库的状态控制哪些changeSet运行<details><summary>demo</summary><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">databaseChangeLog</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog/1.8&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog/1.8</span></span></span><br><span class="line"><span class="string"><span class="tag">http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-1.8.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">preConditions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dbms</span> <span class="attr">type</span>=<span class="string">&quot;oracle&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">runningAs</span> <span class="attr">username</span>=<span class="string">&quot;SYSTEM&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">preConditions</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">changeSet</span> <span class="attr">id</span>=<span class="string">&quot;1&quot;</span> <span class="attr">author</span>=<span class="string">&quot;bob&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">preConditions</span> <span class="attr">onFail</span>=<span class="string">&quot;WARN&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">sqlCheck</span> <span class="attr">expectedResult</span>=<span class="string">&quot;0&quot;</span>&gt;</span>select count(*) from oldtable<span class="tag">&lt;/<span class="name">sqlCheck</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">preConditions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">comment</span>&gt;</span>Comments should go after preCondition. If they are before then liquibase usually gives error.<span class="tag">&lt;/<span class="name">comment</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dropTable</span> <span class="attr">tableName</span>=<span class="string">&quot;oldtable&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">changeSet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">databaseChangeLog</span>&gt;</span></span><br></pre></td></tr></table></figure>仅当针对 Oracle执行的数据库和执行脚本的数据库用户为SYSTEM时，才会运行上述databasechangelog。<br>仅当”oldtable”中没有值时，它才会运行 drop_Table命令。</details></li></ul></li><li><p>property: 将属性设置为的值（如果不是通过其他方法设置）。<a href="http://www.liquibase.org/documentation/changelog_parameters.html">read more</a></p></li><li><p>changeSet: 要执行的changeSet。<a href="http://www.liquibase.org/documentation/changeset.html">read more</a></p></li><li><p>include: 包含要执行的changeSet的其他文件。<a href="http://www.liquibase.org/documentation/include.html">read more</a></p></li></ul><p>当 Liquibase 迁移器运行时，它将分析数据库 ChangeLog 标记。它首先检查指定的先决条件。如果先决条件失败，Liquibase将退出，并显示一条错误消息，解释失败的原因。先决条件对于记录和强制执行更改日志编写器的预期和假设（如要针对的 DBMS 或以用户身份运行更改）非常有用。</p><p>如果满足所有的先决条件，Liquibase将会开始运行在databaseChangeLog文件中按照顺序出现changeSet和include标签。</p><p><strong>changelog文件格式说明</strong></p><p>具体格式参考<a href="https://docs.liquibase.com/concepts/basic/changelog.html">官方文档</a></p><p>本文列举两种常见格式:</p><ul><li><p>SQL 文件格式</p><p>其实各种文件格式使用生成数据库脚本就可以看到格式了，照着写就行：</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--liquibase formatted sql</span><br><span class="line"></span><br><span class="line">--changeset &lt;author&gt;:&lt;version&gt; </span><br><span class="line">sqls</span><br><span class="line"></span><br><span class="line">--rollback rollback sqls </span><br><span class="line"></span><br><span class="line">--comment: 注释都有特殊含义了，所以注释要这样加</span><br></pre></td></tr></table></figure></li><li><p>XML 文件格式</p><p>xml 比 sql 更加可控，它可以加一个预判断条件，来判断这个后面的 changeSet 要不要执行，但相应的就必须照它的语法来写语句了，没 sql 方便了，还好提供了 xsd</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;preConditions&gt;</span><br><span class="line">    &lt;runningAs username=&quot;liquibase&quot;/&gt;</span><br><span class="line">&lt;/preConditions&gt;</span><br><span class="line">&lt;!-- 版本 1 的修改--&gt;</span><br><span class="line">&lt;changeSet id=&quot;1&quot; author=&quot;sanri&quot;&gt;</span><br><span class="line">    &lt;addColumn tableName=&quot;person&quot;&gt;</span><br><span class="line">        &lt;column name=&quot;username&quot; type=&quot;varchar(8)&quot;/&gt;</span><br><span class="line">    &lt;/addColumn&gt;</span><br><span class="line">&lt;/changeSet&gt;</span><br></pre></td></tr></table></figure></li></ul><h5 id="ChangeSet"><a href="#ChangeSet" class="headerlink" title="ChangeSet"></a>ChangeSet</h5><p>changeSet由author和id属性以及changelog文件的位置唯一标识，是 Liquibase 跟踪执行的单位（管理的数据最小单元）。</p><p>changeSet 可以用 xml,yaml,json,sql 来编写</p><p>运行 Liquibase 时，它会查询标记为已执行的changSet的DATABASECHANGELOG 表，然后执行更改日志文件中尚未执行的所有changeSet。</p><h5 id="Changes"><a href="#Changes" class="headerlink" title="Changes"></a>Changes</h5><p>每个changeSet通常包含一个更改，该更改描述要应用于数据库的更改/重构。</p><p>Liquibase 支持为支持的数据库和原始 SQL 生成 SQL 的描述性更改。</p><p>通常，<strong>每个changeSet应只有一个更改</strong>，以避免可能使数据库处于意外状态的自动提交语句失败。</p><h5 id="Preconditions"><a href="#Preconditions" class="headerlink" title="Preconditions"></a>Preconditions</h5><p>先决条件可以应用于整个changelog或单个changeSet。如果先决条件失败，liquibase将停止执行。</p><h5 id="Contexts"><a href="#Contexts" class="headerlink" title="Contexts"></a>Contexts</h5><p>可以将上下文应用于changeSet，以控制在不同环境中运行的changeSet。例如，某些changeSet可以标记为production，另一些可以标记为test。如果未指定上下文，则无论执行上下文如何，changset都将运行。</p><h4 id="Liquibase是如何工作的"><a href="#Liquibase是如何工作的" class="headerlink" title="Liquibase是如何工作的"></a>Liquibase是如何工作的</h4><p>Liquibase的核心是依靠一种简单的机制来跟踪、版本和部署更改：</p><ul><li>Liquibase 使用更改日志（是更改的分类）按特定顺序显式列出数据库更改。更改日志中的每个更改都是一个change set。更改日志可以任意嵌套，以帮助组织和管理数据库迁移。<ul><li>最佳做法是确保每个change set都尽可能原子性更改，以避免失败的结果使数据库中剩下的未处理的语句处于unknown 状态;</li><li>不过，可以将大型 SQL 脚本视为单个更改集。</li></ul></li><li>Liquibase 使用跟踪表（具体称为DATABASECHANGELOG），该表位于每个数据库上，并跟踪已部署更改日志中的change set。<ul><li>如果 Liquibase所在的数据库没有跟踪表，Liquibase 将创建一个跟踪表。</li><li>为了协助处理您未从空白数据库开始的项目，Liquibase具有生成一条更改日志以表示数据库模式当前状态的功能。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">它会在你的目标数据库生成一张表 DATABASECHANGELOG 来管理版本 ，另一个 lock 的是防止多人同时操作数据库加的锁。</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>使用分类和跟踪表，Liquibase 能够：</p><ul><li>跟踪和以版本控制数据库更改 – 用户确切知道已部署到数据库的更改以及尚未部署的更改。</li><li>部署更改 — 具体来说，通过将分类(ledger)中的内容与跟踪表中的内容进行比较，Liquibase 只能将以前尚未部署到数据库的更改部署到数据库中。<ul><li>Liquibase 具有上下文、标签和先决条件等高级功能，可精确控制changeSet的部署时间以及位置。</li></ul></li></ul><h4 id="liquibase使用"><a href="#liquibase使用" class="headerlink" title="liquibase使用"></a>liquibase使用</h4><h5 id="命令行方式"><a href="#命令行方式" class="headerlink" title="命令行方式"></a>命令行方式</h5><p>虽然使用可以集成自 springboot ，但这种数据库脚本一般公司都是运维在维护，使用命令行是最方便的方式，所以我先说下使用命令行, <a href="http://www.liquibase.org/documentation/command_line.html">官网示例</a> </p><p>为先为了不每次都要写一大堆参数，可以在 liquibase 根目录加一个 liquibase.properties，用于配置数据库 jar、url、用户名、密码等参数, <a href="http://www.liquibase.org/documentation/config_properties.html">配置详情</a> </p><p>命令格式： liquibase [options] [command] [command parameters]</p><h6 id="比较开发库和测试库的差异，并生成升级包"><a href="#比较开发库和测试库的差异，并生成升级包" class="headerlink" title="比较开发库和测试库的差异，并生成升级包"></a>比较开发库和测试库的差异，并生成升级包</h6><p>如果要升级哪个，则哪个要做为源，则配置中的 url 不是 referenceUrl，使用如下命令创建升级包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase --changeLogFile=&quot;changeLogFiledevtest.postgresql.sql&quot; diffChangeLog</span><br></pre></td></tr></table></figure><p>changeLogFile 是有命名规则的，命名必须为 *.dbType.format ，如上所示</p><h6 id="为测试库打一个标签"><a href="#为测试库打一个标签" class="headerlink" title="为测试库打一个标签"></a>为测试库打一个标签</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase tag v1.0</span><br></pre></td></tr></table></figure><h6 id="使用差异升级源库"><a href="#使用差异升级源库" class="headerlink" title="使用差异升级源库"></a>使用差异升级源库</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">liquibase --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; update</span><br></pre></td></tr></table></figure><h6 id="升级有问题需要回滚"><a href="#升级有问题需要回滚" class="headerlink" title="升级有问题需要回滚"></a>升级有问题需要回滚</h6><p>liquibase 有几种回滚策略，一种是根据标签回滚，回滚次数，和根据日期回滚；有 9 个与之对应的命令</p><p>回滚要求对应的 changeLogFile 有回滚标签 ，这个在后面文件格式说</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 按照 changeSet 次数回滚</span></span><br><span class="line">liquibase  --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; rollbackCount 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按照标签回滚</span></span><br><span class="line">liquibase  --changeLogFile=&quot;sqls/changeLogFiledevtest.postgresql.sql&quot; rollback v1.0</span><br></pre></td></tr></table></figure><h6 id="生成数据库脚本-新环境"><a href="#生成数据库脚本-新环境" class="headerlink" title="生成数据库脚本(新环境)"></a>生成数据库脚本(新环境)</h6><p>liquibase –changeLogFile=”sqls/create_table.mysql.sql”  generateChangeLog</p><h5 id="使用构建工具"><a href="#使用构建工具" class="headerlink" title="使用构建工具"></a>使用构建工具</h5><p>我们也可以使用 maven 来执行这些操作，引入 maven 的一个插件就行</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.liquibase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>liquibase-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--指定执行主文件 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;changeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/master_changelog.xml&lt;/changeLogFile&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;diffChangeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/changelog/$&#123;maven.build.timestamp&#125;_changelog.xml&lt;/diffChangeLogFile&gt;--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--                    &lt;outputChangeLogFile&gt;$&#123;basedir&#125;/src/main/resources/liquibase/changelog/changelog_original.xml&lt;/outputChangeLogFile&gt;--&gt;</span></span><br><span class="line"></span><br><span class="line">                   <span class="tag">&lt;<span class="name">propertyFile</span>&gt;</span>src/main/resources/liquibase/liquibase.properties<span class="tag">&lt;/<span class="name">propertyFile</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                    <span class="tag">&lt;<span class="name">dropFirst</span>&gt;</span>false<span class="tag">&lt;/<span class="name">dropFirst</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">verbose</span>&gt;</span>true<span class="tag">&lt;/<span class="name">verbose</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">logging</span>&gt;</span>debug<span class="tag">&lt;/<span class="name">logging</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!-- 是否需要弹出确认框 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">promptOnNonLocalDatabase</span>&gt;</span>false<span class="tag">&lt;/<span class="name">promptOnNonLocalDatabase</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--输出文件的编码 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">outputFileEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">outputFileEncoding</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--执行的时候是否显示详细的参数信息 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">verbose</span>&gt;</span>true<span class="tag">&lt;/<span class="name">verbose</span>&gt;</span></span><br><span class="line">                    <span class="comment">&lt;!--是否每次都重新加载properties --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">propertyFileWillOverride</span>&gt;</span>true<span class="tag">&lt;/<span class="name">propertyFileWillOverride</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">rollbackTag</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">rollbackTag</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">tag</span>&gt;</span>$&#123;project.version&#125;<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure><p>相应的命令做成了目标(goal)，使用 -Dkey=value 来指定参数，如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行更新 sql</span> </span><br><span class="line">mvn liquibase:update -DchangeLogFile=&quot;file&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 打标签，这个版本号在插件中配置成项目版本了</span></span><br><span class="line">mvn liquibase:tag </span><br><span class="line"><span class="meta">#</span><span class="bash"> 将当前库导出表结构</span></span><br><span class="line">mvn liquibase:generateChangeLog </span><br></pre></td></tr></table></figure><h5 id="集成进-springboot-在项目启动的时候执行版本管理"><a href="#集成进-springboot-在项目启动的时候执行版本管理" class="headerlink" title="集成进 springboot, 在项目启动的时候执行版本管理"></a>集成进 springboot, 在项目启动的时候执行版本管理</h5><p>具体实现方案参考文章<a href="https://blog.csdn.net/qq_39508627/article/details/89883549?utm_medium=distribute.pc_feed_404.none-task-blog-2~default~BlogCommendFromBaidu~default-3.nonecase&depth_1-utm_source=distribute.pc_feed_404.none-task-blog-2~default~BlogCommendFromBaidu~default-3.nonecas">springboot引入liquibase</a></p><h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="项目开发中存在的问题"><a href="#项目开发中存在的问题" class="headerlink" title="项目开发中存在的问题"></a>项目开发中存在的问题</h4><p>随着项目的发展，一个项目中的代码量会非常庞大，同时数据库表也会错综复杂。如果一个项目使用了Liquibase对数据库结构进行管理，越来越多的问题会浮现出来。</p><ul><li>ChangeSet文件同时多人在修改，自己的ChangeSet被改掉，甚至被删除掉。</li><li>开发人员将ChangeSet添加到已经执行过的文件中，导致执行顺序出问题。</li><li>开发人员擅自添加对业务数据的修改，其它环境无法执行并报错。</li><li>ChangeSet中SQL包含schema名称，导致其它环境schema名称变化时，ChangeSet报错。</li><li>开发人员不小心改动了已经执行过的ChangeSet，在启动时会报错。</li></ul><h4 id="Liquibase基本规范"><a href="#Liquibase基本规范" class="headerlink" title="Liquibase基本规范"></a>Liquibase基本规范</h4><ul><li>ChangeSet id使用[任务ID]-[日期]-[序号]，如 T100-20181009-001</li><li>ChangeSet必须填写author</li><li>Liquibase禁止对业务数据进行sql操作</li><li>使用<sql>时，禁止包含schema名称</sql></li><li>Liquibase禁止使用存储过程</li><li>所有表，列要加remarks进行注释</li><li>已经执行过的ChangeSet严禁修改。</li><li>不要随便升级项目liquibase版本，特别是大版本升级。不同版本ChangeSet MD5SUM的算法不一样。</li></ul><p>其它数据库规范不再赘述。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">databaseChangeLog</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xmlns</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog&quot;</span></span></span><br><span class="line"><span class="tag">        <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">changeSet</span> <span class="attr">id</span>=<span class="string">&quot;T100-20181009-001&quot;</span> <span class="attr">author</span>=<span class="string">&quot;markfredchen&quot;</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">createTable</span> <span class="attr">tableName</span>=<span class="string">&quot;demo_user&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户表&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">column</span> <span class="attr">name</span>=<span class="string">&quot;id&quot;</span> <span class="attr">type</span>=<span class="string">&quot;bigint&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户ID,主键&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">constraints</span> <span class="attr">nullable</span>=<span class="string">&quot;false&quot;</span> <span class="attr">primaryKey</span>=<span class="string">&quot;true&quot;</span> <span class="attr">primaryKeyName</span>=<span class="string">&quot;pk_demo_user_id&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">column</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">column</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> <span class="attr">type</span>=<span class="string">&quot;varchar(100)&quot;</span> <span class="attr">remarks</span>=<span class="string">&quot;用户名&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">constraints</span> <span class="attr">nullable</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">column</span>&gt;</span></span><br><span class="line">            ...</span><br><span class="line">        <span class="tag">&lt;/<span class="name">createTable</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">changeSet</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">databaseChangeLog</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="有效文件管理"><a href="#有效文件管理" class="headerlink" title="有效文件管理"></a>有效文件管理</h4><p>使用Liquibase中提供<include file="xxx">tag，可以将ChangeSet分布在不同文件中。同时<include>支持多级引用。</include></include></p><p>基于此功能可以对项目中的ChangeSet进行有效管理。推荐使用以下规范进行管理。</p><h5 id="根据发布进行管理"><a href="#根据发布进行管理" class="headerlink" title="根据发布进行管理"></a>根据发布进行管理</h5><ul><li>每个发布新建一个文件夹，所有发布相关的ChangeSet文件以及数据初始化文件，均放在些文件夹中。</li><li>每个发布新建一个master.xml。此master.xml中，include本次发布需要执行的ChangeSet文件</li><li>根据开发小组独立ChangeSet文件(可选)</li><li>根据功能独立ChangeSet文件。例如user.xml, company.xml  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">resources</span><br><span class="line">|-liquibase</span><br><span class="line">|-user</span><br><span class="line">| |- master.xml</span><br><span class="line">| |- release.1.0.0</span><br><span class="line">| | |- release.xml</span><br><span class="line">| | |- user.xml -- 用户相关表ChangeSet</span><br><span class="line">| | |- user.csv -- 用户初始化数据</span><br><span class="line">| | |- company.xml -- 公司相关表ChangeSet</span><br><span class="line">| |- release.1.1.0</span><br><span class="line">| | |- release.xml</span><br><span class="line">| | |- ...</span><br></pre></td></tr></table></figure></li></ul><h5 id="模块化管理"><a href="#模块化管理" class="headerlink" title="模块化管理"></a>模块化管理</h5><p>当项目变得庞大之后，一个服务可能包含的功能模块会越来越多。此时大家会想尽办法进行模块拆分，逐步进行微服务化。然而在面对错综复杂的Liquibase ChangeSet就会无从下手。</p><p>针对这种将来可能会面对的问题，项目初期就对Liquibase进行模块化管理，将在未来带来很大收益。</p><p>首先说明一下Spring Boot中Liquibase默认是如何执行以及执行结果。</p><ul><li>在启动时，LiquibaseAutoConfiguration会根据默认配置初始化SpringLiquibase</li><li>SpringLiquibase.afterPropertiesSet()中执行ChangeSet文件</li><li>第一次跑ChangeSets的时候，会在数据库中自动创建两个表databasechangelog和databasechangeloglock</li></ul><p>因此我们可以认为一个SpringLiquibase执行为一个模块。</p><p>引入多模块管理时，基于上节文件管理规范，我们基于模块管理再做下调整。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">resources</span><br><span class="line">  |-liquibase</span><br><span class="line">    |-user</span><br><span class="line">    | |- master.xml</span><br><span class="line">    | |- release.1.0.0</span><br><span class="line">    | | |- release.xml</span><br><span class="line">    | | |- user.xml -- 用户相关表ChangeSet</span><br><span class="line">    | | |- user.csv -- 用户初始化数据</span><br><span class="line">    | | |- company.xml -- 公司相关表ChangeSet</span><br><span class="line">    | |- release.1.1.0</span><br><span class="line">    | | |- release.xml</span><br><span class="line">    | | |- ...</span><br><span class="line">    |- order</span><br><span class="line">    | |- master.xml</span><br><span class="line">    | |- release.1.0.0</span><br><span class="line">    | | |- ...</span><br></pre></td></tr></table></figure><p>当有一天我们需要把订单模块拆分成独立服务时，我们只需要将模块相关的ChangeSet文件迁出来。即可完成数据结构的拆分。</p><p>那如何在一个Spring Boot运行多个SpringLiquibase呢？需要对代码进行以下调整。</p><ol><li><p>禁用Spring Boot自动运行Liquibase。</p><p> 当以下配置被启用时，Spring Boot AutoConfigure会使用默认配置初始化名为springLiquibase的Bean。然后我们不对其进行配置，Spring Boot启动时会报错。</p> <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># application.properties</span></span><br><span class="line"><span class="comment"># spring boot 2以上</span></span><br><span class="line"><span class="meta">spring.liquibase.enabled</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># spring boot 2以下</span></span><br><span class="line"><span class="meta">liquibase.enabled</span>=<span class="string">false</span></span><br></pre></td></tr></table></figure></li><li><p>Spring Boot配置Liquibase Bean</p><p> 配置两个SpringLiquibase Bean，Bean名称分别为userLiquibase和orderLiqubase。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> class <span class="title">LiquibaseConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  用户模块Liquibase   </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SpringLiquibase <span class="title">userLiquibase</span><span class="params">(DataSource dataSource)</span> </span>&#123;</span><br><span class="line">        SpringLiquibase liquibase = <span class="keyword">new</span> SpringLiquibase();</span><br><span class="line">        <span class="comment">// 用户模块Liquibase文件路径</span></span><br><span class="line">        liquibase.setChangeLog(<span class="string">&quot;classpath:liquibase/user/master.xml&quot;</span>);</span><br><span class="line">        liquibase.setDataSource(dataSource);</span><br><span class="line">        liquibase.setShouldRun(<span class="keyword">true</span>);</span><br><span class="line">        liquibase.setResourceLoader(<span class="keyword">new</span> DefaultResourceLoader());</span><br><span class="line">        <span class="comment">// 覆盖Liquibase changelog表名</span></span><br><span class="line">        liquibase.setDatabaseChangeLogTable(<span class="string">&quot;user_changelog_table&quot;</span>);</span><br><span class="line">        liquibase.setDatabaseChangeLogLockTable(<span class="string">&quot;user_changelog_lock_table&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> liquibase;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  订单模块Liquibase   </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SpringLiquibase <span class="title">orderLiquibase</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      SpringLiquibase liquibase = <span class="keyword">new</span> SpringLiquibase();</span><br><span class="line">      liquibase.setChangeLog(<span class="string">&quot;classpath:liquibase/order/master.xml&quot;</span>);</span><br><span class="line">      liquibase.setDataSource(dataSource);</span><br><span class="line">      liquibase.setShouldRun(<span class="keyword">true</span>);</span><br><span class="line">      liquibase.setResourceLoader(<span class="keyword">new</span> DefaultResourceLoader());</span><br><span class="line">      liquibase.setDatabaseChangeLogTable(<span class="string">&quot;order_changelog_table&quot;</span>);</span><br><span class="line">      liquibase.setDatabaseChangeLogLockTable(<span class="string">&quot;order_changelog_lock_table&quot;</span>);</span><br><span class="line">      <span class="keyword">return</span> liquibase;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://blog.csdn.net/u012934325/article/details/100652805">LiquiBase中文学习指南</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;为什么需要数据库版本管理&quot;&gt;&lt;a href=&quot;#为什么需要数据库版本管理&quot; class=&quot;headerlink&quot; title=&quot;为什么需要数据库版本管理&quot;&gt;&lt;/a&gt;为什么需要数据库版本管理&lt;/h3&gt;&lt;p&gt;研发过程中经常涉及到数据库变更，对表结构的修复及对数据的修改</summary>
      
    
    
    
    <category term="实用工具" scheme="http://example.com/categories/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="数据库版本管理" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>微服务解决方案SpringCloud Alibaba系列之Sentinel初探</title>
    <link href="http://example.com/2021/08/09/SpringCloudAlibaba/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88SpringCloud%20Alibaba%E7%B3%BB%E5%88%97%E4%B9%8BSentinel%E5%88%9D%E6%8E%A2/"/>
    <id>http://example.com/2021/08/09/SpringCloudAlibaba/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88SpringCloud%20Alibaba%E7%B3%BB%E5%88%97%E4%B9%8BSentinel%E5%88%9D%E6%8E%A2/</id>
    <published>2021-08-09T08:52:34.000Z</published>
    <updated>2021-08-12T02:54:33.386Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Sentinel-是什么"><a href="#Sentinel-是什么" class="headerlink" title="Sentinel 是什么"></a>Sentinel 是什么</h3><p>新技术学习第一步，<a href="https://sentinelguard.io/zh-cn/docs/introduction.html">官方文档</a></p><p>随着微服务的流行，服务和服务之间的稳定性变得越来越重要。</p><p>Sentinel 是面向分布式服务架构的流量控制组件，作为分布式系统的流量防卫兵， 以<strong>流量</strong>为切入点，从<strong>流量控制、熔断降级、系统负载保护</strong>等多个维度保护服务的稳定性。</p><h3 id="Sentinel-要做什么"><a href="#Sentinel-要做什么" class="headerlink" title="Sentinel 要做什么"></a>Sentinel 要做什么</h3><p>服务的动态注册、服务发现是 SOA、微服务架构体系中首先需要解决的基本问题，服务治理是 SOA 领域又一重要课题，而 dubbo 框架只提供了一些基本的服务治理能力，例如限制服务并发调用数、配置合适的业务线程数量等，但熔断相关的功能就涉及的较少。</p><p>Sentinel 将作为 Dubbo 生态的重要一员，将集中解决服务治理相关的课题，服务限流与熔断又是服务治理首先要解决的课题。</p><p>那什么是限流与熔断呢？</p><ul><li>限流：我们通常使用TPS对流量来进行描述，限流就是现在服务被调用的并发TPS，从而对系统进行自我保护。</li><li>熔断：就是当系统中某一个服务出现性能瓶颈是，对这个服务的调用进行快速失败，避免造成连锁反应，从而影响整个链路的调用。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Sentinel-是什么&quot;&gt;&lt;a href=&quot;#Sentinel-是什么&quot; class=&quot;headerlink&quot; title=&quot;Sentinel 是什么&quot;&gt;&lt;/a&gt;Sentinel 是什么&lt;/h3&gt;&lt;p&gt;新技术学习第一步，&lt;a href=&quot;https://sent</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="高并发" scheme="http://example.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
    <category term="限流" scheme="http://example.com/tags/%E9%99%90%E6%B5%81/"/>
    
    <category term="Sentinel" scheme="http://example.com/tags/Sentinel/"/>
    
    <category term="SpringCloud Alibaba" scheme="http://example.com/tags/SpringCloud-Alibaba/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之与Zookeeper的爱恨缠绵</title>
    <link href="http://example.com/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/"/>
    <id>http://example.com/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/</id>
    <published>2021-08-04T03:08:28.000Z</published>
    <updated>2021-08-12T09:57:21.103Z</updated>
    
    <content type="html"><![CDATA[<p>在 <a href="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/" title="分布式协调组件之Zookeeper基础概念入门">分布式协调组件之Zookeeper基础概念入门</a> 一文中，我们简单介绍了Zookeeper的基础概念。</p><p>而Kafka作为Zookeeper分布式协调的重要案例，本文将通过Kafka与Zookeeper的合与分展示Kafka与Zookeeper的前世今生。</p><h3 id="Kafka为什么需要Zookeeper"><a href="#Kafka为什么需要Zookeeper" class="headerlink" title="Kafka为什么需要Zookeeper"></a>Kafka为什么需要Zookeeper</h3><p>Kafka中存在众多的Leader选举，熟悉Kafka的朋友应该知道，一个主题可以拥有多个分区(数据分片)，每一个数据分片可以配置多个副本，如何保证一个分区的数据在多个副本之间的一致性成为一个迫切的需求。</p><p>Kafka的实现套路就是一个分区的多个副本，从中选举出一个Leader用来承担客户端的读写请求，从节点从主节点处拷贝内容，Leader节点根据数据在副本中成功写入情况，进行抉择来确定是否写入成功。</p><p>Kafka中topic的分区分布示意图：</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_1.png"></p><p>故此处需要进行Leader选举,而基于Zookeeper能轻松实现，从此一拍即合，开启了一段“蜜月之旅”。</p><h3 id="Zookeeper为Kafka提供了什么"><a href="#Zookeeper为Kafka提供了什么" class="headerlink" title="Zookeeper为Kafka提供了什么"></a>Zookeeper为Kafka提供了什么</h3><p>ZooKeeper 作为给分布式系统提供协调服务的工具被 kafka 所依赖。</p><p>在分布式系统中，消费者需要知道有哪些生产者是可用的，而如果每次消费者都需要和生产者建立连接并测试是否成功连接，那效率也太低了，显然是不可取的。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_5.png"></p><p>通过使用 ZooKeeper 协调服务，Kafka 就能将 Producer，Consumer，Broker 等结合在一起，同时借助 ZooKeeper，Kafka 就能够将所有组件在无状态的条件下建立起生产者和消费者的订阅关系，实现负载均衡。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img.png"></p><ol><li><p>注册中心</p><ul><li><p>Broker 信息注册</p><ul><li>在 ZooKeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点，节点路径为 /brokers/ids。  </li><li>Kafka 的每个 Broker 启动时，都会在 ZooKeeper 中注册，创建 /brokers/ids/[0-N] 节点，写入 IP，端口等信息，每个 Broker 都有一个 BrokerId。  </li><li>Broker 创建的是临时节点，在连接断开时节点就会自动删除，所以在 ZooKeeper 上就可以通过 Broker 中节点的变化来得到 Broker 的可用性。</li></ul></li><li><p>Topic 信息注册</p><ul><li><p>在 Kafka 中可以定义很多个 Topic，每个 Topic 又被分为很多个 Partition。一般情况下，每个 Partition 独立在存在一个 Broker 上，所有的这些 Topic 和 Broker 的对应关系都由 ZooKeeper 进行维护。</p></li><li><p>Zookeeper会为topic分配一个单独节点，每个topic都会以/brokers/topics/[topic_name]的形式记录在Zookeeper。</p></li><li><p>一个topic的消息会被保存到多个partition，这些partition跟broker的对应关系也需要保存到Zookeeper。</p></li><li><p>partition是多副本保存的，上图中红色partition是leader副本。当leader副本所在的broker发生故障时，partition需要重新选举leader，这个需要由Zookeeper主导完成。</p></li><li><p>broker启动后，会把自己的Broker ID注册到到对应topic节点的分区列表中。</p><p>我们查看一个topic是xxx，分区编号是1的信息，命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master] get /brokers/topics/xxx/partitions/1/state</span><br><span class="line">&#123;&quot;controller_epoch&quot;:15,&quot;leader&quot;:11,&quot;version&quot;:1,&quot;leader_epoch&quot;:2,&quot;isr&quot;:[11,12,13]&#125;</span><br></pre></td></tr></table></figure><p><code>当broker退出后，Zookeeper会更新其对应topic的分区列表。</code></p></li></ul></li><li><p>consumer 信息注册</p><p>   消费者组也会向Zookeeper进行注册，Zookeeper会为其分配节点来保存相关数据，节点路径为/consumers/{group_id}，有3个子节点，如下图:</p><p>   <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_6.png"></p><p>   这样Zookeeper可以记录分区跟消费者的关系，以及分区的offset。</p></li></ul></li><li><p>负载均衡</p><p> 生产者需要将消息发送给 Broker，消费者需要从 Broker 上获取消息，通过使用 ZooKeeper，就都能监听 Broker 上节点的状态信息，从而实现动态负载均衡。</p><ul><li>broker向Zookeeper进行注册后，生产者根据broker节点来感知broker服务列表变化，这样可以实现动态负载均衡。</li><li>consumer group中的消费者，可以根据topic节点信息来拉取特定分区的消息,实现负载均衡。</li></ul></li><li><p>Controller</p><p> 在 Kafka 中会有多个 Broker，其中一个 Broker 会被选举成为 Controller（控制器），在任意时刻，Kafka 集群中有且仅有一个控制器。</p><p> Controller 负责管理集群中所有分区和副本的状态，当某个分区的 leader 副本出现故障时，由 Controller 为该分区选举出一个新的 leader。</p><p> Controller具体职责如下：</p><ul><li>监听分区变化<ul><li>当某个分区的leader出现故障时，Controller会为该分区选举新的leader。</li><li>当检测到分区的ISR集合发生变化时，Controller会通知所有broker更新元数据。</li><li>当某个topic增加分区时，Controller会负责重新分配分区。</li></ul></li><li>监听topic相关的变化</li><li>监听broker相关的变化</li><li>集群元数据管理</li></ul><p> 下面这张图展示了Controller、Zookeeper和broker的交互细节：<br> <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_7.png"></p><p> Controller选举成功后，会从Zookeeper集群中拉取一份完整的元数据初始化ControllerContext，这些元数据缓存在Controller节点。当集群发生变化时，比如增加topic分区，Controller不仅需要变更本地的缓存数据，还需要将这些变更信息同步到其他Broker。</p><p> Controller监听到Zookeeper事件、定时任务事件和其他事件后，将这些事件按照先后顺序暂存到LinkedBlockingQueue中，由事件处理线程按顺序处理，这些处理多数需要跟Zookeeper交互，Controller则需要更新自己的元数据。</p><p> Kafka 的 Controller 选举就依靠 ZooKeeper 来完成，成功竞选为 Controller 的 Broker 会在 ZooKeeper 中创建 /controller 这个临时节点，在 ZooKeeper 中使用 get 命令查看节点内容：</p><p> <img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_2.png"></p><ul><li>“version”在目前版本中固定为1</li><li>“brokerid”表示 Broker 的编号</li><li>“timestamp”表示竞选称为 Controller 时的时间戳。</li></ul><p> Kafka Controller选举流程: 当 Broker 启动时，会尝试读取 /controller 中的“brokerid”: </p><ul><li>如果读取到的值不是-1，则表示已经有节点竞选成为 Controller 了，当前节点就会放弃竞选；</li><li>而如果读取到的值为-1，ZooKeeper 就会尝试创建 /controller 节点，当该 Broker 去创建的时候，可能还有其他 Broker 一起同时创建节点，但只有一个 Broker 能够创建成功，即成为唯一的 Controller。</li></ul></li></ol><h3 id="为什么Kafka要抛弃Zookeeper"><a href="#为什么Kafka要抛弃Zookeeper" class="headerlink" title="为什么Kafka要抛弃Zookeeper"></a>为什么Kafka要抛弃Zookeeper</h3><h4 id="外部依赖带来的复杂度及系统效率影响"><a href="#外部依赖带来的复杂度及系统效率影响" class="headerlink" title="外部依赖带来的复杂度及系统效率影响"></a>外部依赖带来的复杂度及系统效率影响</h4><p>对于 Kafka 来讲，ZooKeeper 是一套外部系统，要想部署一套 Kafka 集群，就要同时部署、管理、监控 ZooKeeper，Kafka的运维人员必须要具备Zookeeper的运维能力。</p><p>ZooKeeper 有自己的配置方式、管理工具，和 Kafka 完全不一样，所以，一起搞两套分布式系统，自然就提升了<strong>复杂度</strong>，也更容易出现问题。有时工作量还会加倍，例如要开启一些安全特性，Kafka 和 ZooKeeper 中都需要配置。</p><p>除了复杂度，外部存储也会<strong>降低系统效率</strong>。</p><p>例如 Kafka 集群每次启动的时候，Controller 必须从 ZooKeeper 加载集群的状态信息。</p><p>再比如选举出一个新的 Controller 之后也会比较麻烦，Kafaka依赖一个单一Controller节点跟Zookeeper进行交互，如果这个Controller节点发生了故障，就需要从broker中选择新的Controller。如下图,新的Controller变成了broker3。</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_4.png"></p><p>新的Controller选举成功后，会重新从Zookeeper拉取元数据进行初始化，并且需要通知其他所有的broker更新ActiveControllerId。老的Controller需要关闭监听、事件处理线程和定时任务。分区数非常多时，这个过程非常耗时，而且这个过程中Kafka集群是不能工作的。</p><p>当分区数增加时，Zookeeper保存的元数据变多，Zookeeper集群压力变大，达到一定级别后，监听延迟增加，给Kafaka的工作带来了影响。</p><p>所以，Kafka单集群承载的<strong>分区数量是一个瓶颈</strong>。而这又恰恰是一些业务场景需要的。</p><h4 id="Zookeeper的致命缺陷"><a href="#Zookeeper的致命缺陷" class="headerlink" title="Zookeeper的致命缺陷"></a>Zookeeper的致命缺陷</h4><p>Zookeeper是集群部署，只要集群中超过半数节点存活，即可提供服务，例如一个由3个节点的Zookeeper，允许1个Zookeeper节点宕机，集群仍然能提供服务；一个由５个节点的Zookeeper，允许2个节点宕机。</p><p>但Zookeeper的设计是CP模型，即要保证数据的强一致性，必然在可用性方面做出牺牲。</p><p>Zookeeper集群中也存在所谓的Leader节点和从节点，Leader节点负责写，Leader与从节点可用接受读请求，但在Zookeeper内部节点在选举时整个Zookeeper无法对外提供服务。当然正常情况下选举会非常快，但在异常情况下就不好说了，例如Zookeeper节点发生full Gc，此时造成的影响将是毁灭性的。</p><p>Zookeeper节点如果频繁发生Full Gc，此时与客户端的会话将超时，由于此时无法响应客户端的心跳请求(Stop World)，从而与会话相关联的临时节点将被删除，注意，此时是所有的临时节点会被删除，Zookeeper依赖的事件通知机制将失效，整个集群的选举服务将失效。</p><h4 id="设计优雅性"><a href="#设计优雅性" class="headerlink" title="设计优雅性"></a>设计优雅性</h4><p>站在高可用性的角度，Kafka集群的可用性不仅取决于自身，还受到了外部组件的制约，从长久来看，显然都不是一个优雅的方案。</p><h4 id="分布式领域技术完善"><a href="#分布式领域技术完善" class="headerlink" title="分布式领域技术完善"></a>分布式领域技术完善</h4><p>随着分布式领域相关技术的不断完善，<strong>去中心化</strong>的思想逐步兴起，去Zookeeper的呼声也越来越高，在这个进程中涌现了一个非常优秀的算法：<strong>Raft协议</strong>。</p><p>Raft协议的两个重要组成部分：Leader选举、日志复制，而日志复制为多个副本提供数据强一致性提供了强一致性，并且一个显著的特点是Raft节点是去中心化的架构，不依赖外部的组件，而是作为一个协议簇嵌入到应用中的，即与应用本身是融合为一体的。</p><h3 id="Kafka去掉Zookeeper后怎么实现其功能"><a href="#Kafka去掉Zookeeper后怎么实现其功能" class="headerlink" title="Kafka去掉Zookeeper后怎么实现其功能"></a>Kafka去掉Zookeeper后怎么实现其功能</h3><p>KIP-500用Quorum Controller代替之前的Controller，Quorum中每个Controller节点都会保存所有元数据，通过KRaft协议保证副本的一致性。这样即使Quorum Controller节点出故障了，新的Controller迁移也会非常快。</p><p>以Kafka Topic的分布图举例，引用Raft协议的示例图如下：</p><p><img src="/2021/08/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%8EZookeeper%E7%9A%84%E7%88%B1%E6%81%A8%E7%BC%A0%E7%BB%B5/img_3.png"></p><p>官方介绍，升级之后，Kafka可以轻松支持百万级别的分区。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafak团队把通过Raft协议同步数据的方式Kafka Raft Metadata mode,简称KRaft</span><br></pre></td></tr></table></figure><p>关于Raft协议，本文并不打算深入进行探讨，具体参考文章<a href="https://zhuanlan.zhihu.com/p/91288179">Raft协议原理详解</a></p><p>Raft协议为选主提供了另外一种可行方案，而且还无需依赖第三方组件，何乐而不为呢？故最终Kafka在2.8版本中正式废弃了Zookeeper，拥抱Raft。</p><p>Kafaka计划在3.0版本会兼容Zookeeper Controller和Quorum Controller，这样用户可以进行灰度测试。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在大规模集群和云原生的背景下，使用Zookeeper给Kafka的运维和集群性能造成了很大的压力。去除Zookeeper是必然趋势，这也符合大道至简的架构思想。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 &lt;a href=&quot;/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZook</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
    <category term="ZOOKEEPER" scheme="http://example.com/tags/ZOOKEEPER/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件系列之死信、延迟、重试队列</title>
    <link href="http://example.com/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/"/>
    <id>http://example.com/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/</id>
    <published>2021-08-02T11:19:56.000Z</published>
    <updated>2021-08-12T03:37:01.842Z</updated>
    
    <content type="html"><![CDATA[<h3 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a>延迟队列</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在发送延时消息的时候并不是先投递到要发送的真实主题（real_topic）中，而是先投递到一些 Kafka 内部的主题（delay_topic）中，这些内部主题对用户不可见，</span><br><span class="line"></span><br><span class="line">然后通过一个自定义的服务拉取这些内部主题中的消息，并将满足条件的消息再投递到要发送的真实的主题中，消费者所订阅的还是真实的主题。</span><br></pre></td></tr></table></figure><p>如果采用这种方案，那么一般是按照不同的延时等级来划分的，比如设定5s、10s、30s、1min、2min、5min、10min、20min、30min、45min、1hour、2hour这些按延时时间递增的延时等级，延时的消息按照延时时间投递到不同等级的主题中，投递到同一主题中的消息的延时时间会被强转为与此主题延时等级一致的延时时间，这样延时误差控制在两个延时等级的时间差范围之内（比如延时时间为17s的消息投递到30s的延时主题中，之后按照延时时间为30s进行计算，延时误差为13s）。虽然有一定的延时误差，但是误差可控，并且这样只需增加少许的主题就能实现延时队列的功能。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_2.png"></p><p>发送到内部主题（delaytopic*）中的消息会被一个独立的 DelayService 进程消费，这个 DelayService 进程和 Kafka broker 进程以一对一的配比进行同机部署（参考下图），以保证服务的可用性。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_3.png"></p><p><strong>针对不同延时级别的主题，在 DelayService 的内部都会有单独的线程来进行消息的拉取，以及单独的 DelayQueue（这里用的是 JUC 中 DelayQueue）进行消息的暂存。</strong></p><p>与此同时，在 DelayService 内部还会有专门的消息发送线程来获取 DelayQueue 的消息并转发到真实的主题中。从消费、暂存再到转发，线程之间都是一一对应的关系。如下图所示，DelayService 的设计应当尽量保持简单，避免锁机制产生的隐患。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_4.png"></p><p>为了保障内部 DelayQueue 不会因为未处理的消息过多而导致内存的占用过大，DelayService 会对主题中的每个分区进行计数，当达到一定的阈值之后，就会暂停拉取该分区中的消息。</p><p>因为一个主题中一般不止一个分区，分区之间的消息并不会按照投递时间进行排序，DelayQueue的作用是将消息按照再次投递时间进行有序排序，这样下游的消息发送线程就能够按照先后顺序获取最先满足投递条件的消息。</p><h3 id="重试队列"><a href="#重试队列" class="headerlink" title="重试队列"></a>重试队列</h3><p>重试队列其实可以看作一种回退队列，具体指消费端消费消息失败时，为了防止消息无故丢失而重新将消息回滚到 broker 中。</p><p>与回退队列不同的是，重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大。</p><p>理解了他们的概念之后我们就可以为每个主题设置重试队列，消息第一次消费失败入重试队列 Q1，Q1 的重新投递延时为5s，5s过后重新投递该消息；如果消息再次消费失败则入重试队列 Q2，Q2 的重新投递延时为10s，10s过后再次投递该消息。</p><p>然后再设置一个主题作为死信队列，重试越多次重新投递的时间就越久，并且需要设置一个上限，超过投递次数就进入死信队列。重试队列与延时队列有相同的地方，都需要设置延时级别。</p><h3 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a>死信队列</h3><p>当一条消息初次消费失败，消息队列 MQ 会自动进行消息重试；</p><p>达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息; </p><p>此时，消息队列 MQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中，这种正常情况下无法被消费的消息称为<strong>死信消息</strong>（Dead-Letter Message），存储死信消息的特殊队列称为<strong>死信队列</strong>（Dead-Letter Queue）。</p><p>当一条消息在队列中出现以下三种情况的时候，该消息就会变成一条死信。</p><ul><li>消费者拒绝消费消息，并且不把消息重新放回原目标队列(消费者不想处理的数据)</li><li>消息TTL(time to live)过期(不符合处理要求的数据)</li><li>队列达到最大长度(消费者不能处理的数据)</li></ul><p>当消息在一个队列中变成一个死信之后，如果配置了死信队列，它将被重新publish到死信交换机，死信交换机将死信投递到一个队列上，这个队列就是死信队列。</p><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img.png"></p><h4 id="死信队列处理的方式"><a href="#死信队列处理的方式" class="headerlink" title="死信队列处理的方式"></a>死信队列处理的方式</h4><ul><li>丢弃，如果不是很重要，可以选择丢弃</li><li>记录死信入库，然后做后续的业务分析或处理</li><li>通过死信队列，由负责监听死信的应用程序进行处理</li></ul><p><img src="/2021/08/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%B3%BB%E5%88%97%E4%B9%8B%E6%AD%BB%E4%BF%A1%E3%80%81%E5%BB%B6%E8%BF%9F%E3%80%81%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97/img_1.png"></p><h3 id="各中间件支持"><a href="#各中间件支持" class="headerlink" title="各中间件支持"></a>各中间件支持</h3><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><p>Kafka 没有重试机制不支持消息重试，也没有死信队列，因此使用 Kafka 做消息队列时，如果遇到了消息在业务处理时出现异常，就会很难进行下一步处理。</p><p><strong>使用KafkaConnector扩展实现死信队列</strong></p><p>Kafka连接器是Kafka的一部分，是在Kafka和其它技术之间构建流式管道的一个强有力的框架。它可用于将数据从多个地方（包括数据库、消息队列和文本文件）流式注入到Kafka，以及从Kafka将数据流式传输到目标端（如文档存储、NoSQL、数据库、对象存储等）中。</p><p>Kafka连接器可以配置为将无法处理的消息（例如上面提到的反序列化错误）发送到一个单独的Kafka主题，即死信队列。有效消息会正常处理，管道也会继续运行。然后可以从死信队列中检查无效消息，并根据需要忽略或修复并重新处理。</p><p>进行如下的配置可以启用死信队列：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">errors.tolerance</span> = <span class="string">all</span></span><br><span class="line"><span class="meta">errors.deadletterqueue.topic.name</span> =<span class="string"></span></span><br></pre></td></tr></table></figure><p>如果运行于单节点Kafka集群，还需要配置<code>errors.deadletterqueue.topic.replication.factor = 1</code>，其默认值为3。</p><p>但是只有看到消息才能知道它是无效的JSON，即便如此，也只能假设消息被拒绝的原因，要确定Kafka连接器将消息视为无效的实际原因，有两个方法：</p><ul><li>死信队列的消息头；</li><li>Kafka连接器的工作节点日志。</li></ul><p><strong>记录消息的失败原因：消息头</strong></p><p>消息头是使用Kafka消息的键、值和时间戳存储的附加元数据，是在Kafka 0.11版本中引入的。Kafka连接器可以将有关消息拒绝原因的信息写入消息本身的消息头中。这个做法比写入日志文件更好，因为它将原因直接与消息联系起来。</p><p>配置如下的参数，可以在死信队列的消息头中包含拒绝原因：</p><pre><code>errors.deadletterqueue.context.headers.enable = true</code></pre><p><strong>记录消息的失败原因：日志</strong></p><p>记录消息的拒绝原因的第二个选项是将其写入日志。根据安装方式不同，Kafka连接器会将其写入标准输出或日志文件。无论哪种方式都会为每个失败的消息生成一堆详细输出。进行如下配置可启用此功能：</p><pre><code>errors.log.enable = true</code></pre><p>通过配置<code>errors.log.include.messages = true</code>，还可以在输出中包含有关消息本身的元数据。此元数据中包括一些和上面提到的消息头中一样的项目，包括源消息的主题和偏移量。注意它不包括消息键或值本身</p><h4 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h4><p>默认的处理机制中，如果我们只对消息做重复消费，达到最大重试次数之后消息就进入死信队列了。RocketMQ 的处理方式为将达到最大重试次数（16 次）的消息标记为死信消息，将该死信消息投递到 DLQ 死信队列中，业务需要进行人工干预。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;延迟队列&quot;&gt;&lt;a href=&quot;#延迟队列&quot; class=&quot;headerlink&quot; title=&quot;延迟队列&quot;&gt;&lt;/a&gt;延迟队列&lt;/h3&gt;&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
    <category term="RabbitMQ" scheme="http://example.com/tags/RabbitMQ/"/>
    
  </entry>
  
  <entry>
    <title>代码规范之JAVA代码安全指南</title>
    <link href="http://example.com/2021/07/13/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://example.com/2021/07/13/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</id>
    <published>2021-07-13T09:37:37.000Z</published>
    <updated>2021-07-14T08:49:21.089Z</updated>
    
    <content type="html"><![CDATA[<h2 id="后台类"><a href="#后台类" class="headerlink" title="后台类"></a>后台类</h2><h3 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h3><h4 id="【必须】SQL语句默认使用预编译并绑定变量"><a href="#【必须】SQL语句默认使用预编译并绑定变量" class="headerlink" title="【必须】SQL语句默认使用预编译并绑定变量"></a>【必须】SQL语句默认使用预编译并绑定变量</h4><p>Web后台系统应默认使用预编译绑定变量的形式创建sql语句，保持查询语句和数据相分离。以从本质上避免SQL注入风险。</p><p>如使用Mybatis作为持久层框架，应通过#{}语法进行参数绑定，MyBatis 会创建 <code>PreparedStatement</code> 参数占位符，并通过占位符安全地设置参数。</p><p>示例：JDBC</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String custname=request.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        String query=<span class="string">&quot;SELECT * FROM user_data WHERE user_name = ? &quot;</span>;</span><br><span class="line">        PreparedStatement pstmt=connection.prepareStatement(query);</span><br><span class="line">        pstmt.setString(<span class="number">1</span>,custname);</span><br><span class="line">        ResultSet results=pstmt.executeQuery();</span><br></pre></td></tr></table></figure><p>Mybatis</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id=<span class="string">&quot;queryRuleIdByApplicationId&quot;</span>parameterType=<span class="string">&quot;java.lang.String&quot;</span>resultType=<span class="string">&quot;java.lang.String&quot;</span>&gt;</span><br><span class="line">        select rule_id from scan_rule_sqlmap_tab where application_id=#&#123;applicationId&#125;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure><p>应避免外部输入未经过滤直接拼接到SQL语句中，或者通过Mybatis中的${}传入SQL语句（即使使用PreparedStatement，SQL语句直接拼接外部输入也同样有风险。例如Mybatis中部分参数通过${}传入SQL语句后实际执行时调用的是PreparedStatement.execute()<br>，同样存在注入风险）。</p><h4 id="【必须】白名单过滤"><a href="#【必须】白名单过滤" class="headerlink" title="【必须】白名单过滤"></a>【必须】白名单过滤</h4><p>对于表名、列名等无法进行预编译的场景，比如外部数据拼接到order by, group<br>by语句中，需通过白名单的形式对数据进行校验，例如判断传入列名是否存在、升降序仅允许输入“ASC”和“DESC”、表名列名仅允许输入字符、数字、下划线等。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">someMethod</span><span class="params">(<span class="keyword">boolean</span> sortOrder)</span></span>&#123;</span><br><span class="line">        String SQLquery=<span class="string">&quot;some SQL ... order by Salary &quot;</span>+(sortOrder?<span class="string">&quot;ASC&quot;</span>:<span class="string">&quot;DESC&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><h4 id="【必须】文件类型限制"><a href="#【必须】文件类型限制" class="headerlink" title="【必须】文件类型限制"></a>【必须】文件类型限制</h4><p>须在服务器端采用白名单方式对上传或下载的文件类型、大小进行严格的限制。仅允许业务所需文件类型上传，避免上传.jsp、.jspx、.class、.java等可执行文件。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">String file_name=file.getOriginalFilename();</span><br><span class="line">String[]parts=file_name.split(<span class="string">&quot;\\.&quot;</span>);</span><br><span class="line">String suffix=parts[parts.length-<span class="number">1</span>];</span><br><span class="line"><span class="keyword">switch</span>(suffix)&#123;</span><br><span class="line">    <span class="keyword">case</span><span class="string">&quot;jpeg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpeg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;jpg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;bmp&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.bmp&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;png&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.png&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">//handle error</span></span><br><span class="line">        <span class="keyword">return</span><span class="string">&quot;error&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】禁止外部文件存储于可执行目录"><a href="#【必须】禁止外部文件存储于可执行目录" class="headerlink" title="【必须】禁止外部文件存储于可执行目录"></a>【必须】禁止外部文件存储于可执行目录</h4><p>禁止外部文件存储于WEB容器的可执行目录（appBase）。建议保存在专门的文件服务器中。</p><h4 id="【建议】避免路径拼接"><a href="#【建议】避免路径拼接" class="headerlink" title="【建议】避免路径拼接"></a>【建议】避免路径拼接</h4><p>文件目录避免外部参数拼接。保存文件目录建议后台写死并对文件名进行校验（字符类型、长度）。建议文件保存时，将文件名替换为随机字符串。</p><h4 id="【必须】避免路径穿越"><a href="#【必须】避免路径穿越" class="headerlink" title="【必须】避免路径穿越"></a>【必须】避免路径穿越</h4><p>如因业务需要不能满足避免路径拼接，文件路径、文件命中拼接了不可行数据，需判断请求文件名和文件路径参数中是否存在../或..\(仅windows)， 如存在应判定路径非法并拒绝请求。</p><h3 id="网络访问"><a href="#网络访问" class="headerlink" title="网络访问"></a>网络访问</h3><h4 id="【必须】避免直接访问不可信地址"><a href="#【必须】避免直接访问不可信地址" class="headerlink" title="【必须】避免直接访问不可信地址"></a>【必须】避免直接访问不可信地址</h4><p>服务器访问不可信地址时，禁止访问私有地址段及内网域名。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 以RFC定义的专有网络为例，如有自定义私有网段亦应加入禁止访问列表。</span><br><span class="line">10.0.0.0/8</span><br><span class="line">172.16.0.0/12</span><br><span class="line">192.168.0.0/16</span><br><span class="line">127.0.0.0/8</span><br></pre></td></tr></table></figure><p>建议通过URL解析函数进行解析，获取host或者domain后通过DNS获取其IP，然后和内网地址进行比较。</p><p>对已校验通过地址进行访问时，应关闭跟进跳转功能。</p><p>参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">httpConnection=(HttpURLConnection)Url.openConnection();</span><br><span class="line">httpConnection.setFollowRedirects(<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="XML读写"><a href="#XML读写" class="headerlink" title="XML读写"></a>XML读写</h3><h4 id="【必须】XML解析器关闭DTD解析"><a href="#【必须】XML解析器关闭DTD解析" class="headerlink" title="【必须】XML解析器关闭DTD解析"></a>【必须】XML解析器关闭DTD解析</h4><p>读取外部传入XML文件时，XML解析器初始化过程中设置关闭DTD解析。</p><p>参考示例：</p><p>javax.xml.parsers.DocumentBuilderFactory</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setXIncludeAware(<span class="keyword">false</span>);</span><br><span class="line">        dbf.setExpandEntityReferences(<span class="keyword">false</span>);</span><br><span class="line">        ……</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>org.dom4j.io.SAXReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">saxReader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><p>org.jdom2.input.SAXBuilder</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SAXBuilder builder=<span class="keyword">new</span> SAXBuilder();</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">Document doc=builder.build(<span class="keyword">new</span> File(fileName));</span><br></pre></td></tr></table></figure><p>org.xml.sax.XMLReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">XMLReader reader=XMLReaderFactory.createXMLReader();</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="响应输出"><a href="#响应输出" class="headerlink" title="响应输出"></a>响应输出</h3><h4 id="【必须】设置正确的HTTP响应包类型"><a href="#【必须】设置正确的HTTP响应包类型" class="headerlink" title="【必须】设置正确的HTTP响应包类型"></a>【必须】设置正确的HTTP响应包类型</h4><p>响应包的HTTP头“Content-Type”必须正确配置响应包的类型，禁止非HTML类型的响应包设置为“text/html”。此举会使浏览器在直接访问链接时，将非HTML格式的返回报文当做HTML解析，增加反射型XSS的触发几率。</p><h4 id="【建议】设置安全的HTTP响应头"><a href="#【建议】设置安全的HTTP响应头" class="headerlink" title="【建议】设置安全的HTTP响应头"></a>【建议】设置安全的HTTP响应头</h4><ul><li><p>X-Content-Type-Options：</p><p>建议添加“X-Content-Type-Options”响应头并将其值设置为“nosniff”，可避免部分浏览器根据其“Content-Sniff”特性，将一些非“text/html”类型的响应作为HTML解析，增加反射型XSS的触发几率。</p></li><li><p>HttpOnly：</p><p>控制用户登录鉴权的Cookie字段 应当设置HttpOnly属性以防止被XSS漏洞/JavaScript操纵泄漏。</p></li><li><p>X-Frame-Options：</p><p>设置X-Frame-Options响应头，并根据需求合理设置其允许范围。该头用于指示浏览器禁止当前页面在frame、iframe、embed等标签中展现。从而避免点击劫持问题。它有三个可选的值：<br>DENY： 浏览器会拒绝当前页面加载任何frame页面；<br>SAMEORIGIN：则frame页面的地址只能为同源域名下的页面<br>ALLOW-FROM origin：可以定义允许frame加载的页面地址。</p></li><li><p>Access-Control-Allow-Origin</p><p>当需要配置CORS跨域时，应对请求头的Origin值做严格过滤。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String currentOrigin = request.getHeader(<span class="string">&quot;Origin&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (currentOrigin.equals(<span class="string">&quot;https://domain.qq.com&quot;</span>)) &#123;</span><br><span class="line">       response.setHeader(<span class="string">&quot;Access-Control-Allow-Origin&quot;</span>, currentOrigin);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="【必须】外部输入拼接到response页面前进行编码处理"><a href="#【必须】外部输入拼接到response页面前进行编码处理" class="headerlink" title="【必须】外部输入拼接到response页面前进行编码处理"></a>【必须】外部输入拼接到response页面前进行编码处理</h4><p>当响应“content-type”为“html”类型时，外部输入拼接到响应包中，需根据输出位置进行编码处理。编码规则：</p><table><thead><tr><th>场景</th><th>编码规则</th></tr></thead><tbody><tr><td>输出点在HTML标签之间</td><td>需要对以下6个特殊字符进行HTML实体编码(&amp;, &lt;, &gt;, “, ‘,/)。<br>示例：<br>&amp; –&gt; &amp;amp;<br>&lt; –&gt; &amp;lt;<br>&gt;–&gt; &amp;gt;<br>“ –&gt; &amp;quot;<br>‘ –&gt; &amp;#x27;  <br>/ –&gt; &amp;#x2F;</td></tr><tr><td>输出点在HTML标签普通属性内（如href、src、style等，on事件除外）</td><td>要对数据进行HTML属性编码。<br>编码规则：除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为&#xHH;(以&amp;#x开头，HH则是指该字符对应的十六进制数字，分号作为结束符)</td></tr><tr><td>输出点在JS内的数据中</td><td>需要进行js编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \xHH （以 \x 开头，HH则是指该字符对应的十六进制数字）<br>Tips：这种场景仅限于外部数据拼接在js里被引号括起来的变量值中。除此之外禁止直接将代码拼接在js代码中。</td></tr><tr><td>输出点在CSS中（Style属性）</td><td>需要进行CSS编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \HH （以 \ 开头，HH则是指该字符对应的十六进制数字）</td></tr><tr><td>输出点在URL属性中</td><td>对这些数据进行URL编码<br>Tips：除此之外，所有链接类属性应该校验其协议。禁止JavaScript、data和Vb伪协议。</td></tr></tbody></table><p>以上编码规则相对较为繁琐，可参考或直接使用业界已有成熟第三方库如ESAPI.其提供以下函数对象上表中的编码规则:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ESAPI.encoder().encodeForHTML();</span><br><span class="line">        ESAPI.encoder().encodeForHTMLAttribute();</span><br><span class="line">        ESAPI.encoder().encodeForJavaScript();</span><br><span class="line">        ESAPI.encoder().encodeForCSS();</span><br><span class="line">        ESAPI.encoder().encodeForURL();</span><br></pre></td></tr></table></figure><h4 id="【必须】外部输入拼接到HTTP响应头中需进行过滤"><a href="#【必须】外部输入拼接到HTTP响应头中需进行过滤" class="headerlink" title="【必须】外部输入拼接到HTTP响应头中需进行过滤"></a>【必须】外部输入拼接到HTTP响应头中需进行过滤</h4><p>应尽量避免外部可控参数拼接到HTTP响应头中，如业务需要则需要过滤掉“\r”、”\n”等换行符，或者拒绝携带换行符号的外部输入。</p><h4 id="【必须】避免不可信域名的302跳转"><a href="#【必须】避免不可信域名的302跳转" class="headerlink" title="【必须】避免不可信域名的302跳转"></a>【必须】避免不可信域名的302跳转</h4><p>如果对外部传入域名进行302跳转，必须设置可信域名列表并对传入域名进行校验。</p><p>为避免校验被绕过，应避免直接对URL进行字符串匹配。应通过通过URL解析函数进行解析，获取host或者domain后和白名单进行比较。</p><p>需要注意的是，由于浏览器的容错机制，域名<code>https://www.qq.com\www.bbb.com</code>中的<code>\</code>会被替换成<code>/</code>，最终跳转到<code>www.qq.com</code><br>。而Java的域名解析函数则无此特性。为避免解析不一致导致绕过，建议对host中的<code>/</code>和<code>#</code>进行替换。</p><p>参考代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">String host=<span class="string">&quot;&quot;</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  url=url.replaceAll(<span class="string">&quot;[\\\\#]&quot;</span>,<span class="string">&quot;/&quot;</span>); <span class="comment">//替换掉反斜线和井号</span></span><br><span class="line">  host=<span class="keyword">new</span> URL(url).getHost();</span><br><span class="line">&#125; <span class="keyword">catch</span>(MalformedURLException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(host.endsWith(<span class="string">&quot;.qq.com&quot;</span>))&#123;</span><br><span class="line">    <span class="comment">//跳转操作</span></span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】避免通过Jsonp传输非公开敏感信息"><a href="#【必须】避免通过Jsonp传输非公开敏感信息" class="headerlink" title="【必须】避免通过Jsonp传输非公开敏感信息"></a>【必须】避免通过Jsonp传输非公开敏感信息</h4><p>jsonp请求再被CSRF攻击时，其响应包可被攻击方劫持导致信息泄露。应避免通过jsonp传输非公开的敏感信息，例如用户隐私信息、身份凭证等。</p><h4 id="【必须】限定JSONP接口的callback字符集范围"><a href="#【必须】限定JSONP接口的callback字符集范围" class="headerlink" title="【必须】限定JSONP接口的callback字符集范围"></a>【必须】限定JSONP接口的callback字符集范围</h4><p>JSONP接口的callback函数名为固定白名单。如callback函数名可用户自定义，应限制函数名仅包含 字母、数字和下划线。如：<code>[a-zA-Z0-9_-]+</code></p><h4 id="【必须】屏蔽异常栈"><a href="#【必须】屏蔽异常栈" class="headerlink" title="【必须】屏蔽异常栈"></a>【必须】屏蔽异常栈</h4><p>应用程序出现异常时，禁止将数据库版本、数据库结构、操作系统版本、堆栈跟踪、文件名和路径信息、SQL 查询字符串等对攻击者有用的信息返回给客户端。建议重定向到一个统一、默认的错误提示页面，进行信息过滤。</p><h4 id="【必须】模板-amp-表达式"><a href="#【必须】模板-amp-表达式" class="headerlink" title="【必须】模板&amp;表达式"></a>【必须】模板&amp;表达式</h4><p>web view层通常通过模板技术或者表达式引擎来实现界面与业务数据分离，比如jsp中的EL表达式。这些引擎通常可执行敏感操作，如果外部不可信数据未经过滤拼接到表达式中进行解析。则可能造成严重漏洞。</p><p>下列是基于EL表达式注入漏洞的演示demo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    <span class="meta">@RequestMapping(&quot;/ELdemo&quot;)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">ELdemo</span><span class="params">(RepeatDTO repeat)</span></span>&#123;</span><br><span class="line">    ExpressionFactory expressionFactory=<span class="keyword">new</span> ExpressionFactoryImpl();</span><br><span class="line">    SimpleContext simpleContext=<span class="keyword">new</span> SimpleContext();</span><br><span class="line">    String exp=<span class="string">&quot;$&#123;&quot;</span>+repeat.getel()+<span class="string">&quot;&#125;&quot;</span>;</span><br><span class="line">    ValueExpression valueExpression=expressionFactory.createValueExpression(simpleContext,exp,String.class);</span><br><span class="line">    <span class="keyword">return</span> valueExpression.getValue(simpleContext).toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>外部可通过el参数，将不可信输入拼接到EL表达式中并解析。</p><p>此时外部访问：x.x.x.x/ELdemo?el=”’’.getClass().forName(‘java.lang.Runtime’).getMethod(‘exec’,’’.getClass()).invoke(‘’<br>.getClass().forName(‘java.lang.Runtime’).getMethod(‘getRuntime’).invoke(null),’open /Applications/Calculator.app’)“<br>可执行操作系统命令调出计算器。</p><p>基于以上风险：</p><ul><li>应避免外部输入的内容拼接到EL表达式或其他表达式引起、模板引擎进行解析。</li><li>白名单过滤外部输入，仅允许字符、数字、下划线等。</li></ul><h3 id="OS命令执行"><a href="#OS命令执行" class="headerlink" title="OS命令执行"></a>OS命令执行</h3><h4 id="【建议】避免不可信数据拼接操作系统命令"><a href="#【建议】避免不可信数据拼接操作系统命令" class="headerlink" title="【建议】避免不可信数据拼接操作系统命令"></a>【建议】避免不可信数据拼接操作系统命令</h4><p>当不可信数据存在时，应尽量避免外部数据拼接到操作系统命令使用 <code>Runtime</code> 和 <code>ProcessBuilder</code> 来执行。优先使用其他同类操作进行代替，比如通过文件系统API进行文件操作而非直接调用操作系统命令。</p><h4 id="【必须】避免创建SHELL操作"><a href="#【必须】避免创建SHELL操作" class="headerlink" title="【必须】避免创建SHELL操作"></a>【必须】避免创建SHELL操作</h4><p>如无法避免直接访问操作系统命令，需要严格管理外部传入参数，使不可信数据仅作为执行命令的参数而非命令。</p><ul><li><p>禁止外部数据直接直接作为操作系统命令执行。</p></li><li><p>避免通过”cmd”、“bash”、“sh”等命令创建shell后拼接外部数据来执行操作系统命令。</p></li><li><p>对外部传入数据进行过滤。可通过白名单限制字符类型，仅允许字符、数字、下划线；或过滤转义以下符号：|;&amp;$&gt;&lt;`（反引号）!</p><p>白名单示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern FILTER_PATTERN = Pattern.compile(<span class="string">&quot;[0-9A-Za-z_]+&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (!FILTER_PATTERN.matcher(input).matches()) &#123;</span><br><span class="line">  <span class="comment">// 终止当前请求的处理</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="会话管理"><a href="#会话管理" class="headerlink" title="会话管理"></a>会话管理</h3><h4 id="【必须】非一次有效身份凭证禁止在URL中传输"><a href="#【必须】非一次有效身份凭证禁止在URL中传输" class="headerlink" title="【必须】非一次有效身份凭证禁止在URL中传输"></a>【必须】非一次有效身份凭证禁止在URL中传输</h4><p>身份凭证禁止在URL中传输，一次有效的身份凭证除外（如CAS中的st）。</p><h4 id="【必须】避免未经校验的数据直接给会话赋值"><a href="#【必须】避免未经校验的数据直接给会话赋值" class="headerlink" title="【必须】避免未经校验的数据直接给会话赋值"></a>【必须】避免未经校验的数据直接给会话赋值</h4><p>防止会话信息被篡改，如恶意用户通过URL篡改手机号码等。</p><h3 id="加解密"><a href="#加解密" class="headerlink" title="加解密"></a>加解密</h3><h4 id="【建议】对称加密"><a href="#【建议】对称加密" class="headerlink" title="【建议】对称加密"></a>【建议】对称加密</h4><p>建议使用AES，秘钥长度128位以上。禁止使用DES算法，由于秘钥太短，其为目前已知不安全加密算法。使用AES加密算法请参考以下注意事项：</p><ul><li>AES算法如果采用CBC模式：每次加密时IV必须采用密码学安全的伪随机发生器（如/dev/urandom）,禁止填充全0等固定值。</li><li>AES算法如采用GCM模式，nonce须采用密码学安全的伪随机数</li><li>AES算法避免使用ECB模式，推荐使用GCM模式。</li></ul><h4 id="【建议】非对称加密"><a href="#【建议】非对称加密" class="headerlink" title="【建议】非对称加密"></a>【建议】非对称加密</h4><p>建议使用RSA算法，秘钥2048及以上。</p><h4 id="【建议】哈希算法"><a href="#【建议】哈希算法" class="headerlink" title="【建议】哈希算法"></a>【建议】哈希算法</h4><p>哈希算法推荐使用SHA-2及以上。对于签名场景，应使用HMAC算法。如果采用字符串拼接盐值后哈希的方式，禁止将盐值置于字符串开头，以避免哈希长度拓展攻击。</p><h4 id="【建议】密码存储策略"><a href="#【建议】密码存储策略" class="headerlink" title="【建议】密码存储策略"></a>【建议】密码存储策略</h4><p>建议采用随机盐+明文密码进行多轮哈希后存储密码。</p><h3 id="查询业务"><a href="#查询业务" class="headerlink" title="查询业务"></a>查询业务</h3><h4 id="【必须】返回信息最小化"><a href="#【必须】返回信息最小化" class="headerlink" title="【必须】返回信息最小化"></a>【必须】返回信息最小化</h4><p>返回用户信息应遵循最小化原则，避免将业务需求之外的用户信息返回到前端。</p><h4 id="【必须】个人敏感信息脱敏展示"><a href="#【必须】个人敏感信息脱敏展示" class="headerlink" title="【必须】个人敏感信息脱敏展示"></a>【必须】个人敏感信息脱敏展示</h4><p>在满足业务需求的情况下，个人敏感信息需脱敏展示,如：</p><ul><li>鉴权信息（如口令、密保答案、生理标识等）不允许展示</li><li>身份证只显示第一位和最后一位字符，如3****************1。</li><li>移动电话号码隐藏中间6位字符，如134******48。</li><li>工作地址/家庭地址最多显示到“区”一级。</li><li>银行卡号仅显示最后4位字符，如************8639</li></ul><h4 id="【必须】数据权限校验"><a href="#【必须】数据权限校验" class="headerlink" title="【必须】数据权限校验"></a>【必须】数据权限校验</h4><p>查询个人非公开信息时，需要对当前访问账号进行数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>验当前用户是否具备访问数据的权限</li></ol><h3 id="操作业务"><a href="#操作业务" class="headerlink" title="操作业务"></a>操作业务</h3><h4 id="【必须】部署CSRF防御机制"><a href="#【必须】部署CSRF防御机制" class="headerlink" title="【必须】部署CSRF防御机制"></a>【必须】部署CSRF防御机制</h4><p>CSRF是指跨站请求伪造（Cross-site request forgery），是web常见的攻击之一。对于可重放的敏感操作请求，需部署CSRF防御机制。可参考以下两种常见的CSRF防御方式</p><ul><li><p>设置CSRF Token</p><p>服务端给合法的客户颁发CSRF<br>Token，客户端在发送请求时携带该token供服务端校验，服务端拒绝token验证不通过的请求。以此来防止第三方构造合法的恶意操作链接。Token的作用域可以是Request级或者Session级。下面以Session级CSRF<br>Token进行示例</p><ol><li><p>登录成功后颁发Token，并同时存储在服务端Session中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String uuidToken = UUID.randomUUID().toString();</span><br><span class="line">map.put(<span class="string">&quot;token&quot;</span>, uuidToken);</span><br><span class="line">request.getSession().setAttribute(<span class="string">&quot;token&quot;</span>,uuidToken );</span><br><span class="line"><span class="keyword">return</span> map;</span><br></pre></td></tr></table></figure></li></ol></li></ul><ol start="2"><li><p>创建Filter</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CsrfFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;  </span><br><span class="line">   HttpSession session = req.getSession();</span><br><span class="line">   Object token = session.getAttribute(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   String requestToken = req.getParameter(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span>(StringUtils.isBlank(requestToken) || !requestToken.equals(token))&#123;</span><br><span class="line">         AjaxResponseWriter.write(req, resp, ServiceStatusEnum.ILLEGAL_TOKEN, <span class="string">&quot;非法的token&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li></ol><p>CSRF Token应具备随机性，保证其不可预测和枚举。另外由于浏览器会自动对表单所访问的域名添加相应的cookie信息，所以CSRF Token不应该通过Cookie传输。</p><ul><li><p>校验Referer头</p><p>通过检查HTTP请求的Referer字段是否属于本站域名，非本站域名的请求进行拒绝。</p><p>这种校验方式需要注意两点：</p><ol><li>要需要处理Referer为空的情况，当Referer为空则拒绝请求</li><li>注意避免例如qq.com.evil.com 部分匹配的情况。</li></ol></li></ul><h4 id="【必须】权限校验"><a href="#【必须】权限校验" class="headerlink" title="【必须】权限校验"></a>【必须】权限校验</h4><p>对于非公共操作，应当校验当前访问账号进行操作权限（常见于CMS）和数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>校验当前用户是否具备该操作权限</li><li>校验当前用户是否具备所操作数据的权限。避免越权。</li></ol><h4 id="【建议】加锁操作"><a href="#【建议】加锁操作" class="headerlink" title="【建议】加锁操作"></a>【建议】加锁操作</h4><p>对于有次数限制的操作，比如抽奖。如果操作的过程中资源访问未正确加锁。在高并发的情况下可能造成条件竞争，导致实际操作成功次数多于用户实际操作资格次数。此类操作应加锁处理。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;后台类&quot;&gt;&lt;a href=&quot;#后台类&quot; class=&quot;headerlink&quot; title=&quot;后台类&quot;&gt;&lt;/a&gt;后台类&lt;/h2&gt;&lt;h3 id=&quot;数据持久化&quot;&gt;&lt;a href=&quot;#数据持久化&quot; class=&quot;headerlink&quot; title=&quot;数据持久化&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    <category term="代码规范" scheme="http://example.com/categories/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
    
    <category term="代码规范" scheme="http://example.com/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>数据库MySQL系列01之死锁原理及其解决方案研究</title>
    <link href="http://example.com/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/"/>
    <id>http://example.com/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/</id>
    <published>2021-07-09T05:36:08.000Z</published>
    <updated>2021-08-12T03:37:01.975Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是死锁"><a href="#什么是死锁" class="headerlink" title="什么是死锁"></a>什么是死锁</h1><p>死锁是并发系统中常见的问题，同样也会出现在数据库MySQL的并发读写请求场景中。<br>当两个及以上的事务，双方都在等待对方释放已经持有的锁或因为加锁顺序不一致造成循环等待锁资源，就会出现“死锁”。<br>常见的报错信息为 Deadlock found when trying to get lock…<br>举例来说 A 事务持有 X1 锁 ，申请 X2 锁，B事务持有 X2 锁，申请 X1 锁。A 和 B 事务持有锁并且申请对方持有的锁进入循环等待，就造成了死锁。</p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img.png" class><p>如上图，是右侧的四辆汽车资源请求产生了回路现象，即死循环，导致了死锁。</p><h1 id="死锁出现要素"><a href="#死锁出现要素" class="headerlink" title="死锁出现要素"></a>死锁出现要素</h1><ul><li>两个或者两个以上事务</li><li>每个事务都已经持有锁并且申请新的锁</li><li>锁资源同时只能被同一个事务持有或者不兼容</li><li>事务之间因为持有锁和申请锁导致彼此循环等待</li></ul><h1 id="经典案例"><a href="#经典案例" class="headerlink" title="经典案例"></a>经典案例</h1><h2 id="案例一-事务并发-insert-唯一键冲突"><a href="#案例一-事务并发-insert-唯一键冲突" class="headerlink" title="案例一:事务并发 insert 唯一键冲突"></a>案例一:事务并发 insert 唯一键冲突</h2><p>表结构如下所示:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_1.png"></p><p>测试用例如下:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_2.png"></p><p>日志分析如下:</p><ul><li><p>事务 T2 insert into t7(id,a) values (26,10) 语句 insert 成功，持有 a=10 的 排他行锁( Xlocks rec but no gap )</p></li><li><p>事务 T1 insert into t7(id,a) values (30,10), 因为T2的第一条 insert 已经插入 a=10 的记录,事务 T1 insert a=10 则发生唯一键冲突,需要申请对冲突的唯一索引加上S Next-key Lock( 即 lock mode S waiting ) 这是一个间隙锁会申请锁住(,10],(10,20]之间的 gap 区域。</p></li><li><p>事务 T2 insert into t7(id,a) values (40，9)该语句插入的 a=9 的值在事务 T1 申请的 gap 锁4-10之间， 故需事务 T2 的第二条 insert 语句要等待事务 T1 的 S-Next-key Lock 锁释放,在日志中显示 lock_mode X locks gap before rec insert intention waiting 。</p></li></ul><h2 id="案例二-先-update-再-insert-的并发死锁问题"><a href="#案例二-先-update-再-insert-的并发死锁问题" class="headerlink" title="案例二:先 update 再 insert 的并发死锁问题"></a>案例二:先 update 再 insert 的并发死锁问题</h2><p>表结构如下，无数据:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_3.png"></p><p>测试用例如下:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_4.png"></p><p>死锁分析:<br>可以看到两个事务 update 不存在的记录，先后获得间隙锁( gap 锁)，gap 锁之间是兼容的所以在update环节不会阻塞。</p><p>两者都持有 gap 锁，然后去竞争插入意向锁。当存在其他会话持有 gap 锁的时候，当前会话申请不了插入意向锁，导致死锁。</p><h1 id="如何尽可能避免死锁"><a href="#如何尽可能避免死锁" class="headerlink" title="如何尽可能避免死锁"></a>如何尽可能避免死锁</h1><ul><li><p>合理的设计索引，区分度高的列放到组合索引前面，使业务 SQL 尽可能通过索引定位更少的行，减少锁竞争。</p></li><li><p>调整业务逻辑 SQL 执行顺序， 避免 update/delete 长时间持有锁的 SQL 在事务前面。</p></li><li><p>避免大事务，尽量将大事务拆成多个小事务来处理，小事务发生锁冲突的几率也更小。</p></li><li><p>以固定的顺序访问表和行。比如两个更新数据的事务，事务 A 更新数据的顺序为 1，2;事务 B 更新数据的顺序为 2，1。这样更可能会造成死锁。</p></li><li><p>在并发比较高的系统中，不要显式加锁，特别是是在事务里显式加锁。如 select … for update 语句，如果是在事务里（运行了 start transaction 或设置了autocommit 等于0）,那么就会锁定所查找到的记录。</p></li><li><p>尽量按主键/索引去查找记录，范围查找增加了锁冲突的可能性，也不要利用数据库做一些额外额度计算工作。比如有的程序会用到 “select … where … order by rand();”这样的语句，由于类似这样的语句用不到索引，因此将导致整个表的数据都被锁住。</p></li><li><p>优化 SQL 和表设计，减少同时占用太多资源的情况。比如说，减少连接的表，将复杂 SQL 分解为多个简单的 SQL。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;什么是死锁&quot;&gt;&lt;a href=&quot;#什么是死锁&quot; class=&quot;headerlink&quot; title=&quot;什么是死锁&quot;&gt;&lt;/a&gt;什么是死锁&lt;/h1&gt;&lt;p&gt;死锁是并发系统中常见的问题，同样也会出现在数据库MySQL的并发读写请求场景中。&lt;br&gt;当两个及以上的事务，双方都在</summary>
      
    
    
    
    <category term="数据库" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="数据库" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="死锁" scheme="http://example.com/tags/%E6%AD%BB%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>批处理框架之SpringBatch快速入门实践</title>
    <link href="http://example.com/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
    <id>http://example.com/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</id>
    <published>2021-06-19T08:47:31.000Z</published>
    <updated>2021-08-12T03:37:01.815Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是SpringBatch"><a href="#什么是SpringBatch" class="headerlink" title="什么是SpringBatch"></a>什么是SpringBatch</h3><p>一个轻量级，全面的<strong>批处理框架，不是一个 schuedling 的框架</strong>。</p><p>一个标准的批处理程序：</p><ul><li>通常会从数据库，文件或者队列中读取大量的数据和记录，</li><li>然后对获取的数据进行处理，</li><li>然后将修改后的格式写回到数据库中。</li></ul><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img.png"></p><p>通常 Spring Batch 在离线模式下进行工作，不需要用户干预就能自动进行基本的批处理迭代，进行类似事务方式的处理。批处理是大多数 IT 目的一个组成部分，而 Spring Batch<br>是唯一能够提供健壮的企业级扩展性的批处理开源框架。</p><h3 id="什么情况下需要用到SpringBatch"><a href="#什么情况下需要用到SpringBatch" class="headerlink" title="什么情况下需要用到SpringBatch"></a>什么情况下需要用到SpringBatch</h3><p>在大型企业中，由于业务复杂、数据量大、数据格式不同、数据交互格式繁杂，并非所有的操作都能通过交互界面进行处理。而有一些操作需要定期读取大批量的数据，然后进行一系列的后续处理。这样的过程就是“批处理”。</p><ul><li>数据量大，从数万到数百万甚至上亿不等；</li><li>整个过程全部自动化，并预留一定接口进行自定义配置；</li><li>这样的应用通常是周期性运行，比如按日、周、月运行；</li><li>对数据处理的准确性要求高，并且需要容错机制、回滚机制、完善的日志监控等。</li></ul><h3 id="SpringBatch提供了哪些功能"><a href="#SpringBatch提供了哪些功能" class="headerlink" title="SpringBatch提供了哪些功能"></a>SpringBatch提供了哪些功能</h3><ul><li>事务管理：全批次事务(因为可能有小数据量的批处理或存在存储过程/脚本中)</li><li>基于Web的管理员接口</li><li>分阶段的企业消息驱动处理</li><li>极高容量和高性能的基于块的处理过程(通过优化和分区技术)</li><li>按顺序处理任务依赖（使用工作流驱动的批处理插件）</li><li>声明式的输入/输出操作</li><li>启动、终止、（失败后的手动或定时）重启任务</li><li>重试/跳过任务，部分处理跳过记录（例如，回滚）<details><summary>具体使用场景</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在处理百万级的数据过程过程中难免会出现异常。如果一旦出现异常而导致整个批处理工作终止的话那么会导致后续的数据无法被处理。Spring Batch内置了Retry（重试）和Skip（跳过）机制帮助我们轻松处理各种异常。我 们需要将异常分为三种类型。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> 第一种是<span class="strong">**需要进行Retry的异常**</span>，它们的特点是该异常可能会随着时间推移而消失，比如数据库目前有锁无法写入、web服务当前不可用、web服务满载等。所以对它们适合配置Retry机制。</span><br><span class="line"><span class="bullet">*</span> 第二种是<span class="strong">**需要Skip的异常**</span>，比如解析文件的某条数据出现异常等，因为对这些异常即使执行Retry每次的结果也都是相同，但又不想由于某条数据出错而停止对后续数据的处理。</span><br><span class="line"><span class="bullet">*</span> 第三种异常是<span class="strong">**需要让整个Job立刻失败的异常**</span>，比如如果出现了OutOfMemory的异常，那么需要整个Job立刻终止运行。</span><br><span class="line"></span><br><span class="line">一般来说需要Retry的异常也要配置Skip选项，从而保证后续的数据能够被继续处理。我们也可以配置SkipLimit选项保证当Skip的数据条目达到一定数量后及时终止整个Job。</span><br></pre></td></tr></table></figure></details></li></ul><h3 id="SpringBatch整体架构"><a href="#SpringBatch整体架构" class="headerlink" title="SpringBatch整体架构"></a>SpringBatch整体架构</h3><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_1.png"></p><p>Spring batch框架有4个主要组件：JobLauncher、Job、Step和JobRepository。</p><ul><li>JobLauncher（任务启动器）：通过它启动任务，可以理解为程序的入口。</li><li>Job（任务）：一个具体的任务。<ul><li>由一个或多个step组成，</li><li>通过JobBuilderFactory实例创建Bean，</li><li>使用next指向下一个step,  可以按照指定的逻辑顺序组合 step,</li><li>提供了我们给所有 step 设置相同属性的方法（例如一些事件监听，跳过策略）;</li></ul></li><li>Step（步骤）：一个具体的执行步骤，一个Job中可以有多个Step。</li><li>JobRepository（任务仓库）：存储数据的仓库，在任务执行的时候，需要用它来记录任务状态信息，可以看做是一个数据库的接口。</li></ul><h4 id="JOB"><a href="#JOB" class="headerlink" title="JOB"></a>JOB</h4><p>Job 是一个封装整个批处理过程的一个概念。Job 在 spring batch 的体系当中只是一个最顶层的一个抽象概念，体现在代码当中则它只是一个最上层的接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Batch domain object representing a job. Job is an explicit abstraction</span></span><br><span class="line"><span class="comment"> * representing the configuration of a job specified by a developer. It should</span></span><br><span class="line"><span class="comment"> * be noted that restart policy is applied to the job as a whole and not to a</span></span><br><span class="line"><span class="comment"> * step.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"> <span class="function">String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">boolean</span> <span class="title">isRestartable</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecution execution)</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersIncrementer <span class="title">getJobParametersIncrementer</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersValidator <span class="title">getJobParametersValidator</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Job 这个接口当中定义了五个方法，它的实现类主要有两种类型的 job，一个是 simplejob，另一个是 flowjob。</p><p>Spring Batch 以 SimpleJob 类的形式提供了 Job 接口的默认简单实现，它在 Job 之上创建了一些标准功能。一个使用 java config 的例子代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job footballJob() &#123;</span><br><span class="line">    return this.jobBuilderFactory.get(&quot;footballJob&quot;)</span><br><span class="line">                     .start(playerLoad())</span><br><span class="line">                     .next(gameLoad())</span><br><span class="line">                     .next(playerSummarization())</span><br><span class="line">                     .end()</span><br><span class="line">                     .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="JobInstance"><a href="#JobInstance" class="headerlink" title="JobInstance"></a>JobInstance</h4><p>他是 Job 的更加底层的一个抽象，他的定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobInstance</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobInstance.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> instance id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getInstanceId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>他的方法很简单，一个是返回 Job 的 id，另一个是返回 Job 的名字。</p><p>JobInstance 指的是 job 运行当中，作业执行过程当中的概念。</p><p>比如说现在有一个批处理的 job，它的功能是在一天结束时执行行一次。我们假定这个批处理 job 的名字为’EndOfDay’。在这个情况下，那么每天就会有一个逻辑意义上的 JobInstance, 而我们必须记录 job 的每次运行的情况。</p><h4 id="JobParameters"><a href="#JobParameters" class="headerlink" title="JobParameters"></a>JobParameters</h4><p>JobParameters 对象包含一组用于启动批处理作业的参数，它可以在运行期间用于识别或甚至用作参考数据。</p><p>例如, 我们前面的’EndOfDay’的 job 现在已经有了两个实例，一个产生于 1 月 1 日，另一个产生于 1 月 2 日，那么我们就可以定义两个 JobParameter 对象：一个的参数是 01-01, 另一个的参数是 01-02。</p><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_2.png"></p><p>因此，我么可以通过 Jobparameter 来操作正确的 JobInstance</p><h4 id="JobExecution"><a href="#JobExecution" class="headerlink" title="JobExecution"></a>JobExecution</h4><p>JobExecution 指的是单次尝试运行一个我们定义好的 Job 的代码层面的概念。job 的一次执行可能以失败也可能成功。只有当执行成功完成时，给定的与执行相对应的 JobInstance 才也被视为完成。</p><p>还是以前面描述的 EndOfDay 的 job 作为示例，假设第一次运行 01-01-2019 的 JobInstance 结果是失败。那么此时如果使用与第一次运行相同的 Jobparameter 参数（即 01-01-2019）作业参数再次运行，那么就会创建一个对应于之前 jobInstance 的一个新的 JobExecution 实例, JobInstance 仍然只有一个。</p><p>JobExecution 的接口定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobExecution</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobExecution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> execution id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getExecutionId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get batch status of this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> batch status value.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> BatchStatus <span class="title">getBatchStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered STARTED status. </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getStartTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered end status: COMPLETED, STOPPED, FAILED </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getEndTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get execution exit status.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> exit status.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getExitStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was created.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getCreateTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was last updated updated.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getLastUpdatedTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job parameters for this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> job parameters  </span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Properties <span class="title">getJobParameters</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>JobExecution 当中提供了一个方法 getBatchStatus 用于获取一个 job 某一次特地执行的一个状态。BatchStatus 是一个代表 job 状态的枚举类，其定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">BatchStatus</span> </span>&#123;</span><br><span class="line">    STARTING, STARTED, STOPPING, STOPPED, FAILED, COMPLETED, ABANDONED</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h4><p>每一个 Step 对象都封装了批处理作业的一个独立的阶段。事实上，每一个 Job 本质上都是由一个或多个步骤组成。每一个 step 包含定义和控制实际批处理所需的所有信息。任何特定的内容都由编写 Job 的开发人员自行决定。</p><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_3.png"></p><p>StepExecution 表示一次执行 Step, 每次运行一个 Step 时都会创建一个新的 StepExecution，类似于 JobExecution。但是，某个步骤可能由于其之前的步骤失败而无法执行。且仅当 Step 实际启动时才会创建 StepExecution。</p><p>一次 step 执行的实例由 StepExecution 类的对象表示。每个 StepExecution 都包含对其相应步骤的引用以及 JobExecution 和事务相关的数据，例如提交和回滚计数以及开始和结束时间。</p><p>此外，每个步骤执行都包含一个 ExecutionContext，其中包含开发人员需要在批处理运行中保留的任何数据，例如重新启动所需的统计信息或状态信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job JobFlowDemo1()&#123;</span><br><span class="line">    return jobBuilderFactory.get(&quot;jobFlowDemo1&quot;)</span><br><span class="line">//                .start(step1())</span><br><span class="line">//                .next(step2())</span><br><span class="line">//                .next(step3())</span><br><span class="line">//                .build();</span><br><span class="line">                .start(step1())</span><br><span class="line">                .on(&quot;COMPLETED&quot;).to(step2())</span><br><span class="line">                .from(step2()).on(&quot;COMPLETED&quot;).to(step3())</span><br><span class="line">                .from(step3()).end()</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">当step1 成功执行完成后，返回COMPLETED， 才调用step2进行下一步处理。但是过多的step，不易于程序维护和复用</span><br></pre></td></tr></table></figure><h4 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h4><p><img src="/2021/06/19/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_4.png"></p><p>由于我们一次 batch 的任务可能会有很多的数据读写操作，因此一条一条的处理并向数据库提交的话效率不会很高，因此 spring batch 提供了 chunk 这个概念，我们可以设定一个 chunk size，spring batch 将一条一条处理数据，但不提交到数据库，只有当处理的数据数量达到 chunk size 设定的值得时候，才一起去 commit.</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Spring Batch为我们提供了非常实用的功能，对批处理场景进行了完善的抽象，它不仅能实现小数据的迁移，也能应对大企业的大数据实践应用。它让我们开发批处理应用可以事半功倍。  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;什么是SpringBatch&quot;&gt;&lt;a href=&quot;#什么是SpringBatch&quot; class=&quot;headerlink&quot; title=&quot;什么是SpringBatch&quot;&gt;&lt;/a&gt;什么是SpringBatch&lt;/h3&gt;&lt;p&gt;一个轻量级，全面的&lt;strong&gt;批处理框架</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="SpringBatch" scheme="http://example.com/tags/SpringBatch/"/>
    
    <category term="Spring生态" scheme="http://example.com/tags/Spring%E7%94%9F%E6%80%81/"/>
    
    <category term="批处理" scheme="http://example.com/tags/%E6%89%B9%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之Kafka重平衡机制简读</title>
    <link href="http://example.com/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/"/>
    <id>http://example.com/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/</id>
    <published>2021-05-24T07:46:57.000Z</published>
    <updated>2021-08-12T03:37:01.883Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是Rebalance"><a href="#什么是Rebalance" class="headerlink" title="什么是Rebalance"></a>什么是Rebalance</h3><p>如果对RocketMQ或者对消息中间件有所了解的话，消费端在进行消息消费时至少需要先进行队列（分区）的负载，即一个消费组内的多个消费者如何对订阅的主题中的队列进行负载均衡,当消费者新增或减少、队列增加或减少时能否自动重平衡，做到应用无感知，直接决定了程序伸缩性，其说明图如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img0.png"></p><p>Rebalance本质上是一种协议，规定了一个Consumer Group下的所有的Consumer如何达成一致来分配订阅Topic的每个Partition；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">比如某个group下有5个consumer，它订阅了一个具有10个分区的topic。正常情况下，Kafka平均会为每个consumer分配2个分区。这个分配的过程就叫rebalance。</span><br></pre></td></tr></table></figure><h3 id="Kafka消费端基本流程"><a href="#Kafka消费端基本流程" class="headerlink" title="Kafka消费端基本流程"></a>Kafka消费端基本流程</h3><p>在介绍kafka消费端重平衡机制之前，我们首先简单来看看消费者拉取消息的流程，从整个流程来看重平衡的触发时机、在整个消费流程中所起的重要作用，消费端拉取消息的简要流程如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img1.png"></p><p>主要的关键点如下：</p><ul><li>判断KafkaConsumer对象是否处在多线程环境中。注意：<strong>该对象是多线程不安全的，不能有多个线程持有该对象。</strong></li><li>消费组初始化，包含了队列负载(重平衡)</li><li>消息拉取</li><li>消息消费拦截器处理</li></ul><p>关于poll方法的核心无非就是两个：<strong>重平衡</strong>与<strong>消费拉取</strong>，本篇文章将重点剖析Kafka消费者的重平衡机制。</p><h3 id="消费者队列负载-重平衡-机制"><a href="#消费者队列负载-重平衡-机制" class="headerlink" title="消费者队列负载(重平衡)机制"></a>消费者队列负载(重平衡)机制</h3><p>通过对updateAssignmentMetadataIfNeeded方法的源码剖析，最终调用的核心方法为ConsumerCoordinator的poll方法，核心流程图如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img2.png"></p><p>消费者协调器的核心流程关键点：</p><ul><li>消费者协调器寻找组协调器</li><li>队列负载(重平衡)</li><li>提交位点</li></ul><p><strong>Some Question</strong>  </p><ul><li>重平衡会阻塞消息消费吗？</li><li>Kafka的加入组协议哪些变更能有效减少重平衡</li><li>Kafka与RocketMQ的重平衡机制上各有什么优劣势</li></ul><h4 id="消费者协调器"><a href="#消费者协调器" class="headerlink" title="消费者协调器"></a>消费者协调器</h4><p>在Kafka中，在客户端每一个消费者会对应一个消费者协调器(ConsumerCoordinator),在服务端每一个broker会启动一个组协调器。</p><p>接下来将对该过程进行源码级别的跟踪，根据源码提练工作机制，该部分对应上面流程图中的：ensureCoordinatorReady方法。</p><details>    <summary>protected synchronized boolean ensureCoordinatorReady(final Timer timer)</summary>    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">protected synchronized boolean ensureCoordinatorReady(final Timer timer) &#123;</span><br><span class="line">    if (!coordinatorUnknown())</span><br><span class="line">        return true;</span><br><span class="line"></span><br><span class="line">    do &#123;</span><br><span class="line">        final RequestFuture&lt;Void&gt; future = lookupCoordinator();</span><br><span class="line">        client.poll(future, timer);</span><br><span class="line"></span><br><span class="line">        if (!future.isDone()) &#123;</span><br><span class="line">            // ran out of time</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (future.failed()) &#123;</span><br><span class="line">            if (future.isRetriable()) &#123;</span><br><span class="line">                log.debug(&quot;Coordinator discovery failed, refreshing metadata&quot;);</span><br><span class="line">                client.awaitMetadataUpdate(timer);</span><br><span class="line">            &#125; else</span><br><span class="line">                throw future.exception();</span><br><span class="line">        &#125; else if (coordinator != null &amp;&amp; client.isUnavailable(coordinator)) &#123;</span><br><span class="line">            // we found the coordinator, but the connection has failed, so mark</span><br><span class="line">            // it dead and backoff before retrying discovery</span><br><span class="line">            markCoordinatorUnknown();</span><br><span class="line">            timer.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; while (coordinatorUnknown() &amp;&amp; timer.notExpired());</span><br><span class="line"></span><br><span class="line">    return !coordinatorUnknown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>该方法的关键点如下：</p><ul><li>首先判断一下当前消费者是否已找到broker端的组协调器，如果以感知，则返回true。</li><li>如果当前并没有感知组协调器，则向服务端(broker)寻找该消费组的组协调器。</li><li>寻找组协调器的过程是一个同步过程，如果出现异常，则会触发重试，但引入了重试间隔机制。</li><li>如果未超时并且没有获取组协调器，则再次尝试(do while)。</li></ul><p>核心要点为<strong>lookupCoordinator</strong>方法，该方法的核心是<strong>选择一台负载最小的broker</strong>,构建请求，向broker端查询消费组的组协调器，代码如下：</p><details>    <summary>private RequestFuture<Void> sendFindCoordinatorRequest(Node node)</Void></summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Discover the current coordinator for the group. Sends a GroupMetadata request to</span><br><span class="line"> * one of the brokers. The returned future should be polled to get the result of the request.</span><br><span class="line"> * @return A request future which indicates the completion of the metadata request</span><br><span class="line"> */</span><br><span class="line">private RequestFuture&lt;Void&gt; sendFindCoordinatorRequest(Node node) &#123;</span><br><span class="line">    // initiate the group metadata request</span><br><span class="line">    log.debug(&quot;Sending FindCoordinator request to broker &#123;&#125;&quot;, node);</span><br><span class="line">    FindCoordinatorRequest.Builder requestBuilder =</span><br><span class="line">            new FindCoordinatorRequest.Builder(</span><br><span class="line">                    new FindCoordinatorRequestData()</span><br><span class="line">                        .setKeyType(CoordinatorType.GROUP.id())</span><br><span class="line">                        .setKey(this.groupId));</span><br><span class="line">    return client.send(node, requestBuilder)</span><br><span class="line">            .compose(new FindCoordinatorResponseHandler());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>查询组协调器的请求，核心参数为：</p><ul><li><p>ApiKeys apiKey<br>  请求API，类比RocketMQ的RequestCode，根据该值很容易找到服务端对应的处理代码，这里为ApiKeys.FIND_COORDINATOR。</p></li><li><p>String coordinatorKey<br>  协调器key，取消费组名称。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka服务端每一台Broker会创建一个组协调器(GroupCoordinator),每一个组协调器可以协调多个消费组，但一个消费组只会被分配给一个组协调器，那这里负载机制是什么呢？服务端众多Broker如何竞争该消费组的控制权呢？</span><br></pre></td></tr></table></figure></li><li><p>coordinatorType<br>协调器类型，默认为GROUP,表示普通消费组。</p></li><li><p>short minVersion<br>版本。</p></li></ul><p>针对客户端端请求，服务端统一入口为KafkaApis.scala，可以根据ApiKeys快速找到其处理入口：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img.png"><br>具体的处理逻辑在KafkaApis的handleFindCoordinatorRequest中，如下图所示:<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_1.png"></p><p>服务端为消费组分配协调器的核心算法竟然非常简单：</p><ul><li>根据消费组的名称，取hashcode，</li><li>然后与kafka内部topic(__consumer_offsets)的分区个数取模，</li><li>然后返回该分区所在的物理broker作为消费组的分组协调器</li><li>即内部并没有复杂的选举机制，这样也能更好的说明，客户端在发送请求时可以挑选负载最低的broker进行查询的原因。</li></ul><p>客户端收到响应结果后更新ConsumerCoordinator的(Node coordinator)属性，这样再次调用coordinatorUnknown()方法，将会返回false,至此完成消费端协调器的查找。</p><h4 id="消费者加入消费组流程剖析"><a href="#消费者加入消费组流程剖析" class="headerlink" title="消费者加入消费组流程剖析"></a>消费者加入消费组流程剖析</h4><p>用一张时序图来说明协调者一端是如何处理新成员入组的:<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_21.png"></p><p>在消费者获取到协调器后，根据上文提到的协调器处理流程，接下来消费者需要加入到消费者组中，加入到消费组也是参与队列负载机制的前提，接下来我们从源码角度分析一下消费组加入消费组的流程，对应上文中的<strong>AbstractCoordinator的ensureActiveGroup</strong>方法。</p><details>    <summary>boolean ensureActiveGroup(final Timer timer)</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Ensure the group is active (i.e., joined and synced)</span><br><span class="line"> *</span><br><span class="line"> * @param timer Timer bounding how long this method can block</span><br><span class="line"> * @return true iff the group is active</span><br><span class="line"> */</span><br><span class="line">boolean ensureActiveGroup(final Timer timer) &#123;</span><br><span class="line">    // always ensure that the coordinator is ready because we may have been disconnected</span><br><span class="line">    // when sending heartbeats and does not necessarily require us to rejoin the group.</span><br><span class="line">    if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    startHeartbeatThreadIfNeeded();</span><br><span class="line">    return joinGroupIfNeeded(timer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>该方法的核心关键点：</p><ul><li>在加入消费组之前必须确保该消费者已经感知到组协调器。</li><li>启动心跳线程，当消费者加入到消费组后处于MemberState.STABLE后需要定时向协调器上报心跳，表示存活，否则将从消费组中移除。</li><li>加入消费组。</li></ul><p>心跳线程稍后会详细介绍，先跟踪一下加入消费组的核心流程，具体实现方法为</p><details><summary>joinGroupIfneeded</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Joins the group without starting the heartbeat thread.</span><br><span class="line"> *</span><br><span class="line"> * Visible for testing.</span><br><span class="line"> *</span><br><span class="line"> * @param timer Timer bounding how long this method can block</span><br><span class="line"> * @return true iff the operation succeeded</span><br><span class="line"> */</span><br><span class="line">boolean joinGroupIfNeeded(final Timer timer) &#123;</span><br><span class="line">    while (rejoinNeededOrPending()) &#123;</span><br><span class="line">        if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span><br><span class="line">        // time if the client is woken up before a pending rebalance completes. This must be called</span><br><span class="line">        // on each iteration of the loop because an event requiring a rebalance (such as a metadata</span><br><span class="line">        // refresh which changes the matched subscription set) can occur while another rebalance is</span><br><span class="line">        // still in progress.</span><br><span class="line">        if (needsJoinPrepare) &#123;</span><br><span class="line">            onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">            needsJoinPrepare = false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        final RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br><span class="line">        client.poll(future, timer);</span><br><span class="line">        if (!future.isDone()) &#123;</span><br><span class="line">            // we ran out of time</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (future.succeeded()) &#123;</span><br><span class="line">            // Duplicate the buffer in case `onJoinComplete` does not complete and needs to be retried.</span><br><span class="line">            ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line">            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br><span class="line"></span><br><span class="line">            // We reset the join group future only after the completion callback returns. This ensures</span><br><span class="line">            // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            needsJoinPrepare = true;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            final RuntimeException exception = future.exception();</span><br><span class="line">            if (exception instanceof UnknownMemberIdException ||</span><br><span class="line">                    exception instanceof RebalanceInProgressException ||</span><br><span class="line">                    exception instanceof IllegalGenerationException ||</span><br><span class="line">                    exception instanceof MemberIdRequiredException)</span><br><span class="line">                continue;</span><br><span class="line">            else if (!future.isRetriable())</span><br><span class="line">                throw exception;</span><br><span class="line"></span><br><span class="line">            timer.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>接下来对该方法进行分步解读：</p><ol><li><p>加入消费组之前必须先获取对应的组协调器，因为后续所有的请求都是需要发送到组协调器上。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>每一次执行重平衡之前调用其回调函数，我们可以看看ConsumerCoordinatory的实现</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span><br><span class="line">// time if the client is woken up before a pending rebalance completes. This must be called</span><br><span class="line">// on each iteration of the loop because an event requiring a rebalance (such as a metadata</span><br><span class="line">// refresh which changes the matched subscription set) can occur while another rebalance is</span><br><span class="line">// still in progress.</span><br><span class="line">if (needsJoinPrepare) &#123;</span><br><span class="line">    onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">    needsJoinPrepare = false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void onJoinPrepare(int generation, String memberId) &#123;</span><br><span class="line">    // commit offsets prior to rebalance if auto-commit enabled</span><br><span class="line">    maybeAutoCommitOffsetsSync(time.timer(rebalanceTimeoutMs));</span><br><span class="line"></span><br><span class="line">    // execute the user&#x27;s callback before rebalance</span><br><span class="line">    ConsumerRebalanceListener listener = subscriptions.rebalanceListener();</span><br><span class="line">    Set&lt;TopicPartition&gt; revoked = subscriptions.assignedPartitions();</span><br><span class="line">    log.info(&quot;Revoking previously assigned partitions &#123;&#125;&quot;, revoked);</span><br><span class="line">    try &#123;</span><br><span class="line">        listener.onPartitionsRevoked(revoked);</span><br><span class="line">    &#125; catch (WakeupException | InterruptException e) &#123;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        log.error(&quot;User provided listener &#123;&#125; failed on partition revocation&quot;, listener.getClass().getName(), e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    isLeader = false;</span><br><span class="line">    subscriptions.resetGroupSubscription();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>消费端协调器在进行重平衡(加入一个新组)之前通常会执行如下操作：</p><ul><li>如果开启了自动提交位点，进行一次位点提交。</li><li>执行重平衡相关的事件监听器。</li></ul></li><li><p>向消费组的组协调器发送加入请求，但加入消费组并不是目的，而是手段，最终要达成的目的是进行队列的负载均衡。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br></pre></td></tr></table></figure></li><li><p>调用onJoinComplete方法，通知消费端协调器队列负载的最终结果</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line">onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br></pre></td></tr></table></figure><ul><li>generationId</li><li>memberId 成员id</li><li>protocol 协议名称，这里是consumer。</li><li>memberAssignment 队列负载结果，包含了分配给当前消费者的队列信息，其序列后的结果如图所示<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_2.png"></li></ul></li></ol><p>故队列的负载机制蕴含在构建请求中，接下来深入分析一下客户端与服务端详细的交互流程。</p><h5 id="构建加入消费组请求"><a href="#构建加入消费组请求" class="headerlink" title="构建加入消费组请求"></a>构建加入消费组请求</h5><p>构建加入消费组代码见AbstractCoordinator的sendJoinGroupRequest,其代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_3.png"></p><p>发起一次组加入请求，请求体主要包含如下信息：</p><ul><li>消费组的名称</li><li>session timeout，会话超时时间，默认为10s</li><li>memberId 消费组成员id,第一次为null，后续服务端会为该消费者分配一个唯一的id,构成为客户端id + uuid。</li><li>protocolType 协议类型，消费者加入消费组固定为 consumer</li><li>消费端支持的所有队列负载算法</li></ul><p>收到服务端响应后将会调用JoinGroupResponseHandler回掉，稍后会详细介绍。</p><h5 id="服务端响应逻辑"><a href="#服务端响应逻辑" class="headerlink" title="服务端响应逻辑"></a>服务端响应逻辑</h5><p>服务端处理入口：KafkaApis的handleJoinGroupRequest方法，该方法为委托给GroupCoordinator。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_4.png"></p><p>通过这个入口，基本可以看到服务端处理加入请求的关键点：</p><ul><li>从客户端请求中提取客户端的memberId,如果为空，表示第一次加入消费组，还未分配memberId。</li><li>如果协调器中不存在该消费组的信息，表示第一次加入，创建一个，并执行doUnknownJoinGroup(第一次加入消费组逻辑)</li><li>如果协调器中已存在消费组的信息，判断一下是否已达到<strong>最大消费者个数限制</strong>(默认不限制)，超过则会抛出异常；然后根据消费者是否是第一次加入进行对应的逻辑处理。</li></ul><p><strong>组协调器会为每一个路由到的消费组维护一个组元信息(GroupMetadata)，存储在HashMap&lt; String, GroupMetadata&gt;，每一个消费组云信息中存储了当前的所有的消费者，由消费者主动加入，组协调器可以主动剔除消费者。</strong></p><p>接下来分情况处理，来看一下第一次加入(doUnknownJoinGroup)与重新加入(doJoinGroup)分别详细探讨。</p><h6 id="初次加入消费组"><a href="#初次加入消费组" class="headerlink" title="初次加入消费组"></a>初次加入消费组</h6><p>初次加入消费组的代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_5.png"></p><p>关键点如下：</p><ul><li><p>首先来看一下该方法的参数含义：</p><ul><li>GroupMetadata group: 消费组的元信息，并未持久化，存储在内存中，一个消费组当前消费者的信息。 </li><li>boolean requireKnownMemberId: 是否一定需要知道客户端id,如果客户端请求版本为4,在加入消费组时需要明确知道对方的memberId。</li><li>String clientId: 客户端ID,消息组的memberId生成规则为 clientId + uuid</li><li>String clientHost: 消费端端ip地址 </li><li>int rebalanceTimeoutMs: 重平衡超时时间，取自消费端参数max.poll.interval.ms，默认为5分钟。</li><li>int sessionTimeoutMs: 会话超时时间，默认为10s</li><li>String protocolType: 协议类型，默认为consumer</li><li>List protocols: 客户端支持的队列负载算法。</li></ul></li><li><p>对客户端进行状态验证，其校验如下：</p><ul><li>如果消费者状态为dead，则返回UNKNOWN_MEMBER_ID</li><li>如果当前消费组的负载算法协议不支持新客户端端队列负载协议，则抛出UNKNOWN_MEMBER_ID，并提示不一致的队列负载协议。</li></ul></li><li><p>Kafka 的加入请求版本4在加入消费端组时使用有明确的客户端memberId，消费组将创建的memberId加入到组的pendingMember中，并向客户端返回MEMBER_ID_REQUIRED，引导客户端重新加入，客户端会使用服务端生成的memberId，重新发起加入消费组。</p></li><li><p>调用addMemberAndRebalance方法加入消费组并触发重平衡。</p></li></ul><p>接下来继续探究加入消费组并触发重平衡的具体逻辑，具体实现见GroupCoordinator的addMemberAndRebalance。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_6.png"></p><p>核心要点如下：</p><ul><li>组协调器为每一个消费者创建一个MemberMetadata对象。</li><li>如果消费组的状态为PreparingRebalance(此状态表示正在等待消费组加入)，并将组的newMemberAdded设置为true，表示有新成员加入，后续需要触发重平衡。</li><li>将消费组添加到组中，这里会触发一次<strong>消费组选主</strong>,选主逻辑：<strong>该消费组的第一个加入的消费者成为该消费组中的Leader</strong>, Leader的职责是什么呢？<br>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_7.png"><br>总体而言： <strong>消费组Leader的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案</strong>。<ul><li>为每一个消费者创建一个DelayedHeartbeat对象，用于检测会话超时，组协调器如果检测会话超时，会将该消费者移除组，会重新触发重平衡，消费者为了避免被组协调器移除消费组，需要按间隔发送心跳包。</li><li>根据当前消费组的状态是否需要进行重平衡。</li></ul></li></ul><p>接下来继续深入跟踪maybePrepareRebalance方法，其实现如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_8.png"></p><p>根据状态机的驱动规则，判断是否可以进入到PrepareRebalance，其判断逻辑就是根据状态机的驱动，判断当前状态是否可以进入到该状态，其具体实现是为每一个状态存储了一个可以进入当前状态的前驱状态集合。</p><p>如果符合状态驱动流程，消费组将进入到PrepareRebalance，其具体实现如下图所示：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_9.png"></p><ul><li>如果当前消费组的状态为CompletingRebalance，需要重置队列分配动作，并让消费组重新加入到消费组，即重新发送JOIN_GROUP请求。具体实现技巧：<br>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_10.png"><ul><li>将所有消费者已按分配算法分配到的队列信息置空</li><li>将空的分配结果返回给消费者，并且错误码为REBALANCE_IN_PROGRESS，客户端收到该错会重新加入消费组。</li></ul></li><li>如果当前没有消费者，则创建InitialDelayedJoin，否则则创建DelayedJoin<ul><li>值得注意的是这里有一个参数：group.initial.rebalance.delay.ms，用于设置消费组进入到PreparingRebalance真正执行其业务逻辑的延迟时间，其主要目的是等待更多的消费者进入。</li><li>驱动消费组状态为PreparingRebalance。</li><li>尝试执行initialDelayedJoin或DelayedJoin的tryComplete方法，如果没有完成，则创建watch，等待执行完成，最终执行的是组协调器的相关方法，其说明如下：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_11.png"><br>接下来看一下组协调器的tryCompleteJoin方法，其实现如下图所示：<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_12.png"></li><li>*完成PreparingRebalance状态的条件是: 已知的消费组都成功加入到消费组**。该方法返回true后，onCompleteJoin方法将被执行。</li></ul></li></ul><p>接下来看一下GroupCoordinator的onCompleteJoin方法的实现。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_13.png"></p><p>核心的关键点如下：</p><ul><li>驱动消费组的状态转化为CompletingRebalance，将进入到重平衡的第二个阶段(队列负载)</li><li>为每一个成员构建对应JoinResponse对象，其中三个关键点<ul><li>generationId 消费组每一次状态变更，该值加一</li><li>subProtocol 当前消费者组中所有消费者都支持的队列负载算法</li><li>leaderId 消费组中的leader，一个消费组中第一个加入的消费者为leader</li></ul></li></ul><p>接下来，消费者协调器将根据服务端返回的响应结果，进行第二阶段的重平衡，即进入到队列负载算法。</p><h6 id="已知memberId加入消费组处理逻辑"><a href="#已知memberId加入消费组处理逻辑" class="headerlink" title="已知memberId加入消费组处理逻辑"></a>已知memberId加入消费组处理逻辑</h6><p>组协调在已知memberid处理加入请求的核心处理代码在GroupCoordinator的doJoinGroup中，即重新加入请求。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_14.png"></p><ol><li>首先进行相关的错误校验<ul><li>如果消费组状态为Dead，返回错误unknown_member_id错误。</li><li>如果当前消费者支持的队列负载算法消费组并不支持，返回错误inconsistent_group_protocol</li><li>如果当前的memberid处在pendingMember中，对于这种重新加入的消费者会接受并触发重平衡。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">值得注意的是，在Kafka JOIN_REQUEST版本为4后，首先会在服务端生成memberId,并加入到pendingMember中，并立即向客户端返回memberId,引导客户端重新加入。</span><br></pre></td></tr></table></figure></li><li>如果消费组不存在该成员，返回错误，说明消费组已经将该消费者移除。</li></ul></li><li>根据消费组的状态采取不同的行为<ul><li>如果当前状态为PreparingRebalance  更新成员的元信息，按照需要触发重平衡。  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_15.png">  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PreparingRebalance状态，消费组在等待消费组中的消费者加入。</span><br></pre></td></tr></table></figure></li><li>如果状态为CompletingRebalance<ul><li><p>如果收到join group请求，但其元信息并没有发生变化(队列负载算法)，只需将最新的信息返回给消费者；</p></li><li><p>如果状态发生变更，则会进行再次回到重平衡的第一阶段，消费组重新加入。</p></li></ul>  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_16.png">  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">消费组如果处于CompletingRebalance状态，其实不希望再收到Join Group请求，因为处于CompletingRebalance状态的消费组，正在等待消费者Leader分配队列。</span><br></pre></td></tr></table></figure></li><li>如果消费组处于Stable状态  如果成员是leader并且支持的协议发生变化，则进行重平衡，否则只需要将元信息发生给客户端即可。  <img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_17.png"></li></ul></li></ol><h6 id="客户端处理组协调器的Join-Group响应包"><a href="#客户端处理组协调器的Join-Group响应包" class="headerlink" title="客户端处理组协调器的Join Group响应包"></a>客户端处理组协调器的Join Group响应包</h6><p>客户端对Join_Group的响应处理在：JoinGroupResponseHandler，其核心实现如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_18.png"></p><p>关键点：</p><ul><li>队列的负载算法是由Leader节点来分配，</li><li>将分配结果通过向组协调器发送SYNC_GROUP请求，</li><li>然后组协调器从Leader节点获取分配算法后，</li><li>再返回给所有的消费者，</li><li>从而开始进行消费。</li></ul><h4 id="心跳与离开"><a href="#心跳与离开" class="headerlink" title="心跳与离开"></a>心跳与离开</h4><p>消费者通过消费者协调器与组协调器交互完成消费组的加入，但如何退出呢？例如当消费者宕机，协调器如何感知呢？</p><p>原来在Kafka中，消费者协调器会引入心跳机制，即定时向组协调器发送心跳包，在指定时间内未收到客户端的心跳包，表示会话过期，过期时间通过参数session.timeout.ms设置，默认为10s。<br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_22.png"><br><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_23.png"></p><p>通过对ConsumerCoordinator的poll流程可知，消费者协调器在得知消费组的组协调器后，就会启动心跳线程，其代码如下：</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_19.png"></p><p>启动心跳线程后，主要关注HeartbeatThread的run方法。</p><p><img src="/2021/05/24/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_20.png"></p><p>心跳线程的核心要点如下：</p><ul><li>如果距离上一次心跳超过了会话时间，会断开与GroupCoordinator断开链接，并设置为coordinatorUnknow 为true，需要重新寻找组协调器。</li><li>如果此次心跳发送时间距离上一次心跳发送时间超过了pollTimeout，客户端将发送LEAVE_GROUP，离开消费组，并在下一个poll方法调用时重新进入加入消费组的操作，会再次触发重平衡。</li><li>如果两次心跳时间超过了单次心跳发送间隔，将发送消息。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">温馨提示：尽管心跳包通常是定时类任务，但kafka的心跳机制另辟蹊径，使用了Object的wait与notify，心跳线程与消息拉取线程相互协助，**每一次消息拉取，都会进行判断是否应该发送心跳包**。</span><br></pre></td></tr></table></figure><p>关于消费组的离开，服务端端处理逻辑比较简单，就不在这一一介绍了。</p><h3 id="重平衡机制总结"><a href="#重平衡机制总结" class="headerlink" title="重平衡机制总结"></a>重平衡机制总结</h3><p>Kafka的重平衡其实包含两个非常重要的阶段：</p><ul><li>消费组加入阶段(PreparingRebalance)<ul><li>此阶段是消费者陆续加入消费组，该组第一个加入的消费者被推举为Leader</li><li>当该组所有已知memberId的消费者全部加入后，状态驱动到CompletingRebalance。</li></ul></li><li>队列负载(CompletingRebalance)<ul><li>PreparingRebalance状态完成后，如果消费者被推举为Leader，<strong>Leader会采用该消费组中都支持的队列负载算法进行队列分布</strong>，然后将结果回报给组协调器；</li><li>如果消费者的角色为非Leader，会向组协调器发送同步队列分区算法，组协调器会将Leader节点分配的结果分配给消费者。</li></ul></li></ul><p><strong>消费组如果在进行重平衡操作，将会暂停消息消费（STW），频繁的重平衡会导致队列消息消费的速度受到极大的影响。</strong></p><p>与重平衡相关的消费端参数：</p><ul><li><p><strong>max.poll.interval.ms</strong></p><p>  两次poll方法调用的最大间隔时间，单位毫秒，默认为5分钟。如果消费端在该间隔内没有发起poll操作，该消费者将被剔除，触发重平衡，将该消费者分配的队列分配给其他消费者。</p></li><li><p><strong>session.timeout.ms</strong></p><p>  消费者与broker的心跳超时时间,默认10s，broker在指定时间内没有收到心跳请求，broker端将会将该消费者移出，并触发重平衡。</p></li><li><p><strong>heartbeat.interval.ms</strong></p><p>  心跳间隔时间，消费者会以该频率向broker发送心跳，默认为3s，主要是确保session不会失效。</p></li></ul><h4 id="重平衡触发条件—消费群组或者topic分区出现变化时"><a href="#重平衡触发条件—消费群组或者topic分区出现变化时" class="headerlink" title="重平衡触发条件—消费群组或者topic分区出现变化时"></a>重平衡触发条件—消费群组或者topic分区出现变化时</h4><ul><li>消费组内成员个数发生变化(<strong>这种情况在实际情况中更加常见。因为订阅分区数、以及订阅 topic 数都是我们主动改变才会发生，而组内消费组成员个数发生变化，则是更加随机的。</strong>)<ul><li>有新的消费者加入Consumer Group,</li><li>由消费者主动退出，Consumer Group/调用unsubscribe()取消对某Topic的订阅,</li><li>有消费者崩溃，可能由于长时间未向GroupCoordinator(协调者)发送心跳，GroupCoordinator会认为其已下线；</li></ul></li><li>订阅的 Topic 分区数出现变化；</li><li>订阅的 Topic 个数发生变化:<br>一个 consumer group 如果之前只订阅了 A topic，那么其组内的 consumer 知会消费 A topic 的消息。而如果现在新增订阅了 B topic，那么 kafka 就需要把 B topic 的 partition 分配给组内的 consumer 进行消费。</li></ul><h3 id="线上环境频繁重平衡问题实例"><a href="#线上环境频繁重平衡问题实例" class="headerlink" title="线上环境频繁重平衡问题实例"></a>线上环境频繁重平衡问题实例</h3><h4 id="消息处理逻辑太重，超过max-poll-interval-ms限制"><a href="#消息处理逻辑太重，超过max-poll-interval-ms限制" class="headerlink" title="消息处理逻辑太重，超过max.poll.interval.ms限制"></a>消息处理逻辑太重，超过max.poll.interval.ms限制</h4><h5 id="问题原因："><a href="#问题原因：" class="headerlink" title="问题原因："></a>问题原因：</h5><p>kafkaConsumer调用一次轮询方法只是拉取一次消息。客户端为了不断拉取消息，会用一个外部循环不断调用消费者的轮询方法。每次轮询到消息，在处理完这一批消息后，才会继续下一次轮询。但如果一次轮询返回的结构没办法及时处理完成，会有什么后果呢？服务端约定了和客户端max.poll.interval.ms，两次poll最大间隔。如果客户端处理一批消息花费的时间超过了这个限制时间，服务端可能就会把消费者客户端移除掉，并触发rebalance。</p><h5 id="引发出的其他问题："><a href="#引发出的其他问题：" class="headerlink" title="引发出的其他问题："></a>引发出的其他问题：</h5><p>拉取偏移量与提交偏移量：kafka的偏移量(offset)是由消费者进行管理的，偏移量有两种，拉取偏移量(position)与提交偏移量(committed)。拉取偏移量代表当前消费者分区消费进度。每次消息消费后，需要提交偏移量。在提交偏移量时，kafka会使用拉取偏移量的值作为分区的提交偏移量发送给协调者。</p><p>如果没有提交偏移量，下一次消费者重新与broker连接后，会从当前消费者group已提交到broker的偏移量处开始消费。</p><p>所以，问题就在这里，当我们处理消息时间太长时,已经被broker剔除，提交偏移量又会报错。所以拉取偏移量没有提交到broker，分区又rebalance。</p><p>下一次重新分配分区时，消费者会从最新的已提交偏移量处开始消费。</p><p>这里就出现了<strong>重复消费</strong>的问题。</p><h5 id="处理方案："><a href="#处理方案：" class="headerlink" title="处理方案："></a>处理方案：</h5><ol><li>调大max.poll.interval.ms参数值或优化消息处理逻辑 <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">max.poll.interval.ms</span>=<span class="string">300</span></span><br></pre></td></tr></table></figure></li><li>设置分区拉取阈值<br>kafkaConsumer调用一次轮询方法只是拉取一次消息。客户端为了不断拉取消息，会用一个外部循环不断调用轮询方法poll()。每次轮询后，在处理完这一批消息后，才会继续下一次的轮询。<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">max.poll.records</span> = <span class="string">50</span></span><br></pre></td></tr></table></figure></li><li>poll到的消息，处理完一条就提交一条，当出现提交失败时，马上跳出循环，这时候kafka就会进行rebalance,下一次会继续从当前offset进行消费。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;什么是Rebalance&quot;&gt;&lt;a href=&quot;#什么是Rebalance&quot; class=&quot;headerlink&quot; title=&quot;什么是Rebalance&quot;&gt;&lt;/a&gt;什么是Rebalance&lt;/h3&gt;&lt;p&gt;如果对RocketMQ或者对消息中间件有所了解的话，消费端在</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之Kafka消息拉取机制简读</title>
    <link href="http://example.com/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/"/>
    <id>http://example.com/2021/05/20/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/</id>
    <published>2021-05-20T10:45:45.000Z</published>
    <updated>2021-08-04T08:24:40.508Z</updated>
    
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之Kafka消息发送者核心参数与工作机制</title>
    <link href="http://example.com/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/</id>
    <published>2021-05-16T10:46:45.000Z</published>
    <updated>2021-08-12T03:37:01.829Z</updated>
    
    <content type="html"><![CDATA[<p>本文将从Kafka Producer的配置属性为突破口，结合源码深入提炼出Kafka Producer的工作机制，方便大家更好使用Kafka Producer，并且胸有成竹的进行性能调优。</p><p>将Kafka Producer相关的参数分成如下几个类型：</p><ul><li>常规参数</li><li>工作原理(性能相关)参数(图解)</li></ul><p>本文会结合图解方式，重点阐述与Kafka生产者运作机制密切相关的参数。 </p><h3 id="Producer-核心流程一览"><a href="#Producer-核心流程一览" class="headerlink" title="Producer 核心流程一览"></a>Producer 核心流程一览</h3><p>producer也就是生产者，是kafka中消息的产生方，产生消息并提交给kafka集群完成消息的持久化。</p><h4 id="KafkaProducer构造方法"><a href="#KafkaProducer构造方法" class="headerlink" title="KafkaProducer构造方法"></a>KafkaProducer构造方法</h4><p>KafkaProducer构造方法主要是根据配置文件进行一些实例化操作</p><ol><li>解析clientId，若没有配置则由是producer-递增的数字</li><li>解析并实例化分区器partitioner</li><li>解析key、value的序列化方式并实例化</li><li>解析并实例化拦截器</li><li>解析并实例化RecordAccumulator</li><li>解析Broker地址</li><li>创建一个Sender线程并启动</li></ol><details><summary>一个KafkaProducer的小demo</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String[] args) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">        if (args.length != 2) &#123;</span><br><span class="line">            throw new IllegalArgumentException(&quot;usage: com.ding.KafkaProducerDemo bootstrap-servers topic-name&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        // kafka服务器ip和端口，多个用逗号分割</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, args[0]);</span><br><span class="line">        // 确认信号配置</span><br><span class="line">        // ack=0 代表producer端不需要等待确认信号，可用性最低</span><br><span class="line">        // ack=1 等待至少一个leader成功把消息写到log中，不保证follower写入成功，如果leader宕机同时follower没有把数据写入成功</span><br><span class="line">        // 消息丢失</span><br><span class="line">        // ack=all leader需要等待所有follower成功备份，可用性最高</span><br><span class="line">        props.put(&quot;ack&quot;, &quot;all&quot;);</span><br><span class="line">        // 重试次数</span><br><span class="line">        props.put(&quot;retries&quot;, 0);</span><br><span class="line">        // 批处理消息的大小，批处理可以增加吞吐量</span><br><span class="line">        props.put(&quot;batch.size&quot;, 16384);</span><br><span class="line">        // 延迟发送消息的时间</span><br><span class="line">        props.put(&quot;linger.ms&quot;, 1);</span><br><span class="line">        // 用来换出数据的内存大小</span><br><span class="line">        props.put(&quot;buffer.memory&quot;, 33554432);</span><br><span class="line">        // key 序列化方式</span><br><span class="line">        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        // value 序列化方式</span><br><span class="line">        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line"></span><br><span class="line">        // 创建KafkaProducer对象，创建时会启动Sender线程</span><br><span class="line">        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line">        for (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">            // 往RecordAccumulator中写消息</span><br><span class="line">            Future&lt;RecordMetadata&gt; result = producer.send(new ProducerRecord&lt;&gt;(args[1], Integer.toString(i), Integer.toString(i)));</span><br><span class="line">            RecordMetadata rm = result.get();</span><br><span class="line">            System.out.println(&quot;topic: &quot; + rm.topic() + &quot;, partition: &quot; +  rm.partition() + &quot;, offset: &quot; + rm.offset());</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></details><p>相关参数:</p><ul><li><strong>bootstrap.servers</strong>: 配置Kafka broker的服务器地址列表，多个用英文逗号分开，可以不必写全，Kafka内部有自动感知Kafka broker的机制。</li><li><strong>key.serializer</strong>: 消息key的序列化策略，为org.apache.kafka.common.serialization接口的实现类。</li><li><strong>value.serializer</strong>: 消息体的序列化策略</li><li><strong>client.id</strong>: 客户端ID，如果不设置默认为producer-递增，<strong>强烈建议设置该值，尽量包含ip,port,pid</strong>。</li><li><strong>client.dns.lookup</strong>: 客户端寻找bootstrap地址的方式，支持如下两种方式：<ul><li><strong>resolve_canonical_bootstrap_servers_only</strong>: 这种方式，会依据bootstrap.servers提供的主机名(hostname)，根据主机上的名称服务返回其IP地址的数组(InetAddress.getAllByName)，然后依次获取inetAddress.getCanonicalHostName()，再建立tcp连接。<br><strong>一个主机可配置多个网卡，如果启用该功能，应该可以有效利用多网卡的优势，降低Broker的网络端负载压力。</strong></li><li><strong>use_all_dns_ips</strong>: 这种方式会直接使用bootstrap.servers中提供的hostname、port创建tcp连接，默认选项。</li></ul></li></ul><h4 id="KafkaProducer消息发送流程"><a href="#KafkaProducer消息发送流程" class="headerlink" title="KafkaProducer消息发送流程"></a>KafkaProducer消息发送流程</h4><p>Kafka将一条待发送的消息抽象为ProducerRecord对象，其数据结构是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerRecord</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic; <span class="comment">//目标topic</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition; <span class="comment">//目标partition</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;<span class="comment">//消息头信息</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;   <span class="comment">//消息key</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value; <span class="comment">//消息体</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp; <span class="comment">//消息时间戳</span></span><br><span class="line">    <span class="comment">//省略构造方法与成员方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>目前消息结构包括6个核心属性，分别是topic，partition，headers，key，value与timestamp，各属性含义如上也比较好理解，其中headers属性是Kafka 0.11.x 版本引入的，可以用它存储一些应用或业务相关的信息。</p><p>Kafka消息发送过程中主要涉及ProducerRecord对象的构建、分区选择、元数据的填充、ProducerRecord对象的序列化、进入消息缓冲池、完成消息的发送、接受broker的响应。</p><p>消息的发送入口是KafkaProducer.send方法，具体流程如下: </p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_3.png"></p><ol><li>确定topic信息</li><li>确定value信息</li><li>然后进行消息的序列化处理</li><li>由分区选择器确定对应的分区信息</li><li>将消息写入消息缓冲区</li><li>完成消息请求的发送</li><li>完成消息响应的处理</li></ol><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img.png"></p><p>总的来说，Kafka生产端发送数据过程涉及到序列化器Serializer、分区器Partitioner，消息缓存池Accumulator，还可能会涉及到拦截器Interceptor（这部分暂不做介绍）。</p><p>Kafka 的 Producer 发送消息采用的是异步发送的方式。</p><p>在消息发送的过程中，涉及到了 两个线程——<strong>main线程</strong>和 <strong>Sender线程</strong>，以及<strong>一个线程共享变量——RecordAccumulator。 main 线程将消息发送给 RecordAccumulator</strong>，Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka broker</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_4.png"></p><p>在消息发送端Kafka引入了批的概念，发送到服务端的消息通常不是一条一条发送，而是一批一批发送，一个批次对应源码层级为ProducerBatch对象。<br>相关参数：</p><ul><li><strong>batch.size</strong><br>该值用于设置每一个批次的内存大小,默认为16K,只有数据积累到 batch.size 之后，sender 才会发送数据。</li><li><strong>linger.ms</strong>:<br>Kafka希望一个批次一个批次去发送到Broker，应用程序往KafkaProducer中发送一条消息，首先会进入到内部缓冲区，具体是会进入到某一个批次中(ProducerBatch), 等待该批次堆满后一次发送到Broker，这样能提高消息的吞吐量，但其消息发送的延迟也会相应提高。<br>为了解决该问题，linger.ms参数应运而生。<br>它的作用是控制在缓存区中未积满时来控制消息发送线程的行为。 如果linger.ms 设置为 0表示立即发送，如果设置为大于0，则消息发送线程会等待这个值后才会向broker发送。有点类似于 TCP 领域的 Nagle 算法。.如果数据迟迟未达到 batch.size，sender 等待 linger.time 之后就会发送数据。</li></ul><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_1.png"></p><p>Kafka的每一个消息发送者，也就是KafkaProducer对象内部会有一块缓存区，缓冲区内存的组织会按照topic+parition构建双端队列。<br>相关参数：</p><ul><li><strong>buffer.memory</strong>:<br>指定缓存区大小，默认为32M</li><li><strong>delivery.timeout.ms</strong>:<br>默认为120s，该参数控制在双端队列中的过期时间，从进入双端队列开始计时，超过该值未被sender发送后会返回超时异常(TimeoutException)。</li></ul><p>队列中的每一个元素为一个ProducerBatch对象，表示一个消息发送批次，但发送线程将消息发送到Broker端时，一次可以包含多个批次。</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_2.png"></p><p>相关参数：</p><ul><li><p><strong>max.block.ms</strong>:<br>默认为60s，当消息发送者申请空闲内存时，如果在指定时间（包含发送端用于查找元信息的时间）内未申请到内存，消息发送端会直接报TimeoutException。</p></li><li><p><strong>max.request.size</strong>:<br>Send线程一次发送的最大字节数量，也就是Send线程向服务端一次消息发送请求的最大传输数据，默认为1M。</p></li><li><p><strong>request.timeout.ms</strong>:<br>请求的超时时间，主要是Kafka消息发送线程(Sender)与Broker端的网络通讯的请求超时时间。</p></li><li><p><strong>retries</strong>:<br>Kafka Sender线程从缓存区尝试发送到Broker端的重试次数，默认为Integer.MAX_VALUE。<br>为了避免无限重试，只针对可恢复的异常，例如Leader选举中这种异常就是可恢复的，重试最终是能解决问题的。</p></li><li><p><strong>max.in.flight.requests.per.connection</strong>:<br>设置每一个客户端与服务端连接，在应用层一个通道的积压消息数量，默认为5，有点类似Netty用高低水位线控制发送缓冲区中积压的多少，避免内存溢出。</p></li></ul><h5 id="RecordAccumulator"><a href="#RecordAccumulator" class="headerlink" title="RecordAccumulator"></a>RecordAccumulator</h5><p>RecordAccumulator是消息队列用于缓存消息，根据TopicPartition对消息分组</p><details><summary>RecordAccumulator源码解读</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Add a record to the accumulator, return the append result</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> * The append result will contain the future metadata, and flag for whether the appended batch is full or a new batch is created</span><br><span class="line"> * &lt;p&gt;</span><br><span class="line"> *</span><br><span class="line"> * @param tp The topic/partition to which this record is being sent</span><br><span class="line"> * @param timestamp The timestamp of the record</span><br><span class="line"> * @param key The key for the record</span><br><span class="line"> * @param value The value for the record</span><br><span class="line"> * @param headers the Headers for the record</span><br><span class="line"> * @param callback The user-supplied callback to execute when the request is complete</span><br><span class="line"> * @param maxTimeToBlock The maximum time in milliseconds to block for buffer memory to be available</span><br><span class="line"> */</span><br><span class="line">public RecordAppendResult append(TopicPartition tp,</span><br><span class="line">                                 long timestamp,</span><br><span class="line">                                 byte[] key,</span><br><span class="line">                                 byte[] value,</span><br><span class="line">                                 Header[] headers,</span><br><span class="line">                                 Callback callback,</span><br><span class="line">                                 long maxTimeToBlock) throws InterruptedException &#123;</span><br><span class="line">    // We keep track of the number of appending thread to make sure we do not miss batches in</span><br><span class="line">    // abortIncompleteBatches().</span><br><span class="line">    // ---记录进行applend的线程数---</span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    ByteBuffer buffer = null;</span><br><span class="line">    if (headers == null) headers = Record.EMPTY_HEADERS;</span><br><span class="line">    try &#123;</span><br><span class="line">        // check if we have an in-progress batch</span><br><span class="line">        // ---根据TopicPartition获取或新建Deque双端队列---</span><br><span class="line">        Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">        // ---尝试将消息加入到缓冲区中---</span><br><span class="line">        // ---加锁保证同一个TopicPartition写入有序---</span><br><span class="line">        synchronized (dq) &#123;</span><br><span class="line">            if (closed)</span><br><span class="line">                throw new KafkaException(&quot;Producer closed while send in progress&quot;);</span><br><span class="line">            // 尝试写入</span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            if (appendResult != null)</span><br><span class="line">                return appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // we don&#x27;t have an in-progress record batch try to allocate a new batch</span><br><span class="line">        byte maxUsableMagic = apiVersions.maxUsableProduceMagic();</span><br><span class="line">        int size = Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line">        log.trace(&quot;Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;&quot;, size, tp.topic(), tp.partition());</span><br><span class="line">        // 尝试applend失败（返回null），会走到这里。如果tryApplend成功直接返回了</span><br><span class="line">        // 从BufferPool中申请内存空间，用于创建新的ProducerBatch</span><br><span class="line">        buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">        synchronized (dq) &#123;</span><br><span class="line">            // Need to check if producer is closed again after grabbing the dequeue lock.</span><br><span class="line">            if (closed)</span><br><span class="line">                throw new KafkaException(&quot;Producer closed while send in progress&quot;);</span><br><span class="line">            </span><br><span class="line">            // 注意这里，前面已经尝试添加失败了，且已经分配了内存，为何还要尝试添加？</span><br><span class="line">            // 因为可能已经有其他线程创建了ProducerBatch或者之前的ProducerBatch已经被Sender线程释放了一些空间，所以在尝试添加一次。这里如果添加成功，后面会在finally中释放申请的空间</span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">            if (appendResult != null) &#123;</span><br><span class="line">                // Somebody else found us a batch, return the one we waited for! Hopefully this doesn&#x27;t happen often...</span><br><span class="line">                return appendResult;</span><br><span class="line">            &#125;</span><br><span class="line">            // 尝试添加失败了，新建ProducerBatch</span><br><span class="line">            MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">            ProducerBatch batch = new ProducerBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            incomplete.add(batch);</span><br><span class="line"></span><br><span class="line">            // 将buffer置为null,避免在finally汇总释放空间</span><br><span class="line">            // Don&#x27;t deallocate this buffer in the finally block as it&#x27;s being used in the record batch</span><br><span class="line">            buffer = null;</span><br><span class="line">            return new RecordAppendResult(future, dq.size() &gt; 1 || batch.isFull(), true);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 最后如果再次尝试添加成功，会释放之前申请的内存（为了新建ProducerBatch）</span><br><span class="line">        if (buffer != null)</span><br><span class="line">            free.deallocate(buffer);</span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers,</span><br><span class="line">                                     Callback callback, Deque&lt;ProducerBatch&gt; deque) &#123;</span><br><span class="line">    // 从双端队列的尾部取出ProducerBatch</span><br><span class="line">    ProducerBatch last = deque.peekLast();</span><br><span class="line">    if (last != null) &#123;</span><br><span class="line">        // 取到了，尝试添加消息</span><br><span class="line">        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, headers, callback, time.milliseconds());</span><br><span class="line">        // 空间不够，返回null</span><br><span class="line">        if (future == null)</span><br><span class="line">            last.closeForRecordAppends();</span><br><span class="line">        else</span><br><span class="line">            return new RecordAppendResult(future, deque.size() &gt; 1 || last.isFull(), false);</span><br><span class="line">    &#125;</span><br><span class="line">    // 取不到返回null</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br><span class="line">public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long now) &#123;</span><br><span class="line">    // 空间不够，返回null</span><br><span class="line">    if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) &#123;</span><br><span class="line">        return null;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        // 真正添加消息</span><br><span class="line">        Long checksum = this.recordsBuilder.append(timestamp, key, value, headers);</span><br><span class="line">        ...</span><br><span class="line">        FutureRecordMetadata future = ...</span><br><span class="line">        // future和回调callback进行关联    </span><br><span class="line">        thunks.add(new Thunk(callback, future));</span><br><span class="line">        ...</span><br><span class="line">        return future;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 将消息写入缓冲区</span><br><span class="line">RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey,serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line">if (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">    // 缓冲区满了或者新创建的ProducerBatch，唤起Sender线程</span><br><span class="line">    this.sender.wakeup();</span><br><span class="line">&#125;</span><br><span class="line">return result.future;</span><br></pre></td></tr></table></figure></details><h5 id="Sender"><a href="#Sender" class="headerlink" title="Sender"></a>Sender</h5><p>KafkaProducer的构造方法在实例化时启动一个KafkaThread线程来执行Sender</p><p>Sender主要流程如下： </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Sender.run</span><br><span class="line">Sender.runOnce</span><br><span class="line">Sender.sendProducerData</span><br><span class="line">// 获取集群信息</span><br><span class="line">Metadata.fetch</span><br><span class="line">// 获取可以发送消息的分区且已经获取到了leader分区的节点</span><br><span class="line">RecordAccumulator.ready</span><br><span class="line">// 根据准备好的节点信息从缓冲区中获取topicPartion对应的Deque队列中取出ProducerBatch信息</span><br><span class="line">RecordAccumulator.drain</span><br><span class="line">// 将消息转移到每个节点的生产请求队列中</span><br><span class="line">Sender.sendProduceRequests</span><br><span class="line">// 为消息创建生产请求队列</span><br><span class="line">Sender.sendProducerRequest</span><br><span class="line">KafkaClient.newClientRequest</span><br><span class="line">// 下面是发送消息</span><br><span class="line">KafkaClient.sent</span><br><span class="line">NetWorkClient.doSent</span><br><span class="line">Selector.send</span><br><span class="line">// 其实上面并不是真正执行I/O，只是写入到KafkaChannel中</span><br><span class="line">// poll 真正执行I/O</span><br><span class="line">KafkaClient.poll</span><br></pre></td></tr></table></figure><details><summary></summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// KafkaProducer构造方法启动Sender</span><br><span class="line">String ioThreadName = NETWORK_THREAD_PREFIX + &quot; | &quot; + clientId;</span><br><span class="line">this.ioThread = new KafkaThread(ioThreadName, this.sender, true);</span><br><span class="line">this.ioThread.start();</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// Sender-&gt;run()-&gt;runOnce()</span><br><span class="line">long currentTimeMs = time.milliseconds();</span><br><span class="line">// 发送生产的消息</span><br><span class="line">long pollTimeout = sendProducerData(currentTimeMs);</span><br><span class="line">// 真正执行I/O操作</span><br><span class="line">client.poll(pollTimeout, currentTimeMs);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 获取集群信息</span><br><span class="line">Cluster cluster = metadata.fetch();</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 获取准备好可以发送消息的分区且已经获取到leader分区的节点</span><br><span class="line">RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);</span><br><span class="line">// ReadyCheckResult 包含可以发送消息且获取到leader分区的节点集合、未获取到leader分区节点的topic集合</span><br><span class="line">public final Set&lt;Node&gt; 的节点;</span><br><span class="line">public final long nextReadyCheckDelayMs;</span><br><span class="line">public final Set&lt;String&gt; unknownLeaderTopics;</span><br></pre></td></tr></table></figure><p>ready方法主要是遍历在上面介绍RecordAccumulator添加消息的容器，Map&lt;TopicPartition, Deque&gt;，从集群信息中根据TopicPartition获取leader分区所在节点，找不到对应leader节点但有要发送的消息的topic添加到unknownLeaderTopics中。同时把那些根据TopicPartition可以获取leader分区且消息满足发送的条件的节点添加到的节点中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// 遍历batches</span><br><span class="line">for (Map.Entry&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; entry : this.batches.entrySet()) &#123;</span><br><span class="line">    TopicPartition part = entry.getKey();</span><br><span class="line">    Deque&lt;ProducerBatch&gt; deque = entry.getValue();</span><br><span class="line">    // 根据TopicPartition从集群信息获取leader分区所在节点</span><br><span class="line">    Node leader = cluster.leaderFor(part);</span><br><span class="line">    synchronized (deque) &#123;</span><br><span class="line">        if (leader == null &amp;&amp; !deque.isEmpty()) &#123;</span><br><span class="line">            // 添加未找到对应leader分区所在节点但有要发送的消息的topic</span><br><span class="line">            unknownLeaderTopics.add(part.topic());</span><br><span class="line">        &#125; else if (!readyNodes.contains(leader) &amp;&amp; !isMuted(part, nowMs)) &#123;</span><br><span class="line">....</span><br><span class="line">                if (sendable &amp;&amp; !backingOff) &#123;</span><br><span class="line">                    // 添加准备好的节点</span><br><span class="line">                    readyNodes.add(leader);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后对返回的unknownLeaderTopics进行遍历，将topic加入到metadata信息中，调用metadata.requestUpdate方法请求更新metadata信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for (String topic : result.unknownLeaderTopics)</span><br><span class="line">    this.metadata.add(topic);</span><br><span class="line">    result.unknownLeaderTopics);</span><br><span class="line">this.metadata.requestUpdate();</span><br></pre></td></tr></table></figure><p>对已经准备好的节点进行最后的检查，移除那些节点连接没有就绪的节点，主要根据KafkaClient.ready方法进行判断</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">long notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">while (iter.hasNext()) &#123;</span><br><span class="line">    Node node = iter.next();</span><br><span class="line">    // 调用KafkaClient.ready方法验证节点连接是否就绪</span><br><span class="line">    if (!this.client.ready(node, now)) &#123;</span><br><span class="line">        // 移除没有就绪的节点</span><br><span class="line">        iter.remove();</span><br><span class="line">        notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面开始创建生产消息的请求</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 从RecordAccumulator中取出TopicPartition对应的Deque双端队列，然后从双端队列头部取出ProducerBatch，作为要发送的信息</span><br><span class="line">Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);</span><br></pre></td></tr></table></figure><p>把消息封装成ClientRequest</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0,requestTimeoutMs, callback);</span><br></pre></td></tr></table></figure><p>调用KafkaClient发送消息（并非真正执行I/O），涉及到KafkaChannel。Kafka的通信采用的是NIO方式</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// NetworkClient.doSent方法</span><br><span class="line">String destination = clientRequest.destination();</span><br><span class="line">RequestHeader header = clientRequest.makeHeader(request.version());</span><br><span class="line">...</span><br><span class="line">Send send = request.toSend(destination, header);</span><br><span class="line">InFlightRequest inFlightRequest = new InFlightRequest(clientRequest,header,isInternalRequest,request,send,now);</span><br><span class="line">this.inFlightRequests.add(inFlightRequest);</span><br><span class="line">selector.send(send);</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">// Selector.send方法    </span><br><span class="line">String connectionId = send.destination();</span><br><span class="line">KafkaChannel channel = openOrClosingChannelOrFail(connectionId);</span><br><span class="line">if (closingChannels.containsKey(connectionId)) &#123;</span><br><span class="line">    this.failedSends.add(connectionId);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        channel.setSend(send);</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>到这里，发送消息的工作准备的差不多了，调用KafkaClient.poll方法，真正执行I/O操作</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.poll(pollTimeout, currentTimeMs);</span><br></pre></td></tr></table></figure></details><p>用一张图总结Sender线程的流程</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_6.png"></p><h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>Kafka生产消息的主要流程，涉及到主线程往RecordAccumulator中写入消息，同时后台的Sender线程从RecordAccumulator中获取消息，使用NIO的方式把消息发送给Kafka，用一张图总结</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_5.png"></p><h3 id="Producer分区器"><a href="#Producer分区器" class="headerlink" title="Producer分区器"></a>Producer分区器</h3><p>分区器partitioner，可以实现自己的partitioner，比如根据key分区，可以保证相同key分到同一个分区，对保证顺序很有用。</p><p>相关参数：</p><ul><li><strong>partitioner.class</strong>:<br>消息发送队列负载算法，其默 DefaultPartitioner，路由算法如下：<ul><li>如果指定了 key，则使用 key 的 hashcode 与分区数取模。</li><li>如果未指定 key，则轮询所有的分区(用随机数对可用分区取模, counter值初始值是随机的，但后面都是递增的，所以可以算到roundrobin)。</li></ul></li></ul><h3 id="Producer-压缩算法"><a href="#Producer-压缩算法" class="headerlink" title="Producer 压缩算法"></a>Producer 压缩算法</h3><p>Kafka支持的压缩算法还是很可观的：GZIP、Snappy、LZ4，默认情况下不进行消息压缩，毕竟会消耗很大一部分cpu时间，导致send方法处理时间变慢。启动LZ4 进行消息压缩的producer的吞吐量是最高的。</p><p><strong>发送方与Broker 服务器采用相同的压缩类型，可有效避免在Broker服务端进行消息的压缩与解压缩，大大降低Broker的CPU使用压力</strong></p><p>相关参数：</p><ul><li><strong>compression.type</strong>:<br>消息的压缩算法，目前可选值：none、gzip、snappy、lz4、zstd，<strong>默认不压缩，建议与Kafka服务器配置的一样</strong>。</li></ul><p>当然Kafka服务端可以配置的压缩类型为 producer，即采用与发送方配置的压缩类型。</p><h3 id="Producer-interceptor"><a href="#Producer-interceptor" class="headerlink" title="Producer interceptor"></a>Producer interceptor</h3><p>拦截器是新版本才出现的一个特性，并且是非必须的。</p><p>interceptor 核心的函数有: </p><ul><li>onSend（在消息序列化计算分区之前就被调用）</li><li>onAcknowleagement（被应答前或者说在发送失败时，这个方法是运行在producer的I/O线程中的，所以说如果存在很多重逻辑的话会导致严重影响处理消息的速率）</li><li>close。通常是通过为clients定制一部分通用且简单的逻辑时才会使用的。</li></ul><p>相关参数: </p><ul><li><strong>interceptor.classes</strong>:<br>拦截器列表，kafka运行在消息真正发送到broker之前对消息进行拦截加工。</li></ul><h3 id="数据可靠性保证"><a href="#数据可靠性保证" class="headerlink" title="数据可靠性保证"></a>数据可靠性保证</h3><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后都需要向producer发送ack(acknowledgement 确认收到)，如果producer收到ack,就会进行下一轮的发送，否则重新发送数据。</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_7.png"></p><h4 id="副本数据同步策略"><a href="#副本数据同步策略" class="headerlink" title="副本数据同步策略"></a>副本数据同步策略</h4><table><thead><tr><th align="left">方案</th><th align="left">优点</th><th align="left">缺点</th></tr></thead><tbody><tr><td align="left">半数以上完成同步，就发送ack</td><td align="left">延迟低</td><td align="left">选举新的leader时，容忍n台节点故障，需要2n+1个副本</td></tr><tr><td align="left">全部完成同步，才发送ack</td><td align="left">选举新的leader时，容忍n台节点故障，需要n+1个副本</td><td align="left">延迟高</td></tr></tbody></table><p>Kafka选择了第二种方案，原因如下：</p><p>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1 个副本，而 Kafka 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</p><p>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</p><h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h4><p>采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据， 但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去， 直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p><p>Leader 维护了一个动态的 in-sync replica set (ISR)，意为和 leader 保持同步的 follower 集合。当 ISR 中的 follower 完成数据的同步之后，leader 就会给 follower 发送 ack。如果 follower 长时间未向 leader 同步数据 ， 则该 follower 将被踢出ISR ， 该时间阈值由replica.lag.time.max.ms 参数设定。Leader 发生故障之后，就会从 ISR 中选举新的 leader。</p><h4 id="ack-应答机制"><a href="#ack-应答机制" class="headerlink" title="ack 应答机制"></a>ack 应答机制</h4><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等 ISR 中的 follower 全部接收成功。</p><p>所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p><ul><li>0: 表示生产者不关心该条消息在 broker 端的处理结果，只要调用 KafkaProducer 的 send 方法返回后即认为成功，显然这种方式是最不安全的，因为 Broker 端可能压根都没有收到该条消息或存储失败。</li><li>1: 等待至少一个leader成功把消息写到log中，不保证follower写入成功，如果leader宕机同时follower没有把数据写入成功，数据丢失。</li><li>all 或 -1: 表示消息不仅需要 Leader 节点已存储该消息，并且要求其副本（准确的来说是 ISR 中的节点）全部存储才认为已提交，才向客户端返回提交成功。这是最严格的持久化保障，当然性能也最低。<ul><li>但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成数据重复。</li></ul></li></ul><p>相关参数:</p><ul><li><strong>acks</strong>:<br>ack应答级别</li></ul><h4 id="故障处理细节"><a href="#故障处理细节" class="headerlink" title="故障处理细节"></a>故障处理细节</h4><p>Log文件中的HW和LEO</p><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img_8.png"></p><p>LEO：指的是每个副本最大的 offset；<br>HW：指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。</p><ul><li>follower 故障: follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后，follower 会读取本地磁盘 记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。 等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重 新加入 ISR 了</li><li>leader 故障: leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性，其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader 同步数据。</li></ul><p><strong>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p><h3 id="消息队列投递语义"><a href="#消息队列投递语义" class="headerlink" title="消息队列投递语义"></a>消息队列投递语义</h3><ul><li>At Least Once 可以保证数据不丢失，但是不能保证数据不重复。</li><li>At Most Once 可以保证数据不重复，但是不能保证数据不丢失。</li><li>对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即 Exactly Once 语义。</li></ul><p>Kafka投递语义实现方案：</p><ul><li><p>将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 At Least Once 语义。</p></li><li><p>相对的，将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被 发送一次，即 At Most Once 语义。</p></li></ul><p>在 0.11 版本以前的 Kafka，对Exactly Once 语义是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。</p><p>对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11 版本的 Kafka，引入了一项重大特性：<strong>幂等性</strong>。</p><pre><code>所谓的幂等性就是指 Producer 不论向 Server 发送多少次重复数据，Server 端都只会持久化一条。</code></pre><p>幂等性结合 At Least Once 语义，就构成了 Kafka 的 Exactly Once 语义。即：</p><p><strong>At Least Once + 幂等性 = Exactly Once</strong></p><p>相关参数: </p><ul><li><strong>enable.idempotence</strong>: 是否开启发送端的幂等，默认为false。</li><li><strong>acks</strong>: all</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。 </span><br><span class="line">开启幂等性的 Producer 在初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。</span><br><span class="line">而 Broker 端会对做缓存，当具有相同主键的消息提交时，Broker 只会持久化一条。</span><br></pre></td></tr></table></figure><p>但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以<strong>幂等性无法保证分区跨会话的 Exactly Once</strong></p><h3 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h3><ul><li><strong>send.buffer.bytes</strong>: 网络通道(TCP)的发送缓存区大小，默认为128K。</li><li><strong>receive.buffer.bytes</strong>: 网络通道(TCP)的接收缓存区大小，默认为32K。</li><li><strong>reconnect.backoff.ms</strong>: 重新建立链接的等待时长，默认为50ms，属于底层网络参数，基本无需关注。</li><li><strong>reconnect.backoff.max.ms</strong>: 重新建立链接的最大等待时长，默认为1s，连续两次对同一个连接建立重连，等待时间会在reconnect.backoff.ms的初始值上成指数级递增，但超过max后，将不再指数级递增。</li><li><strong>transaction.timeout.ms</strong>: 事务协调器等待客户端的事务状态反馈的最大超时时间，默认为60s。</li><li><strong>transactional.id</strong>: 事务id,用于在一个事务中唯一标识一个客户端</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将从Kafka Producer的配置属性为突破口，结合源码深入提炼出Kafka Producer的工作机制，方便大家更好使用Kafka Producer，并且胸有成竹的进行性能调优。&lt;/p&gt;
&lt;p&gt;将Kafka Producer相关的参数分成如下几个类型：&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之Kafka复制原理</title>
    <link href="http://example.com/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/</id>
    <published>2021-05-16T10:03:58.000Z</published>
    <updated>2021-08-12T03:37:01.869Z</updated>
    
    <content type="html"><![CDATA[<h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/img.png"></p><h4 id="HW（High-Watermark）："><a href="#HW（High-Watermark）：" class="headerlink" title="HW（High Watermark）："></a>HW（High Watermark）：</h4><ul><li>在分区高水位以下的消息被认为是已提交消息，反之就是未提交消息；</li><li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的；</li><li>小于等于HW值的所有消息都被认为是“已备份”的（replicated）。</li></ul><h4 id="LEO（Log-End-Offset）"><a href="#LEO（Log-End-Offset）" class="headerlink" title="LEO（Log End Offset）"></a>LEO（Log End Offset）</h4><ul><li>记录了该副本底层日志(log)中下一条消息的位移值（注意是下一条消息！！）</li><li>数字 15 所在的方框是虚线，这就说明，这个副本当前只有 15 条消息，位移值是从 0 到 14，下一条新消息的位移是 15；</li></ul><h3 id="更新机制"><a href="#更新机制" class="headerlink" title="更新机制"></a>更新机制</h3><p><img src="/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/img_1.png"></p><p><strong>流程如下</strong></p><ol><li>生产者写入消息到leader副本</li><li>leader副本LEO值更新</li><li>follower副本尝试拉取消息，发现有消息可以拉取，更新自身LEO</li><li>follower副本继续尝试拉取消息，这时会更新remote副本LEO，同时会更新leader副本的HW</li><li>完成4步骤后，leader副本会将已更新过的HW发送给所有follower副本</li><li>follower副本接收leader副本HW，更新自身的HW</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kafka副本之间的数据复制既不是完全的同步复制，也不是单纯的异步复制；</span><br><span class="line">Leader副本的HW更新原则：取当前leader副本的LEO和所有remote副本的LEO的最小值</span><br><span class="line">Follower副本的HW更新原则：取leader副本发送的HW和自身的LEO中的最小值</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;预备知识&quot;&gt;&lt;a href=&quot;#预备知识&quot; class=&quot;headerlink&quot; title=&quot;预备知识&quot;&gt;&lt;/a&gt;预备知识&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2021/05/16/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列01之Kafka为什么这么快</title>
    <link href="http://example.com/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/"/>
    <id>http://example.com/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/</id>
    <published>2021-05-02T06:12:42.000Z</published>
    <updated>2021-08-12T03:37:01.863Z</updated>
    
    <content type="html"><![CDATA[<ul><li>partition 并行处理</li><li>顺序写磁盘，充分利用磁盘特性</li><li>利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率</li><li>采用了零拷贝技术</li><li>Producer 生产的数据持久化到 broker，采用 mmap 文件映射，实现顺序的快速写入</li><li>Customer 从 broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer进行网络发送，减少 CPU 消耗</li></ul><h2 id="详细解读"><a href="#详细解读" class="headerlink" title="详细解读"></a>详细解读</h2><p>无论 kafka 作为 MQ 也好，作为存储层也罢，无非就是两个功能（好简单的样子），一是 Producer 生产的数据存到 broker，二是 Consumer 从 broker 读取数据。那 Kafka 的快也就体现在读写两个方面了，下面我们就聊聊 Kafka 快的原因。</p><h3 id="利用-Partition-实现并行处理"><a href="#利用-Partition-实现并行处理" class="headerlink" title="利用 Partition 实现并行处理"></a>利用 Partition 实现并行处理</h3><p>我们都知道 Kafka 是一个 Pub-Sub 的消息系统，无论是发布还是订阅，都要指定 Topic。</p><p>Topic 只是一个逻辑的概念。每个 Topic 都包含一个或多个 Partition，不同 Partition 可位于不同节点。</p><p>一方面，由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p><p>能并行处理，速度肯定会有提升，多个工人肯定比一个工人干的快。</p><h3 id="顺序写磁盘"><a href="#顺序写磁盘" class="headerlink" title="顺序写磁盘"></a>顺序写磁盘</h3><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img.png"><br>Kafka 中每个分区是一个有序的，不可变的消息序列，新的消息不断追加到 partition 的末尾，这个就是顺序写。</p><p>由于磁盘有限，不可能保存所有数据，实际上作为消息系统 Kafka 也没必要保存所有数据，需要删除旧的数据。</p><p>又由于顺序写入的原因，所以 Kafka 采用各种删除策略删除数据的时候，并非通过使用“读 - 写”模式去修改文件，而是将 Partition 分为多个 Segment，每个 Segment 对应一个物理文件，通过删除整个文件的方式去删除 Partition 内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。</p><h4 id="简单扯扯磁盘-IO-的那些事"><a href="#简单扯扯磁盘-IO-的那些事" class="headerlink" title="简单扯扯磁盘/IO 的那些事"></a>简单扯扯磁盘/IO 的那些事</h4><p>硬盘性能的制约因素是什么？如何根据磁盘I/O特性来进行系统设计？<br>硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。<br>实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img2.png"></p><p>由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示：</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img1.png"></p><p>影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。<br>机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。<br>在许多的开源框架如 Kafka、HBase 中，都通过追加写的方式来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。  </p><p>感兴趣的同学可以看看 <a href="https://link.zhihu.com/?target=https://tech.meituan.com/2017/05/19/about-desk-io.html">磁盘I/O那些事</a></p><p>磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。</p><h3 id="充分利用-Page-Cache"><a href="#充分利用-Page-Cache" class="headerlink" title="充分利用 Page Cache"></a>充分利用 Page Cache</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache。</span><br><span class="line">  每一个 Page Cache 包含若干 Buffer Cache。</span><br><span class="line">* Page Cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read/write 操作的时候。</span><br><span class="line">* Buffer Cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。</span><br></pre></td></tr></table></figure><p>使用 Page Cache 的好处：</p><ul><li>I/O Scheduler 会将连续的小块写组装成大块的物理写从而提高性能</li><li>I/O Scheduler 会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</li><li>充分利用所有空闲内存（非 JVM 内存）。如果使用应用层 Cache（即 JVM 堆内存），会增加 GC 负担</li><li>读操作可直接在 Page Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 Page Cache）交换数据</li><li>如果进程重启，JVM 内的 Cache 会失效，但 Page Cache 仍然可用</li></ul><p>Broker 收到数据后，写磁盘时只是将数据写入 Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache 内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由 Kafka 层面的 Replication 机制去解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。也正因如此，Kafka 虽然提供了 flush.messages 和 flush.ms 两个参数将 Page Cache 中的数据强制 Flush 到磁盘，但是 Kafka 并不建议使用。</p><h3 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h3><p>Kafka 中存在大量的网络数据持久化到磁盘（Producer 到 Broker）和磁盘文件通过网络发送（Broker 到 Consumer）的过程。这一过程的性能直接影响 Kafka 的整体吞吐量。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的权限。</span><br><span class="line">为了避免用户进程直接操作内核，保证内核安全，操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space），一部分是用户空间（User-space）。</span><br></pre></td></tr></table></figure><p>传统的 Linux 系统中，标准的 I/O 接口（例如read，write）都是基于数据拷贝操作的，即 I/O 操作会导致数据在内核地址空间的缓冲区和用户地址空间的缓冲区之间进行拷贝，所以标准 I/O 也被称作缓存 I/O。这样做的好处是，如果所请求的数据已经存放在内核的高速缓冲存储器中，那么就可以减少实际的 I/O 操作，但坏处就是数据拷贝的过程，会导致 CPU 开销。</p><p>我们把 Kafka 的生产和消费简化成如下两个过程来看：</p><ul><li>网络数据持久化到磁盘 (Producer 到 Broker)</li><li>磁盘文件通过网络发送（Broker 到 Consumer）</li></ul><h4 id="1-网络数据持久化到磁盘-Producer-到-Broker"><a href="#1-网络数据持久化到磁盘-Producer-到-Broker" class="headerlink" title="1) 网络数据持久化到磁盘 (Producer 到 Broker)"></a>1) 网络数据持久化到磁盘 (Producer 到 Broker)</h4><p>传统模式下，数据从网络传输到文件需要 4 次数据拷贝、4 次上下文切换和两次系统调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = socket.read()// 读取网络数据 </span><br><span class="line">File file = new File() </span><br><span class="line">file.write(data)// 持久化到磁盘 </span><br><span class="line">file.flush()</span><br></pre></td></tr></table></figure><p>这一过程实际上发生了四次数据拷贝：</p><ul><li>首先通过 DMA copy 将网络数据拷贝到内核态 Socket Buffer</li><li>然后应用程序将内核态 Buffer 数据读入用户态（CPU copy）</li><li>接着用户程序将用户态 Buffer 再拷贝到内核态（CPU copy）</li><li>最后通过 DMA copy 将数据拷贝到磁盘文件</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DMA（Direct Memory Access）：直接存储器访问。DMA 是一种无需 CPU 的参与，让外设和系统内存之间进行双向数据传输的硬件机制。使用 DMA 可以使系统 CPU 从实际的 I/O 数据传输过程中摆脱出来，从而大大提高系统的吞吐率。</span><br></pre></td></tr></table></figure><p>其中伴随着四次上下文切换，如图所示</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img3.png"></p><p>数据落盘通常都是非实时的，kafka 生产者数据持久化也是如此。Kafka 的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高 I/O 效率，就是上一节提到的 Page Cache。</p><p>对于 kafka 来说，Producer 生产的数据存到 broker，这个过程读取到 socket buffer 的网络数据，其实可以直接在内核空间完成落盘。并没有必要将 socket buffer 的网络数据，读取到应用进程缓冲区；在这里应用进程缓冲区其实就是 broker，broker 收到生产者的数据，就是为了持久化。</p><p><strong>在此特殊场景下</strong>：接收来自 socket buffer 的网络数据，应用进程不需要中间处理、直接进行持久化时。可以使用 <strong>mmpp</strong> 内存文件映射。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Memory Mapped Files：简称 mmap，也有叫 MMFile 的，使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射。从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程。它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。</span><br><span class="line">使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销。</span><br><span class="line">mmap 也有一个很明显的缺陷——不可靠，写到 mmap 中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。Kafka 提供了一个参数——producer.type 来控制是不是主动flush；如果 Kafka 写入到 mmap 之后就立即 flush 然后再返回 Producer 叫同步(sync)；写入 mmap 之后立即返回 Producer 不调用 flush 就叫异步(async)，默认是 sync。</span><br></pre></td></tr></table></figure><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img4.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。</span><br><span class="line">它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。</span><br><span class="line">目前零拷贝技术主要有三种类型：</span><br><span class="line">直接I/O：</span><br><span class="line">        数据直接跨过内核，在用户地址空间与I/O设备之间传递，内核只是进行必要的虚拟存储配置等辅助工作；</span><br><span class="line">避免内核和用户空间之间的数据拷贝：</span><br><span class="line">        当应用程序不需要对数据进行访问时，则可以避免将数据从内核空间拷贝到用户空间</span><br><span class="line">        * mmap</span><br><span class="line">        * sendfile</span><br><span class="line">        * splice &amp;&amp; tee</span><br><span class="line">        * sockmap</span><br><span class="line">copy on write：</span><br><span class="line">        写时拷贝技术，数据不需要提前拷贝，而是当需要修改的时候再进行部分拷贝。</span><br></pre></td></tr></table></figure><h4 id="2-磁盘文件通过网络发送（Broker-到-Consumer）"><a href="#2-磁盘文件通过网络发送（Broker-到-Consumer）" class="headerlink" title="2) 磁盘文件通过网络发送（Broker 到 Consumer）"></a>2) 磁盘文件通过网络发送（Broker 到 Consumer）</h4><p>传统方式实现：先读取磁盘、再用 socket 发送，实际也是进过四次 copy</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buffer = File.read</span><br><span class="line">Socket.send(buffer)</span><br></pre></td></tr></table></figure><p>这一过程可以类比上边的生产消息：</p><ul><li>首先通过系统调用将文件数据读入到内核态 Buffer（DMA 拷贝）</li><li>然后应用程序将内存态 Buffer 数据读入到用户态 Buffer（CPU 拷贝）</li><li>接着用户程序通过 Socket 发送数据时将用户态 Buffer 数据拷贝到内核态 Buffer（CPU 拷贝）</li><li>最后通过 DMA 拷贝将数据拷贝到 NIC Buffer </li></ul><p>Linux 2.4+ 内核通过 sendfile 系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件 - 网络发送由一个 sendfile 调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p><p><img src="/2021/05/02/%E4%B8%AD%E9%97%B4%E4%BB%B6/MQ/Kafka/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img5.png"></p><p>Kafka 在这里采用的方案是通过 NIO 的 transferTo/transferFrom 调用操作系统的 sendfile 实现零拷贝。总共发生 2 次内核数据拷贝、2 次上下文切换和一次系统调用，消除了 CPU 数据拷贝</p><h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>在很多情况下，系统的瓶颈不是 CPU 或磁盘，而是网络IO。</p><p>因此，除了操作系统提供的低级批处理之外，Kafka 的客户端和 broker 还会在通过网络发送数据之前，在一个批处理中累积多条记录 (包括读和写)。记录的批处理分摊了网络往返的开销，使用了更大的数据包从而提高了带宽利用率。</p><h3 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h3><p>Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;partition 并行处理&lt;/li&gt;
&lt;li&gt;顺序写磁盘，充分利用磁盘特性&lt;/li&gt;
&lt;li&gt;利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率&lt;/li&gt;
&lt;li&gt;采用了零拷贝技术&lt;/li&gt;
&lt;li&gt;Producer 生产的数据持久</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>数据库连接池之HikariCP实现详解</title>
    <link href="http://example.com/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-04-26T02:08:03.000Z</published>
    <updated>2021-08-12T03:37:01.912Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是数据库连接池，为什么需要数据库连接池"><a href="#什么是数据库连接池，为什么需要数据库连接池" class="headerlink" title="什么是数据库连接池，为什么需要数据库连接池"></a>什么是数据库连接池，为什么需要数据库连接池</h2><p>从根本上而言，数据库连接池和我们常用的线程池一样，都属于池化资源，它在程序初始化时创建一定数量的数据库连接对象并将其保存在一块内存区中。</p><p>它允许应用程序重复使用一个现有的数据库连接，当需要执行 SQL 时，我们是直接从连接池中获取一个连接，而不是重新建立一个数据库连接，当 SQL 执行完，也并不是将数据库连接真的关掉，而是将其归还到数据库连接池中。</p><p>我们可以通过配置连接池的参数来控制连接池中的初始连接数、最小连接、最大连接、最大空闲时间等参数，来保证访问数据库的数量在一定可控制的范围类，防止系统崩溃，同时保证用户良好的体验。</p><p>数据库连接池示意图如下所示：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img.png"></p><p>因为数据库连接是有限且代价昂贵，创建和释放数据库连接都非常耗时，频繁地进行这样的操作将占用大量的性能开销，进而导致网站的响应速度下降，甚至引起服务器崩溃。</p><p>因此使用数据库连接池的核心作用，就是<strong>避免数据库连接频繁创建和销毁，节省系统开销</strong>。</p><h3 id="常见数据库连接池对比分析"><a href="#常见数据库连接池对比分析" class="headerlink" title="常见数据库连接池对比分析"></a>常见数据库连接池对比分析</h3><p>这里详细总结了常见数据库连接池的各项功能比较，我们重点分析下当前主流的阿里巴巴Druid与HikariCP，HikariCP在性能上是完全优于Druid连接池的。</p><p>而Druid的性能稍微差点是由于锁机制的不同，并且Druid提供更丰富的功能，包括监控、sql拦截与解析等功能，两者的侧重点不一样，HikariCP追求极致的高性能。</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_1.png"></p><p>下面是官网提供的性能对比图，在性能上面这五种数据库连接池的排序如下：HikariCP&gt;druid&gt;tomcat-jdbc&gt;dbcp&gt;c3p0：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_2.png"></p><h3 id="一个简单的小问题"><a href="#一个简单的小问题" class="headerlink" title="一个简单的小问题"></a>一个简单的小问题</h3><pre><code>连接池本身的性能消耗在整个调用链路中通常占比不大，连接池的性能关键点是：连接是否LRU方式重用，是否支持PSCache（PreparedStatementCache）。</code></pre><h2 id="HikariCP数据库连接池简介"><a href="#HikariCP数据库连接池简介" class="headerlink" title="HikariCP数据库连接池简介"></a>HikariCP数据库连接池简介</h2><p>HikariCP 号称是史上性能最好的数据库连接池，SpringBoot 2.0将它设置为默认的数据源连接池。</p><p>Hikari相比起其它连接池的性能高了非常多，那么，这是怎么做到的呢？</p><p>通过查看HikariCP官网介绍，对于HikariCP所做优化总结如下：</p><ol><li><p><strong>字节码精简</strong> ：优化代码，编译后的字节码量极少，使得CPU缓存可以加载更多的程序代码；</p><p> HikariCP在优化并精简字节码上也下了功夫，使用第三方的Java字节码修改类库Javassist来生成委托实现动态代理.动态代理的实现在ProxyFactory类，速度更快，相比于JDK Proxy生成的字节码更少，精简了很多不必要的字节码。</p></li><li><p><strong>优化代理和拦截器</strong>：减少代码，例如HikariCP的Statement proxy只有100行代码，只有BoneCP的十分之一；</p></li><li><p><strong>自定义数组类型（FastStatementList）代替ArrayList</strong>：避免ArrayList每次get()都要进行range check，避免调用remove()时的从头到尾的扫描（由于连接的特点是后获取连接的先释放）；</p></li><li><p><strong>自定义集合类型（ConcurrentBag）</strong>：提高并发读写的效率；</p></li><li><p><strong>其他针对BoneCP缺陷的优化</strong>，比如对于耗时超过一个CPU时间片的方法调用的研究。</p></li></ol><h2 id="HikariCP详细设计之类图和流程图"><a href="#HikariCP详细设计之类图和流程图" class="headerlink" title="HikariCP详细设计之类图和流程图"></a>HikariCP详细设计之类图和流程图</h2><p>开始前先来了解下HikariCP获取一个连接时类间的交互流程，方便下面详细流程的阅读。</p><p>获取连接时的类间交互：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_3.png"></p><h2 id="HikariCP详细设计之流程源码解读"><a href="#HikariCP详细设计之流程源码解读" class="headerlink" title="HikariCP详细设计之流程源码解读"></a>HikariCP详细设计之流程源码解读</h2><h3 id="主流程1：获取连接流程"><a href="#主流程1：获取连接流程" class="headerlink" title="主流程1：获取连接流程"></a>主流程1：获取连接流程</h3><p>HikariCP获取连接时的入口是<code>HikariDataSource</code>里的<code>getConnection</code>方法，现在来看下该方法的具体流程：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_4.png"></p><p>上述为HikariCP获取连接时的流程图，由图可知:</p><ul><li>每个datasource对象里都会持有一个HikariPool对象，记为pool;</li><li>初始化后的datasource对象pool是空的，所以第一次getConnection的时候会进行实例化pool属性（参考主流程1），初始化的时候需要将当前datasource里的config属性传过去，用于pool的初始化，最终标记sealed;</li><li>然后根据pool对象调用getConnection方法（参考流程1.1），获取成功后返回连接对象。</li></ul><h4 id="流程1-1：通过HikariPool获取连接对象"><a href="#流程1-1：通过HikariPool获取连接对象" class="headerlink" title="流程1.1：通过HikariPool获取连接对象"></a>流程1.1：通过HikariPool获取连接对象</h4><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_6.png"></p><ul><li>从最开始的结构图可知，每个HikariPool里都维护一个ConcurrentBag对象，用于存放连接对象。</li><li>由上图可以看到，实际上HikariPool的getConnection就是从ConcurrentBag里获取连接的（调用其borrow方法获得，对应ConnectionBag主流程），</li><li>在长连接检查这块，与之前说的Druid不同，这里的长连接判活检查在连接对象没有被标记为“已丢弃”时，只要距离上次使用超过500ms每次取出都会进行检查（500ms是默认值，可通过配置<code>com.zaxxer.hikari.aliveBypassWindowMs</code>的系统参数来控制），也就是说HikariCP对长连接的活性检查很频繁，但是其并发性能依旧优于Druid，说明<strong>频繁的长连接检查并不是导致连接池性能高低的关键所在</strong>。<ul><li>这个其实是由于HikariCP的无锁实现，在高并发时对CPU的负载没有其他连接池那么高而产生的并发性能差异，后面会说HikariCP的具体做法；</li><li>即使是Druid，在获取连接、生成连接、归还连接时都进行了锁控制。</li><li>Druid里的连接池资源是多线程共享的，不可避免的会有锁竞争，有锁竞争意味着线程状态的变化会很频繁，线程状态变化频繁意味着CPU上下文切换也将会很频繁。</li></ul></li></ul><p>主体流程：</p><ul><li>如果拿到的连接为空，直接报错；</li><li>不为空则进行相应的检查<ul><li>如果检查通过，则包装成ConnectionProxy对象返回给业务方；</li><li>不通过则调用closeConnection方法关闭连接（对应流程1.1.2，该流程会触发ConcurrentBag的remove方法丢弃该连接，然后把实际的驱动连接交给closeConnectionExecutor线程池，异步关闭驱动连接）。</li></ul></li></ul><h5 id="流程1-1-1：连接判活"><a href="#流程1-1-1：连接判活" class="headerlink" title="流程1.1.1：连接判活"></a>流程1.1.1：连接判活</h5><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_7.png"></p><p>承接上面的<code>流程1.1</code>里的判活流程，来看下判活是如何做的</p><ul><li>首先说验证方法（注意这里该方法接受的这个connection对象不是poolEntry，而是poolEntry持有的实际驱动的连接对象），<ul><li>Druid是根据驱动程序里是否存在ping方法来判断是否启用ping的方式判断连接是否存活;</li><li>但是到了HikariCP则更加简单粗暴，仅根据是否配置了connectionTestQuery觉定是否启用ping：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.isUseJdbc4Validation = config.getConnectionTestQuery() == null;</span><br></pre></td></tr></table></figure></li><li>所以一般驱动如果不是特别低的版本，不建议配置该项，否则便会走createStatement+excute的方式，相比ping简单发送心跳数据，这种方式显然更低效。</li></ul></li><li>超时时间<ul><li>在刚进来还会通过驱动的连接对象重新给它设置一遍networkTimeout的值，使之变成validationTimeout，表示一次验证的超时时间；</li><li>因为在使用ping方法校验时，是没办法通过类似statement那样可以setQueryTimeout的，所以只能由网络通信的超时时间来控制，这个时间可以通过jdbc的连接参数socketTimeout来控制：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbc:mysql://127.0.0.1:3306/xxx?socketTimeout=250</span><br></pre></td></tr></table></figure></li><li>这个值最终会被赋值给HikariCP的networkTimeout字段，这就是为什么最后那一步使用这个字段来还原驱动连接超时属性的原因；</li><li>最后那里为啥要再次还原呢？这就很容易理解了，因为验证结束了，连接对象还存活的情况下，它的networkTimeout的值这时仍然等于validationTimeout（不合预期），显然在拿出去用之前，需要恢复成本来的值，也就是HikariCP里的networkTimeout属性。</li></ul></li></ul><h5 id="流程1-1-2：关闭连接对象"><a href="#流程1-1-2：关闭连接对象" class="headerlink" title="流程1.1.2：关闭连接对象"></a>流程1.1.2：关闭连接对象</h5><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_8.png"></p><p>这个流程简单来说就是把流程1.1.1中验证不通过的死连接，主动关闭的一个流程。</p><ul><li>首先会把这个连接对象从ConnectionBag里移除，</li><li>然后把实际的物理连接交给一个线程池去异步执行，这个线程池就是在主流程2里初始化池的时候初始化的线程池closeConnectionExecutor，</li><li>然后异步任务内开始实际的关连接操作，</li><li>因为主动关闭了一个连接相当于少了一个连接，所以还会触发一次扩充连接池（参考<code>主流程5</code>）操作。</li></ul><h3 id="主流程2：初始化池对象"><a href="#主流程2：初始化池对象" class="headerlink" title="主流程2：初始化池对象"></a>主流程2：初始化池对象</h3><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_5.png"></p><p>该流程用于初始化整个连接池，这个流程会给连接池内所有的属性做初始化的工作，其中比较主要的几个流程上图已经指出，简单概括一下：</p><ol><li>利用config初始化各种连接池属性，并且产生一个用于生产物理连接的数据源DriverDataSource</li><li>初始化存放连接对象的核心类connectionBag</li><li>初始化一个延时任务线程池类型的对象houseKeepingExecutorService，用于后续执行一些延时/定时类任务（比如连接泄漏检查延时任务，参考流程2.2以及<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B4%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%BC%A9%E5%AE%B9">主流程4：连接池缩容</a>，除此之外maxLifeTime后主动回收关闭连接也是交由该对象来执行的，这个过程可以参考主流程3）</li><li>预热连接池，HikariCP会在该流程的checkFailFast里初始化好一个连接对象放进池子内，当然触发该流程得保证initializationTimeout &gt; 0时（默认值1），这个配置属性表示留给预热操作的时间（默认值1在预热失败时不会发生重试）。与Druid通过initialSize控制预热连接对象数不一样的是，HikariCP仅预热进池一个连接对象。</li><li>初始化一个线程池对象addConnectionExecutor，用于后续扩充连接对象</li><li>初始化一个线程池对象closeConnectionExecutor，用于关闭一些连接对象，怎么触发关闭任务呢？可以参考流程1.1.2</li></ol><h4 id="流程2-1：HikariCP监控设置"><a href="#流程2-1：HikariCP监控设置" class="headerlink" title="流程2.1：HikariCP监控设置"></a>流程2.1：HikariCP监控设置</h4><p>不同于Druid那样监控指标那么多，HikariCP会把我们非常关心的几项指标暴露给我们，</p><p>比如当前连接池内闲置连接数、总连接数、一个连接被用了多久归还、创建一个物理连接花费多久等，</p><p>HikariCP的连接池的监控我们这一节专门详细的分解一下，首先找到HikariCP下面的metrics文件夹，这下面放置了一些规范实现的监控接口等，还有一些现成的实现（比如HikariCP自带对prometheus、micrometer、dropwizard的支持，不太了解后面两个，prometheus下文直接称为普罗米修斯）：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_9.png"></p><p>下面，来着重看下接口的定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这个接口的实现主要负责收集一些动作的耗时</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IMetricsTracker</span> <span class="keyword">extends</span> <span class="title">AutoCloseable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">//这个方法触发点在创建实际的物理连接时（主流程3），用于记录一个实际的物理连接创建所耗费的时间</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionCreatedMillis</span><span class="params">(<span class="keyword">long</span> connectionCreatedMillis)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点在getConnection时（主流程1），用于记录获取一个连接时实际的耗时</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionAcquiredNanos</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> elapsedAcquiredNanos)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点在回收连接时（主流程6），用于记录一个连接从被获取到被回收时所消耗的时间</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionUsageMillis</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> elapsedBorrowedMillis)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点也在getConnection时（主流程1），用于记录获取连接超时的次数，每发生一次获取连接超时，就会触发一次该方法的调用</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionTimeout</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>触发点都了解清楚后，再来看看MetricsTrackerFactory的接口定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//用于创建IMetricsTracker实例，并且按需记录PoolStats对象里的属性（这个对象里的属性就是类似连接池当前闲置连接数之类的线程池状态类指标）</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">MetricsTrackerFactory</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">//返回一个IMetricsTracker对象，并且把PoolStats传了过去</span></span><br><span class="line">    <span class="function">IMetricsTracker <span class="title">create</span><span class="params">(String poolName, PoolStats poolStats)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的接口用法见注释，针对新出现的PoolStats类，我们来看看它做了什么：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">PoolStats</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicLong reloadAt; <span class="comment">//触发下次刷新的时间（时间戳）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> timeoutMs; <span class="comment">//刷新下面的各项属性值的频率，默认1s，无法改变</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 总连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> totalConnections;</span><br><span class="line">    <span class="comment">// 闲置连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> idleConnections;</span><br><span class="line">    <span class="comment">// 活动连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> activeConnections;</span><br><span class="line">    <span class="comment">// 由于无法获取到可用连接而阻塞的业务线程数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> pendingThreads;</span><br><span class="line">    <span class="comment">// 最大连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> maxConnections;</span><br><span class="line">    <span class="comment">// 最小连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> minConnections;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PoolStats</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.timeoutMs = timeoutMs;</span><br><span class="line">        <span class="keyword">this</span>.reloadAt = <span class="keyword">new</span> AtomicLong();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这里以获取最大连接数为例，其他的跟这个差不多</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getMaxConnections</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (shouldLoad()) &#123; <span class="comment">//是否应该刷新</span></span><br><span class="line">            update(); <span class="comment">//刷新属性值，注意这个update的实现在HikariPool里，因为这些属性值的直接或间接来源都是HikariPool</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> maxConnections;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">()</span></span>; <span class="comment">//实现在↑上面已经说了</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldLoad</span><span class="params">()</span> </span>&#123; <span class="comment">//按照更新频率来决定是否刷新属性值</span></span><br><span class="line">        <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> now = currentTime();</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> reloadTime = reloadAt.get();</span><br><span class="line">            <span class="keyword">if</span> (reloadTime &gt; now) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (reloadAt.compareAndSet(reloadTime, plusMillis(now, timeoutMs))) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上这里就是这些属性获取和触发刷新的地方，那么这个对象是在哪里被生成并且丢给<code>MetricsTrackerFactory</code>的<code>create</code>方法的呢？这就是本节所需要讲述的要点：<code>主流程2</code>里的设置监控器的流程，来看看那里发生了什么事吧：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">//监控器设置方法（此方法在HikariPool中，metricsTracker属性就是HikariPool用来触发IMetricsTracker里方法调用的）</span><br><span class="line">public void setMetricsTrackerFactory(MetricsTrackerFactory metricsTrackerFactory) &#123;</span><br><span class="line">    if (metricsTrackerFactory != null) &#123;</span><br><span class="line">        //MetricsTrackerDelegate是包装类，是HikariPool的一个静态内部类，是实际持有IMetricsTracker对象的类，也是实际触发IMetricsTracker里方法调用的类</span><br><span class="line">        //这里首先会触发MetricsTrackerFactory类的create方法拿到IMetricsTracker对象，然后利用getPoolStats初始化PoolStat对象，然后也一并传给MetricsTrackerFactory</span><br><span class="line">        this.metricsTracker = new MetricsTrackerDelegate(metricsTrackerFactory.create(config.getPoolName(), getPoolStats()));</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        //不启用监控，直接等于一个没有实现方法的空类</span><br><span class="line">        this.metricsTracker = new NopMetricsTrackerDelegate();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private PoolStats getPoolStats() &#123;</span><br><span class="line">    //初始化PoolStats对象，并且规定1s触发一次属性值刷新的update方法</span><br><span class="line">    return new PoolStats(SECONDS.toMillis(1)) &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void update() &#123;</span><br><span class="line">            //实现了PoolStat的update方法，刷新各个属性的值</span><br><span class="line">            this.pendingThreads = HikariPool.this.getThreadsAwaitingConnection();</span><br><span class="line">            this.idleConnections = HikariPool.this.getIdleConnections();</span><br><span class="line">            this.totalConnections = HikariPool.this.getTotalConnections();</span><br><span class="line">            this.activeConnections = HikariPool.this.getActiveConnections();</span><br><span class="line">            this.maxConnections = config.getMaximumPoolSize();</span><br><span class="line">            this.minConnections = config.getMinimumIdle();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里HikariCP的监控器就算是注册进去了，所以要想实现自己的监控器拿到上面的指标，要经过如下步骤：</p><ol><li>新建一个类实现IMetricsTracker接口，我们这里将该类记为IMetricsTrackerImpl</li><li>新建一个类实现MetricsTrackerFactory接口，我们这里将该类记为MetricsTrackerFactoryImpl，并且将上面的IMetricsTrackerImpl在其create方法内实例化</li><li>将MetricsTrackerFactoryImpl实例化后调用HikariPool的setMetricsTrackerFactory方法注册到Hikari连接池。</li></ol><p>上面没有提到PoolStats里的属性怎么监控，这里来说下。</p><p>由于create方法是调用一次就没了，create方法只是接收了PoolStats对象的实例，如果不处理，那么随着create调用的结束，这个实例针对监控模块来说就失去持有了，所以这里如果想要拿到PoolStats里的属性，就需要开启一个守护线程，让其持有PoolStats对象实例，并且定时获取其内部属性值，然后push给监控系统，如果是<strong>普罗米修斯等使用pull方式获取监控数据的监控系统</strong>，可以效仿HikariCP原生普罗米修斯监控的实现，自定义一个Collector对象来接收PoolStats实例，这样普罗米修斯就可以定期拉取了，比如HikariCP根据普罗米修斯监控系统自己定义的<code>MetricsTrackerFactory</code>实现（对应<code>PrometheusMetricsTrackerFactory</code>类）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public IMetricsTracker create(String poolName, PoolStats poolStats) &#123;</span><br><span class="line">    getCollector().add(poolName, poolStats); //将接收到的PoolStats对象直接交给Collector，这样普罗米修斯服务端每触发一次采集接口的调用，PoolStats都会跟着执行一遍内部属性获取流程</span><br><span class="line">    return new PrometheusMetricsTracker(poolName, this.collectorRegistry); //返回IMetricsTracker接口的实现类</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//自定义的Collector</span><br><span class="line">private HikariCPCollector getCollector() &#123;</span><br><span class="line">    if (collector == null) &#123;</span><br><span class="line">        //注册到普罗米修斯收集中心</span><br><span class="line">        collector = new HikariCPCollector().register(this.collectorRegistry);</span><br><span class="line">    &#125;</span><br><span class="line">    return collector;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上面的解释可以知道在HikariCP中如何自定义一个自己的监控器，以及相比Druid的监控，有什么区别。 </p><h4 id="流程2-2：连接泄漏的检测与告警"><a href="#流程2-2：连接泄漏的检测与告警" class="headerlink" title="流程2.2：连接泄漏的检测与告警"></a>流程2.2：连接泄漏的检测与告警</h4><p>本节对应<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里的<a href="#%E6%B5%81%E7%A8%8B2.2%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B3%84%E6%BC%8F%E7%9A%84%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%91%8A%E8%AD%A6">子流程2.2</a>，在初始化池对象时，初始化了一个叫做<code>leakTaskFactory</code>的属性，本节来看下它具体是用来做什么的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个连接被拿出去使用时间超过leakDetectionThreshold（可配置，默认0）未归还的，会触发一个连接泄漏警告，通知业务方目前存在连接泄漏的问题。</span><br></pre></td></tr></table></figure><p><strong>过程详解</strong>:</p><p>该属性是<code>ProxyLeakTaskFactory</code>类型对象，且它还会持有<code>houseKeepingExecutorService</code>这个线程池对象，用于生产<code>ProxyLeakTask</code>对象，然后利用上面的<code>houseKeepingExecutorService</code>延时运行该对象里的run方法。</p><p>该流程的触发点在上面的<a href="#%E6%B5%81%E7%A8%8B1.1.1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%88%A4%E6%B4%BB">流程1.1</a>最后包装成ProxyConnection对象的那一步，来看看具体的流程图：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_10.png"></p><p>每次在<a href="#%E6%B5%81%E7%A8%8B1.1.1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%88%A4%E6%B4%BB">流程1.1</a>那里生成ProxyConnection对象时，都会触发上面的流程。</p><p>由流程图可以知道，ProxyConnection对象持有PoolEntry和ProxyLeakTask的对象，其中初始化ProxyLeakTask对象时就用到了leakTaskFactory对象，通过其schedule方法可以进行ProxyLeakTask的初始化，并将其实例传递给ProxyConnection进行初始化赋值</p><p><code>ps：由图知ProxyConnection在触发回收事件时，会主动取消这个泄漏检查任务，这也是ProxyConnection需要持有ProxyLeakTask对象的原因</code></p><p>只有在leakDetectionThreshold不等于0的时候才会生成一个带有实际延时任务的ProxyLeakTask对象，否则返回无实际意义的空对象。所以要想启用连接泄漏检查，首先要把leakDetectionThreshold配置设置上，这个属性表示经过该时间后借出去的连接仍未归还，则触发连接泄漏告警。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ProxyConnection之所以要持有ProxyLeakTask对象，是因为它可以监听到连接是否触发归还操作，如果触发，则调用cancel方法取消延时任务，防止误告。</span><br></pre></td></tr></table></figure><p>由此流程可以知道，跟Druid一样，HikariCP也有连接对象泄漏检查，与Druid主动回收连接相比，HikariCP实现更加简单，仅仅是在触发时打印警告日志，不会采取具体的强制回收的措施。</p><p>与Druid一样，默认也是关闭这个流程的，因为实际开发中一般使用第三方框架，框架本身会保证及时的close连接，防止连接对象泄漏，开启与否还是取决于业务是否需要，如果一定要开启，如何设置leakDetectionThreshold的大小也是需要考虑的一件事。</p><h3 id="主流程3：生成连接对象"><a href="#主流程3：生成连接对象" class="headerlink" title="主流程3：生成连接对象"></a>主流程3：生成连接对象</h3><p>本节来讲下<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里的<code>createEntry</code>方法，这个方法利用PoolBase里的DriverDataSource对象生成一个实际的连接对象（如果忘记DriverDatasource是哪里初始化的了，可以看下主流程2里PoolBase的initializeDataSource方法的作用），然后用PoolEntry类包装成PoolEntry对象：</p><details><summary>现在来看下这个包装类有哪些主要属性</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PoolEntry</span> <span class="keyword">implements</span> <span class="title">IConcurrentBagEntry</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(PoolEntry.class);</span><br><span class="line">    <span class="comment">//通过cas来修改state属性</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> AtomicIntegerFieldUpdater stateUpdater;</span><br><span class="line"></span><br><span class="line">    Connection connection; <span class="comment">//实际的物理连接对象</span></span><br><span class="line">    <span class="keyword">long</span> lastAccessed; <span class="comment">//触发回收时刷新该时间，表示“最近一次使用时间”</span></span><br><span class="line">    <span class="keyword">long</span> lastBorrowed; <span class="comment">//getConnection里borrow成功后刷新该时间，表示“最近一次借出的时间”</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;FieldCanBeLocal&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state = <span class="number">0</span>; <span class="comment">//连接状态，枚举值：IN_USE（使用中）、NOT_IN_USE（闲置中）、REMOVED（已移除）、RESERVED（标记为保留中）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> evict; <span class="comment">//是否被标记为废弃，很多地方用到（比如流程1.1靠这个判断连接是否已被废弃，再比如主流程4里时钟回拨时触发的直接废弃逻辑）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> ScheduledFuture&lt;?&gt; endOfLife; <span class="comment">//用于在超过连接生命周期（maxLifeTime）时废弃连接的延时任务，这里poolEntry要持有该对象，主要是因为在对象主动被关闭时（意味着不需要在超过maxLifeTime时主动失效了），需要cancel掉该任务</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> FastList openStatements; <span class="comment">//当前该连接对象上生成的所有的statement对象，用于在回收连接时主动关闭这些对象，防止存在漏关的statement</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> HikariPool hikariPool; <span class="comment">//持有pool对象</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isReadOnly; <span class="comment">//是否为只读</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isAutoCommit; <span class="comment">//是否存在事务</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面就是整个<code>PoolEntry</code>对象里所有的属性，这里再说下<em><strong>endOfLife</strong></em>对象。</p><p>它是一个利用houseKeepingExecutorService这个线程池对象做的延时任务，这个延时任务一般在创建好连接对象后maxLifeTime左右的时间触发</p><details><summary>具体来看下createEntry代码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">private PoolEntry createPoolEntry() &#123;</span><br><span class="line"></span><br><span class="line">        final PoolEntry poolEntry = newPoolEntry(); //生成实际的连接对象</span><br><span class="line"></span><br><span class="line">        final long maxLifetime = config.getMaxLifetime(); //拿到配置好的maxLifetime</span><br><span class="line">        if (maxLifetime &gt; 0) &#123; //&lt;=0的时候不启用主动过期策略</span><br><span class="line">            // 计算需要减去的随机数</span><br><span class="line">            // 源注释：variance up to 2.5% of the maxlifetime</span><br><span class="line">            final long variance = maxLifetime &gt; 10_000 ? ThreadLocalRandom.current().nextLong(maxLifetime / 40) : 0;</span><br><span class="line">            final long lifetime = maxLifetime - variance; //生成实际的延时时间</span><br><span class="line">            poolEntry.setFutureEol(houseKeepingExecutorService.schedule(</span><br><span class="line">                    () -&gt; &#123; //实际的延时任务，这里直接触发softEvictConnection，而softEvictConnection内则会标记该连接对象为废弃状态，然后尝试修改其状态为STATE_RESERVED，若成功，则触发closeConnection（对应流程1.1.2）</span><br><span class="line">                        if (softEvictConnection(poolEntry, &quot;(connection has passed maxLifetime)&quot;, false /* not owner */)) &#123;</span><br><span class="line">                            addBagItem(connectionBag.getWaitingThreadCount()); //回收完毕后，连接池内少了一个连接，就会尝试新增一个连接对象</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    lifetime, MILLISECONDS)); //给endOfLife赋值，并且提交延时任务，lifetime后触发</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return poolEntry;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //触发新增连接任务</span><br><span class="line">    public void addBagItem(final int waiting) &#123;</span><br><span class="line">        //前排提示：addConnectionQueue和addConnectionExecutor的关系和初始化参考主流程2</span><br><span class="line"></span><br><span class="line">        //当添加连接的队列里已提交的任务超过那些因为获取不到连接而发生阻塞的线程个数时，就进行提交连接新增连接的任务</span><br><span class="line">        final boolean shouldAdd = waiting - addConnectionQueue.size() &gt;= 0; // Yes, &gt;= is intentional.</span><br><span class="line">        if (shouldAdd) &#123;</span><br><span class="line">            //提交任务给addConnectionExecutor这个线程池，PoolEntryCreator是一个实现了Callable接口的类，下面将通过流程图的方式介绍该类的call方法</span><br><span class="line">            addConnectionExecutor.submit(poolEntryCreator);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></details></details><p>可以知道，HikariCP一般通过createEntry方法来新增一个连接入池，每个连接被包装成PoolEntry对象，在创建好对象时，同时会提交一个延时任务来关闭废弃该连接，这个时间就是我们配置的maxLifeTime，为了保证不在同一时间失效，HikariCP还会利用maxLifeTime减去一个随机数作为最终的延时任务延迟时间，然后在触发废弃任务时，还会触发addBagItem，进行连接添加任务（因为废弃了一个连接，需要往池子里补充一个），该任务则交给由<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里定义好的addConnectionExecutor线程池执行，那么，现在来看下这个异步添加连接对象的任务流程：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_11.png"></p><p>这个流程就是往连接池里加连接用的，跟<code>createEntry</code>结合起来说是因为这俩流程是紧密相关的，除此之外，<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B5%EF%BC%9A%E6%89%A9%E5%85%85%E8%BF%9E%E6%8E%A5%E6%B1%A0">主流程5：扩充连接池</a>也会触发该任务。</p><h3 id="主流程4：连接池缩容"><a href="#主流程4：连接池缩容" class="headerlink" title="主流程4：连接池缩容"></a>主流程4：连接池缩容</h3><p>HikariCP会按照 <strong>minIdle</strong> 定时清理闲置过久的连接，这个定时任务在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2：初始化池对象</a>时被启用，跟上面的流程一样，也是利用 <strong>houseKeepingExecutorService</strong> 这个线程池对象做该定时任务的执行器。</p><details><summary>来看下主流程2里是怎么启用该任务的</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//housekeepingPeriodMs的默认值是30s，所以定时任务的间隔为30s</span><br><span class="line">this.houseKeeperTask = houseKeepingExecutorService.scheduleWithFixedDelay(new HouseKeeper(), 100L, housekeepingPeriodMs, MILLISECONDS);</span><br></pre></td></tr></table></figure></details><p>那么本节主要来说下HouseKeeper这个类，该类实现了Runnable接口，回收逻辑主要在其run方法内，来看看run方法的逻辑流程图：</p><p><img src="/2021/04/26/Spring%E5%85%A8%E5%AE%B6%E6%A1%B6/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_12.png"></p><p>上面的流程就是HouseKeeper的run方法里具体做的事情，由于系统时间回拨会导致该定时任务回收一些连接时产生误差。<br>因此存在如下判断：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//now就是当前系统时间，previous就是上次触发该任务时的时间，housekeepingPeriodMs就是隔多久触发该任务一次</span><br><span class="line">//也就是说plusMillis(previous, housekeepingPeriodMs)表示当前时间</span><br><span class="line">//如果系统时间没被回拨，那么plusMillis(now, 128)一定是大于当前时间的，如果被系统时间被回拨</span><br><span class="line">//回拨的时间超过128ms，那么下面的判断就成立，否则永远不会成立</span><br><span class="line">if (plusMillis(now, 128) &lt; plusMillis(previous, housekeepingPeriodMs))</span><br></pre></td></tr></table></figure><p>这是hikariCP在解决系统时钟被回拨时做出的一种措施，通过流程图可以看到，它是直接把池子里所有的连接对象取出来挨个儿的标记成废弃，并且尝试把状态值修改为<code>STATE_RESERVED</code>（后面会说明这些状态，这里先不深究）。</p><p>如果系统时钟没有发生改变（绝大多数情况会命中这一块的逻辑），由图知，会把当前池内所有处于<code>闲置状态(STATE_NOT_IN_USE)</code>的连接拿出来，然后计算需要检查的范围，然后循环着修改连接的状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//拿到所有处于闲置状态的连接</span><br><span class="line">final List notInUse = connectionBag.values(STATE_NOT_IN_USE);</span><br><span class="line">//计算出需要被检查闲置时间的数量，简单来说，池内需要保证最小minIdle个连接活着，所以需要计算出超出这个范围的闲置对象进行检查</span><br><span class="line">int toRemove = notInUse.size() - config.getMinIdle();</span><br><span class="line">for (PoolEntry entry : notInUse) &#123;</span><br><span class="line">  //在检查范围内，且闲置时间超出idleTimeout，然后尝试将连接对象状态由STATE_NOT_IN_USE变为STATE_RESERVED成功</span><br><span class="line">  if (toRemove &gt; 0 &amp;&amp; elapsedMillis(entry.lastAccessed, now) &gt; idleTimeout &amp;&amp; connectionBag.reserve(entry)) &#123;</span><br><span class="line">    closeConnection(entry, &quot;(connection has passed idleTimeout)&quot;); //满足上述条件，进行连接关闭</span><br><span class="line">    toRemove--;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">fillPool(); //因为可能回收了一些连接，所以要再次触发连接池扩充流程检查下是否需要新增连接。</span><br></pre></td></tr></table></figure><p>上面的代码就是流程图里对应的没有回拨系统时间时的流程逻辑。</p><p>该流程在<code>idleTimeout大于0（默认等于0）并且minIdle小于maxPoolSize</code>的时候才会启用，默认是不启用的，若需要启用，可以按照条件来配置。</p><h3 id="主流程5：扩充连接池"><a href="#主流程5：扩充连接池" class="headerlink" title="主流程5：扩充连接池"></a>主流程5：扩充连接池</h3><p>这个流程主要依附<code>HikariPool</code>里的<code>fillPool</code>方法，这个方法已经在上面很多流程里出现过了，它的作用就是<strong>在触发连接废弃、连接池连接不够用时，发起扩充连接数的操作</strong>。</p><details><summary>下面看下源码（为了使代码结构更加清晰，对源码做了细微改动）</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// PoolEntryCreator关于call方法的实现流程在主流程3里已经看过了，但是这里却有俩PoolEntryCreator对象，</span><br><span class="line">// 这是个较细节的地方，用于打日志用，不再说这部分，为了便于理解，只需要知道这俩对象执行的是同一块call方法即可</span><br><span class="line">private final PoolEntryCreator poolEntryCreator = new PoolEntryCreator(null);</span><br><span class="line">private final PoolEntryCreator postFillPoolEntryCreator = new PoolEntryCreator(&quot;After adding &quot;);</span><br><span class="line"></span><br><span class="line">private synchronized void fillPool() &#123;</span><br><span class="line">  // 这个判断就是根据当前池子里相关数据，推算出需要扩充的连接数，</span><br><span class="line">  // 判断方式就是利用最大连接数跟当前连接总数的差值，与最小连接数与当前池内闲置的连接数的差值，取其最小的那一个得到</span><br><span class="line">  int needAdd = Math.min(maxPoolSize - connectionBag.size(),</span><br><span class="line">  minIdle - connectionBag.getCount(STATE_NOT_IN_USE));</span><br><span class="line"></span><br><span class="line">  //减去当前排队的任务，就是最终需要新增的连接数</span><br><span class="line">  final int connectionsToAdd = needAdd - addConnectionQueue.size();</span><br><span class="line">  for (int i = 0; i &lt; connectionsToAdd; i++) &#123;</span><br><span class="line">    //一般循环的最后一次会命中postFillPoolEntryCreator任务，其实就是在最后一次会打印一次日志而已（可以忽略该干扰逻辑）</span><br><span class="line">    addConnectionExecutor.submit((i &lt; connectionsToAdd - 1) ? poolEntryCreator : postFillPoolEntryCreator);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>最终这个新增连接的任务也是交由<code>addConnectionExecutor线程池</code>来处理的，而任务的主题也是<code>PoolEntryCreator</code>，这个流程可以参考<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B3%EF%BC%9A%E7%94%9F%E6%88%90%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1">主流程3：生成连接对象</a>.</p><p>然后needAdd的推算：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Math.min(最大连接数 - 池内当前连接总数, 最小连接数 - 池内闲置的连接数)</span><br></pre></td></tr></table></figure><p>根据这个方式判断，可以保证池内的连接数永远不会超过maxPoolSize，也永远不会低于minIdle。在连接吃紧的时候，可以保证每次触发都以minIdle的数量扩容。</p><p><code>因此如果在maxPoolSize跟minIdle配置的值一样的话，在池内连接吃紧的时候，就不会发生任何扩容了。</code></p><h3 id="主流程6：连接回收"><a href="#主流程6：连接回收" class="headerlink" title="主流程6：连接回收"></a>主流程6：连接回收</h3><p>最开始说过，最终真实的物理连接对象会被包装成PoolEntry对象，存放进ConcurrentBag，然后获取时，PoolEntry对象又会被再次包装成ProxyConnection对象暴露给使用方的，那么触发连接回收，实际上就是触发ProxyConnection里的close方法：</p><details><summary>查看源码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public final void close() throws SQLException &#123;</span><br><span class="line">  // 原注释：Closing statements can cause connection eviction, so this must run before the conditional below</span><br><span class="line">  closeStatements(); //此连接对象在业务方使用过程中产生的所有statement对象，进行统一close，防止漏close的情况</span><br><span class="line">  if (delegate != ClosedConnection.CLOSED_CONNECTION) &#123;</span><br><span class="line">    leakTask.cancel(); //取消连接泄漏检查任务，参考流程2.2</span><br><span class="line">    try &#123;</span><br><span class="line">      if (isCommitStateDirty &amp;&amp; !isAutoCommit) &#123; //在存在执行语句后并且还打开了事务，调用close时需要主动回滚事务</span><br><span class="line">        delegate.rollback(); //回滚</span><br><span class="line">        lastAccess = currentTime(); //刷新&quot;最后一次使用时间&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">      delegate = ClosedConnection.CLOSED_CONNECTION;</span><br><span class="line">      poolEntry.recycle(lastAccess); //触发回收</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>它最终会调用PoolEntry的recycle方法进行回收，除此之外，连接对象的最后一次使用时间也是在这个时候刷新的，该时间是个很重要的属性，可以用来判断一个连接对象的闲置时间.</p><details><summary>来看下PoolEntry的recycle方法</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void recycle(final long lastAccessed) &#123;</span><br><span class="line">  if (connection != null) &#123;</span><br><span class="line">    this.lastAccessed = lastAccessed; //刷新最后使用时间</span><br><span class="line">    hikariPool.recycle(this); //触发HikariPool的回收方法，把自己传过去</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>之前有说过，每个PoolEntry对象都持有HikariPool的对象，方便触发连接池的一些操作，由上述代码可以看到，最终还是会触发HikariPool里的recycle方法：</p><details><summary>再来看下HikariPool的recycle方法</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void recycle(final PoolEntry poolEntry) &#123;</span><br><span class="line">  metricsTracker.recordConnectionUsage(poolEntry); //监控指标相关，忽略</span><br><span class="line">  connectionBag.requite(poolEntry); //最终触发connectionBag的requite方法归还连接，该流程参考ConnectionBag主流程里的requite方法部分</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h3 id="ConcurrentBag主流程"><a href="#ConcurrentBag主流程" class="headerlink" title="ConcurrentBag主流程"></a>ConcurrentBag主流程</h3><p>当前主流数据库连接池实现方式，大都用两个阻塞队列来实现。一个用于保存空闲数据库连接的队列 idle，另一个用于保存忙碌数据库连接的队列 busy；获取连接时将空闲的数据库连接从 idle 队列移动到 busy 队列，而关闭连接时将数据库连接从 busy 移动到 idle。这种方案将并发问题委托给了阻塞队列，实现简单，但是性能并不是很理想。因为 Java SDK 中的阻塞队列是用锁实现的，而高并发场景下锁的争用对性能影响很大。</p><p>HiKariCP 并没有使用 Java SDK 中的阻塞队列，而是自己实现了一个叫做 ConcurrentBag 的并发容器，在连接池（多线程数据交互）的实现上具有比LinkedBlockingQueue和LinkedTransferQueue更优越的性能。</p><p>ConcurrentBag 中的关键属性</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 存放共享元素，用于存储所有的数据库连接</span><br><span class="line">private final CopyOnWriteArrayList&lt;T&gt; sharedList;</span><br><span class="line">// 在 ThreadLocal 缓存线程本地的数据库连接，避免线程争用</span><br><span class="line">private final ThreadLocal&lt;List&lt;Object&gt;&gt; threadList;</span><br><span class="line">// 等待数据库连接的线程数</span><br><span class="line">private final AtomicInteger waiters;</span><br><span class="line">// 接力队列，用来分配数据库连接</span><br><span class="line">private final SynchronousQueue&lt;T&gt; handoffQueue;</span><br></pre></td></tr></table></figure><p>这个类用来存放最终的PoolEntry类型的连接对象，提供了基本的增删查的功能，被HikariPool持有，上面那么多的操作，几乎都是在HikariPool中完成的，HikariPool用来管理实际的连接生产动作和回收动作，实际操作的却是ConcurrentBag类，梳理下上面所有流程的触发点：</p><ul><li>流程1.1：通过HikariPool获取连接时，通过调用<strong>ConcurrentBag.borrow</strong>拿到一个连接对象。</li><li>流程1.1.2：触发关闭连接时，会通过<strong>ConcurrentBag.remove</strong>移除连接对象，由前面的流程可知关闭连接触发点为：连接超过最大生命周期maxLifeTime主动废弃、健康检查不通过主动废弃、连接池缩容。</li><li>主流程2：初始化HikariPool时初始化ConcurrentBag（构造方法），预热时通过createEntry拿到连接对象，调用<strong>ConcurrentBag.add</strong>添加连接到ConcurrentBag。</li><li>主流程3：通过异步添加连接时，通过调用<strong>ConcurrentBag.add</strong>添加连接到ConcurrentBag，由前面的流程可知添加连接触发点为：连接超过最大生命周期maxLifeTime主动废弃连接后、连接池扩容。</li><li>主流程4：连接池缩容任务，通过调用<strong>ConcurrentBag.values</strong>筛选出需要的做操作的连接对象，然后再通过<strong>ConcurrentBag.reserve</strong>完成对连接对象状态的修改，然后会通过流程1.1.2触发关闭和移除连接操作。</li><li>主流程6：通过<strong>ConcurrentBag.requite</strong>归还一个连接。</li></ul><p>通过触发点整理，可以知道该结构里的主要方法，就是上面触发点里整理的部分。</p><details><summary>具体看下该类的基本定义和主要方法</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcurrentBag</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">IConcurrentBagEntry</span>&gt; <span class="keyword">implements</span> <span class="title">AutoCloseable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CopyOnWriteArrayList&lt;T&gt; sharedList; <span class="comment">//最终存放PoolEntry对象的地方，它是一个CopyOnWriteArrayList</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> weakThreadLocals; <span class="comment">//默认false，为true时可以让一个连接对象在下方threadList里的list内处于弱引用状态，防止内存泄漏（参见备注1）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ThreadLocal&lt;List&lt;Object&gt;&gt; threadList; <span class="comment">//线程级的缓存，从sharedList拿到的连接对象，会被缓存进当前线程内，borrow时会先从缓存中拿，从而达到池内无锁实现</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IBagStateListener listener; <span class="comment">//内部接口，HikariPool实现了该接口，主要用于ConcurrentBag主动通知HikariPool触发添加连接对象的异步操作（也就是主流程3里的addConnectionExecutor所触发的流程）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger waiters; <span class="comment">//当前因为获取不到连接而发生阻塞的业务线程数，这个在之前的流程里也出现过，比如主流程3里addBagItem就会根据该指标进行判断是否需要新增连接</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> closed; <span class="comment">//标记当前ConcurrentBag是否已被关闭</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SynchronousQueue&lt;T&gt; handoffQueue; <span class="comment">//这是个即产即销的队列，用于在连接不够用时，及时获取到add方法里新创建的连接对象，详情可以参考下面borrow和add的代码</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//内部接口，PoolEntry类实现了该接口</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IConcurrentBagEntry</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//连接对象的状态，前面的流程很多地方都已经涉及到了，比如主流程4的缩容</span></span><br><span class="line">        <span class="keyword">int</span> STATE_NOT_IN_USE = <span class="number">0</span>; <span class="comment">//闲置</span></span><br><span class="line">        <span class="keyword">int</span> STATE_IN_USE = <span class="number">1</span>; <span class="comment">//使用中</span></span><br><span class="line">        <span class="keyword">int</span> STATE_REMOVED = -<span class="number">1</span>; <span class="comment">//已废弃</span></span><br><span class="line">        <span class="keyword">int</span> STATE_RESERVED = -<span class="number">2</span>; <span class="comment">//标记保留，介于闲置和废弃之间的中间状态，主要由缩容那里触发修改</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">int</span> expectState, <span class="keyword">int</span> newState)</span></span>; <span class="comment">//尝试利用cas修改连接对象的状态值</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setState</span><span class="params">(<span class="keyword">int</span> newState)</span></span>; <span class="comment">//设置状态值</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">int</span> <span class="title">getState</span><span class="params">()</span></span>; <span class="comment">//获取状态值</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//参考上面listener属性的解释</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IBagStateListener</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">addBagItem</span><span class="params">(<span class="keyword">int</span> waiting)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">borrow</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">final</span> TimeUnit timeUnit)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//回收连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requite</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//添加连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//移除连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//根据连接状态值获取当前池子内所有符合条件的连接集合</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List <span class="title">values</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取当前池子内所有的连接</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List <span class="title">values</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//利用cas把传入的连接对象的state从 STATE_NOT_IN_USE 变为 STATE_RESERVED</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">reserve</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取当前池子内符合传入状态值的连接数量</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>ConcurrentBag 实现采用了queue-stealing的机制获取元素：首先尝试从ThreadLocal中获取属于当前线程的元素来避免锁竞争，如果没有可用元素则再次从共享的CopyOnWriteArrayList中获取。此外，ThreadLocal和CopyOnWriteArrayList在ConcurrentBag中都是成员变量，线程间不共享，避免了伪共享(false sharing)的发生。同时因为线程本地存储中的连接是可以被其他线程窃取的，在共享队列中获取空闲连接，所以需要用 CAS 方法防止重复分配。</p><details><summary>ConcurrentBag具体方法详细阅读</summary><h4 id="borrow"><a href="#borrow" class="headerlink" title="borrow"></a>borrow</h4><p>这个方法用来获取一个可用的连接对象，触发点为流程1.1，HikariPool就是利用该方法获取连接的。</p><details><summary>下面来看下该方法做了什么</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">public T borrow(long timeout, final TimeUnit timeUnit) throws InterruptedException &#123;</span><br><span class="line">    // 源注释：Try the thread-local list first</span><br><span class="line">    final List&lt;Object&gt; list = threadList.get(); //首先从当前线程的缓存里拿到之前被缓存进来的连接对象集合</span><br><span class="line">    for (int i = list.size() - 1; i &gt;= 0; i--) &#123;</span><br><span class="line">        final Object entry = list.remove(i); //先移除，回收方法那里会再次add进来</span><br><span class="line">        final T bagEntry = weakThreadLocals ? ((WeakReference&lt;T&gt;) entry).get() : (T) entry; //默认不启用弱引用</span><br><span class="line">        // 获取到对象后，通过cas尝试把其状态从STATE_NOT_IN_USE 变为 STATE_IN_USE，注意，这里如果其他线程也在使用这个连接对象，</span><br><span class="line">        // 并且成功修改属性，那么当前线程的cas会失败，那么就会继续循环尝试获取下一个连接对象</span><br><span class="line">        if (bagEntry != null &amp;&amp; bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">            return bagEntry; //cas设置成功后，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 源注释：Otherwise, scan the shared list ... then poll the handoff queue</span><br><span class="line">    final int waiting = waiters.incrementAndGet(); //如果缓存内找不到一个可用的连接对象，则认为需要“回源”，waiters+1</span><br><span class="line">    try &#123;</span><br><span class="line">        for (T bagEntry : sharedList) &#123;</span><br><span class="line">            //循环sharedList，尝试把连接状态值从STATE_NOT_IN_USE 变为 STATE_IN_USE</span><br><span class="line">            if (bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">                // 源注释：If we may have stolen another waiter&#x27;s connection, request another bag add.</span><br><span class="line">                if (waiting &gt; 1) &#123; //阻塞线程数大于1时，需要触发HikariPool的addBagItem方法来进行添加连接入池，这个方法的实现参考主流程3</span><br><span class="line">                    listener.addBagItem(waiting - 1);</span><br><span class="line">                &#125;</span><br><span class="line">                return bagEntry; //cas设置成功，跟上面的逻辑一样，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //走到这里说明不光线程缓存里的列表竞争不到连接对象，连sharedList里也找不到可用的连接，这时则认为需要通知HikariPool，该触发添加连接操作了</span><br><span class="line">        listener.addBagItem(waiting);</span><br><span class="line"></span><br><span class="line">        timeout = timeUnit.toNanos(timeout); //这时候开始利用timeout控制获取时间</span><br><span class="line">        do &#123;</span><br><span class="line">            final long start = currentTime();</span><br><span class="line">            //尝试从handoffQueue队列里获取最新被加进来的连接对象（一般新入的连接对象除了加进sharedList之外，还会被offer进该队列）</span><br><span class="line">            final T bagEntry = handoffQueue.poll(timeout, NANOSECONDS);</span><br><span class="line">            //如果超出指定时间后仍然没有获取到可用的连接对象，或者获取到对象后通过cas设置成功，这两种情况都不需要重试，直接返回对象</span><br><span class="line">            if (bagEntry == null || bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">                return bagEntry;</span><br><span class="line">            &#125;</span><br><span class="line">            //走到这里说明从队列内获取到了连接对象，但是cas设置失败，说明又该对象又被其他线程率先拿去用了，若时间还够，则再次尝试获取</span><br><span class="line">            timeout -= elapsedNanos(start); //timeout减去消耗的时间，表示下次循环可用时间</span><br><span class="line">        &#125; while (timeout &gt; 10_000); //剩余时间大于10s时才继续进行，一般情况下，这个循环只会走一次，因为timeout很少会配的比10s还大</span><br><span class="line"></span><br><span class="line">        return null; //超时，仍然返回null</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        waiters.decrementAndGet(); //这一步出去后，HikariPool收到borrow的结果，算是走出阻塞，所以waiters-1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>仔细看下注释，该过程大致分成三个主要步骤：</p><ol><li>从线程缓存获取连接</li><li>获取不到再从sharedList里获取</li><li>都获取不到则触发添加连接逻辑，并尝试从队列里获取新生成的连接对象</li></ol><h4 id="add"><a href="#add" class="headerlink" title="add"></a>add</h4><p>这个流程会添加一个连接对象进入bag，通常由<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B3%EF%BC%9A%E7%94%9F%E6%88%90%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1">主流程3：生成连接对象</a>里的addBagItem方法通过addConnectionExecutor异步任务触发添加操作，该方法主流程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public void add(final T bagEntry) &#123;</span><br><span class="line"></span><br><span class="line">    sharedList.add(bagEntry); //直接加到sharedList里去</span><br><span class="line"></span><br><span class="line">    // 源注释：spin until a thread takes it or none are waiting</span><br><span class="line">    // 参考borrow流程，当存在线程等待获取可用连接，并且当前新入的这个连接状态仍然是闲置状态，且队列里无消费者等待获取时，发起一次线程调度</span><br><span class="line">    while (waiters.get() &gt; 0 &amp;&amp; bagEntry.getState() == STATE_NOT_IN_USE &amp;&amp; !handoffQueue.offer(bagEntry)) &#123; //注意这里会offer一个连接对象入队列</span><br><span class="line">        yield();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结合borrow来理解的话，这里在存在等待线程时会添加一个连接对象入队列，可以让borrow里发生等待的地方更容易poll到这个连接对象。</p><h4 id="requite"><a href="#requite" class="headerlink" title="requite"></a>requite</h4><p>这个流程会回收一个连接，该方法的触发点在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B6%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%9B%9E%E6%94%B6">主流程6：连接回收</a></p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public void requite(final T bagEntry) &#123;</span><br><span class="line">    bagEntry.setState(STATE_NOT_IN_USE); //回收意味着使用完毕，更改state为STATE_NOT_IN_USE状态</span><br><span class="line"></span><br><span class="line">    for (int i = 0; waiters.get() &gt; 0; i++) &#123; //如果存在等待线程的话，尝试传给队列，让borrow获取</span><br><span class="line">        if (bagEntry.getState() != STATE_NOT_IN_USE || handoffQueue.offer(bagEntry)) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        else if ((i &amp; 0xff) == 0xff) &#123;</span><br><span class="line">            parkNanos(MICROSECONDS.toNanos(10));</span><br><span class="line">        &#125;</span><br><span class="line">        else &#123;</span><br><span class="line">            yield();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    final List&lt;Object&gt; threadLocalList = threadList.get();</span><br><span class="line">    if (threadLocalList.size() &lt; 50) &#123; //线程内连接集合的缓存最多50个，这里回收连接时会再次加进当前线程的缓存里，方便下次borrow获取</span><br><span class="line">        threadLocalList.add(weakThreadLocals ? new WeakReference&lt;&gt;(bagEntry) : bagEntry); //默认不启用弱引用，若启用的话，则缓存集合里的连接对象没有内存泄露的风险</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h4><p>这个负责从池子里移除一个连接对象，触发点在流程1.1.2。</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public boolean remove(final T bagEntry) &#123;</span><br><span class="line">    // 下面两个cas操作，都是从其他状态变为移除状态，任意一个成功，都不会走到下面的warn log</span><br><span class="line">    if (!bagEntry.compareAndSet(STATE_IN_USE, STATE_REMOVED) &amp;&amp; !bagEntry.compareAndSet(STATE_RESERVED, STATE_REMOVED) &amp;&amp; !closed) &#123;</span><br><span class="line">        LOGGER.warn(&quot;Attempt to remove an object from the bag that was not borrowed or reserved: &#123;&#125;&quot;, bagEntry);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 直接从sharedList移除掉</span><br><span class="line">    final boolean removed = sharedList.remove(bagEntry);</span><br><span class="line">    if (!removed &amp;&amp; !closed) &#123;</span><br><span class="line">        LOGGER.warn(&quot;Attempt to remove an object from the bag that does not exist: &#123;&#125;&quot;, bagEntry);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return removed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>移除时仅仅移除了sharedList里的对象，各个线程内缓存的那一份集合里对应的对象并没有被移除，这个时候会不会存在该连接再次从缓存里拿到呢？</p><p>会的，但是不会返回出去，而是直接remove掉了，仔细看borrow的代码发现状态不是闲置状态的时候，取出来时就会remove掉，然后也拿不出去，自然也不会触发回收方法。</p><h4 id="values"><a href="#values" class="headerlink" title="values"></a>values</h4><p>该方法存在重载方法，用于返回当前池子内连接对象的集合，触发点在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B4%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%BC%A9%E5%AE%B9">主流程4：连接池缩容</a>，代码如下：</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public List values(final int state) &#123;</span><br><span class="line">    //过滤出来符合状态值的对象集合逆序后返回出去</span><br><span class="line">    final List list = sharedList.stream().filter(e -&gt; e.getState() == state).collect(Collectors.toList());</span><br><span class="line">    Collections.reverse(list);</span><br><span class="line">    return list;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public List values() &#123;</span><br><span class="line">    //返回全部连接对象（注意下方clone为浅拷贝）</span><br><span class="line">    return (List) sharedList.clone();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="reserve"><a href="#reserve" class="headerlink" title="reserve"></a>reserve</h4><p>该方法单纯将连接对象的状态值由STATE_NOT_IN_USE修改为STATE_RESERVED，触发点仍然是主流程4，缩容时使用：</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public boolean reserve(final T bagEntry)&#123;</span><br><span class="line">   return bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_RESERVED);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="getCount"><a href="#getCount" class="headerlink" title="getCount"></a>getCount</h4><p>该方法用于返回池内符合某个状态值的连接的总数量，触发点为主流程5，扩充连接池时用于获取闲置连接总数。</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public int getCount(final int state)&#123;</span><br><span class="line">   int count = 0;</span><br><span class="line">   for (IConcurrentBagEntry e : sharedList) &#123;</span><br><span class="line">      if (e.getState() == state) &#123;</span><br><span class="line">         count++;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   return count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details></details><h2 id="基于FastList的性能优化"><a href="#基于FastList的性能优化" class="headerlink" title="基于FastList的性能优化"></a>基于FastList的性能优化</h2><p>首先我们来看一下执行数据库操作规范化的操作步骤：</p><ol><li>通过数据源获取一个数据库连接；</li><li>创建 Statement；</li><li>执行 SQL；</li><li>通过 ResultSet 获取 SQL 执行结果；</li><li>释放 ResultSet；</li><li>释放 Statement；</li><li>释放数据库连接。</li></ol><p>当前所有数据库连接池都是严格地根据这个顺序来进行数据库操作的，为了防止最后的释放操作，各类数据库连接池都会把创建的 Statement 保存在数组 ArrayList 里，来保证当关闭连接的时候，可以依次将数组中的所有 Statement 关闭。</p><p>HiKariCP 在处理这一步骤中，认为 ArrayList 的某些方法操作存在优化空间，因此对List接口的精简实现，针对List接口中核心的几个方法进行优化，其他部分与ArrayList基本一致。</p><ul><li>首先是get()方法<ul><li>ArrayList每次调用get()方法时都会进行rangeCheck检查索引是否越界，FastList的实现中去除了这一检查，是因为数据库连接池满足索引的合法性，能保证不会越界，此时rangeCheck就属于无效的计算开销，所以不用每次都进行越界检查。省去频繁的无效操作，可以明显地减少性能消耗。</li></ul></li><li>其次是remove方法<ul><li>当通过 conn.createStatement() 创建一个 Statement 时，需要调用 ArrayList 的 add() 方法加入到 ArrayList 中，这个是没有问题的；但是当通过 stmt.close() 关闭 Statement 的时候，需要调用 ArrayList 的 remove() 方法来将其从 ArrayList 中删除，而ArrayList的remove(Object)方法是从头开始遍历数组，而FastList是从数组的尾部开始遍历，因此更为高效。</li><li>相比于ArrayList的 remove()代码， FastList 去除了检查范围 和 从头到尾遍历检查元素的步骤，其性能更快。</li></ul></li></ul><p>总体而言，FastList 的优化点还是很简单的。相比ArrayList仅仅是去掉了rage检查，扩容优化等细节处，删除时数组从后往前遍历查找元素等微小的调整，从而追求性能极致。</p><p>当然FastList 对于 ArrayList 的优化，我们不能说ArrayList不好。所谓定位不同、追求不同，ArrayList作为通用容器，更追求安全、稳定，操作前rangeCheck检查，对非法请求直接抛出异常，更符合 fail-fast(快速失败)机制，而FastList追求的是性能极致。</p><h2 id="通过字节码修改类库Javassist完成字节码精简"><a href="#通过字节码修改类库Javassist完成字节码精简" class="headerlink" title="通过字节码修改类库Javassist完成字节码精简"></a>通过字节码修改类库Javassist完成字节码精简</h2><p>待补充，具体实现参考文章<a href="https://mp.weixin.qq.com/s?__biz=MzUzNTY4NTYxMA==&mid=2247483812&idx=1&sn=0fa3e648f853b840ed8a1c2f19468d6d&chksm=fa80f121cdf778379c70219665ef9c36d66dd0d6c6547add55a8fd920d523c6738835af308f7&scene=21#wechat_redirect">HikariCP源码分析之字节码修改类库Javassist委托实现动态代理</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是数据库连接池，为什么需要数据库连接池&quot;&gt;&lt;a href=&quot;#什么是数据库连接池，为什么需要数据库连接池&quot; class=&quot;headerlink&quot; title=&quot;什么是数据库连接池，为什么需要数据库连接池&quot;&gt;&lt;/a&gt;什么是数据库连接池，为什么需要数据库连接池&lt;/</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Spring生态" scheme="http://example.com/tags/Spring%E7%94%9F%E6%80%81/"/>
    
    <category term="池化设计" scheme="http://example.com/tags/%E6%B1%A0%E5%8C%96%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="数据库连接池" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/"/>
    
  </entry>
  
  <entry>
    <title>分布式协调组件之Zookeeper基础概念入门</title>
    <link href="http://example.com/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/"/>
    <id>http://example.com/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/</id>
    <published>2021-02-04T08:22:59.000Z</published>
    <updated>2021-08-12T03:37:01.942Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是分布式协调组件"><a href="#什么是分布式协调组件" class="headerlink" title="什么是分布式协调组件"></a>什么是分布式协调组件</h2><p>讲Zookeeper之前，首先我们了解下什么是”分布式协调组件“。</p><p>所谓的“分布式协调组件”，就是我们在分布式应用开发中，为了协调分布式系统中各个机器协同运行而使用到的“公共组件”。比如Zookeeper、Redis等，都可以看作是“分布式协调组件”。</p><p>这里很容易可以看到，分布式环境中的“分布式协调组件”，和单机环境中的“多线程协调组件”（比如Java多线程并发工具包），其实是类似的东西。</p><p>不同的是: </p><ul><li>多线程协调组件是在同一台机器的内存中；而分布式协调组件的调用则是需要通过网络通信的，“网络不可达”的不确定性，就加大了使用分布式协调组件的使用难度</li><li>可用性：多线程协调组件是单机应用中的一部分，完全不需要担心某个并发变量会“挂掉”；而分布式协调组件一般是独立运行的，如何保障分布式协调组件的高可用，是一个很复杂的命题。比如一般会通过集群保障高可用，而集群里的机器之间如何保障数据一致性，则又是一个更加复杂的命题</li><li>分布式协调组件还需要考虑性能问题、可扩展性等</li></ul><h3 id="常用的分布式协调组件"><a href="#常用的分布式协调组件" class="headerlink" title="常用的分布式协调组件"></a>常用的分布式协调组件</h3><p><strong>全局功能数据存储/有功能的组件</strong>：</p><ul><li>K-V类：redis、memcache</li><li>Zookeeper</li><li>消息队列</li><li>配置中心：Spring Cloud Config等</li></ul><p><strong>持久数据存储</strong>：</p><ul><li>MySQL</li><li>MongoDB</li></ul><h3 id="分布式协调组件应用场景"><a href="#分布式协调组件应用场景" class="headerlink" title="分布式协调组件应用场景"></a>分布式协调组件应用场景</h3><ul><li>分布式session</li><li>分布式计数器</li><li>分布式锁</li><li>分布式队列：<ul><li>先入先出队列</li><li>要等所有队列元素聚集之后才能统一安排执行的Barrier模型队列</li></ul></li><li>分布式配置</li><li>分布式协调 / 通知</li><li>数据发布、订阅</li><li>软负载均衡：域名 -&gt; IP和端口号配置</li><li>命名服务：在分布式环境中，上层应用需要一个全局唯一的名字，类似于数据库中的主键</li><li>集群管理：<ul><li>集群监控（进群运行时状态收集）</li><li>集群控制（对集群进行操作和控制）</li></ul></li><li>Master选举</li></ul><h2 id="分布式协调组件Zookeeper概览"><a href="#分布式协调组件Zookeeper概览" class="headerlink" title="分布式协调组件Zookeeper概览"></a>分布式协调组件Zookeeper概览</h2><h3 id="ZooKeeper-实现了什么"><a href="#ZooKeeper-实现了什么" class="headerlink" title="ZooKeeper 实现了什么"></a>ZooKeeper 实现了什么</h3><p>ZooKeeper 是一个开源的分布式协调服务，它的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。</p><p><strong>原语</strong>： 操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。具有不可分割性·即原语的执行必须是连续的，在执行过程中不允许被中断。</p><p>ZooKeeper为我们提供了高可用、高性能、稳定的分布式数据一致性解决方案，通常被用于实现诸如<strong>数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列</strong>等功能。</p><p>另外，ZooKeeper 将<strong>数据保存在内存</strong>中，性能是非常棒的。</p><ul><li>在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。</li></ul><p><code>“读”多于“写”是协调服务的典型场景</code></p><h3 id="ZooKeeper-特点"><a href="#ZooKeeper-特点" class="headerlink" title="ZooKeeper 特点"></a>ZooKeeper 特点</h3><ul><li><p><strong>顺序一致性</strong>： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。</p></li><li><p><strong>原子性</strong>： 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。</p></li><li><p><strong>单一系统映像</strong>： 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。</p></li><li><p><strong>可靠性</strong>： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。</p></li></ul><h3 id="ZooKeeper-典型应用场景"><a href="#ZooKeeper-典型应用场景" class="headerlink" title="ZooKeeper 典型应用场景"></a>ZooKeeper 典型应用场景</h3><ul><li><p><strong>分布式锁</strong>： 通过创建唯一节点获得分布式锁，当获得锁的一方执行完相关代码或者是挂掉之后就释放锁。</p></li><li><p><strong>命名服务</strong>： 可以通过 ZooKeeper 的顺序节点生成全局唯一 ID</p></li><li><p><strong>数据发布/订阅</strong>：通过 Watcher 机制可以很方便地实现数据发布/订阅。当你将数据发布到 ZooKeeper 被监听的节点上，其他机器可通过监听 ZooKeeper 上节点的变化来实现配置的动态更新。</p></li></ul><h2 id="Zookeeper重要概念"><a href="#Zookeeper重要概念" class="headerlink" title="Zookeeper重要概念"></a>Zookeeper重要概念</h2><h3 id="Data-model（数据模型）"><a href="#Data-model（数据模型）" class="headerlink" title="Data model（数据模型）"></a>Data model（数据模型）</h3><p>ZooKeeper 数据模型采用层次化的多叉树形结构，每个节点上都可以存储数据，这些数据可以是数字、字符串或者是二级制序列。并且。每个节点还可以拥有 N 个子节点，最上层是根节点以“/”来代表。每个数据节点在 ZooKeeper 中被称为 znode，它是 ZooKeeper 中数据的最小单元。并且，每个 znode 都一个唯一的路径标识。</p><p>强调一句：ZooKeeper 主要是用来协调服务的，而不是用来存储业务数据的，所以<strong>不要放比较大的数据在znode上</strong>，ZooKeeper 给出的上限是每个结点的数据大小最大是 1M。</p><p>ZooKeeper 节点路径标识方式和 Unix 文件系统路径非常相似，都是由一系列使用斜杠”/“进行分割的路径表示，开发员可以向这个节点中写人数据，也可以在节点下面创建子节点。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/b26842dad2872eb0498fdf2bb1471cee.jpeg#pic_center"></p><h3 id="znode（数据节点）"><a href="#znode（数据节点）" class="headerlink" title="znode（数据节点）"></a>znode（数据节点）</h3><h4 id="znode节点分类"><a href="#znode节点分类" class="headerlink" title="znode节点分类"></a>znode节点分类</h4><ul><li><p>持久（PERSISTENT）节点： 一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。</p></li><li><p>临时（EPHEMERAL）节点： 临时节点的生命周期是与客户端会话（session）绑定的，会话消失则节点消失。并且，临时节点只能做叶子节点，不能创建子节点。</p></li><li><p>持久顺序（PERSISTENT_SEQUENTIAL）节点：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如/node1/app0000000001 、/node1/app0000000002 。</p></li><li><p>临时顺序（EPHEMERAL_SEQUENTIAL）节点：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。</p></li></ul><h4 id="znode-数据结构"><a href="#znode-数据结构" class="headerlink" title="znode 数据结构"></a>znode 数据结构</h4><p>每个 znode 由 2 部分组成:</p><ul><li>stat ：状态信息</li><li>data ： 节点存放的数据的具体内容</li></ul><p>Stat 类中包含了一个数据节点的所有状态信息的字段，包括事务 ID-cZxid、节点创建时间-ctime 和子节点个数-numChildren 等等，详细信息参考下表。</p><table><thead><tr><th>znode 状态信息</th><th>解释</th></tr></thead><tbody><tr><td>cZxid</td><td>create ZXID，即该数据节点被创建时的事务 id</td></tr><tr><td>ctime</td><td>create time，即该节点的创建时间</td></tr><tr><td>mZxid</td><td>modified ZXID，即该节点最终一次更新时的事务 id</td></tr><tr><td>mtime</td><td>modified time，即该节点最后一次的更新时间</td></tr><tr><td>pZxid</td><td>该节点的子节点列表最后一次修改时的事务 id，只有子节点列表变更才会更新 pZxid，子节点内容变更不会更新</td></tr><tr><td>cversion</td><td>子节点版本号，当前节点的子节点每次变化时值增加 1</td></tr><tr><td>dataVersion</td><td>数据节点内容版本号，节点创建时为 0，每更新一次节点内容(不管内容有无变化)该版本号的值增加 1</td></tr><tr><td>aclVersion</td><td>节点的 ACL 版本号，表示该节点 ACL 信息变更次数</td></tr><tr><td>ephemeralOwner</td><td>创建该临时节点的会话的 sessionId；如果当前节点为持久节点，则 ephemeralOwner=0</td></tr><tr><td>dataLength</td><td>数据节点内容长度</td></tr><tr><td>numChildren</td><td>当前节点的子节点个数</td></tr></tbody></table><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>前面我们已经提到，对应于每个 znode，ZooKeeper 都会为其维护一个叫作 <strong>Stat</strong>的数据结构，Stat 中记录了这个 znode 的三个相关的版本：</p><ul><li><p>  <strong>dataVersion</strong> ：当前 znode 节点的版本号</p></li><li><p>  <strong>cversion</strong> ： 当前 znode 子节点的版本</p></li><li><p>  <strong>aclVersion</strong> ： 当前 znode 的 ACL 的版本。</p></li></ul><h3 id="ACL（权限控制）"><a href="#ACL（权限控制）" class="headerlink" title="ACL（权限控制）"></a><strong>ACL（权限控制）</strong></h3><p>ZooKeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。</p><p>对于 znode 操作的权限，ZooKeeper 提供了以下 5 种：</p><ul><li><p>  <strong>CREATE</strong> : 能创建子节点</p></li><li><p>  <strong>READ</strong> ：能获取节点数据和列出其子节点</p></li><li><p>  <strong>WRITE</strong> : 能设置/更新节点数据</p></li><li><p>  <strong>DELETE</strong> : 能删除子节点</p></li><li><p>  <strong>ADMIN</strong> : 能设置节点 ACL 的权限</p></li></ul><p>其中尤其需要注意的是，<strong>CREATE</strong>和<strong>DELETE</strong>这两种权限都是针对<strong>子节点</strong>的权限控制。</p><p>对于身份认证，提供了以下几种方式：</p><ul><li><p>  <strong>world</strong> ： 默认方式，所有用户都可无条件访问。</p></li><li><p>  <strong>auth</strong>: 不使用任何 id，代表任何已认证的用户。</p></li><li><p>  <strong>digest</strong>: 用户名:密码认证方式： <em>username:password</em> 。</p></li><li><p>  <strong>ip</strong>: 对指定 ip 进行限制。</p></li></ul><h3 id="Watcher"><a href="#Watcher" class="headerlink" title="Watcher"></a><strong>Watcher</strong></h3><p>Watcher（事件监听器），是 ZooKeeper 中的一个很重要的特性。ZooKeeper允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper实现分布式协调服务的重要特性。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/be40875cd45d92900b44c4d39dedcb57.jpeg"></p><p><em>用到 ZooKeeper 基本离不开 Watcher（事件监听器）机制。</em></p><h3 id="会话（Session）"><a href="#会话（Session）" class="headerlink" title="会话（Session）"></a><strong>会话（Session）</strong></h3><p>Session 可以看作是 ZooKeeper 服务器与客户端的之间的一个 TCP 长连接，通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的 Watcher 事件通知。</p><p>Session 有一个属性叫做：sessionTimeout ，sessionTimeout代表会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。</p><p>另外，在为客户端创建会话之前，服务端首先会为每个客户端都分配一个 sessionID。由于 sessionID是 ZooKeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。</p><h2 id="ZooKeeper-集群"><a href="#ZooKeeper-集群" class="headerlink" title="ZooKeeper 集群"></a>ZooKeeper 集群</h2><p>为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的，通常 3 台服务器就可以构成一个 ZooKeeper 集群了。</p><p><img src="/2021/02/04/%E4%B8%AD%E9%97%B4%E4%BB%B6/Zookeeper/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%B0%83%E7%BB%84%E4%BB%B6%E4%B9%8BZookeeper%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E5%85%A5%E9%97%A8/8de274eb6351bdf85a64e4ce1a4b9f65.png"></p><p>上图中每一个 Server 代表一个安装 ZooKeeper 服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 ZAB 协议（ZooKeeper Atomic Broadcast）来保持数据的一致性。</p><p><strong>最典型集群模式： Master/Slave 模式（主备模式）</strong>。</p><p>在这种模式中，通常 Master 服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。</p><h3 id="ZooKeeper-集群角色"><a href="#ZooKeeper-集群角色" class="headerlink" title="ZooKeeper 集群角色"></a>ZooKeeper 集群角色</h3><table><thead><tr><th><strong>角色</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>Leader</td><td>为客户端提供读和写的服务，负责投票的发起和决议，更新系统状态。</td></tr><tr><td>Follower</td><td>为客户端提供读服务，如果是写服务则转发给 Leader。在选举过程中参与投票。</td></tr><tr><td>Observer</td><td>为客户端提供读服务器，如果是写服务则转发给 Leader。不参与选举过程中的投票，也不参与“过半写成功”策略。在不影响写性能的情况下提升集群的读性能。此角色于 ZooKeeper3.3 系列新增的角色。</td></tr></tbody></table><h3 id="Zookeeper-Leader选举"><a href="#Zookeeper-Leader选举" class="headerlink" title="Zookeeper Leader选举"></a>Zookeeper Leader选举</h3><p>当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，就会进入 Leader 选举过程，这个过程会选举产生新的 Leader 服务器。</p><p>这个过程大致是这样的：</p><ol><li><p> <strong>Leader election（选举阶段）</strong>: 节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。</p></li><li><p> <strong>Discovery（发现阶段）</strong>: 在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。</p></li><li><p> <strong>Synchronization（同步阶段）</strong>: 同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。同步完成之后 准 leader 才会成为真正的 leader。</p></li><li><p> <strong>Broadcast（广播阶段）</strong>: 到了这个阶段，ZooKeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。</p></li></ol><h3 id="ZooKeeper-集群中的服务器状态"><a href="#ZooKeeper-集群中的服务器状态" class="headerlink" title="ZooKeeper 集群中的服务器状态"></a><strong>ZooKeeper 集群中的服务器状态</strong></h3><ul><li><p>  <strong>LOOKING</strong>: 寻找 Leader。</p></li><li><p>  <strong>LEADING</strong>: Leader 状态，对应的节点为 Leader。</p></li><li><p>  <strong>FOLLOWING</strong>: Follower 状态，对应的节点为 Follower。</p></li><li><p>  <strong>OBSERVING</strong>: Observer 状态，对应节点为 Observer，该节点不参与 Leader 选举。</p></li></ul><h3 id="ZooKeeper-集群为啥最好奇数台"><a href="#ZooKeeper-集群为啥最好奇数台" class="headerlink" title="ZooKeeper 集群为啥最好奇数台"></a><strong>ZooKeeper 集群为啥最好奇数台</strong></h3><p>ZooKeeper 集群在宕掉几个 ZooKeeper 服务器之后，如果剩下的 ZooKeeper 服务器个数大于宕掉的个数的话整个 ZooKeeper 才依然可用。假如我们的集群中有 n 台 ZooKeeper 服务器，那么也就是剩下的服务数必须大于 n/2。先说一下结论，2n 和 2n-1 的容忍度是一样的，都是n-1，大家可以先自己仔细想一想，这应该是一个很简单的数学问题了。 比如假如我们有 3 台，那么最大允许宕掉 1 台 ZooKeeper 服务器，如果我们有 4 台的的时候也同样只允许宕掉 1 台。 假如我们有 5 台，那么最大允许宕掉 2 台ZooKeeper 服务器，如果我们有 6 台的的时候也同样只允许宕掉 2 台。</p><h2 id="ZAB-协议和Paxos-算法"><a href="#ZAB-协议和Paxos-算法" class="headerlink" title="ZAB 协议和Paxos 算法"></a>ZAB 协议和Paxos 算法</h2><p>Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像Paxos算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。</p><h3 id="ZAB-协议介绍"><a href="#ZAB-协议介绍" class="headerlink" title="ZAB 协议介绍"></a><strong>ZAB 协议介绍</strong></h3><p>ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。</p><p><strong>ZAB 协议两种基本的模式：崩溃恢复和消息广播</strong></p><p>ZAB 协议包括两种基本的模式，分别是</p><ul><li><p><strong>崩溃恢复</strong>：当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。<br>  其中，<strong>所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致</strong>。</p></li><li><p><strong>消息广播</strong>：<strong>当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。</strong><br>  当一台同样遵守ZAB协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。</p></li></ul><p>具体ZAB协议介绍可参考 <a href="https://dbaplus.cn/news-141-1875-1.html">实例详解ZooKeeper ZAB协议、分布式锁与领导选举</a></p><h2 id="Zookeeper总结"><a href="#Zookeeper总结" class="headerlink" title="Zookeeper总结"></a>Zookeeper总结</h2><ol><li><p>ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。</p></li><li><p>为了保证高可用，最好是以集群形态来部署ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么ZooKeeper 本身仍然是可用的。</p></li><li><p>ZooKeeper 将数据保存在内存中，这也就保证了高吞吐量和低延迟</p></li></ol><ul><li>但是内存限制了能够存储的容量不太大，此限制也是保持 znode 中存储的数据量较小的进一步原因。</li></ul><ol start="4"><li><p>ZooKeeper 是高性能的。<br>在“读”多于“写”的应用程序中尤其地明显，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。）</p></li><li><p>ZooKeeper 有临时节点的概念。  </p></li></ol><ul><li>当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。  </li><li>持久节点是指一旦这个 znode 被创建了，除非主动进行 znode 的移除操作，否则这个 znode 将一直保存在 ZooKeeper 上。</li></ul><ol start="6"><li>ZooKeeper 底层其实只提供了两个功能：</li></ol><ul><li>管理（存储、读取）用户程序提交的数据；</li><li>为用户程序提供数据节点监听服务。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是分布式协调组件&quot;&gt;&lt;a href=&quot;#什么是分布式协调组件&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式协调组件&quot;&gt;&lt;/a&gt;什么是分布式协调组件&lt;/h2&gt;&lt;p&gt;讲Zookeeper之前，首先我们了解下什么是”分布式协调组件“。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="ZOOKEEPER" scheme="http://example.com/tags/ZOOKEEPER/"/>
    
  </entry>
  
  <entry>
    <title>高并发系统00之如何设计一个高并发系统</title>
    <link href="http://example.com/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-10-11T07:08:32.000Z</published>
    <updated>2021-08-12T03:37:01.821Z</updated>
    
    <content type="html"><![CDATA[<p>为啥会有高并发？为啥高并发就很牛逼？</p><p>很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。<br>所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。</p><p>设计一个高并发系统可以简单分为以下 6 点：</p><ul><li>系统拆分</li><li>缓存</li><li>MQ</li><li>分库分表</li><li>读写分离</li><li>ElasticSearch</li></ul><p><img src="/2020/10/11/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/img_1.png"></p><h3 id="系统拆分"><a href="#系统拆分" class="headerlink" title="系统拆分"></a>系统拆分</h3><p>将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存，必须得用缓存。大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。</p><h3 id="MQ"><a href="#MQ" class="headerlink" title="MQ"></a>MQ</h3><p>MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。</p><h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h3><p>分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 sql 跑的性能。</p><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。</p><h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>Elasticsearch，简称 ES。</p><p>ES 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;为啥会有高并发？为啥高并发就很牛逼？&lt;/p&gt;
&lt;p&gt;很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。&lt;br&gt;所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。&lt;/p&gt;</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="高并发" scheme="http://example.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
    <category term="设计理念" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>高并发系统03之高并发三大利器之降级</title>
    <link href="http://example.com/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%8D%E7%BA%A7/"/>
    <id>http://example.com/2020/10/09/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%8D%E7%BA%A7/</id>
    <published>2020-10-09T08:28:03.000Z</published>
    <updated>2021-08-04T07:20:58.564Z</updated>
    
    <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h3 id="什么是服务降级"><a href="#什么是服务降级" class="headerlink" title="什么是服务降级"></a>什么是服务降级</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。</span><br></pre></td></tr></table></figure><p>服务降级主要用于当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，将一些 不重要 或 不紧急 的服务或任务进行服务的 <strong>延迟使用</strong> 或 <strong>暂停使用</strong>。</p><p>降级就是为了解决资源不足和访问量增加的矛盾。</p><h3 id="服务降级方式"><a href="#服务降级方式" class="headerlink" title="服务降级方式"></a>服务降级方式</h3><ul><li><strong>延迟服务</strong>：定时任务处理、或者mq延时处理。比如新用户注册送多少优惠券可以提示用户优惠券会24小时到达用户账号中，我们可以选择再凌晨流量较小的时候，批量去执行送券</li><li><strong>页面降级</strong>：页面点击按钮全部置灰，或者页面调整成为一个静态页面显示“系统正在维护中，。。。。”。</li><li><strong>关闭非核心服务</strong>：比如电商关闭推荐服务、关闭运费险、退货退款等。保证主流程的核心服务下单付款就好。</li><li><strong>写降级</strong>：比如秒杀抢购，我们可以只进行Cache的更新返回，然后通过mq异步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。</li><li><strong>读降级</strong>：比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景。</li></ul><h3 id="服务熔断"><a href="#服务熔断" class="headerlink" title="服务熔断"></a>服务熔断</h3><h4 id="服务雪崩"><a href="#服务雪崩" class="headerlink" title="服务雪崩"></a>服务雪崩</h4><p>多个微服务之间调用的时候，比如A服务调用了B服务，B服务调用了C服务，然后C服务由于机器宕机或者网略故障， 然后就会导致B服务调用C服务的时候超时，然后A服务调用B服务也会超时，最终整个链路都不可用了，导致整个系统不可用就跟雪蹦一样。</p><h4 id="雪崩效应产生的几种场景"><a href="#雪崩效应产生的几种场景" class="headerlink" title="雪崩效应产生的几种场景"></a>雪崩效应产生的几种场景</h4><p><strong>突增流量</strong>：比如一大波爬虫，或者黑客攻击等。<br><strong>程序bug</strong>：代码死循环，或者资源未释放等。<br><strong>硬件原因</strong>：机器宕机、机房断电、光纤被挖断等。  </p><h4 id="服务熔断-1"><a href="#服务熔断-1" class="headerlink" title="服务熔断"></a>服务熔断</h4><p>熔断机制是应对雪崩效应的一种微服务链路保护机制，在互联网系统中当下游的服务因为某种原因突然变得不可用或响应过慢，上游服务为了保证自己整体服务的可用性，暂时不再继续调用目标服务，直接快速返回，快速释放资源。如果目标服务情况好转则恢复调用。</p><h3 id="熔断和降级的比较"><a href="#熔断和降级的比较" class="headerlink" title="熔断和降级的比较"></a>熔断和降级的比较</h3><h4 id="共性"><a href="#共性" class="headerlink" title="共性"></a>共性</h4><ul><li>目的很一致：都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段，都是为了保证系统的稳定。</li><li>最终表现类似:对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用；</li><li>粒度一般都是服务级别:当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）；</li><li>自治性要求很高: 熔断模式一般都是服务基于策略的自动触发，比如</li><li>降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段；</li></ul><h4 id="差异性"><a href="#差异性" class="headerlink" title="差异性"></a>差异性</h4><ul><li>触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；</li><li>管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）熔断是降级方式的一种体现。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;高并发三大利器&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹&lt;/li&gt;
&lt;li&gt;降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="高并发" scheme="http://example.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
    <category term="降级" scheme="http://example.com/tags/%E9%99%8D%E7%BA%A7/"/>
    
  </entry>
  
</feed>
