<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>沉默者</title>
  
  <subtitle>路漫漫其修远兮，吾将上下而求索</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-08-02T11:10:48.456Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>何鹏 [smile.hepeng@qq.com]</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>代码规范之BigDecimal的equals方法等值比较引坑</title>
    <link href="http://example.com/2021/08/02/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/"/>
    <id>http://example.com/2021/08/02/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/</id>
    <published>2021-08-02T10:54:13.000Z</published>
    <updated>2021-08-02T11:10:48.456Z</updated>
    
    <content type="html"><![CDATA[<p>BigDecimal，相信对于很多人来说都不陌生，很多人都知道他的用法，这是一种java.math包中提供的一种可以用来进行精确运算的类型。</p><p>很多人都知道，在进行金额表示、金额计算等场景，不能使用double、float等类型，而是要使用对精度支持的更好的BigDecimal。</p><p>所以，很多支付、电商、金融等业务中，BigDecimal的使用非常频繁。而且不得不说这是一个非常好用的类，其内部自带了很多方法，如加，减，乘，除等运算方法都是可以直接调用的。</p><p>除了需要用BigDecimal表示数字和进行数字运算以外，代码中还经常需要对于数字进行相等判断。</p><p>关于BigDecimal等值判断的这个知识点，在最新版的《阿里巴巴Java开发手册》中也有说明：<br><img src="/2021/08/02/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_1.png"></p><p>那么，为什么会有这样的要求呢？背后的思考是什么呢？</p><p>其实，我在之前的CodeReview中，看到过以下这样的低级错误：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(bigDecimal == bigDecimal1)&#123;</span><br><span class="line">    // 两个数相等</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种错误，相信聪明的读者一眼就可以看出问题，因为BigDecimal是对象，所以不能用==来判断两个数字的值是否相等。</p><p>以上这种问题，在有一定的经验之后，还是可以避免的，但是聪明的读者，看一下以下这行代码，你觉得他有问题吗：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(bigDecimal.equals(bigDecimal1))&#123;</span><br><span class="line">    // 两个数相等</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以明确的告诉大家，以上这种写法，可能得到的结果和你预想的不一样！</p><p>先来做个实验，运行以下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal bigDecimal = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal1 = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal.equals(bigDecimal1));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal2 = new BigDecimal(1);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal3 = new BigDecimal(1.0);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal2.equals(bigDecimal3));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal4 = new BigDecimal(&quot;1&quot;);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal5 = new BigDecimal(&quot;1.0&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal4.equals(bigDecimal5));</span><br></pre></td></tr></table></figure><p>以上代码，输出结果为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">true</span><br><span class="line"></span><br><span class="line">true</span><br><span class="line"></span><br><span class="line">false</span><br></pre></td></tr></table></figure><h3 id="BigDecimal的equals原理"><a href="#BigDecimal的equals原理" class="headerlink" title="BigDecimal的equals原理"></a>BigDecimal的equals原理</h3><p>通过以上代码示例，我们发现，在使用BigDecimal的equals方法对1和1.0进行比较的时候，有的时候是true（当使用int、double定义BigDecimal时），有的时候是false（当使用String定义BigDecimal时）。</p><p>那么，为什么会出现这样的情况呢，我们先来看下BigDecimal的equals方法。</p><p>在BigDecimal的JavaDoc中其实已经解释了其中原因：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Compares this  BigDecimal with the specified Object for equality.  Unlike compareTo, this method considers two BigDecimal objects equal only if they are equal in value and scale (thus 2.0 is not equal to 2.00 when compared by  this method)</span><br></pre></td></tr></table></figure><p>大概意思就是，equals方法和compareTo并不一样，equals方法会比较两部分内容，分别是<strong>值(value)<strong>和</strong>标度(scale)</strong></p><p><img src="/2021/08/02/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_2.png"></p><p>到这里，我们大概解释清楚了，之所以equals比较bigDecimal4和bigDecimal5的结果是false，是因为标度不同。</p><p>那么，为什么标度不同呢？为什么bigDecimal2和bigDecimal3的标度是一样的（当使用int、double定义BigDecimal时），而bigDecimal4和bigDecimal5却不一样（当使用String定义BigDecimal时）呢？</p><h3 id="为什么标度不同"><a href="#为什么标度不同" class="headerlink" title="为什么标度不同"></a>为什么标度不同</h3><p>这个就涉及到BigDecimal的标度问题了，这个问题其实是比较复杂的，由于不是本文的重点，这里面就简单介绍一下吧。</p><p>首先，BigDecimal一共有以下4个构造方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal(int)</span><br><span class="line"></span><br><span class="line">BigDecimal(double) </span><br><span class="line"></span><br><span class="line">BigDecimal(long) </span><br><span class="line"></span><br><span class="line">BigDecimal(String)</span><br></pre></td></tr></table></figure><p>以上四个方法，创建出来的的BigDecimal的标度是不同的。</p><ul><li><p><strong>BigDecimal(long) 和BigDecimal(int)</strong><br>首先，最简单的就是BigDecimal(long) 和BigDecimal(int)，<strong>因为是整数，所以标度就是0</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public BigDecimal(int val) &#123;</span><br><span class="line">  this.intCompact = val;</span><br><span class="line">  this.scale = 0;</span><br><span class="line">  this.intVal = null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public BigDecimal(long val) &#123;</span><br><span class="line">  this.intCompact = val;</span><br><span class="line">  this.intVal = (val == INFLATED) ? INFLATED_BIGINT : null;</span><br><span class="line">  this.scale = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>BigDecimal(double)</strong><br>而对于BigDecimal(double), 当我们使用new BigDecimal(0.1)创建一个BigDecimal 的时候，其实创建出来的值并不是正好等于0.1的，而是0.1000000000000000055511151231257827021181583404541015625 。这是因为doule自身表示的只是一个近似值。</p><p>那么，无论我们使用new BigDecimal(0.1)还是new BigDecimal(0.10)定义，他的近似值都是0.1000000000000000055511151231257827021181583404541015625这个，那么他的标度就是这个数字的位数，即55。</p><p><img src="/2021/08/02/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_3.png"> </p><p>其他的浮点数也同样的道理。对于new BigDecimal(1.0)这样的形式来说，因为他本质上也是个整数，所以他创建出来的数字的标度就是0。</p><p>所以，因为BigDecimal(1.0)和BigDecimal(1.00)的标度是一样的，所以在使用equals方法比较的时候，得到的结果就是true。</p></li><li><p><strong>BigDecimal(string)</strong><br>而对于BigDecimal(double) ，当我们使用new BigDecimal(“0.1”)创建一个BigDecimal 的时候，其实创建出来的值正好就是等于0.1的。那么他的标度也就是1。</p><p>如果使用new BigDecimal(“0.10000”)，那么创建出来的数就是0.10000，标度也就是5。</p></li></ul><p>所以，因为BigDecimal(“1.0”)和BigDecimal(“1.00”)的标度不一样，所以在使用equals方法比较的时候，得到的结果就是false。</p><h3 id="如何比较BigDecimal"><a href="#如何比较BigDecimal" class="headerlink" title="如何比较BigDecimal"></a>如何比较BigDecimal</h3><p>前面，我们解释了BigDecimal的equals方法，其实不只是会比较数字的值，还会对其标度进行比较。</p><p>所以，当我们使用equals方法判断判断两个数是否相等的时候，是极其严格的。</p><p>那么，如果我们只想判断两个BigDecimal的值是否相等，那么该如何判断呢？</p><p><strong>BigDecimal中提供了compareTo方法，这个方法就可以只比较两个数字的值，如果两个数相等，则返回0。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BigDecimal bigDecimal4 = new BigDecimal(&quot;1&quot;);</span><br><span class="line"></span><br><span class="line">BigDecimal bigDecimal5 = new BigDecimal(&quot;1.0000&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(bigDecimal4.compareTo(bigDecimal5));</span><br></pre></td></tr></table></figure><p>以上代码，输出结果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0</span><br></pre></td></tr></table></figure><p>其源码如下：</p><p><img src="/2021/08/02/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BBigDecimal%E7%9A%84equals%E6%96%B9%E6%B3%95%E7%AD%89%E5%80%BC%E6%AF%94%E8%BE%83%E5%BC%95%E5%9D%91/img_4.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>BigDecimal是一个非常好用的表示高精度数字的类，其中提供了很多丰富的方法。</p><p>但是，他的equals方法使用的时候需要谨慎，因为他在比较的时候，不仅比较两个数字的值，还会比较他们的标度，只要这两个因素有一个是不相等的，那么结果也是false</p><p>如果读者想要对两个BigDecimal的数值进行比较的话，可以使用compareTo方法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;BigDecimal，相信对于很多人来说都不陌生，很多人都知道他的用法，这是一种java.math包中提供的一种可以用来进行精确运算的类型。&lt;/p&gt;
&lt;p&gt;很多人都知道，在进行金额表示、金额计算等场景，不能使用double、float等类型，而是要使用对精度支持的更好的Bi</summary>
      
    
    
    
    <category term="代码规范" scheme="http://example.com/categories/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
    
    <category term="代码规范" scheme="http://example.com/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之Kafka消息发送者核心参数与工作机制</title>
    <link href="http://example.com/2021/07/26/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2021/07/26/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/</id>
    <published>2021-07-26T10:46:45.000Z</published>
    <updated>2021-07-27T01:33:53.620Z</updated>
    
    <content type="html"><![CDATA[<p>本文将从Kafka Producer的配置属性为突破口，结合源码深入提炼出Kafka Producer的工作机制，方便大家更好使用Kafka Producer，并且胸有成竹的进行性能调优。</p><p>将Kafka Producer相关的参数分成如下几个类型：</p><ul><li>常规参数</li><li>工作原理(性能相关)参数(图解)</li></ul><p>本文会结合图解方式，重点阐述与Kafka生产者运作机制密切相关的参数。</p><h2 id="Producer-架构"><a href="#Producer-架构" class="headerlink" title="Producer 架构"></a>Producer 架构</h2><p><img src="/2021/07/26/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E8%80%85%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E4%B8%8E%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/img.png"><br>总的来说，Kafka生产端发送数据过程涉及到序列化器Serializer、分区器Partitioner，消息缓存池Accumulator，还可能会涉及到拦截器Interceptor（这部分暂不做介绍）。</p><h3 id="常规参数"><a href="#常规参数" class="headerlink" title="常规参数"></a>常规参数</h3><p>为了更好的使用Kafka Producer，首先介绍一下几个基本参数。</p><ul><li><strong>bootstrap.servers</strong>: 配置Kafka broker的服务器地址列表，多个用英文逗号分开，可以不必写全，Kafka内部有自动感知Kafka broker的机制。</li><li><strong>client.dns.lookup</strong>: 客户端寻找bootstrap地址的方式，支持如下两种方式：<ul><li><strong>resolve_canonical_bootstrap_servers_only</strong>: 这种方式，会依据bootstrap.servers提供的主机名(hostname)，根据主机上的名称服务返回其IP地址的数组(InetAddress.getAllByName)，然后依次获取inetAddress.getCanonicalHostName()，再建立tcp连接。<br>  <strong>一个主机可配置多个网卡，如果启用该功能，应该可以有效利用多网卡的优势，降低Broker的网络端负载压力。</strong></li><li><strong>use_all_dns_ips</strong>: 这种方式会直接使用bootstrap.servers中提供的hostname、port创建tcp连接，默认选项。</li></ul></li><li><strong>compression.type</strong>: 消息的压缩算法，目前可选值：none、gzip、snappy、lz4、zstd，<strong>默认不压缩，建议与Kafka服务器配置的一样</strong>，当然Kafka服务端可以配置的压缩类型为 producer，即采用与发送方配置的压缩类型。<strong>发送方与Broker 服务器采用相同的压缩类型，可有效避免在Broker服务端进行消息的压缩与解压缩，大大降低Broker的CPU使用压力</strong>。</li><li><strong>client.id</strong>: 客户端ID，如果不设置默认为producer-递增，<strong>强烈建议设置该值，尽量包含ip,port,pid</strong>。</li><li><strong>send.buffer.bytes</strong>: 网络通道(TCP)的发送缓存区大小，默认为128K。</li><li><strong>receive.buffer.bytes</strong>: 网络通道(TCP)的接收缓存区大小，默认为32K。</li><li><strong>reconnect.backoff.ms</strong>: 重新建立链接的等待时长，默认为50ms，属于底层网络参数，基本无需关注。</li><li><strong>reconnect.backoff.max.ms</strong>: 重新建立链接的最大等待时长，默认为1s，连续两次对同一个连接建立重连，等待时间会在reconnect.backoff.ms的初始值上成指数级递增，但超过max后，将不再指数级递增。</li><li><strong>key.serializer</strong>: 消息key的序列化策略，为org.apache.kafka.common.serialization接口的实现类。</li><li><strong>value.serializer</strong>: 消息体的序列化策略</li><li><strong>partitioner.class</strong>: 消息发送队列负载算法，其默 DefaultPartitioner，路由算法如下：<ul><li>如果指定了 key ，则使用 key 的 hashcode 与分区数取模。</li><li>如果未指定 key，则轮询所有的分区。</li></ul></li><li><strong>interceptor.classes</strong>: 拦截器列表，kafka运行在消息真正发送到broker之前对消息进行拦截加工。</li><li><strong>enable.idempotence</strong>: 是否开启发送端的幂等，这个机制后续会重点剖析其实现原理，默认为false。</li><li><strong>transaction.timeout.ms</strong>: 事务协调器等待客户端的事务状态反馈的最大超时时间，默认为60s。</li><li><strong>transactional.id</strong>: 事务id,用于在一个事务中唯一标识一个客户端。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将从Kafka Producer的配置属性为突破口，结合源码深入提炼出Kafka Producer的工作机制，方便大家更好使用Kafka Producer，并且胸有成竹的进行性能调优。&lt;/p&gt;
&lt;p&gt;将Kafka Producer相关的参数分成如下几个类型：&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之Kafka消息拉取机制简读</title>
    <link href="http://example.com/2021/07/26/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/"/>
    <id>http://example.com/2021/07/26/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/</id>
    <published>2021-07-26T10:45:45.000Z</published>
    <updated>2021-07-27T01:13:53.112Z</updated>
    
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>数据库连接池之HikariCP实现详解</title>
    <link href="http://example.com/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-07-26T02:08:03.000Z</published>
    <updated>2021-07-26T07:25:51.436Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是数据库连接池，为什么需要数据库连接池"><a href="#什么是数据库连接池，为什么需要数据库连接池" class="headerlink" title="什么是数据库连接池，为什么需要数据库连接池"></a>什么是数据库连接池，为什么需要数据库连接池</h2><p>从根本上而言，数据库连接池和我们常用的线程池一样，都属于池化资源，它在程序初始化时创建一定数量的数据库连接对象并将其保存在一块内存区中。</p><p>它允许应用程序重复使用一个现有的数据库连接，当需要执行 SQL 时，我们是直接从连接池中获取一个连接，而不是重新建立一个数据库连接，当 SQL 执行完，也并不是将数据库连接真的关掉，而是将其归还到数据库连接池中。</p><p>我们可以通过配置连接池的参数来控制连接池中的初始连接数、最小连接、最大连接、最大空闲时间等参数，来保证访问数据库的数量在一定可控制的范围类，防止系统崩溃，同时保证用户良好的体验。</p><p>数据库连接池示意图如下所示：</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img.png"></p><p>因为数据库连接是有限且代价昂贵，创建和释放数据库连接都非常耗时，频繁地进行这样的操作将占用大量的性能开销，进而导致网站的响应速度下降，甚至引起服务器崩溃。</p><p>因此使用数据库连接池的核心作用，就是<strong>避免数据库连接频繁创建和销毁，节省系统开销</strong>。</p><h3 id="常见数据库连接池对比分析"><a href="#常见数据库连接池对比分析" class="headerlink" title="常见数据库连接池对比分析"></a>常见数据库连接池对比分析</h3><p>这里详细总结了常见数据库连接池的各项功能比较，我们重点分析下当前主流的阿里巴巴Druid与HikariCP，HikariCP在性能上是完全优于Druid连接池的。</p><p>而Druid的性能稍微差点是由于锁机制的不同，并且Druid提供更丰富的功能，包括监控、sql拦截与解析等功能，两者的侧重点不一样，HikariCP追求极致的高性能。</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_1.png"></p><p>下面是官网提供的性能对比图，在性能上面这五种数据库连接池的排序如下：HikariCP&gt;druid&gt;tomcat-jdbc&gt;dbcp&gt;c3p0：</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_2.png"></p><h3 id="一个简单的小问题"><a href="#一个简单的小问题" class="headerlink" title="一个简单的小问题"></a>一个简单的小问题</h3><pre><code>连接池本身的性能消耗在整个调用链路中通常占比不大，连接池的性能关键点是：连接是否LRU方式重用，是否支持PSCache（PreparedStatementCache）。</code></pre><h2 id="HikariCP数据库连接池简介"><a href="#HikariCP数据库连接池简介" class="headerlink" title="HikariCP数据库连接池简介"></a>HikariCP数据库连接池简介</h2><p>HikariCP 号称是史上性能最好的数据库连接池，SpringBoot 2.0将它设置为默认的数据源连接池。</p><p>Hikari相比起其它连接池的性能高了非常多，那么，这是怎么做到的呢？</p><p>通过查看HikariCP官网介绍，对于HikariCP所做优化总结如下：</p><ol><li><p><strong>字节码精简</strong> ：优化代码，编译后的字节码量极少，使得CPU缓存可以加载更多的程序代码；</p><p> HikariCP在优化并精简字节码上也下了功夫，使用第三方的Java字节码修改类库Javassist来生成委托实现动态代理.动态代理的实现在ProxyFactory类，速度更快，相比于JDK Proxy生成的字节码更少，精简了很多不必要的字节码。</p></li><li><p><strong>优化代理和拦截器</strong>：减少代码，例如HikariCP的Statement proxy只有100行代码，只有BoneCP的十分之一；</p></li><li><p><strong>自定义数组类型（FastStatementList）代替ArrayList</strong>：避免ArrayList每次get()都要进行range check，避免调用remove()时的从头到尾的扫描（由于连接的特点是后获取连接的先释放）；</p></li><li><p><strong>自定义集合类型（ConcurrentBag）</strong>：提高并发读写的效率；</p></li><li><p><strong>其他针对BoneCP缺陷的优化</strong>，比如对于耗时超过一个CPU时间片的方法调用的研究。</p></li></ol><h2 id="HikariCP详细设计之类图和流程图"><a href="#HikariCP详细设计之类图和流程图" class="headerlink" title="HikariCP详细设计之类图和流程图"></a>HikariCP详细设计之类图和流程图</h2><p>开始前先来了解下HikariCP获取一个连接时类间的交互流程，方便下面详细流程的阅读。</p><p>获取连接时的类间交互：</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_3.png"></p><h2 id="HikariCP详细设计之流程源码解读"><a href="#HikariCP详细设计之流程源码解读" class="headerlink" title="HikariCP详细设计之流程源码解读"></a>HikariCP详细设计之流程源码解读</h2><h3 id="主流程1：获取连接流程"><a href="#主流程1：获取连接流程" class="headerlink" title="主流程1：获取连接流程"></a>主流程1：获取连接流程</h3><p>HikariCP获取连接时的入口是<code>HikariDataSource</code>里的<code>getConnection</code>方法，现在来看下该方法的具体流程：</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_4.png"></p><p>上述为HikariCP获取连接时的流程图，由图可知:</p><ul><li>每个datasource对象里都会持有一个HikariPool对象，记为pool;</li><li>初始化后的datasource对象pool是空的，所以第一次getConnection的时候会进行实例化pool属性（参考主流程1），初始化的时候需要将当前datasource里的config属性传过去，用于pool的初始化，最终标记sealed;</li><li>然后根据pool对象调用getConnection方法（参考流程1.1），获取成功后返回连接对象。</li></ul><h4 id="流程1-1：通过HikariPool获取连接对象"><a href="#流程1-1：通过HikariPool获取连接对象" class="headerlink" title="流程1.1：通过HikariPool获取连接对象"></a>流程1.1：通过HikariPool获取连接对象</h4><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_6.png"></p><ul><li>从最开始的结构图可知，每个HikariPool里都维护一个ConcurrentBag对象，用于存放连接对象。</li><li>由上图可以看到，实际上HikariPool的getConnection就是从ConcurrentBag里获取连接的（调用其borrow方法获得，对应ConnectionBag主流程），</li><li>在长连接检查这块，与之前说的Druid不同，这里的长连接判活检查在连接对象没有被标记为“已丢弃”时，只要距离上次使用超过500ms每次取出都会进行检查（500ms是默认值，可通过配置<code>com.zaxxer.hikari.aliveBypassWindowMs</code>的系统参数来控制），也就是说HikariCP对长连接的活性检查很频繁，但是其并发性能依旧优于Druid，说明<strong>频繁的长连接检查并不是导致连接池性能高低的关键所在</strong>。<ul><li>这个其实是由于HikariCP的无锁实现，在高并发时对CPU的负载没有其他连接池那么高而产生的并发性能差异，后面会说HikariCP的具体做法；</li><li>即使是Druid，在获取连接、生成连接、归还连接时都进行了锁控制。</li><li>Druid里的连接池资源是多线程共享的，不可避免的会有锁竞争，有锁竞争意味着线程状态的变化会很频繁，线程状态变化频繁意味着CPU上下文切换也将会很频繁。</li></ul></li></ul><p>主体流程：</p><ul><li>如果拿到的连接为空，直接报错；</li><li>不为空则进行相应的检查<ul><li>如果检查通过，则包装成ConnectionProxy对象返回给业务方；</li><li>不通过则调用closeConnection方法关闭连接（对应流程1.1.2，该流程会触发ConcurrentBag的remove方法丢弃该连接，然后把实际的驱动连接交给closeConnectionExecutor线程池，异步关闭驱动连接）。</li></ul></li></ul><h5 id="流程1-1-1：连接判活"><a href="#流程1-1-1：连接判活" class="headerlink" title="流程1.1.1：连接判活"></a>流程1.1.1：连接判活</h5><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_7.png"></p><p>承接上面的<code>流程1.1</code>里的判活流程，来看下判活是如何做的</p><ul><li>首先说验证方法（注意这里该方法接受的这个connection对象不是poolEntry，而是poolEntry持有的实际驱动的连接对象），<ul><li>Druid是根据驱动程序里是否存在ping方法来判断是否启用ping的方式判断连接是否存活;</li><li>但是到了HikariCP则更加简单粗暴，仅根据是否配置了connectionTestQuery觉定是否启用ping：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.isUseJdbc4Validation = config.getConnectionTestQuery() == null;</span><br></pre></td></tr></table></figure></li><li>所以一般驱动如果不是特别低的版本，不建议配置该项，否则便会走createStatement+excute的方式，相比ping简单发送心跳数据，这种方式显然更低效。</li></ul></li><li>超时时间<ul><li>在刚进来还会通过驱动的连接对象重新给它设置一遍networkTimeout的值，使之变成validationTimeout，表示一次验证的超时时间；</li><li>因为在使用ping方法校验时，是没办法通过类似statement那样可以setQueryTimeout的，所以只能由网络通信的超时时间来控制，这个时间可以通过jdbc的连接参数socketTimeout来控制：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbc:mysql://127.0.0.1:3306/xxx?socketTimeout=250</span><br></pre></td></tr></table></figure></li><li>这个值最终会被赋值给HikariCP的networkTimeout字段，这就是为什么最后那一步使用这个字段来还原驱动连接超时属性的原因；</li><li>最后那里为啥要再次还原呢？这就很容易理解了，因为验证结束了，连接对象还存活的情况下，它的networkTimeout的值这时仍然等于validationTimeout（不合预期），显然在拿出去用之前，需要恢复成本来的值，也就是HikariCP里的networkTimeout属性。</li></ul></li></ul><h5 id="流程1-1-2：关闭连接对象"><a href="#流程1-1-2：关闭连接对象" class="headerlink" title="流程1.1.2：关闭连接对象"></a>流程1.1.2：关闭连接对象</h5><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_8.png"></p><p>这个流程简单来说就是把流程1.1.1中验证不通过的死连接，主动关闭的一个流程。</p><ul><li>首先会把这个连接对象从ConnectionBag里移除，</li><li>然后把实际的物理连接交给一个线程池去异步执行，这个线程池就是在主流程2里初始化池的时候初始化的线程池closeConnectionExecutor，</li><li>然后异步任务内开始实际的关连接操作，</li><li>因为主动关闭了一个连接相当于少了一个连接，所以还会触发一次扩充连接池（参考<code>主流程5</code>）操作。</li></ul><h3 id="主流程2：初始化池对象"><a href="#主流程2：初始化池对象" class="headerlink" title="主流程2：初始化池对象"></a>主流程2：初始化池对象</h3><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_5.png"></p><p>该流程用于初始化整个连接池，这个流程会给连接池内所有的属性做初始化的工作，其中比较主要的几个流程上图已经指出，简单概括一下：</p><ol><li>利用config初始化各种连接池属性，并且产生一个用于生产物理连接的数据源DriverDataSource</li><li>初始化存放连接对象的核心类connectionBag</li><li>初始化一个延时任务线程池类型的对象houseKeepingExecutorService，用于后续执行一些延时/定时类任务（比如连接泄漏检查延时任务，参考流程2.2以及<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B4%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%BC%A9%E5%AE%B9">主流程4：连接池缩容</a>，除此之外maxLifeTime后主动回收关闭连接也是交由该对象来执行的，这个过程可以参考主流程3）</li><li>预热连接池，HikariCP会在该流程的checkFailFast里初始化好一个连接对象放进池子内，当然触发该流程得保证initializationTimeout &gt; 0时（默认值1），这个配置属性表示留给预热操作的时间（默认值1在预热失败时不会发生重试）。与Druid通过initialSize控制预热连接对象数不一样的是，HikariCP仅预热进池一个连接对象。</li><li>初始化一个线程池对象addConnectionExecutor，用于后续扩充连接对象</li><li>初始化一个线程池对象closeConnectionExecutor，用于关闭一些连接对象，怎么触发关闭任务呢？可以参考流程1.1.2</li></ol><h4 id="流程2-1：HikariCP监控设置"><a href="#流程2-1：HikariCP监控设置" class="headerlink" title="流程2.1：HikariCP监控设置"></a>流程2.1：HikariCP监控设置</h4><p>不同于Druid那样监控指标那么多，HikariCP会把我们非常关心的几项指标暴露给我们，</p><p>比如当前连接池内闲置连接数、总连接数、一个连接被用了多久归还、创建一个物理连接花费多久等，</p><p>HikariCP的连接池的监控我们这一节专门详细的分解一下，首先找到HikariCP下面的metrics文件夹，这下面放置了一些规范实现的监控接口等，还有一些现成的实现（比如HikariCP自带对prometheus、micrometer、dropwizard的支持，不太了解后面两个，prometheus下文直接称为普罗米修斯）：</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_9.png"></p><p>下面，来着重看下接口的定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这个接口的实现主要负责收集一些动作的耗时</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IMetricsTracker</span> <span class="keyword">extends</span> <span class="title">AutoCloseable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">//这个方法触发点在创建实际的物理连接时（主流程3），用于记录一个实际的物理连接创建所耗费的时间</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionCreatedMillis</span><span class="params">(<span class="keyword">long</span> connectionCreatedMillis)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点在getConnection时（主流程1），用于记录获取一个连接时实际的耗时</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionAcquiredNanos</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> elapsedAcquiredNanos)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点在回收连接时（主流程6），用于记录一个连接从被获取到被回收时所消耗的时间</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionUsageMillis</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> elapsedBorrowedMillis)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这个方法触发点也在getConnection时（主流程1），用于记录获取连接超时的次数，每发生一次获取连接超时，就会触发一次该方法的调用</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">recordConnectionTimeout</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>触发点都了解清楚后，再来看看MetricsTrackerFactory的接口定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//用于创建IMetricsTracker实例，并且按需记录PoolStats对象里的属性（这个对象里的属性就是类似连接池当前闲置连接数之类的线程池状态类指标）</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">MetricsTrackerFactory</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">//返回一个IMetricsTracker对象，并且把PoolStats传了过去</span></span><br><span class="line">    <span class="function">IMetricsTracker <span class="title">create</span><span class="params">(String poolName, PoolStats poolStats)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的接口用法见注释，针对新出现的PoolStats类，我们来看看它做了什么：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">PoolStats</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicLong reloadAt; <span class="comment">//触发下次刷新的时间（时间戳）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> timeoutMs; <span class="comment">//刷新下面的各项属性值的频率，默认1s，无法改变</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 总连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> totalConnections;</span><br><span class="line">    <span class="comment">// 闲置连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> idleConnections;</span><br><span class="line">    <span class="comment">// 活动连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> activeConnections;</span><br><span class="line">    <span class="comment">// 由于无法获取到可用连接而阻塞的业务线程数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> pendingThreads;</span><br><span class="line">    <span class="comment">// 最大连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> maxConnections;</span><br><span class="line">    <span class="comment">// 最小连接数</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">int</span> minConnections;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PoolStats</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> timeoutMs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.timeoutMs = timeoutMs;</span><br><span class="line">        <span class="keyword">this</span>.reloadAt = <span class="keyword">new</span> AtomicLong();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这里以获取最大连接数为例，其他的跟这个差不多</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getMaxConnections</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (shouldLoad()) &#123; <span class="comment">//是否应该刷新</span></span><br><span class="line">            update(); <span class="comment">//刷新属性值，注意这个update的实现在HikariPool里，因为这些属性值的直接或间接来源都是HikariPool</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> maxConnections;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">()</span></span>; <span class="comment">//实现在↑上面已经说了</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldLoad</span><span class="params">()</span> </span>&#123; <span class="comment">//按照更新频率来决定是否刷新属性值</span></span><br><span class="line">        <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> now = currentTime();</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> reloadTime = reloadAt.get();</span><br><span class="line">            <span class="keyword">if</span> (reloadTime &gt; now) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (reloadAt.compareAndSet(reloadTime, plusMillis(now, timeoutMs))) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上这里就是这些属性获取和触发刷新的地方，那么这个对象是在哪里被生成并且丢给<code>MetricsTrackerFactory</code>的<code>create</code>方法的呢？这就是本节所需要讲述的要点：<code>主流程2</code>里的设置监控器的流程，来看看那里发生了什么事吧：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">//监控器设置方法（此方法在HikariPool中，metricsTracker属性就是HikariPool用来触发IMetricsTracker里方法调用的）</span><br><span class="line">public void setMetricsTrackerFactory(MetricsTrackerFactory metricsTrackerFactory) &#123;</span><br><span class="line">    if (metricsTrackerFactory != null) &#123;</span><br><span class="line">        //MetricsTrackerDelegate是包装类，是HikariPool的一个静态内部类，是实际持有IMetricsTracker对象的类，也是实际触发IMetricsTracker里方法调用的类</span><br><span class="line">        //这里首先会触发MetricsTrackerFactory类的create方法拿到IMetricsTracker对象，然后利用getPoolStats初始化PoolStat对象，然后也一并传给MetricsTrackerFactory</span><br><span class="line">        this.metricsTracker = new MetricsTrackerDelegate(metricsTrackerFactory.create(config.getPoolName(), getPoolStats()));</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        //不启用监控，直接等于一个没有实现方法的空类</span><br><span class="line">        this.metricsTracker = new NopMetricsTrackerDelegate();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private PoolStats getPoolStats() &#123;</span><br><span class="line">    //初始化PoolStats对象，并且规定1s触发一次属性值刷新的update方法</span><br><span class="line">    return new PoolStats(SECONDS.toMillis(1)) &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void update() &#123;</span><br><span class="line">            //实现了PoolStat的update方法，刷新各个属性的值</span><br><span class="line">            this.pendingThreads = HikariPool.this.getThreadsAwaitingConnection();</span><br><span class="line">            this.idleConnections = HikariPool.this.getIdleConnections();</span><br><span class="line">            this.totalConnections = HikariPool.this.getTotalConnections();</span><br><span class="line">            this.activeConnections = HikariPool.this.getActiveConnections();</span><br><span class="line">            this.maxConnections = config.getMaximumPoolSize();</span><br><span class="line">            this.minConnections = config.getMinimumIdle();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里HikariCP的监控器就算是注册进去了，所以要想实现自己的监控器拿到上面的指标，要经过如下步骤：</p><ol><li>新建一个类实现IMetricsTracker接口，我们这里将该类记为IMetricsTrackerImpl</li><li>新建一个类实现MetricsTrackerFactory接口，我们这里将该类记为MetricsTrackerFactoryImpl，并且将上面的IMetricsTrackerImpl在其create方法内实例化</li><li>将MetricsTrackerFactoryImpl实例化后调用HikariPool的setMetricsTrackerFactory方法注册到Hikari连接池。</li></ol><p>上面没有提到PoolStats里的属性怎么监控，这里来说下。</p><p>由于create方法是调用一次就没了，create方法只是接收了PoolStats对象的实例，如果不处理，那么随着create调用的结束，这个实例针对监控模块来说就失去持有了，所以这里如果想要拿到PoolStats里的属性，就需要开启一个守护线程，让其持有PoolStats对象实例，并且定时获取其内部属性值，然后push给监控系统，如果是<strong>普罗米修斯等使用pull方式获取监控数据的监控系统</strong>，可以效仿HikariCP原生普罗米修斯监控的实现，自定义一个Collector对象来接收PoolStats实例，这样普罗米修斯就可以定期拉取了，比如HikariCP根据普罗米修斯监控系统自己定义的<code>MetricsTrackerFactory</code>实现（对应<code>PrometheusMetricsTrackerFactory</code>类）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public IMetricsTracker create(String poolName, PoolStats poolStats) &#123;</span><br><span class="line">    getCollector().add(poolName, poolStats); //将接收到的PoolStats对象直接交给Collector，这样普罗米修斯服务端每触发一次采集接口的调用，PoolStats都会跟着执行一遍内部属性获取流程</span><br><span class="line">    return new PrometheusMetricsTracker(poolName, this.collectorRegistry); //返回IMetricsTracker接口的实现类</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//自定义的Collector</span><br><span class="line">private HikariCPCollector getCollector() &#123;</span><br><span class="line">    if (collector == null) &#123;</span><br><span class="line">        //注册到普罗米修斯收集中心</span><br><span class="line">        collector = new HikariCPCollector().register(this.collectorRegistry);</span><br><span class="line">    &#125;</span><br><span class="line">    return collector;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上面的解释可以知道在HikariCP中如何自定义一个自己的监控器，以及相比Druid的监控，有什么区别。 </p><h4 id="流程2-2：连接泄漏的检测与告警"><a href="#流程2-2：连接泄漏的检测与告警" class="headerlink" title="流程2.2：连接泄漏的检测与告警"></a>流程2.2：连接泄漏的检测与告警</h4><p>本节对应<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里的<a href="#%E6%B5%81%E7%A8%8B2.2%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B3%84%E6%BC%8F%E7%9A%84%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%91%8A%E8%AD%A6">子流程2.2</a>，在初始化池对象时，初始化了一个叫做<code>leakTaskFactory</code>的属性，本节来看下它具体是用来做什么的。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个连接被拿出去使用时间超过leakDetectionThreshold（可配置，默认0）未归还的，会触发一个连接泄漏警告，通知业务方目前存在连接泄漏的问题。</span><br></pre></td></tr></table></figure><p><strong>过程详解</strong>:</p><p>该属性是<code>ProxyLeakTaskFactory</code>类型对象，且它还会持有<code>houseKeepingExecutorService</code>这个线程池对象，用于生产<code>ProxyLeakTask</code>对象，然后利用上面的<code>houseKeepingExecutorService</code>延时运行该对象里的run方法。</p><p>该流程的触发点在上面的<a href="#%E6%B5%81%E7%A8%8B1.1.1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%88%A4%E6%B4%BB">流程1.1</a>最后包装成ProxyConnection对象的那一步，来看看具体的流程图：</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_10.png"></p><p>每次在<a href="#%E6%B5%81%E7%A8%8B1.1.1%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%88%A4%E6%B4%BB">流程1.1</a>那里生成ProxyConnection对象时，都会触发上面的流程。</p><p>由流程图可以知道，ProxyConnection对象持有PoolEntry和ProxyLeakTask的对象，其中初始化ProxyLeakTask对象时就用到了leakTaskFactory对象，通过其schedule方法可以进行ProxyLeakTask的初始化，并将其实例传递给ProxyConnection进行初始化赋值</p><p><code>ps：由图知ProxyConnection在触发回收事件时，会主动取消这个泄漏检查任务，这也是ProxyConnection需要持有ProxyLeakTask对象的原因</code></p><p>只有在leakDetectionThreshold不等于0的时候才会生成一个带有实际延时任务的ProxyLeakTask对象，否则返回无实际意义的空对象。所以要想启用连接泄漏检查，首先要把leakDetectionThreshold配置设置上，这个属性表示经过该时间后借出去的连接仍未归还，则触发连接泄漏告警。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ProxyConnection之所以要持有ProxyLeakTask对象，是因为它可以监听到连接是否触发归还操作，如果触发，则调用cancel方法取消延时任务，防止误告。</span><br></pre></td></tr></table></figure><p>由此流程可以知道，跟Druid一样，HikariCP也有连接对象泄漏检查，与Druid主动回收连接相比，HikariCP实现更加简单，仅仅是在触发时打印警告日志，不会采取具体的强制回收的措施。</p><p>与Druid一样，默认也是关闭这个流程的，因为实际开发中一般使用第三方框架，框架本身会保证及时的close连接，防止连接对象泄漏，开启与否还是取决于业务是否需要，如果一定要开启，如何设置leakDetectionThreshold的大小也是需要考虑的一件事。</p><h3 id="主流程3：生成连接对象"><a href="#主流程3：生成连接对象" class="headerlink" title="主流程3：生成连接对象"></a>主流程3：生成连接对象</h3><p>本节来讲下<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里的<code>createEntry</code>方法，这个方法利用PoolBase里的DriverDataSource对象生成一个实际的连接对象（如果忘记DriverDatasource是哪里初始化的了，可以看下主流程2里PoolBase的initializeDataSource方法的作用），然后用PoolEntry类包装成PoolEntry对象：</p><details><summary>现在来看下这个包装类有哪些主要属性</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">PoolEntry</span> <span class="keyword">implements</span> <span class="title">IConcurrentBagEntry</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(PoolEntry.class);</span><br><span class="line">    <span class="comment">//通过cas来修改state属性</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> AtomicIntegerFieldUpdater stateUpdater;</span><br><span class="line"></span><br><span class="line">    Connection connection; <span class="comment">//实际的物理连接对象</span></span><br><span class="line">    <span class="keyword">long</span> lastAccessed; <span class="comment">//触发回收时刷新该时间，表示“最近一次使用时间”</span></span><br><span class="line">    <span class="keyword">long</span> lastBorrowed; <span class="comment">//getConnection里borrow成功后刷新该时间，表示“最近一次借出的时间”</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;FieldCanBeLocal&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state = <span class="number">0</span>; <span class="comment">//连接状态，枚举值：IN_USE（使用中）、NOT_IN_USE（闲置中）、REMOVED（已移除）、RESERVED（标记为保留中）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> evict; <span class="comment">//是否被标记为废弃，很多地方用到（比如流程1.1靠这个判断连接是否已被废弃，再比如主流程4里时钟回拨时触发的直接废弃逻辑）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> ScheduledFuture&lt;?&gt; endOfLife; <span class="comment">//用于在超过连接生命周期（maxLifeTime）时废弃连接的延时任务，这里poolEntry要持有该对象，主要是因为在对象主动被关闭时（意味着不需要在超过maxLifeTime时主动失效了），需要cancel掉该任务</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> FastList openStatements; <span class="comment">//当前该连接对象上生成的所有的statement对象，用于在回收连接时主动关闭这些对象，防止存在漏关的statement</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> HikariPool hikariPool; <span class="comment">//持有pool对象</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isReadOnly; <span class="comment">//是否为只读</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> isAutoCommit; <span class="comment">//是否存在事务</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面就是整个<code>PoolEntry</code>对象里所有的属性，这里再说下<em><strong>endOfLife</strong></em>对象。</p><p>它是一个利用houseKeepingExecutorService这个线程池对象做的延时任务，这个延时任务一般在创建好连接对象后maxLifeTime左右的时间触发</p><details><summary>具体来看下createEntry代码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">private PoolEntry createPoolEntry() &#123;</span><br><span class="line"></span><br><span class="line">        final PoolEntry poolEntry = newPoolEntry(); //生成实际的连接对象</span><br><span class="line"></span><br><span class="line">        final long maxLifetime = config.getMaxLifetime(); //拿到配置好的maxLifetime</span><br><span class="line">        if (maxLifetime &gt; 0) &#123; //&lt;=0的时候不启用主动过期策略</span><br><span class="line">            // 计算需要减去的随机数</span><br><span class="line">            // 源注释：variance up to 2.5% of the maxlifetime</span><br><span class="line">            final long variance = maxLifetime &gt; 10_000 ? ThreadLocalRandom.current().nextLong(maxLifetime / 40) : 0;</span><br><span class="line">            final long lifetime = maxLifetime - variance; //生成实际的延时时间</span><br><span class="line">            poolEntry.setFutureEol(houseKeepingExecutorService.schedule(</span><br><span class="line">                    () -&gt; &#123; //实际的延时任务，这里直接触发softEvictConnection，而softEvictConnection内则会标记该连接对象为废弃状态，然后尝试修改其状态为STATE_RESERVED，若成功，则触发closeConnection（对应流程1.1.2）</span><br><span class="line">                        if (softEvictConnection(poolEntry, &quot;(connection has passed maxLifetime)&quot;, false /* not owner */)) &#123;</span><br><span class="line">                            addBagItem(connectionBag.getWaitingThreadCount()); //回收完毕后，连接池内少了一个连接，就会尝试新增一个连接对象</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    lifetime, MILLISECONDS)); //给endOfLife赋值，并且提交延时任务，lifetime后触发</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return poolEntry;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //触发新增连接任务</span><br><span class="line">    public void addBagItem(final int waiting) &#123;</span><br><span class="line">        //前排提示：addConnectionQueue和addConnectionExecutor的关系和初始化参考主流程2</span><br><span class="line"></span><br><span class="line">        //当添加连接的队列里已提交的任务超过那些因为获取不到连接而发生阻塞的线程个数时，就进行提交连接新增连接的任务</span><br><span class="line">        final boolean shouldAdd = waiting - addConnectionQueue.size() &gt;= 0; // Yes, &gt;= is intentional.</span><br><span class="line">        if (shouldAdd) &#123;</span><br><span class="line">            //提交任务给addConnectionExecutor这个线程池，PoolEntryCreator是一个实现了Callable接口的类，下面将通过流程图的方式介绍该类的call方法</span><br><span class="line">            addConnectionExecutor.submit(poolEntryCreator);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></details></details><p>可以知道，HikariCP一般通过createEntry方法来新增一个连接入池，每个连接被包装成PoolEntry对象，在创建好对象时，同时会提交一个延时任务来关闭废弃该连接，这个时间就是我们配置的maxLifeTime，为了保证不在同一时间失效，HikariCP还会利用maxLifeTime减去一个随机数作为最终的延时任务延迟时间，然后在触发废弃任务时，还会触发addBagItem，进行连接添加任务（因为废弃了一个连接，需要往池子里补充一个），该任务则交给由<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2</a>里定义好的addConnectionExecutor线程池执行，那么，现在来看下这个异步添加连接对象的任务流程：</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_11.png"></p><p>这个流程就是往连接池里加连接用的，跟<code>createEntry</code>结合起来说是因为这俩流程是紧密相关的，除此之外，<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B5%EF%BC%9A%E6%89%A9%E5%85%85%E8%BF%9E%E6%8E%A5%E6%B1%A0">主流程5：扩充连接池</a>也会触发该任务。</p><h3 id="主流程4：连接池缩容"><a href="#主流程4：连接池缩容" class="headerlink" title="主流程4：连接池缩容"></a>主流程4：连接池缩容</h3><p>HikariCP会按照 <strong>minIdle</strong> 定时清理闲置过久的连接，这个定时任务在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B2%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B1%A0%E5%AF%B9%E8%B1%A1">主流程2：初始化池对象</a>时被启用，跟上面的流程一样，也是利用 <strong>houseKeepingExecutorService</strong> 这个线程池对象做该定时任务的执行器。</p><details><summary>来看下主流程2里是怎么启用该任务的</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//housekeepingPeriodMs的默认值是30s，所以定时任务的间隔为30s</span><br><span class="line">this.houseKeeperTask = houseKeepingExecutorService.scheduleWithFixedDelay(new HouseKeeper(), 100L, housekeepingPeriodMs, MILLISECONDS);</span><br></pre></td></tr></table></figure></details><p>那么本节主要来说下HouseKeeper这个类，该类实现了Runnable接口，回收逻辑主要在其run方法内，来看看run方法的逻辑流程图：</p><p><img src="/2021/07/26/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B9%8BHikariCP%E5%AE%9E%E7%8E%B0%E8%AF%A6%E8%A7%A3/img_12.png"></p><p>上面的流程就是HouseKeeper的run方法里具体做的事情，由于系统时间回拨会导致该定时任务回收一些连接时产生误差。<br>因此存在如下判断：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//now就是当前系统时间，previous就是上次触发该任务时的时间，housekeepingPeriodMs就是隔多久触发该任务一次</span><br><span class="line">//也就是说plusMillis(previous, housekeepingPeriodMs)表示当前时间</span><br><span class="line">//如果系统时间没被回拨，那么plusMillis(now, 128)一定是大于当前时间的，如果被系统时间被回拨</span><br><span class="line">//回拨的时间超过128ms，那么下面的判断就成立，否则永远不会成立</span><br><span class="line">if (plusMillis(now, 128) &lt; plusMillis(previous, housekeepingPeriodMs))</span><br></pre></td></tr></table></figure><p>这是hikariCP在解决系统时钟被回拨时做出的一种措施，通过流程图可以看到，它是直接把池子里所有的连接对象取出来挨个儿的标记成废弃，并且尝试把状态值修改为<code>STATE_RESERVED</code>（后面会说明这些状态，这里先不深究）。</p><p>如果系统时钟没有发生改变（绝大多数情况会命中这一块的逻辑），由图知，会把当前池内所有处于<code>闲置状态(STATE_NOT_IN_USE)</code>的连接拿出来，然后计算需要检查的范围，然后循环着修改连接的状态：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//拿到所有处于闲置状态的连接</span><br><span class="line">final List notInUse = connectionBag.values(STATE_NOT_IN_USE);</span><br><span class="line">//计算出需要被检查闲置时间的数量，简单来说，池内需要保证最小minIdle个连接活着，所以需要计算出超出这个范围的闲置对象进行检查</span><br><span class="line">int toRemove = notInUse.size() - config.getMinIdle();</span><br><span class="line">for (PoolEntry entry : notInUse) &#123;</span><br><span class="line">  //在检查范围内，且闲置时间超出idleTimeout，然后尝试将连接对象状态由STATE_NOT_IN_USE变为STATE_RESERVED成功</span><br><span class="line">  if (toRemove &gt; 0 &amp;&amp; elapsedMillis(entry.lastAccessed, now) &gt; idleTimeout &amp;&amp; connectionBag.reserve(entry)) &#123;</span><br><span class="line">    closeConnection(entry, &quot;(connection has passed idleTimeout)&quot;); //满足上述条件，进行连接关闭</span><br><span class="line">    toRemove--;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">fillPool(); //因为可能回收了一些连接，所以要再次触发连接池扩充流程检查下是否需要新增连接。</span><br></pre></td></tr></table></figure><p>上面的代码就是流程图里对应的没有回拨系统时间时的流程逻辑。</p><p>该流程在<code>idleTimeout大于0（默认等于0）并且minIdle小于maxPoolSize</code>的时候才会启用，默认是不启用的，若需要启用，可以按照条件来配置。</p><h3 id="主流程5：扩充连接池"><a href="#主流程5：扩充连接池" class="headerlink" title="主流程5：扩充连接池"></a>主流程5：扩充连接池</h3><p>这个流程主要依附<code>HikariPool</code>里的<code>fillPool</code>方法，这个方法已经在上面很多流程里出现过了，它的作用就是<strong>在触发连接废弃、连接池连接不够用时，发起扩充连接数的操作</strong>。</p><details><summary>下面看下源码（为了使代码结构更加清晰，对源码做了细微改动）</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// PoolEntryCreator关于call方法的实现流程在主流程3里已经看过了，但是这里却有俩PoolEntryCreator对象，</span><br><span class="line">// 这是个较细节的地方，用于打日志用，不再说这部分，为了便于理解，只需要知道这俩对象执行的是同一块call方法即可</span><br><span class="line">private final PoolEntryCreator poolEntryCreator = new PoolEntryCreator(null);</span><br><span class="line">private final PoolEntryCreator postFillPoolEntryCreator = new PoolEntryCreator(&quot;After adding &quot;);</span><br><span class="line"></span><br><span class="line">private synchronized void fillPool() &#123;</span><br><span class="line">  // 这个判断就是根据当前池子里相关数据，推算出需要扩充的连接数，</span><br><span class="line">  // 判断方式就是利用最大连接数跟当前连接总数的差值，与最小连接数与当前池内闲置的连接数的差值，取其最小的那一个得到</span><br><span class="line">  int needAdd = Math.min(maxPoolSize - connectionBag.size(),</span><br><span class="line">  minIdle - connectionBag.getCount(STATE_NOT_IN_USE));</span><br><span class="line"></span><br><span class="line">  //减去当前排队的任务，就是最终需要新增的连接数</span><br><span class="line">  final int connectionsToAdd = needAdd - addConnectionQueue.size();</span><br><span class="line">  for (int i = 0; i &lt; connectionsToAdd; i++) &#123;</span><br><span class="line">    //一般循环的最后一次会命中postFillPoolEntryCreator任务，其实就是在最后一次会打印一次日志而已（可以忽略该干扰逻辑）</span><br><span class="line">    addConnectionExecutor.submit((i &lt; connectionsToAdd - 1) ? poolEntryCreator : postFillPoolEntryCreator);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>最终这个新增连接的任务也是交由<code>addConnectionExecutor线程池</code>来处理的，而任务的主题也是<code>PoolEntryCreator</code>，这个流程可以参考<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B3%EF%BC%9A%E7%94%9F%E6%88%90%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1">主流程3：生成连接对象</a>.</p><p>然后needAdd的推算：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Math.min(最大连接数 - 池内当前连接总数, 最小连接数 - 池内闲置的连接数)</span><br></pre></td></tr></table></figure><p>根据这个方式判断，可以保证池内的连接数永远不会超过maxPoolSize，也永远不会低于minIdle。在连接吃紧的时候，可以保证每次触发都以minIdle的数量扩容。</p><p><code>因此如果在maxPoolSize跟minIdle配置的值一样的话，在池内连接吃紧的时候，就不会发生任何扩容了。</code></p><h3 id="主流程6：连接回收"><a href="#主流程6：连接回收" class="headerlink" title="主流程6：连接回收"></a>主流程6：连接回收</h3><p>最开始说过，最终真实的物理连接对象会被包装成PoolEntry对象，存放进ConcurrentBag，然后获取时，PoolEntry对象又会被再次包装成ProxyConnection对象暴露给使用方的，那么触发连接回收，实际上就是触发ProxyConnection里的close方法：</p><details><summary>查看源码</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public final void close() throws SQLException &#123;</span><br><span class="line">  // 原注释：Closing statements can cause connection eviction, so this must run before the conditional below</span><br><span class="line">  closeStatements(); //此连接对象在业务方使用过程中产生的所有statement对象，进行统一close，防止漏close的情况</span><br><span class="line">  if (delegate != ClosedConnection.CLOSED_CONNECTION) &#123;</span><br><span class="line">    leakTask.cancel(); //取消连接泄漏检查任务，参考流程2.2</span><br><span class="line">    try &#123;</span><br><span class="line">      if (isCommitStateDirty &amp;&amp; !isAutoCommit) &#123; //在存在执行语句后并且还打开了事务，调用close时需要主动回滚事务</span><br><span class="line">        delegate.rollback(); //回滚</span><br><span class="line">        lastAccess = currentTime(); //刷新&quot;最后一次使用时间&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">      delegate = ClosedConnection.CLOSED_CONNECTION;</span><br><span class="line">      poolEntry.recycle(lastAccess); //触发回收</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>它最终会调用PoolEntry的recycle方法进行回收，除此之外，连接对象的最后一次使用时间也是在这个时候刷新的，该时间是个很重要的属性，可以用来判断一个连接对象的闲置时间.</p><details><summary>来看下PoolEntry的recycle方法</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void recycle(final long lastAccessed) &#123;</span><br><span class="line">  if (connection != null) &#123;</span><br><span class="line">    this.lastAccessed = lastAccessed; //刷新最后使用时间</span><br><span class="line">    hikariPool.recycle(this); //触发HikariPool的回收方法，把自己传过去</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>之前有说过，每个PoolEntry对象都持有HikariPool的对象，方便触发连接池的一些操作，由上述代码可以看到，最终还是会触发HikariPool里的recycle方法：</p><details><summary>再来看下HikariPool的recycle方法</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void recycle(final PoolEntry poolEntry) &#123;</span><br><span class="line">  metricsTracker.recordConnectionUsage(poolEntry); //监控指标相关，忽略</span><br><span class="line">  connectionBag.requite(poolEntry); //最终触发connectionBag的requite方法归还连接，该流程参考ConnectionBag主流程里的requite方法部分</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h3 id="ConcurrentBag主流程"><a href="#ConcurrentBag主流程" class="headerlink" title="ConcurrentBag主流程"></a>ConcurrentBag主流程</h3><p>当前主流数据库连接池实现方式，大都用两个阻塞队列来实现。一个用于保存空闲数据库连接的队列 idle，另一个用于保存忙碌数据库连接的队列 busy；获取连接时将空闲的数据库连接从 idle 队列移动到 busy 队列，而关闭连接时将数据库连接从 busy 移动到 idle。这种方案将并发问题委托给了阻塞队列，实现简单，但是性能并不是很理想。因为 Java SDK 中的阻塞队列是用锁实现的，而高并发场景下锁的争用对性能影响很大。</p><p>HiKariCP 并没有使用 Java SDK 中的阻塞队列，而是自己实现了一个叫做 ConcurrentBag 的并发容器，在连接池（多线程数据交互）的实现上具有比LinkedBlockingQueue和LinkedTransferQueue更优越的性能。</p><p>ConcurrentBag 中的关键属性</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 存放共享元素，用于存储所有的数据库连接</span><br><span class="line">private final CopyOnWriteArrayList&lt;T&gt; sharedList;</span><br><span class="line">// 在 ThreadLocal 缓存线程本地的数据库连接，避免线程争用</span><br><span class="line">private final ThreadLocal&lt;List&lt;Object&gt;&gt; threadList;</span><br><span class="line">// 等待数据库连接的线程数</span><br><span class="line">private final AtomicInteger waiters;</span><br><span class="line">// 接力队列，用来分配数据库连接</span><br><span class="line">private final SynchronousQueue&lt;T&gt; handoffQueue;</span><br></pre></td></tr></table></figure><p>这个类用来存放最终的PoolEntry类型的连接对象，提供了基本的增删查的功能，被HikariPool持有，上面那么多的操作，几乎都是在HikariPool中完成的，HikariPool用来管理实际的连接生产动作和回收动作，实际操作的却是ConcurrentBag类，梳理下上面所有流程的触发点：</p><ul><li>流程1.1：通过HikariPool获取连接时，通过调用<strong>ConcurrentBag.borrow</strong>拿到一个连接对象。</li><li>流程1.1.2：触发关闭连接时，会通过<strong>ConcurrentBag.remove</strong>移除连接对象，由前面的流程可知关闭连接触发点为：连接超过最大生命周期maxLifeTime主动废弃、健康检查不通过主动废弃、连接池缩容。</li><li>主流程2：初始化HikariPool时初始化ConcurrentBag（构造方法），预热时通过createEntry拿到连接对象，调用<strong>ConcurrentBag.add</strong>添加连接到ConcurrentBag。</li><li>主流程3：通过异步添加连接时，通过调用<strong>ConcurrentBag.add</strong>添加连接到ConcurrentBag，由前面的流程可知添加连接触发点为：连接超过最大生命周期maxLifeTime主动废弃连接后、连接池扩容。</li><li>主流程4：连接池缩容任务，通过调用<strong>ConcurrentBag.values</strong>筛选出需要的做操作的连接对象，然后再通过<strong>ConcurrentBag.reserve</strong>完成对连接对象状态的修改，然后会通过流程1.1.2触发关闭和移除连接操作。</li><li>主流程6：通过<strong>ConcurrentBag.requite</strong>归还一个连接。</li></ul><p>通过触发点整理，可以知道该结构里的主要方法，就是上面触发点里整理的部分。</p><details><summary>具体看下该类的基本定义和主要方法</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcurrentBag</span>&lt;<span class="title">T</span> <span class="keyword">extends</span> <span class="title">IConcurrentBagEntry</span>&gt; <span class="keyword">implements</span> <span class="title">AutoCloseable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CopyOnWriteArrayList&lt;T&gt; sharedList; <span class="comment">//最终存放PoolEntry对象的地方，它是一个CopyOnWriteArrayList</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> weakThreadLocals; <span class="comment">//默认false，为true时可以让一个连接对象在下方threadList里的list内处于弱引用状态，防止内存泄漏（参见备注1）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ThreadLocal&lt;List&lt;Object&gt;&gt; threadList; <span class="comment">//线程级的缓存，从sharedList拿到的连接对象，会被缓存进当前线程内，borrow时会先从缓存中拿，从而达到池内无锁实现</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> IBagStateListener listener; <span class="comment">//内部接口，HikariPool实现了该接口，主要用于ConcurrentBag主动通知HikariPool触发添加连接对象的异步操作（也就是主流程3里的addConnectionExecutor所触发的流程）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger waiters; <span class="comment">//当前因为获取不到连接而发生阻塞的业务线程数，这个在之前的流程里也出现过，比如主流程3里addBagItem就会根据该指标进行判断是否需要新增连接</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> closed; <span class="comment">//标记当前ConcurrentBag是否已被关闭</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> SynchronousQueue&lt;T&gt; handoffQueue; <span class="comment">//这是个即产即销的队列，用于在连接不够用时，及时获取到add方法里新创建的连接对象，详情可以参考下面borrow和add的代码</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//内部接口，PoolEntry类实现了该接口</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IConcurrentBagEntry</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//连接对象的状态，前面的流程很多地方都已经涉及到了，比如主流程4的缩容</span></span><br><span class="line">        <span class="keyword">int</span> STATE_NOT_IN_USE = <span class="number">0</span>; <span class="comment">//闲置</span></span><br><span class="line">        <span class="keyword">int</span> STATE_IN_USE = <span class="number">1</span>; <span class="comment">//使用中</span></span><br><span class="line">        <span class="keyword">int</span> STATE_REMOVED = -<span class="number">1</span>; <span class="comment">//已废弃</span></span><br><span class="line">        <span class="keyword">int</span> STATE_RESERVED = -<span class="number">2</span>; <span class="comment">//标记保留，介于闲置和废弃之间的中间状态，主要由缩容那里触发修改</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">boolean</span> <span class="title">compareAndSet</span><span class="params">(<span class="keyword">int</span> expectState, <span class="keyword">int</span> newState)</span></span>; <span class="comment">//尝试利用cas修改连接对象的状态值</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setState</span><span class="params">(<span class="keyword">int</span> newState)</span></span>; <span class="comment">//设置状态值</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">int</span> <span class="title">getState</span><span class="params">()</span></span>; <span class="comment">//获取状态值</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//参考上面listener属性的解释</span></span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IBagStateListener</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">addBagItem</span><span class="params">(<span class="keyword">int</span> waiting)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">borrow</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">final</span> TimeUnit timeUnit)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//回收连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requite</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//添加连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//移除连接方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//根据连接状态值获取当前池子内所有符合条件的连接集合</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List <span class="title">values</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取当前池子内所有的连接</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List <span class="title">values</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//利用cas把传入的连接对象的state从 STATE_NOT_IN_USE 变为 STATE_RESERVED</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">reserve</span><span class="params">(<span class="keyword">final</span> T bagEntry)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取当前池子内符合传入状态值的连接数量</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCount</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> state)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//省略...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>ConcurrentBag 实现采用了queue-stealing的机制获取元素：首先尝试从ThreadLocal中获取属于当前线程的元素来避免锁竞争，如果没有可用元素则再次从共享的CopyOnWriteArrayList中获取。此外，ThreadLocal和CopyOnWriteArrayList在ConcurrentBag中都是成员变量，线程间不共享，避免了伪共享(false sharing)的发生。同时因为线程本地存储中的连接是可以被其他线程窃取的，在共享队列中获取空闲连接，所以需要用 CAS 方法防止重复分配。</p><details><summary>ConcurrentBag具体方法详细阅读</summary><h4 id="borrow"><a href="#borrow" class="headerlink" title="borrow"></a>borrow</h4><p>这个方法用来获取一个可用的连接对象，触发点为流程1.1，HikariPool就是利用该方法获取连接的。</p><details><summary>下面来看下该方法做了什么</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">public T borrow(long timeout, final TimeUnit timeUnit) throws InterruptedException &#123;</span><br><span class="line">    // 源注释：Try the thread-local list first</span><br><span class="line">    final List&lt;Object&gt; list = threadList.get(); //首先从当前线程的缓存里拿到之前被缓存进来的连接对象集合</span><br><span class="line">    for (int i = list.size() - 1; i &gt;= 0; i--) &#123;</span><br><span class="line">        final Object entry = list.remove(i); //先移除，回收方法那里会再次add进来</span><br><span class="line">        final T bagEntry = weakThreadLocals ? ((WeakReference&lt;T&gt;) entry).get() : (T) entry; //默认不启用弱引用</span><br><span class="line">        // 获取到对象后，通过cas尝试把其状态从STATE_NOT_IN_USE 变为 STATE_IN_USE，注意，这里如果其他线程也在使用这个连接对象，</span><br><span class="line">        // 并且成功修改属性，那么当前线程的cas会失败，那么就会继续循环尝试获取下一个连接对象</span><br><span class="line">        if (bagEntry != null &amp;&amp; bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">            return bagEntry; //cas设置成功后，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 源注释：Otherwise, scan the shared list ... then poll the handoff queue</span><br><span class="line">    final int waiting = waiters.incrementAndGet(); //如果缓存内找不到一个可用的连接对象，则认为需要“回源”，waiters+1</span><br><span class="line">    try &#123;</span><br><span class="line">        for (T bagEntry : sharedList) &#123;</span><br><span class="line">            //循环sharedList，尝试把连接状态值从STATE_NOT_IN_USE 变为 STATE_IN_USE</span><br><span class="line">            if (bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">                // 源注释：If we may have stolen another waiter&#x27;s connection, request another bag add.</span><br><span class="line">                if (waiting &gt; 1) &#123; //阻塞线程数大于1时，需要触发HikariPool的addBagItem方法来进行添加连接入池，这个方法的实现参考主流程3</span><br><span class="line">                    listener.addBagItem(waiting - 1);</span><br><span class="line">                &#125;</span><br><span class="line">                return bagEntry; //cas设置成功，跟上面的逻辑一样，表示当前线程绕过其他线程干扰，成功获取到该连接对象，直接返回</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //走到这里说明不光线程缓存里的列表竞争不到连接对象，连sharedList里也找不到可用的连接，这时则认为需要通知HikariPool，该触发添加连接操作了</span><br><span class="line">        listener.addBagItem(waiting);</span><br><span class="line"></span><br><span class="line">        timeout = timeUnit.toNanos(timeout); //这时候开始利用timeout控制获取时间</span><br><span class="line">        do &#123;</span><br><span class="line">            final long start = currentTime();</span><br><span class="line">            //尝试从handoffQueue队列里获取最新被加进来的连接对象（一般新入的连接对象除了加进sharedList之外，还会被offer进该队列）</span><br><span class="line">            final T bagEntry = handoffQueue.poll(timeout, NANOSECONDS);</span><br><span class="line">            //如果超出指定时间后仍然没有获取到可用的连接对象，或者获取到对象后通过cas设置成功，这两种情况都不需要重试，直接返回对象</span><br><span class="line">            if (bagEntry == null || bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_IN_USE)) &#123;</span><br><span class="line">                return bagEntry;</span><br><span class="line">            &#125;</span><br><span class="line">            //走到这里说明从队列内获取到了连接对象，但是cas设置失败，说明又该对象又被其他线程率先拿去用了，若时间还够，则再次尝试获取</span><br><span class="line">            timeout -= elapsedNanos(start); //timeout减去消耗的时间，表示下次循环可用时间</span><br><span class="line">        &#125; while (timeout &gt; 10_000); //剩余时间大于10s时才继续进行，一般情况下，这个循环只会走一次，因为timeout很少会配的比10s还大</span><br><span class="line"></span><br><span class="line">        return null; //超时，仍然返回null</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        waiters.decrementAndGet(); //这一步出去后，HikariPool收到borrow的结果，算是走出阻塞，所以waiters-1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>仔细看下注释，该过程大致分成三个主要步骤：</p><ol><li>从线程缓存获取连接</li><li>获取不到再从sharedList里获取</li><li>都获取不到则触发添加连接逻辑，并尝试从队列里获取新生成的连接对象</li></ol><h4 id="add"><a href="#add" class="headerlink" title="add"></a>add</h4><p>这个流程会添加一个连接对象进入bag，通常由<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B3%EF%BC%9A%E7%94%9F%E6%88%90%E8%BF%9E%E6%8E%A5%E5%AF%B9%E8%B1%A1">主流程3：生成连接对象</a>里的addBagItem方法通过addConnectionExecutor异步任务触发添加操作，该方法主流程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">public void add(final T bagEntry) &#123;</span><br><span class="line"></span><br><span class="line">    sharedList.add(bagEntry); //直接加到sharedList里去</span><br><span class="line"></span><br><span class="line">    // 源注释：spin until a thread takes it or none are waiting</span><br><span class="line">    // 参考borrow流程，当存在线程等待获取可用连接，并且当前新入的这个连接状态仍然是闲置状态，且队列里无消费者等待获取时，发起一次线程调度</span><br><span class="line">    while (waiters.get() &gt; 0 &amp;&amp; bagEntry.getState() == STATE_NOT_IN_USE &amp;&amp; !handoffQueue.offer(bagEntry)) &#123; //注意这里会offer一个连接对象入队列</span><br><span class="line">        yield();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>结合borrow来理解的话，这里在存在等待线程时会添加一个连接对象入队列，可以让borrow里发生等待的地方更容易poll到这个连接对象。</p><h4 id="requite"><a href="#requite" class="headerlink" title="requite"></a>requite</h4><p>这个流程会回收一个连接，该方法的触发点在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B6%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%9B%9E%E6%94%B6">主流程6：连接回收</a></p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public void requite(final T bagEntry) &#123;</span><br><span class="line">    bagEntry.setState(STATE_NOT_IN_USE); //回收意味着使用完毕，更改state为STATE_NOT_IN_USE状态</span><br><span class="line"></span><br><span class="line">    for (int i = 0; waiters.get() &gt; 0; i++) &#123; //如果存在等待线程的话，尝试传给队列，让borrow获取</span><br><span class="line">        if (bagEntry.getState() != STATE_NOT_IN_USE || handoffQueue.offer(bagEntry)) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        else if ((i &amp; 0xff) == 0xff) &#123;</span><br><span class="line">            parkNanos(MICROSECONDS.toNanos(10));</span><br><span class="line">        &#125;</span><br><span class="line">        else &#123;</span><br><span class="line">            yield();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    final List&lt;Object&gt; threadLocalList = threadList.get();</span><br><span class="line">    if (threadLocalList.size() &lt; 50) &#123; //线程内连接集合的缓存最多50个，这里回收连接时会再次加进当前线程的缓存里，方便下次borrow获取</span><br><span class="line">        threadLocalList.add(weakThreadLocals ? new WeakReference&lt;&gt;(bagEntry) : bagEntry); //默认不启用弱引用，若启用的话，则缓存集合里的连接对象没有内存泄露的风险</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h4><p>这个负责从池子里移除一个连接对象，触发点在流程1.1.2。</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public boolean remove(final T bagEntry) &#123;</span><br><span class="line">    // 下面两个cas操作，都是从其他状态变为移除状态，任意一个成功，都不会走到下面的warn log</span><br><span class="line">    if (!bagEntry.compareAndSet(STATE_IN_USE, STATE_REMOVED) &amp;&amp; !bagEntry.compareAndSet(STATE_RESERVED, STATE_REMOVED) &amp;&amp; !closed) &#123;</span><br><span class="line">        LOGGER.warn(&quot;Attempt to remove an object from the bag that was not borrowed or reserved: &#123;&#125;&quot;, bagEntry);</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 直接从sharedList移除掉</span><br><span class="line">    final boolean removed = sharedList.remove(bagEntry);</span><br><span class="line">    if (!removed &amp;&amp; !closed) &#123;</span><br><span class="line">        LOGGER.warn(&quot;Attempt to remove an object from the bag that does not exist: &#123;&#125;&quot;, bagEntry);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return removed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>移除时仅仅移除了sharedList里的对象，各个线程内缓存的那一份集合里对应的对象并没有被移除，这个时候会不会存在该连接再次从缓存里拿到呢？</p><p>会的，但是不会返回出去，而是直接remove掉了，仔细看borrow的代码发现状态不是闲置状态的时候，取出来时就会remove掉，然后也拿不出去，自然也不会触发回收方法。</p><h4 id="values"><a href="#values" class="headerlink" title="values"></a>values</h4><p>该方法存在重载方法，用于返回当前池子内连接对象的集合，触发点在<a href="#%E4%B8%BB%E6%B5%81%E7%A8%8B4%EF%BC%9A%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%BC%A9%E5%AE%B9">主流程4：连接池缩容</a>，代码如下：</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">public List values(final int state) &#123;</span><br><span class="line">    //过滤出来符合状态值的对象集合逆序后返回出去</span><br><span class="line">    final List list = sharedList.stream().filter(e -&gt; e.getState() == state).collect(Collectors.toList());</span><br><span class="line">    Collections.reverse(list);</span><br><span class="line">    return list;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public List values() &#123;</span><br><span class="line">    //返回全部连接对象（注意下方clone为浅拷贝）</span><br><span class="line">    return (List) sharedList.clone();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="reserve"><a href="#reserve" class="headerlink" title="reserve"></a>reserve</h4><p>该方法单纯将连接对象的状态值由STATE_NOT_IN_USE修改为STATE_RESERVED，触发点仍然是主流程4，缩容时使用：</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public boolean reserve(final T bagEntry)&#123;</span><br><span class="line">   return bagEntry.compareAndSet(STATE_NOT_IN_USE, STATE_RESERVED);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="getCount"><a href="#getCount" class="headerlink" title="getCount"></a>getCount</h4><p>该方法用于返回池内符合某个状态值的连接的总数量，触发点为主流程5，扩充连接池时用于获取闲置连接总数。</p><details><summary>具体代码如下</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public int getCount(final int state)&#123;</span><br><span class="line">   int count = 0;</span><br><span class="line">   for (IConcurrentBagEntry e : sharedList) &#123;</span><br><span class="line">      if (e.getState() == state) &#123;</span><br><span class="line">         count++;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   return count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details></details><h2 id="基于FastList的性能优化"><a href="#基于FastList的性能优化" class="headerlink" title="基于FastList的性能优化"></a>基于FastList的性能优化</h2><p>首先我们来看一下执行数据库操作规范化的操作步骤：</p><ol><li>通过数据源获取一个数据库连接；</li><li>创建 Statement；</li><li>执行 SQL；</li><li>通过 ResultSet 获取 SQL 执行结果；</li><li>释放 ResultSet；</li><li>释放 Statement；</li><li>释放数据库连接。</li></ol><p>当前所有数据库连接池都是严格地根据这个顺序来进行数据库操作的，为了防止最后的释放操作，各类数据库连接池都会把创建的 Statement 保存在数组 ArrayList 里，来保证当关闭连接的时候，可以依次将数组中的所有 Statement 关闭。</p><p>HiKariCP 在处理这一步骤中，认为 ArrayList 的某些方法操作存在优化空间，因此对List接口的精简实现，针对List接口中核心的几个方法进行优化，其他部分与ArrayList基本一致。</p><ul><li>首先是get()方法<ul><li>ArrayList每次调用get()方法时都会进行rangeCheck检查索引是否越界，FastList的实现中去除了这一检查，是因为数据库连接池满足索引的合法性，能保证不会越界，此时rangeCheck就属于无效的计算开销，所以不用每次都进行越界检查。省去频繁的无效操作，可以明显地减少性能消耗。</li></ul></li><li>其次是remove方法<ul><li>当通过 conn.createStatement() 创建一个 Statement 时，需要调用 ArrayList 的 add() 方法加入到 ArrayList 中，这个是没有问题的；但是当通过 stmt.close() 关闭 Statement 的时候，需要调用 ArrayList 的 remove() 方法来将其从 ArrayList 中删除，而ArrayList的remove(Object)方法是从头开始遍历数组，而FastList是从数组的尾部开始遍历，因此更为高效。</li><li>相比于ArrayList的 remove()代码， FastList 去除了检查范围 和 从头到尾遍历检查元素的步骤，其性能更快。</li></ul></li></ul><p>总体而言，FastList 的优化点还是很简单的。相比ArrayList仅仅是去掉了rage检查，扩容优化等细节处，删除时数组从后往前遍历查找元素等微小的调整，从而追求性能极致。</p><p>当然FastList 对于 ArrayList 的优化，我们不能说ArrayList不好。所谓定位不同、追求不同，ArrayList作为通用容器，更追求安全、稳定，操作前rangeCheck检查，对非法请求直接抛出异常，更符合 fail-fast(快速失败)机制，而FastList追求的是性能极致。</p><h2 id="通过字节码修改类库Javassist完成字节码精简"><a href="#通过字节码修改类库Javassist完成字节码精简" class="headerlink" title="通过字节码修改类库Javassist完成字节码精简"></a>通过字节码修改类库Javassist完成字节码精简</h2><p>待补充，具体实现参考文章<a href="https://mp.weixin.qq.com/s?__biz=MzUzNTY4NTYxMA==&mid=2247483812&idx=1&sn=0fa3e648f853b840ed8a1c2f19468d6d&chksm=fa80f121cdf778379c70219665ef9c36d66dd0d6c6547add55a8fd920d523c6738835af308f7&scene=21#wechat_redirect">HikariCP源码分析之字节码修改类库Javassist委托实现动态代理</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是数据库连接池，为什么需要数据库连接池&quot;&gt;&lt;a href=&quot;#什么是数据库连接池，为什么需要数据库连接池&quot; class=&quot;headerlink&quot; title=&quot;什么是数据库连接池，为什么需要数据库连接池&quot;&gt;&lt;/a&gt;什么是数据库连接池，为什么需要数据库连接池&lt;/</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Spring生态" scheme="http://example.com/tags/Spring%E7%94%9F%E6%80%81/"/>
    
    <category term="池化设计" scheme="http://example.com/tags/%E6%B1%A0%E5%8C%96%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="数据库连接池" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之Kafka复制原理</title>
    <link href="http://example.com/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/</id>
    <published>2021-07-20T10:03:58.000Z</published>
    <updated>2021-07-26T10:07:59.308Z</updated>
    
    <content type="html"><![CDATA[<h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/img.png"></p><h4 id="HW（High-Watermark）："><a href="#HW（High-Watermark）：" class="headerlink" title="HW（High Watermark）："></a>HW（High Watermark）：</h4><ul><li>在分区高水位以下的消息被认为是已提交消息，反之就是未提交消息；</li><li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的；</li><li>小于等于HW值的所有消息都被认为是“已备份”的（replicated）。</li></ul><h4 id="LEO（Log-End-Offset）"><a href="#LEO（Log-End-Offset）" class="headerlink" title="LEO（Log End Offset）"></a>LEO（Log End Offset）</h4><ul><li>记录了该副本底层日志(log)中下一条消息的位移值（注意是下一条消息！！）</li><li>数字 15 所在的方框是虚线，这就说明，这个副本当前只有 15 条消息，位移值是从 0 到 14，下一条新消息的位移是 15；</li></ul><h3 id="更新机制"><a href="#更新机制" class="headerlink" title="更新机制"></a>更新机制</h3><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86/img_1.png"></p><p><strong>流程如下</strong></p><ol><li>生产者写入消息到leader副本</li><li>leader副本LEO值更新</li><li>follower副本尝试拉取消息，发现有消息可以拉取，更新自身LEO</li><li>follower副本继续尝试拉取消息，这时会更新remote副本LEO，同时会更新leader副本的HW</li><li>完成4步骤后，leader副本会将已更新过的HW发送给所有follower副本</li><li>follower副本接收leader副本HW，更新自身的HW</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Kafka副本之间的数据复制既不是完全的同步复制，也不是单纯的异步复制；</span><br><span class="line">Leader副本的HW更新原则：取当前leader副本的LEO和所有remote副本的LEO的最小值</span><br><span class="line">Follower副本的HW更新原则：取leader副本发送的HW和自身的LEO中的最小值</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;预备知识&quot;&gt;&lt;a href=&quot;#预备知识&quot; class=&quot;headerlink&quot; title=&quot;预备知识&quot;&gt;&lt;/a&gt;预备知识&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列之Kafka重平衡机制简读</title>
    <link href="http://example.com/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/"/>
    <id>http://example.com/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/</id>
    <published>2021-07-20T07:46:57.000Z</published>
    <updated>2021-07-22T06:51:27.321Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是Rebalance"><a href="#什么是Rebalance" class="headerlink" title="什么是Rebalance"></a>什么是Rebalance</h3><p>如果对RocketMQ或者对消息中间件有所了解的话，消费端在进行消息消费时至少需要先进行队列（分区）的负载，即一个消费组内的多个消费者如何对订阅的主题中的队列进行负载均衡,当消费者新增或减少、队列增加或减少时能否自动重平衡，做到应用无感知，直接决定了程序伸缩性，其说明图如下：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img0.png"></p><p>Rebalance本质上是一种协议，规定了一个Consumer Group下的所有的Consumer如何达成一致来分配订阅Topic的每个Partition；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">比如某个group下有5个consumer，它订阅了一个具有10个分区的topic。正常情况下，Kafka平均会为每个consumer分配2个分区。这个分配的过程就叫rebalance。</span><br></pre></td></tr></table></figure><h3 id="Kafka消费端基本流程"><a href="#Kafka消费端基本流程" class="headerlink" title="Kafka消费端基本流程"></a>Kafka消费端基本流程</h3><p>在介绍kafka消费端重平衡机制之前，我们首先简单来看看消费者拉取消息的流程，从整个流程来看重平衡的触发时机、在整个消费流程中所起的重要作用，消费端拉取消息的简要流程如下图所示：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img1.png"></p><p>主要的关键点如下：</p><ul><li>判断KafkaConsumer对象是否处在多线程环境中。注意：<strong>该对象是多线程不安全的，不能有多个线程持有该对象。</strong></li><li>消费组初始化，包含了队列负载(重平衡)</li><li>消息拉取</li><li>消息消费拦截器处理</li></ul><p>关于poll方法的核心无非就是两个：<strong>重平衡</strong>与<strong>消费拉取</strong>，本篇文章将重点剖析Kafka消费者的重平衡机制。</p><h3 id="消费者队列负载-重平衡-机制"><a href="#消费者队列负载-重平衡-机制" class="headerlink" title="消费者队列负载(重平衡)机制"></a>消费者队列负载(重平衡)机制</h3><p>通过对updateAssignmentMetadataIfNeeded方法的源码剖析，最终调用的核心方法为ConsumerCoordinator的poll方法，核心流程图如下：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img2.png"></p><p>消费者协调器的核心流程关键点：</p><ul><li>消费者协调器寻找组协调器</li><li>队列负载(重平衡)</li><li>提交位点</li></ul><p><strong>Some Question</strong>  </p><ul><li>重平衡会阻塞消息消费吗？</li><li>Kafka的加入组协议哪些变更能有效减少重平衡</li><li>Kafka与RocketMQ的重平衡机制上各有什么优劣势</li></ul><h4 id="消费者协调器"><a href="#消费者协调器" class="headerlink" title="消费者协调器"></a>消费者协调器</h4><p>在Kafka中，在客户端每一个消费者会对应一个消费者协调器(ConsumerCoordinator),在服务端每一个broker会启动一个组协调器。</p><p>接下来将对该过程进行源码级别的跟踪，根据源码提练工作机制，该部分对应上面流程图中的：ensureCoordinatorReady方法。</p><details>    <summary>protected synchronized boolean ensureCoordinatorReady(final Timer timer)</summary>    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">protected synchronized boolean ensureCoordinatorReady(final Timer timer) &#123;</span><br><span class="line">    if (!coordinatorUnknown())</span><br><span class="line">        return true;</span><br><span class="line"></span><br><span class="line">    do &#123;</span><br><span class="line">        final RequestFuture&lt;Void&gt; future = lookupCoordinator();</span><br><span class="line">        client.poll(future, timer);</span><br><span class="line"></span><br><span class="line">        if (!future.isDone()) &#123;</span><br><span class="line">            // ran out of time</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (future.failed()) &#123;</span><br><span class="line">            if (future.isRetriable()) &#123;</span><br><span class="line">                log.debug(&quot;Coordinator discovery failed, refreshing metadata&quot;);</span><br><span class="line">                client.awaitMetadataUpdate(timer);</span><br><span class="line">            &#125; else</span><br><span class="line">                throw future.exception();</span><br><span class="line">        &#125; else if (coordinator != null &amp;&amp; client.isUnavailable(coordinator)) &#123;</span><br><span class="line">            // we found the coordinator, but the connection has failed, so mark</span><br><span class="line">            // it dead and backoff before retrying discovery</span><br><span class="line">            markCoordinatorUnknown();</span><br><span class="line">            timer.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; while (coordinatorUnknown() &amp;&amp; timer.notExpired());</span><br><span class="line"></span><br><span class="line">    return !coordinatorUnknown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>该方法的关键点如下：</p><ul><li>首先判断一下当前消费者是否已找到broker端的组协调器，如果以感知，则返回true。</li><li>如果当前并没有感知组协调器，则向服务端(broker)寻找该消费组的组协调器。</li><li>寻找组协调器的过程是一个同步过程，如果出现异常，则会触发重试，但引入了重试间隔机制。</li><li>如果未超时并且没有获取组协调器，则再次尝试(do while)。</li></ul><p>核心要点为<strong>lookupCoordinator</strong>方法，该方法的核心是<strong>选择一台负载最小的broker</strong>,构建请求，向broker端查询消费组的组协调器，代码如下：</p><details>    <summary>private RequestFuture<Void> sendFindCoordinatorRequest(Node node)</Void></summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Discover the current coordinator for the group. Sends a GroupMetadata request to</span><br><span class="line"> * one of the brokers. The returned future should be polled to get the result of the request.</span><br><span class="line"> * @return A request future which indicates the completion of the metadata request</span><br><span class="line"> */</span><br><span class="line">private RequestFuture&lt;Void&gt; sendFindCoordinatorRequest(Node node) &#123;</span><br><span class="line">    // initiate the group metadata request</span><br><span class="line">    log.debug(&quot;Sending FindCoordinator request to broker &#123;&#125;&quot;, node);</span><br><span class="line">    FindCoordinatorRequest.Builder requestBuilder =</span><br><span class="line">            new FindCoordinatorRequest.Builder(</span><br><span class="line">                    new FindCoordinatorRequestData()</span><br><span class="line">                        .setKeyType(CoordinatorType.GROUP.id())</span><br><span class="line">                        .setKey(this.groupId));</span><br><span class="line">    return client.send(node, requestBuilder)</span><br><span class="line">            .compose(new FindCoordinatorResponseHandler());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>查询组协调器的请求，核心参数为：</p><ul><li><p>ApiKeys apiKey<br>  请求API，类比RocketMQ的RequestCode，根据该值很容易找到服务端对应的处理代码，这里为ApiKeys.FIND_COORDINATOR。</p></li><li><p>String coordinatorKey<br>  协调器key，取消费组名称。</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka服务端每一台Broker会创建一个组协调器(GroupCoordinator),每一个组协调器可以协调多个消费组，但一个消费组只会被分配给一个组协调器，那这里负载机制是什么呢？服务端众多Broker如何竞争该消费组的控制权呢？</span><br></pre></td></tr></table></figure></li><li><p>coordinatorType<br>协调器类型，默认为GROUP,表示普通消费组。</p></li><li><p>short minVersion<br>版本。</p></li></ul><p>针对客户端端请求，服务端统一入口为KafkaApis.scala，可以根据ApiKeys快速找到其处理入口：<br><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img.png"><br>具体的处理逻辑在KafkaApis的handleFindCoordinatorRequest中，如下图所示:<br><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_1.png"></p><p>服务端为消费组分配协调器的核心算法竟然非常简单：</p><ul><li>根据消费组的名称，取hashcode，</li><li>然后与kafka内部topic(__consumer_offsets)的分区个数取模，</li><li>然后返回该分区所在的物理broker作为消费组的分组协调器</li><li>即内部并没有复杂的选举机制，这样也能更好的说明，客户端在发送请求时可以挑选负载最低的broker进行查询的原因。</li></ul><p>客户端收到响应结果后更新ConsumerCoordinator的(Node coordinator)属性，这样再次调用coordinatorUnknown()方法，将会返回false,至此完成消费端协调器的查找。</p><h4 id="消费者加入消费组流程剖析"><a href="#消费者加入消费组流程剖析" class="headerlink" title="消费者加入消费组流程剖析"></a>消费者加入消费组流程剖析</h4><p>用一张时序图来说明协调者一端是如何处理新成员入组的:<br><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_21.png"></p><p>在消费者获取到协调器后，根据上文提到的协调器处理流程，接下来消费者需要加入到消费者组中，加入到消费组也是参与队列负载机制的前提，接下来我们从源码角度分析一下消费组加入消费组的流程，对应上文中的<strong>AbstractCoordinator的ensureActiveGroup</strong>方法。</p><details>    <summary>boolean ensureActiveGroup(final Timer timer)</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Ensure the group is active (i.e., joined and synced)</span><br><span class="line"> *</span><br><span class="line"> * @param timer Timer bounding how long this method can block</span><br><span class="line"> * @return true iff the group is active</span><br><span class="line"> */</span><br><span class="line">boolean ensureActiveGroup(final Timer timer) &#123;</span><br><span class="line">    // always ensure that the coordinator is ready because we may have been disconnected</span><br><span class="line">    // when sending heartbeats and does not necessarily require us to rejoin the group.</span><br><span class="line">    if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    startHeartbeatThreadIfNeeded();</span><br><span class="line">    return joinGroupIfNeeded(timer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>该方法的核心关键点：</p><ul><li>在加入消费组之前必须确保该消费者已经感知到组协调器。</li><li>启动心跳线程，当消费者加入到消费组后处于MemberState.STABLE后需要定时向协调器上报心跳，表示存活，否则将从消费组中移除。</li><li>加入消费组。</li></ul><p>心跳线程稍后会详细介绍，先跟踪一下加入消费组的核心流程，具体实现方法为</p><details><summary>joinGroupIfneeded</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Joins the group without starting the heartbeat thread.</span><br><span class="line"> *</span><br><span class="line"> * Visible for testing.</span><br><span class="line"> *</span><br><span class="line"> * @param timer Timer bounding how long this method can block</span><br><span class="line"> * @return true iff the operation succeeded</span><br><span class="line"> */</span><br><span class="line">boolean joinGroupIfNeeded(final Timer timer) &#123;</span><br><span class="line">    while (rejoinNeededOrPending()) &#123;</span><br><span class="line">        if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span><br><span class="line">        // time if the client is woken up before a pending rebalance completes. This must be called</span><br><span class="line">        // on each iteration of the loop because an event requiring a rebalance (such as a metadata</span><br><span class="line">        // refresh which changes the matched subscription set) can occur while another rebalance is</span><br><span class="line">        // still in progress.</span><br><span class="line">        if (needsJoinPrepare) &#123;</span><br><span class="line">            onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">            needsJoinPrepare = false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        final RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br><span class="line">        client.poll(future, timer);</span><br><span class="line">        if (!future.isDone()) &#123;</span><br><span class="line">            // we ran out of time</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (future.succeeded()) &#123;</span><br><span class="line">            // Duplicate the buffer in case `onJoinComplete` does not complete and needs to be retried.</span><br><span class="line">            ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line">            onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br><span class="line"></span><br><span class="line">            // We reset the join group future only after the completion callback returns. This ensures</span><br><span class="line">            // that if the callback is woken up, we will retry it on the next joinGroupIfNeeded.</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            needsJoinPrepare = true;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            resetJoinGroupFuture();</span><br><span class="line">            final RuntimeException exception = future.exception();</span><br><span class="line">            if (exception instanceof UnknownMemberIdException ||</span><br><span class="line">                    exception instanceof RebalanceInProgressException ||</span><br><span class="line">                    exception instanceof IllegalGenerationException ||</span><br><span class="line">                    exception instanceof MemberIdRequiredException)</span><br><span class="line">                continue;</span><br><span class="line">            else if (!future.isRetriable())</span><br><span class="line">                throw exception;</span><br><span class="line"></span><br><span class="line">            timer.sleep(retryBackoffMs);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>接下来对该方法进行分步解读：</p><ol><li><p>加入消费组之前必须先获取对应的组协调器，因为后续所有的请求都是需要发送到组协调器上。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (!ensureCoordinatorReady(timer)) &#123;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>每一次执行重平衡之前调用其回调函数，我们可以看看ConsumerCoordinatory的实现</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// call onJoinPrepare if needed. We set a flag to make sure that we do not call it a second</span><br><span class="line">// time if the client is woken up before a pending rebalance completes. This must be called</span><br><span class="line">// on each iteration of the loop because an event requiring a rebalance (such as a metadata</span><br><span class="line">// refresh which changes the matched subscription set) can occur while another rebalance is</span><br><span class="line">// still in progress.</span><br><span class="line">if (needsJoinPrepare) &#123;</span><br><span class="line">    onJoinPrepare(generation.generationId, generation.memberId);</span><br><span class="line">    needsJoinPrepare = false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void onJoinPrepare(int generation, String memberId) &#123;</span><br><span class="line">    // commit offsets prior to rebalance if auto-commit enabled</span><br><span class="line">    maybeAutoCommitOffsetsSync(time.timer(rebalanceTimeoutMs));</span><br><span class="line"></span><br><span class="line">    // execute the user&#x27;s callback before rebalance</span><br><span class="line">    ConsumerRebalanceListener listener = subscriptions.rebalanceListener();</span><br><span class="line">    Set&lt;TopicPartition&gt; revoked = subscriptions.assignedPartitions();</span><br><span class="line">    log.info(&quot;Revoking previously assigned partitions &#123;&#125;&quot;, revoked);</span><br><span class="line">    try &#123;</span><br><span class="line">        listener.onPartitionsRevoked(revoked);</span><br><span class="line">    &#125; catch (WakeupException | InterruptException e) &#123;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        log.error(&quot;User provided listener &#123;&#125; failed on partition revocation&quot;, listener.getClass().getName(), e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    isLeader = false;</span><br><span class="line">    subscriptions.resetGroupSubscription();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>消费端协调器在进行重平衡(加入一个新组)之前通常会执行如下操作：</p><ul><li>如果开启了自动提交位点，进行一次位点提交。</li><li>执行重平衡相关的事件监听器。</li></ul></li><li><p>向消费组的组协调器发送加入请求，但加入消费组并不是目的，而是手段，最终要达成的目的是进行队列的负载均衡。</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final RequestFuture&lt;ByteBuffer&gt; future = initiateJoinGroup();</span><br></pre></td></tr></table></figure></li><li><p>调用onJoinComplete方法，通知消费端协调器队列负载的最终结果</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer memberAssignment = future.value().duplicate();</span><br><span class="line">onJoinComplete(generation.generationId, generation.memberId, generation.protocol, memberAssignment);</span><br></pre></td></tr></table></figure><ul><li>generationId</li><li>memberId 成员id</li><li>protocol 协议名称，这里是consumer。</li><li>memberAssignment 队列负载结果，包含了分配给当前消费者的队列信息，其序列后的结果如图所示<br><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_2.png"></li></ul></li></ol><p>故队列的负载机制蕴含在构建请求中，接下来深入分析一下客户端与服务端详细的交互流程。</p><h5 id="构建加入消费组请求"><a href="#构建加入消费组请求" class="headerlink" title="构建加入消费组请求"></a>构建加入消费组请求</h5><p>构建加入消费组代码见AbstractCoordinator的sendJoinGroupRequest,其代码如下：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_3.png"></p><p>发起一次组加入请求，请求体主要包含如下信息：</p><ul><li>消费组的名称</li><li>session timeout，会话超时时间，默认为10s</li><li>memberId 消费组成员id,第一次为null，后续服务端会为该消费者分配一个唯一的id,构成为客户端id + uuid。</li><li>protocolType 协议类型，消费者加入消费组固定为 consumer</li><li>消费端支持的所有队列负载算法</li></ul><p>收到服务端响应后将会调用JoinGroupResponseHandler回掉，稍后会详细介绍。</p><h5 id="服务端响应逻辑"><a href="#服务端响应逻辑" class="headerlink" title="服务端响应逻辑"></a>服务端响应逻辑</h5><p>服务端处理入口：KafkaApis的handleJoinGroupRequest方法，该方法为委托给GroupCoordinator。</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_4.png"></p><p>通过这个入口，基本可以看到服务端处理加入请求的关键点：</p><ul><li>从客户端请求中提取客户端的memberId,如果为空，表示第一次加入消费组，还未分配memberId。</li><li>如果协调器中不存在该消费组的信息，表示第一次加入，创建一个，并执行doUnknownJoinGroup(第一次加入消费组逻辑)</li><li>如果协调器中已存在消费组的信息，判断一下是否已达到<strong>最大消费者个数限制</strong>(默认不限制)，超过则会抛出异常；然后根据消费者是否是第一次加入进行对应的逻辑处理。</li></ul><p><strong>组协调器会为每一个路由到的消费组维护一个组元信息(GroupMetadata)，存储在HashMap&lt; String, GroupMetadata&gt;，每一个消费组云信息中存储了当前的所有的消费者，由消费者主动加入，组协调器可以主动剔除消费者。</strong></p><p>接下来分情况处理，来看一下第一次加入(doUnknownJoinGroup)与重新加入(doJoinGroup)分别详细探讨。</p><h6 id="初次加入消费组"><a href="#初次加入消费组" class="headerlink" title="初次加入消费组"></a>初次加入消费组</h6><p>初次加入消费组的代码如下：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_5.png"></p><p>关键点如下：</p><ul><li><p>首先来看一下该方法的参数含义：</p><ul><li>GroupMetadata group: 消费组的元信息，并未持久化，存储在内存中，一个消费组当前消费者的信息。 </li><li>boolean requireKnownMemberId: 是否一定需要知道客户端id,如果客户端请求版本为4,在加入消费组时需要明确知道对方的memberId。</li><li>String clientId: 客户端ID,消息组的memberId生成规则为 clientId + uuid</li><li>String clientHost: 消费端端ip地址 </li><li>int rebalanceTimeoutMs: 重平衡超时时间，取自消费端参数max.poll.interval.ms，默认为5分钟。</li><li>int sessionTimeoutMs: 会话超时时间，默认为10s</li><li>String protocolType: 协议类型，默认为consumer</li><li>List protocols: 客户端支持的队列负载算法。</li></ul></li><li><p>对客户端进行状态验证，其校验如下：</p><ul><li>如果消费者状态为dead，则返回UNKNOWN_MEMBER_ID</li><li>如果当前消费组的负载算法协议不支持新客户端端队列负载协议，则抛出UNKNOWN_MEMBER_ID，并提示不一致的队列负载协议。</li></ul></li><li><p>Kafka 的加入请求版本4在加入消费端组时使用有明确的客户端memberId，消费组将创建的memberId加入到组的pendingMember中，并向客户端返回MEMBER_ID_REQUIRED，引导客户端重新加入，客户端会使用服务端生成的memberId，重新发起加入消费组。</p></li><li><p>调用addMemberAndRebalance方法加入消费组并触发重平衡。</p></li></ul><p>接下来继续探究加入消费组并触发重平衡的具体逻辑，具体实现见GroupCoordinator的addMemberAndRebalance。</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_6.png"></p><p>核心要点如下：</p><ul><li>组协调器为每一个消费者创建一个MemberMetadata对象。</li><li>如果消费组的状态为PreparingRebalance(此状态表示正在等待消费组加入)，并将组的newMemberAdded设置为true，表示有新成员加入，后续需要触发重平衡。</li><li>将消费组添加到组中，这里会触发一次<strong>消费组选主</strong>,选主逻辑：<strong>该消费组的第一个加入的消费者成为该消费组中的Leader</strong>, Leader的职责是什么呢？<br>  <img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_7.png"><br>总体而言： <strong>消费组Leader的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案</strong>。<ul><li>为每一个消费者创建一个DelayedHeartbeat对象，用于检测会话超时，组协调器如果检测会话超时，会将该消费者移除组，会重新触发重平衡，消费者为了避免被组协调器移除消费组，需要按间隔发送心跳包。</li><li>根据当前消费组的状态是否需要进行重平衡。</li></ul></li></ul><p>接下来继续深入跟踪maybePrepareRebalance方法，其实现如下图所示：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_8.png"></p><p>根据状态机的驱动规则，判断是否可以进入到PrepareRebalance，其判断逻辑就是根据状态机的驱动，判断当前状态是否可以进入到该状态，其具体实现是为每一个状态存储了一个可以进入当前状态的前驱状态集合。</p><p>如果符合状态驱动流程，消费组将进入到PrepareRebalance，其具体实现如下图所示：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_9.png"></p><ul><li>如果当前消费组的状态为CompletingRebalance，需要重置队列分配动作，并让消费组重新加入到消费组，即重新发送JOIN_GROUP请求。具体实现技巧：<br>  <img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_10.png"><ul><li>将所有消费者已按分配算法分配到的队列信息置空</li><li>将空的分配结果返回给消费者，并且错误码为REBALANCE_IN_PROGRESS，客户端收到该错会重新加入消费组。</li></ul></li><li>如果当前没有消费者，则创建InitialDelayedJoin，否则则创建DelayedJoin<ul><li>值得注意的是这里有一个参数：group.initial.rebalance.delay.ms，用于设置消费组进入到PreparingRebalance真正执行其业务逻辑的延迟时间，其主要目的是等待更多的消费者进入。</li><li>驱动消费组状态为PreparingRebalance。</li><li>尝试执行initialDelayedJoin或DelayedJoin的tryComplete方法，如果没有完成，则创建watch，等待执行完成，最终执行的是组协调器的相关方法，其说明如下：<br><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_11.png"><br>接下来看一下组协调器的tryCompleteJoin方法，其实现如下图所示：<br><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_12.png"></li><li>*完成PreparingRebalance状态的条件是: 已知的消费组都成功加入到消费组**。该方法返回true后，onCompleteJoin方法将被执行。</li></ul></li></ul><p>接下来看一下GroupCoordinator的onCompleteJoin方法的实现。</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_13.png"></p><p>核心的关键点如下：</p><ul><li>驱动消费组的状态转化为CompletingRebalance，将进入到重平衡的第二个阶段(队列负载)</li><li>为每一个成员构建对应JoinResponse对象，其中三个关键点<ul><li>generationId 消费组每一次状态变更，该值加一</li><li>subProtocol 当前消费者组中所有消费者都支持的队列负载算法</li><li>leaderId 消费组中的leader，一个消费组中第一个加入的消费者为leader</li></ul></li></ul><p>接下来，消费者协调器将根据服务端返回的响应结果，进行第二阶段的重平衡，即进入到队列负载算法。</p><h6 id="已知memberId加入消费组处理逻辑"><a href="#已知memberId加入消费组处理逻辑" class="headerlink" title="已知memberId加入消费组处理逻辑"></a>已知memberId加入消费组处理逻辑</h6><p>组协调在已知memberid处理加入请求的核心处理代码在GroupCoordinator的doJoinGroup中，即重新加入请求。</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_14.png"></p><ol><li>首先进行相关的错误校验<ul><li>如果消费组状态为Dead，返回错误unknown_member_id错误。</li><li>如果当前消费者支持的队列负载算法消费组并不支持，返回错误inconsistent_group_protocol</li><li>如果当前的memberid处在pendingMember中，对于这种重新加入的消费者会接受并触发重平衡。  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">值得注意的是，在Kafka JOIN_REQUEST版本为4后，首先会在服务端生成memberId,并加入到pendingMember中，并立即向客户端返回memberId,引导客户端重新加入。</span><br></pre></td></tr></table></figure></li><li>如果消费组不存在该成员，返回错误，说明消费组已经将该消费者移除。</li></ul></li><li>根据消费组的状态采取不同的行为<ul><li>如果当前状态为PreparingRebalance  更新成员的元信息，按照需要触发重平衡。  <img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_15.png">  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PreparingRebalance状态，消费组在等待消费组中的消费者加入。</span><br></pre></td></tr></table></figure></li><li>如果状态为CompletingRebalance<ul><li><p>如果收到join group请求，但其元信息并没有发生变化(队列负载算法)，只需将最新的信息返回给消费者；</p></li><li><p>如果状态发生变更，则会进行再次回到重平衡的第一阶段，消费组重新加入。</p></li></ul>  <img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_16.png">  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">消费组如果处于CompletingRebalance状态，其实不希望再收到Join Group请求，因为处于CompletingRebalance状态的消费组，正在等待消费者Leader分配队列。</span><br></pre></td></tr></table></figure></li><li>如果消费组处于Stable状态  如果成员是leader并且支持的协议发生变化，则进行重平衡，否则只需要将元信息发生给客户端即可。  <img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_17.png"></li></ul></li></ol><h6 id="客户端处理组协调器的Join-Group响应包"><a href="#客户端处理组协调器的Join-Group响应包" class="headerlink" title="客户端处理组协调器的Join Group响应包"></a>客户端处理组协调器的Join Group响应包</h6><p>客户端对Join_Group的响应处理在：JoinGroupResponseHandler，其核心实现如下：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_18.png"></p><p>关键点：</p><ul><li>队列的负载算法是由Leader节点来分配，</li><li>将分配结果通过向组协调器发送SYNC_GROUP请求，</li><li>然后组协调器从Leader节点获取分配算法后，</li><li>再返回给所有的消费者，</li><li>从而开始进行消费。</li></ul><h4 id="心跳与离开"><a href="#心跳与离开" class="headerlink" title="心跳与离开"></a>心跳与离开</h4><p>消费者通过消费者协调器与组协调器交互完成消费组的加入，但如何退出呢？例如当消费者宕机，协调器如何感知呢？</p><p>原来在Kafka中，消费者协调器会引入心跳机制，即定时向组协调器发送心跳包，在指定时间内未收到客户端的心跳包，表示会话过期，过期时间通过参数session.timeout.ms设置，默认为10s。<br><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_22.png"><br><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_23.png"></p><p>通过对ConsumerCoordinator的poll流程可知，消费者协调器在得知消费组的组协调器后，就会启动心跳线程，其代码如下：</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_19.png"></p><p>启动心跳线程后，主要关注HeartbeatThread的run方法。</p><p><img src="/2021/07/20/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%97%E4%B9%8BKafka%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6%E7%AE%80%E8%AF%BB/img_20.png"></p><p>心跳线程的核心要点如下：</p><ul><li>如果距离上一次心跳超过了会话时间，会断开与GroupCoordinator断开链接，并设置为coordinatorUnknow 为true，需要重新寻找组协调器。</li><li>如果此次心跳发送时间距离上一次心跳发送时间超过了pollTimeout，客户端将发送LEAVE_GROUP，离开消费组，并在下一个poll方法调用时重新进入加入消费组的操作，会再次触发重平衡。</li><li>如果两次心跳时间超过了单次心跳发送间隔，将发送消息。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">温馨提示：尽管心跳包通常是定时类任务，但kafka的心跳机制另辟蹊径，使用了Object的wait与notify，心跳线程与消息拉取线程相互协助，**每一次消息拉取，都会进行判断是否应该发送心跳包**。</span><br></pre></td></tr></table></figure><p>关于消费组的离开，服务端端处理逻辑比较简单，就不在这一一介绍了。</p><h3 id="重平衡机制总结"><a href="#重平衡机制总结" class="headerlink" title="重平衡机制总结"></a>重平衡机制总结</h3><p>Kafka的重平衡其实包含两个非常重要的阶段：</p><ul><li>消费组加入阶段(PreparingRebalance)<ul><li>此阶段是消费者陆续加入消费组，该组第一个加入的消费者被推举为Leader</li><li>当该组所有已知memberId的消费者全部加入后，状态驱动到CompletingRebalance。</li></ul></li><li>队列负载(CompletingRebalance)<ul><li>PreparingRebalance状态完成后，如果消费者被推举为Leader，<strong>Leader会采用该消费组中都支持的队列负载算法进行队列分布</strong>，然后将结果回报给组协调器；</li><li>如果消费者的角色为非Leader，会向组协调器发送同步队列分区算法，组协调器会将Leader节点分配的结果分配给消费者。</li></ul></li></ul><p><strong>消费组如果在进行重平衡操作，将会暂停消息消费（STW），频繁的重平衡会导致队列消息消费的速度受到极大的影响。</strong></p><p>与重平衡相关的消费端参数：</p><ul><li><p><strong>max.poll.interval.ms</strong></p><p>  两次poll方法调用的最大间隔时间，单位毫秒，默认为5分钟。如果消费端在该间隔内没有发起poll操作，该消费者将被剔除，触发重平衡，将该消费者分配的队列分配给其他消费者。</p></li><li><p><strong>session.timeout.ms</strong></p><p>  消费者与broker的心跳超时时间,默认10s，broker在指定时间内没有收到心跳请求，broker端将会将该消费者移出，并触发重平衡。</p></li><li><p><strong>heartbeat.interval.ms</strong></p><p>  心跳间隔时间，消费者会以该频率向broker发送心跳，默认为3s，主要是确保session不会失效。</p></li></ul><h4 id="重平衡触发条件—消费群组或者topic分区出现变化时"><a href="#重平衡触发条件—消费群组或者topic分区出现变化时" class="headerlink" title="重平衡触发条件—消费群组或者topic分区出现变化时"></a>重平衡触发条件—消费群组或者topic分区出现变化时</h4><ul><li>消费组内成员个数发生变化(<strong>这种情况在实际情况中更加常见。因为订阅分区数、以及订阅 topic 数都是我们主动改变才会发生，而组内消费组成员个数发生变化，则是更加随机的。</strong>)<ul><li>有新的消费者加入Consumer Group,</li><li>由消费者主动退出，Consumer Group/调用unsubscribe()取消对某Topic的订阅,</li><li>有消费者崩溃，可能由于长时间未向GroupCoordinator(协调者)发送心跳，GroupCoordinator会认为其已下线；</li></ul></li><li>订阅的 Topic 分区数出现变化；</li><li>订阅的 Topic 个数发生变化:<br>一个 consumer group 如果之前只订阅了 A topic，那么其组内的 consumer 知会消费 A topic 的消息。而如果现在新增订阅了 B topic，那么 kafka 就需要把 B topic 的 partition 分配给组内的 consumer 进行消费。</li></ul><h3 id="线上环境频繁重平衡问题实例"><a href="#线上环境频繁重平衡问题实例" class="headerlink" title="线上环境频繁重平衡问题实例"></a>线上环境频繁重平衡问题实例</h3><h4 id="消息处理逻辑太重，超过max-poll-interval-ms限制"><a href="#消息处理逻辑太重，超过max-poll-interval-ms限制" class="headerlink" title="消息处理逻辑太重，超过max.poll.interval.ms限制"></a>消息处理逻辑太重，超过max.poll.interval.ms限制</h4><h5 id="问题原因："><a href="#问题原因：" class="headerlink" title="问题原因："></a>问题原因：</h5><p>kafkaConsumer调用一次轮询方法只是拉取一次消息。客户端为了不断拉取消息，会用一个外部循环不断调用消费者的轮询方法。每次轮询到消息，在处理完这一批消息后，才会继续下一次轮询。但如果一次轮询返回的结构没办法及时处理完成，会有什么后果呢？服务端约定了和客户端max.poll.interval.ms，两次poll最大间隔。如果客户端处理一批消息花费的时间超过了这个限制时间，服务端可能就会把消费者客户端移除掉，并触发rebalance。</p><h5 id="引发出的其他问题："><a href="#引发出的其他问题：" class="headerlink" title="引发出的其他问题："></a>引发出的其他问题：</h5><p>拉取偏移量与提交偏移量：kafka的偏移量(offset)是由消费者进行管理的，偏移量有两种，拉取偏移量(position)与提交偏移量(committed)。拉取偏移量代表当前消费者分区消费进度。每次消息消费后，需要提交偏移量。在提交偏移量时，kafka会使用拉取偏移量的值作为分区的提交偏移量发送给协调者。</p><p>如果没有提交偏移量，下一次消费者重新与broker连接后，会从当前消费者group已提交到broker的偏移量处开始消费。</p><p>所以，问题就在这里，当我们处理消息时间太长时,已经被broker剔除，提交偏移量又会报错。所以拉取偏移量没有提交到broker，分区又rebalance。</p><p>下一次重新分配分区时，消费者会从最新的已提交偏移量处开始消费。</p><p>这里就出现了<strong>重复消费</strong>的问题。</p><h5 id="处理方案："><a href="#处理方案：" class="headerlink" title="处理方案："></a>处理方案：</h5><ol><li>调大max.poll.interval.ms参数值或优化消息处理逻辑 <figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">max.poll.interval.ms</span>=<span class="string">300</span></span><br></pre></td></tr></table></figure></li><li>设置分区拉取阈值<br>kafkaConsumer调用一次轮询方法只是拉取一次消息。客户端为了不断拉取消息，会用一个外部循环不断调用轮询方法poll()。每次轮询后，在处理完这一批消息后，才会继续下一次的轮询。<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">max.poll.records</span> = <span class="string">50</span></span><br></pre></td></tr></table></figure></li><li>poll到的消息，处理完一条就提交一条，当出现提交失败时，马上跳出循环，这时候kafka就会进行rebalance,下一次会继续从当前offset进行消费。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;什么是Rebalance&quot;&gt;&lt;a href=&quot;#什么是Rebalance&quot; class=&quot;headerlink&quot; title=&quot;什么是Rebalance&quot;&gt;&lt;/a&gt;什么是Rebalance&lt;/h3&gt;&lt;p&gt;如果对RocketMQ或者对消息中间件有所了解的话，消费端在</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>批处理框架之SpringBatch快速入门实践</title>
    <link href="http://example.com/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
    <id>http://example.com/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</id>
    <published>2021-07-19T08:47:31.000Z</published>
    <updated>2021-07-20T03:13:47.056Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是SpringBatch"><a href="#什么是SpringBatch" class="headerlink" title="什么是SpringBatch"></a>什么是SpringBatch</h3><p>一个轻量级，全面的<strong>批处理框架，不是一个 schuedling 的框架</strong>。</p><p>一个标准的批处理程序：</p><ul><li>通常会从数据库，文件或者队列中读取大量的数据和记录，</li><li>然后对获取的数据进行处理，</li><li>然后将修改后的格式写回到数据库中。</li></ul><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img.png"></p><p>通常 Spring Batch 在离线模式下进行工作，不需要用户干预就能自动进行基本的批处理迭代，进行类似事务方式的处理。批处理是大多数 IT 目的一个组成部分，而 Spring Batch<br>是唯一能够提供健壮的企业级扩展性的批处理开源框架。</p><h3 id="什么情况下需要用到SpringBatch"><a href="#什么情况下需要用到SpringBatch" class="headerlink" title="什么情况下需要用到SpringBatch"></a>什么情况下需要用到SpringBatch</h3><p>在大型企业中，由于业务复杂、数据量大、数据格式不同、数据交互格式繁杂，并非所有的操作都能通过交互界面进行处理。而有一些操作需要定期读取大批量的数据，然后进行一系列的后续处理。这样的过程就是“批处理”。</p><ul><li>数据量大，从数万到数百万甚至上亿不等；</li><li>整个过程全部自动化，并预留一定接口进行自定义配置；</li><li>这样的应用通常是周期性运行，比如按日、周、月运行；</li><li>对数据处理的准确性要求高，并且需要容错机制、回滚机制、完善的日志监控等。</li></ul><h3 id="SpringBatch提供了哪些功能"><a href="#SpringBatch提供了哪些功能" class="headerlink" title="SpringBatch提供了哪些功能"></a>SpringBatch提供了哪些功能</h3><ul><li>事务管理：全批次事务(因为可能有小数据量的批处理或存在存储过程/脚本中)</li><li>基于Web的管理员接口</li><li>分阶段的企业消息驱动处理</li><li>极高容量和高性能的基于块的处理过程(通过优化和分区技术)</li><li>按顺序处理任务依赖（使用工作流驱动的批处理插件）</li><li>声明式的输入/输出操作</li><li>启动、终止、（失败后的手动或定时）重启任务</li><li>重试/跳过任务，部分处理跳过记录（例如，回滚）<details><summary>具体使用场景</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在处理百万级的数据过程过程中难免会出现异常。如果一旦出现异常而导致整个批处理工作终止的话那么会导致后续的数据无法被处理。Spring Batch内置了Retry（重试）和Skip（跳过）机制帮助我们轻松处理各种异常。我 们需要将异常分为三种类型。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> 第一种是<span class="strong">**需要进行Retry的异常**</span>，它们的特点是该异常可能会随着时间推移而消失，比如数据库目前有锁无法写入、web服务当前不可用、web服务满载等。所以对它们适合配置Retry机制。</span><br><span class="line"><span class="bullet">*</span> 第二种是<span class="strong">**需要Skip的异常**</span>，比如解析文件的某条数据出现异常等，因为对这些异常即使执行Retry每次的结果也都是相同，但又不想由于某条数据出错而停止对后续数据的处理。</span><br><span class="line"><span class="bullet">*</span> 第三种异常是<span class="strong">**需要让整个Job立刻失败的异常**</span>，比如如果出现了OutOfMemory的异常，那么需要整个Job立刻终止运行。</span><br><span class="line"></span><br><span class="line">一般来说需要Retry的异常也要配置Skip选项，从而保证后续的数据能够被继续处理。我们也可以配置SkipLimit选项保证当Skip的数据条目达到一定数量后及时终止整个Job。</span><br></pre></td></tr></table></figure></details></li></ul><h3 id="SpringBatch整体架构"><a href="#SpringBatch整体架构" class="headerlink" title="SpringBatch整体架构"></a>SpringBatch整体架构</h3><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_1.png"></p><p>Spring batch框架有4个主要组件：JobLauncher、Job、Step和JobRepository。</p><ul><li>JobLauncher（任务启动器）：通过它启动任务，可以理解为程序的入口。</li><li>Job（任务）：一个具体的任务。<ul><li>由一个或多个step组成，</li><li>通过JobBuilderFactory实例创建Bean，</li><li>使用next指向下一个step,  可以按照指定的逻辑顺序组合 step,</li><li>提供了我们给所有 step 设置相同属性的方法（例如一些事件监听，跳过策略）;</li></ul></li><li>Step（步骤）：一个具体的执行步骤，一个Job中可以有多个Step。</li><li>JobRepository（任务仓库）：存储数据的仓库，在任务执行的时候，需要用它来记录任务状态信息，可以看做是一个数据库的接口。</li></ul><h4 id="JOB"><a href="#JOB" class="headerlink" title="JOB"></a>JOB</h4><p>Job 是一个封装整个批处理过程的一个概念。Job 在 spring batch 的体系当中只是一个最顶层的一个抽象概念，体现在代码当中则它只是一个最上层的接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Batch domain object representing a job. Job is an explicit abstraction</span></span><br><span class="line"><span class="comment"> * representing the configuration of a job specified by a developer. It should</span></span><br><span class="line"><span class="comment"> * be noted that restart policy is applied to the job as a whole and not to a</span></span><br><span class="line"><span class="comment"> * step.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"> <span class="function">String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">boolean</span> <span class="title">isRestartable</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecution execution)</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersIncrementer <span class="title">getJobParametersIncrementer</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersValidator <span class="title">getJobParametersValidator</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Job 这个接口当中定义了五个方法，它的实现类主要有两种类型的 job，一个是 simplejob，另一个是 flowjob。</p><p>Spring Batch 以 SimpleJob 类的形式提供了 Job 接口的默认简单实现，它在 Job 之上创建了一些标准功能。一个使用 java config 的例子代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job footballJob() &#123;</span><br><span class="line">    return this.jobBuilderFactory.get(&quot;footballJob&quot;)</span><br><span class="line">                     .start(playerLoad())</span><br><span class="line">                     .next(gameLoad())</span><br><span class="line">                     .next(playerSummarization())</span><br><span class="line">                     .end()</span><br><span class="line">                     .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="JobInstance"><a href="#JobInstance" class="headerlink" title="JobInstance"></a>JobInstance</h4><p>他是 Job 的更加底层的一个抽象，他的定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobInstance</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobInstance.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> instance id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getInstanceId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>他的方法很简单，一个是返回 Job 的 id，另一个是返回 Job 的名字。</p><p>JobInstance 指的是 job 运行当中，作业执行过程当中的概念。</p><p>比如说现在有一个批处理的 job，它的功能是在一天结束时执行行一次。我们假定这个批处理 job 的名字为’EndOfDay’。在这个情况下，那么每天就会有一个逻辑意义上的 JobInstance, 而我们必须记录 job 的每次运行的情况。</p><h4 id="JobParameters"><a href="#JobParameters" class="headerlink" title="JobParameters"></a>JobParameters</h4><p>JobParameters 对象包含一组用于启动批处理作业的参数，它可以在运行期间用于识别或甚至用作参考数据。</p><p>例如, 我们前面的’EndOfDay’的 job 现在已经有了两个实例，一个产生于 1 月 1 日，另一个产生于 1 月 2 日，那么我们就可以定义两个 JobParameter 对象：一个的参数是 01-01, 另一个的参数是 01-02。</p><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_2.png"></p><p>因此，我么可以通过 Jobparameter 来操作正确的 JobInstance</p><h4 id="JobExecution"><a href="#JobExecution" class="headerlink" title="JobExecution"></a>JobExecution</h4><p>JobExecution 指的是单次尝试运行一个我们定义好的 Job 的代码层面的概念。job 的一次执行可能以失败也可能成功。只有当执行成功完成时，给定的与执行相对应的 JobInstance 才也被视为完成。</p><p>还是以前面描述的 EndOfDay 的 job 作为示例，假设第一次运行 01-01-2019 的 JobInstance 结果是失败。那么此时如果使用与第一次运行相同的 Jobparameter 参数（即 01-01-2019）作业参数再次运行，那么就会创建一个对应于之前 jobInstance 的一个新的 JobExecution 实例, JobInstance 仍然只有一个。</p><p>JobExecution 的接口定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobExecution</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobExecution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> execution id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getExecutionId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get batch status of this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> batch status value.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> BatchStatus <span class="title">getBatchStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered STARTED status. </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getStartTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered end status: COMPLETED, STOPPED, FAILED </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getEndTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get execution exit status.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> exit status.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getExitStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was created.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getCreateTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was last updated updated.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getLastUpdatedTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job parameters for this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> job parameters  </span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Properties <span class="title">getJobParameters</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>JobExecution 当中提供了一个方法 getBatchStatus 用于获取一个 job 某一次特地执行的一个状态。BatchStatus 是一个代表 job 状态的枚举类，其定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">BatchStatus</span> </span>&#123;</span><br><span class="line">    STARTING, STARTED, STOPPING, STOPPED, FAILED, COMPLETED, ABANDONED</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h4><p>每一个 Step 对象都封装了批处理作业的一个独立的阶段。事实上，每一个 Job 本质上都是由一个或多个步骤组成。每一个 step 包含定义和控制实际批处理所需的所有信息。任何特定的内容都由编写 Job 的开发人员自行决定。</p><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_3.png"></p><p>StepExecution 表示一次执行 Step, 每次运行一个 Step 时都会创建一个新的 StepExecution，类似于 JobExecution。但是，某个步骤可能由于其之前的步骤失败而无法执行。且仅当 Step 实际启动时才会创建 StepExecution。</p><p>一次 step 执行的实例由 StepExecution 类的对象表示。每个 StepExecution 都包含对其相应步骤的引用以及 JobExecution 和事务相关的数据，例如提交和回滚计数以及开始和结束时间。</p><p>此外，每个步骤执行都包含一个 ExecutionContext，其中包含开发人员需要在批处理运行中保留的任何数据，例如重新启动所需的统计信息或状态信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job JobFlowDemo1()&#123;</span><br><span class="line">    return jobBuilderFactory.get(&quot;jobFlowDemo1&quot;)</span><br><span class="line">//                .start(step1())</span><br><span class="line">//                .next(step2())</span><br><span class="line">//                .next(step3())</span><br><span class="line">//                .build();</span><br><span class="line">                .start(step1())</span><br><span class="line">                .on(&quot;COMPLETED&quot;).to(step2())</span><br><span class="line">                .from(step2()).on(&quot;COMPLETED&quot;).to(step3())</span><br><span class="line">                .from(step3()).end()</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">当step1 成功执行完成后，返回COMPLETED， 才调用step2进行下一步处理。但是过多的step，不易于程序维护和复用</span><br></pre></td></tr></table></figure><h4 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h4><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_4.png"></p><p>由于我们一次 batch 的任务可能会有很多的数据读写操作，因此一条一条的处理并向数据库提交的话效率不会很高，因此 spring batch 提供了 chunk 这个概念，我们可以设定一个 chunk size，spring batch 将一条一条处理数据，但不提交到数据库，只有当处理的数据数量达到 chunk size 设定的值得时候，才一起去 commit.</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Spring Batch为我们提供了非常实用的功能，对批处理场景进行了完善的抽象，它不仅能实现小数据的迁移，也能应对大企业的大数据实践应用。它让我们开发批处理应用可以事半功倍。  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;什么是SpringBatch&quot;&gt;&lt;a href=&quot;#什么是SpringBatch&quot; class=&quot;headerlink&quot; title=&quot;什么是SpringBatch&quot;&gt;&lt;/a&gt;什么是SpringBatch&lt;/h3&gt;&lt;p&gt;一个轻量级，全面的&lt;strong&gt;批处理框架</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="SpringBatch" scheme="http://example.com/tags/SpringBatch/"/>
    
    <category term="Spring生态" scheme="http://example.com/tags/Spring%E7%94%9F%E6%80%81/"/>
    
    <category term="批处理" scheme="http://example.com/tags/%E6%89%B9%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>状态机系列之SpringStatusMachine详解</title>
    <link href="http://example.com/2021/07/15/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2021/07/15/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-07-15T01:48:09.000Z</published>
    <updated>2021-07-19T08:50:08.249Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是状态机"><a href="#什么是状态机" class="headerlink" title="什么是状态机"></a>什么是状态机</h2><p>有限状态机是一种用来进行对象行为建模的工具，其作用主要是描述对象在它的生命周期内所经历的状态序列，以及如何响应来自外界的各种事件。</p><p>在电商场景（订单、物流、售后）、社交（IM消息投递）、分布式集群管理（分布式计算平台任务编排）等场景都有大规模的使用。</p><h3 id="状态机的要素"><a href="#状态机的要素" class="headerlink" title="状态机的要素"></a>状态机的要素</h3><ul><li><strong>现态</strong>：指当前所处的状态</li><li><strong>条件</strong>：又称“事件”，当一个条件被满足，将会触发一个动作，或者执行一次状态的迁移</li><li><strong>动作</strong>：条件满足后执行的动作。动作执行完毕后，可以迁移到新的状态，也可以仍旧保持原状态。动作不是必须的，当条件满足后，也可以不执行任何动作，直接迁移到新的状态。<ul><li>进入动作：在进入状态时进行</li><li>退出动作：在退出状态时进行</li><li>输入动作：依赖于当前状态和输入条件进行</li><li>转移动作：在进行特定转移时进行</li></ul></li><li><strong>次态</strong>：条件满足后要迁往的新状态。“次态”是相对于“现态”而言的，“次态”一旦被激活，就转换成“现态”。</li></ul><h3 id="什么时候需要用到状态机"><a href="#什么时候需要用到状态机" class="headerlink" title="什么时候需要用到状态机"></a>什么时候需要用到状态机</h3><p>Spring文档指出，在以下情况下，项目很适合使用状态机：</p><ul><li>您可以将应用程序或其结构的一部分表示为状态。</li><li>您想将复杂的逻辑拆分为更小的可管理任务。</li><li>应用程序已经遇到了（例如）异步发生的并发问题。</li></ul><p>如果满足以下条件，您已经在尝试实现状态机 ：  </p><ul><li>使用布尔标志或枚举对情况进行建模。</li><li>具有仅对应用程序生命周期的一部分有意义的变量。</li><li>遍历if / else结构并检查是否设置了特定的标志或枚举，然后进一步对当标志和枚举的某些组合存在或不存在时的处理方式作进一步的例外。</li></ul><h4 id="使用状态机的优缺点"><a href="#使用状态机的优缺点" class="headerlink" title="使用状态机的优缺点"></a>使用状态机的优缺点</h4><p><strong>优点</strong></p><ul><li>状态及转换与业务解耦；</li><li>代码的可维护性增强；</li><li>对于流程复杂易变的业务场景能大减轻维护和测试的难度。</li></ul><p><strong>缺点</strong></p><ul><li>事务不好控制；</li><li>增加更多的类。<h3 id="状态机对比"><a href="#状态机对比" class="headerlink" title="状态机对比"></a>状态机对比</h3></li></ul><table><thead><tr><th>状态机</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>stateless4j</td><td>轻量级<br>支持基本事件迁移<br>二次开发难度低</td><td>不支持持久化和上下文传参</td></tr><tr><td>squirrel-foundation</td><td>功能齐全<br>StatueMachine精简版</td><td>—</td></tr><tr><td>Spring StatusMachine</td><td>功能齐全<br>&ensp; 状态：初始终止、历史状态、连接交并；<br>&ensp; 延迟事件;<br>&ensp; Guard;<br>&ensp; 持久化;<br>&ensp; JPA<br>使用方便<br>&ensp; 配置+注解，文档齐全</td><td>学习成本较高<br>状态机已捕获异常，需要手动编码处理异常，单个状态机可以被共享，需要builder多个实例<br>同时使用多个状态机事务需要手工控制</td></tr></tbody></table><h3 id="Spring-StatusMachine使用案例"><a href="#Spring-StatusMachine使用案例" class="headerlink" title="Spring StatusMachine使用案例"></a>Spring StatusMachine使用案例</h3><p>假设在一个业务系统中，有这样一个对象，它有三个状态：草稿、待发布、发布完成，针对这三个状态的业务动作也比较简单，分别是：上线、发布、回滚。该业务状态机如下图所示。<br><img src="/2021/07/15/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/img.png" alt="img.png"></p><p>创建一个基础的Spring Boot工程，在主pom文件中加入Spring StateMachine的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--加入spring statemachine的依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.statemachine<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-statemachine-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.3.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>定义状态枚举和事件枚举，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 状态枚举</span></span><br><span class="line"><span class="comment">**/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">States</span> </span>&#123;</span><br><span class="line">    DRAFT,</span><br><span class="line">    PUBLISH_TODO,</span><br><span class="line">    PUBLISH_DONE,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 事件枚举</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Events</span> </span>&#123;</span><br><span class="line">  ONLINE,</span><br><span class="line">  PUBLISH,</span><br><span class="line">  ROLLBACK</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成状态机的配置，包括：（1）状态机的初始状态和所有状态；（2）状态之间的转移规则</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="comment">// @EnableStateMachine批注时，它将在应用程序启动时自动创建默认状态机。</span></span><br><span class="line"><span class="meta">@EnableStateMachine</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StateMachineConfig</span> <span class="keyword">extends</span> <span class="title">EnumStateMachineConfigurerAdapter</span>&lt;<span class="title">States</span>, <span class="title">Events</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(StateMachineStateConfigurer&lt;States, Events&gt; states)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        states.withStates().initial(States.DRAFT).states(EnumSet.allOf(States.class));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(StateMachineTransitionConfigurer&lt;States, Events&gt; transitions)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        transitions.withExternal()</span><br><span class="line">            .source(States.DRAFT).target(States.PUBLISH_TODO)</span><br><span class="line">            .event(Events.ONLINE)</span><br><span class="line">            .and()</span><br><span class="line">            .withExternal()</span><br><span class="line">            .source(States.PUBLISH_TODO).target(States.PUBLISH_DONE)</span><br><span class="line">            .event(Events.PUBLISH)</span><br><span class="line">            .and()</span><br><span class="line">            .withExternal()</span><br><span class="line">            .source(States.PUBLISH_DONE).target(States.DRAFT)</span><br><span class="line">            .event(Events.ROLLBACK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个测试业务对象，状态机的状态转移都会反映到该业务对象的状态变更上</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WithStateMachine</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BizBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@see</span> States</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String status = States.DRAFT.name();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;PUBLISH_TODO&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">online</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作上线，待发布. target status:&#123;&#125;&quot;</span>, States.PUBLISH_TODO.name());</span><br><span class="line">        setStatus(States.PUBLISH_TODO.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;PUBLISH_DONE&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">publish</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作发布,发布完成. target status:&#123;&#125;&quot;</span>, States.PUBLISH_DONE.name());</span><br><span class="line">        setStatus(States.PUBLISH_DONE.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;DRAFT&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rollback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作回滚,回到草稿状态. target status:&#123;&#125;&quot;</span>, States.DRAFT.name());</span><br><span class="line">        setStatus(States.DRAFT.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编写测试用例，这里我们使用CommandLineRunner接口代替，定义了一个StartupRunner，在该类的run方法中启动状态机、发送不同的事件，通过日志验证状态机的流转过程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StartupRunner</span> <span class="keyword">implements</span> <span class="title">CommandLineRunner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    StateMachine&lt;States, Events&gt; stateMachine;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(String... args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        stateMachine.start();</span><br><span class="line">        stateMachine.sendEvent(Events.ONLINE);</span><br><span class="line">        stateMachine.sendEvent(Events.PUBLISH);</span><br><span class="line">        stateMachine.sendEvent(Events.ROLLBACK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>使用步骤总结：</strong></p><ul><li>定义状态枚举和事件枚举</li><li>定义状态机的初始状态和所有状态</li><li>定义状态之间的转移规则</li><li>在业务对象中使用状态机，编写响应状态变化的监听器方法</li></ul><p>使用Spring StateMachine的好处在于自己无需关心状态机的实现细节，只需要关心业务有什么状态、它们之间的转移规则是什么、每个状态转移后真正要进行的业务操作。</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>Spring State Machine可以做的事情还很多。 </p><ul><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#statemachine-config-states">状态可以嵌套</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-security">可以配置为检查是否允许过渡的防护措施</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-extendedstate">允许定义选择状态，接合状态等的伪状态</a> </li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-triggers">事件可以由操作或在计时器上触发</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-persist">状态机可以持久化以提高性能</a> </li></ul><p>要浏览所有内容，您需要研究 <a href="https://docs.spring.io/spring-statemachine/docs/current/reference/">Spring StateMachine文档</a> 并确定适合您的特定情况的文档。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是状态机&quot;&gt;&lt;a href=&quot;#什么是状态机&quot; class=&quot;headerlink&quot; title=&quot;什么是状态机&quot;&gt;&lt;/a&gt;什么是状态机&lt;/h2&gt;&lt;p&gt;有限状态机是一种用来进行对象行为建模的工具，其作用主要是描述对象在它的生命周期内所经历的状态序列，以及如何响</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Spring生态" scheme="http://example.com/tags/Spring%E7%94%9F%E6%80%81/"/>
    
    <category term="状态机" scheme="http://example.com/tags/%E7%8A%B6%E6%80%81%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之分布式定时调度Elastic-Job解析</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Elastic-Job%E8%A7%A3%E6%9E%90/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Elastic-Job%E8%A7%A3%E6%9E%90/</id>
    <published>2021-07-14T01:11:37.000Z</published>
    <updated>2021-07-14T08:49:21.120Z</updated>
    
    <content type="html"><![CDATA[<p>待完善，具体信息参考： </p><p><a href="http://www.iocoder.cn/categories/Elastic-Job-Lite/?vip&architect-awesome">Elastic-Job-Lite 源码解析</a></p><p><a href="http://www.iocoder.cn/categories/Elastic-Job-Cloud/?vip&architect-awesome">Elastic-Job-Cloud 源码解析</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;待完善，具体信息参考： &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.iocoder.cn/categories/Elastic-Job-Lite/?vip&amp;architect-awesome&quot;&gt;Elastic-Job-Lite 源码解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之分布式定时调度Quartz集群基本实现原理</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</id>
    <published>2021-07-14T01:11:09.000Z</published>
    <updated>2021-07-14T08:49:21.156Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Quartz集群架构"><a href="#Quartz集群架构" class="headerlink" title="Quartz集群架构"></a>Quartz集群架构</h3><p>一个Quartz集群中的每个节点是一个独立的Quartz应用，它又管理着其他的节点。这就意味着你必须对每个节点分别启动或停止。Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的，如图2.1所示。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img.png" alt="img.png"></p><h3 id="Quartz集群相关数据库表"><a href="#Quartz集群相关数据库表" class="headerlink" title="Quartz集群相关数据库表"></a>Quartz集群相关数据库表</h3><p>因为Quartz集群依赖于数据库，所以必须首先创建Quartz数据库表，Quartz发布包中包括了所有被支持的数据库平台的SQL脚本。这些SQL脚本存放于<quartz_home>/docs/dbTables 目录下。</quartz_home></p><p>这里采用的Quartz 1.8.4版本，总共12张表，不同版本，表个数可能不同。数据库为mysql，用tables_mysql.sql创建数据库表。</p><p>Quartz 1.8.4在mysql数据库中生成的表：<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img_1.png" alt="img_1.png"></p><p>Quartz数据表简介：<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img_2.png" alt="img_2.png"></p><h3 id="Quartz-Scheduler在集群中的启动流程"><a href="#Quartz-Scheduler在集群中的启动流程" class="headerlink" title="Quartz Scheduler在集群中的启动流程"></a>Quartz Scheduler在集群中的启动流程</h3><p>Quartz Scheduler自身是察觉不到被集群的，只有配置给Scheduler的JDBC JobStore才知道。<br>当Quartz Scheduler启动时，它调用JobStore的schedulerStarted()方法，它告诉JobStore Scheduler已经启动了。<br>schedulerStarted() 方法是在JobStoreSupport类中实现的。<br>JobStoreSupport类会根据<strong>quartz.properties</strong>文件中的设置来确定Scheduler实例是否参与到集群中。<br>假如配置了集群，一个新的ClusterManager类的实例就被创建、初始化并启动。<br>ClusterManager是在JobStoreSupport类中的一个内嵌类，继承了java.lang.Thread，它会定期运行，并对Scheduler实例执行检入的功能。<br>Scheduler也要查看是否有任何一个别的集群节点失败了。检入操作执行周期在quartz.properties中配置。</p><h4 id="侦测失败的Scheduler节点"><a href="#侦测失败的Scheduler节点" class="headerlink" title="侦测失败的Scheduler节点"></a>侦测失败的Scheduler节点</h4><p>当一个Scheduler实例执行检入时，它会查看是否有其他的Scheduler实例在到达他们所预期的时间还未检入。这是通过检查SCHEDULER_STATE表中Scheduler记录在LAST_CHEDK_TIME列的值是否早于org.quartz.jobStore.clusterCheckinInterval来确定的。如果一个或多个节点到了预定时间还没有检入，那么运行中的Scheduler就假定它(们) 失败了。</p><h4 id="从故障实例中恢复Job"><a href="#从故障实例中恢复Job" class="headerlink" title="从故障实例中恢复Job"></a>从故障实例中恢复Job</h4><p>当一个Sheduler实例在执行某个Job时失败了，有可能由另一正常工作的Scheduler实例接过这个Job重新运行。要实现这种行为，配置给JobDetail对象的Job可恢复属性必须设置为true（job.setRequestsRecovery(true)）。如果可恢复属性被设置为false(默认为false)，当某个Scheduler在运行该job失败时，它将不会重新运行；而是由另一个Scheduler实例在下一次触发时间触发。Scheduler实例出现故障后多快能被侦测到取决于每个Scheduler的检入间隔（即2.3中提到的org.quartz.jobStore.clusterCheckinInterval）。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><h4 id="时间同步问题"><a href="#时间同步问题" class="headerlink" title="时间同步问题"></a>时间同步问题</h4><p>Quartz实际并不关心你是在相同还是不同的机器上运行节点。当集群放置在不同的机器上时，称之为水平集群。节点跑在同一台机器上时，称之为垂直集群。对于垂直集群，存在着单点故障的问题。这对高可用性的应用来说是无法接受的，因为一旦机器崩溃了，所有的节点也就被终止了。对于水平集群，存在着时间同步问题。</p><p>节点用时间戳来通知其他实例它自己的最后检入时间。假如节点的时钟被设置为将来的时间，那么运行中的Scheduler将再也意识不到那个结点已经宕掉了。另一方面，如果某个节点的时钟被设置为过去的时间，也许另一节点就会认定那个节点已宕掉并试图接过它的Job重运行。最简单的同步计算机时钟的方式是使用某一个Internet时间服务器(Internet Time Server ITS)。</p><h4 id="节点争抢Job问题"><a href="#节点争抢Job问题" class="headerlink" title="节点争抢Job问题"></a>节点争抢Job问题</h4><p>因为Quartz使用了一个随机的负载均衡算法， Job以随机的方式由不同的实例执行。Quartz官网上提到当前，还不存在一个方法来指派(钉住) 一个 Job 到集群中特定的节点。</p><h4 id="从集群获取Job列表问题"><a href="#从集群获取Job列表问题" class="headerlink" title="从集群获取Job列表问题"></a>从集群获取Job列表问题</h4><p>当前，如果不直接进到数据库查询的话，还没有一个简单的方式来得到集群中所有正在执行的Job列表。请求一个Scheduler实例，将只能得到在那个实例上正运行Job的列表。Quartz官网建议可以通过写一些访问数据库JDBC代码来从相应的表中获取全部的Job信息。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Quartz集群架构&quot;&gt;&lt;a href=&quot;#Quartz集群架构&quot; class=&quot;headerlink&quot; title=&quot;Quartz集群架构&quot;&gt;&lt;/a&gt;Quartz集群架构&lt;/h3&gt;&lt;p&gt;一个Quartz集群中的每个节点是一个独立的Quartz应用，它又管理着其他</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
    <category term="Quartz" scheme="http://example.com/tags/Quartz/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之分布式定时调度优秀国产调度系统</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/</id>
    <published>2021-07-14T01:10:12.000Z</published>
    <updated>2021-07-14T08:49:21.111Z</updated>
    
    <content type="html"><![CDATA[<h3 id="opencron"><a href="#opencron" class="headerlink" title="opencron"></a>opencron</h3><p>opencron 是一个功能完善且通用的开源定时任务调度系统，拥有先进可靠的自动化任务管理调度功能，提供可操作的 web 图形化管理满足多种场景下各种复杂的定时任务调度，同时集成了 linux 实时监控、webssh 等功能特性。</p><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img.png" alt="img.png"></p><h3 id="LTS"><a href="#LTS" class="headerlink" title="LTS"></a>LTS</h3><p>LTS，light-task-scheduler，是一款分布式任务调度框架, 支持实时任务、定时任务和 Cron 任务。有较好的伸缩性和扩展性，提供对 Spring 的支持（包括 Xml 和注解），提供业务日志记录器。支持节点监控、任务执行监、JVM 监控，支持动态提交、更改、停止任务。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_1.png" alt="img_1.png"></p><h3 id="XXL-JOB"><a href="#XXL-JOB" class="headerlink" title="XXL-JOB"></a>XXL-JOB</h3><p>XXL-JOB 是一个轻量级分布式任务调度框架，支持通过 Web 页面对任务进行 CRUD 操作，支持动态修改任务状态、暂停/恢复任务，以及终止运行中任务，支持在线配置调度任务入参和在线查看调度结果。</p><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_2.png" alt="img_2.png"></p><h3 id="Elastic-Job"><a href="#Elastic-Job" class="headerlink" title="Elastic-Job"></a>Elastic-Job</h3><p>Elastic-Job 是一个分布式调度解决方案，由两个相互独立的子项目 Elastic-Job-Lite 和 Elastic-Job-Cloud 组成。定位为轻量级无中心化解决方案，使用 jar 包的形式提供分布式任务的协调服务。支持分布式调度协调、弹性扩容缩容、失效转移、错过执行作业重触发、并行调度、自诊断和修复等等功能特性。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_3.png" alt="img_3.png"></p><h3 id="Uncode-Schedule"><a href="#Uncode-Schedule" class="headerlink" title="Uncode-Schedule"></a>Uncode-Schedule</h3><p>Uncode-Schedule 是基于 ZooKeeper + Quartz / spring task 的分布式任务调度组件，确保每个任务在集群中不同节点上不重复的执行。支持动态添加和删除任务，支持添加 ip 黑名单，过滤不需要执行任务的节点。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_4.png" alt="img_4.png"></p><h3 id="Antares"><a href="#Antares" class="headerlink" title="Antares"></a>Antares</h3><p>Antares 是一款基于 Quartz 机制的分布式任务调度管理平台，内部重写执行逻辑，一个任务仅会被服务器集群中的某个节点调度。用户可通过对任务预分片，有效提升任务执行效率；也可通过控制台 antares-tower 对任务进行基本操作，如触发，暂停，监控等。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_5.png" alt="img_5.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;opencron&quot;&gt;&lt;a href=&quot;#opencron&quot; class=&quot;headerlink&quot; title=&quot;opencron&quot;&gt;&lt;/a&gt;opencron&lt;/h3&gt;&lt;p&gt;opencron 是一个功能完善且通用的开源定时任务调度系统，拥有先进可靠的自动化任务管理调</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之单机定时调度Quartz使用总结及原理解析</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</id>
    <published>2021-07-14T01:08:59.000Z</published>
    <updated>2021-07-14T08:49:21.074Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Quartz可以用来做什么？"><a href="#Quartz可以用来做什么？" class="headerlink" title="Quartz可以用来做什么？"></a>Quartz可以用来做什么？</h2><p>在某一个有规律的时间点干某件事。<br>并且时间的触发的条件可以非常复杂（比如每月最后一个工作日的17:50），复杂到需要一个专门的框架来干这个事。<br>Quartz就是来干这样的事，你给它一个触发条件的定义，它负责到了时间点，触发相应的Job起来干活。</p><h2 id="Quartz使用总结"><a href="#Quartz使用总结" class="headerlink" title="Quartz使用总结"></a>Quartz使用总结</h2><h3 id="从简单示例看Quartz核心设计"><a href="#从简单示例看Quartz核心设计" class="headerlink" title="从简单示例看Quartz核心设计"></a>从简单示例看Quartz核心设计</h3><h4 id="一个简单的Demo程序"><a href="#一个简单的Demo程序" class="headerlink" title="一个简单的Demo程序"></a>一个简单的Demo程序</h4><p>这里面的所有例子都是基于Quartz 2.2.1</p><details><summary>点击展开/收起</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.quartz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DateBuilder.newDate;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.JobBuilder.newJob;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.SimpleScheduleBuilder.simpleSchedule;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.TriggerBuilder.newTrigger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.GregorianCalendar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Scheduler;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Trigger;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.StdSchedulerFactory;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.calendar.AnnualCalendar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuartzTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//创建scheduler</span></span><br><span class="line">            Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义一个Trigger</span></span><br><span class="line">            Trigger trigger = newTrigger().withIdentity(<span class="string">&quot;trigger1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//定义name/group</span></span><br><span class="line">                .startNow()<span class="comment">//一旦加入scheduler，立即生效</span></span><br><span class="line">                .withSchedule(simpleSchedule() <span class="comment">//使用SimpleTrigger</span></span><br><span class="line">                    .withIntervalInSeconds(<span class="number">1</span>) <span class="comment">//每隔一秒执行一次</span></span><br><span class="line">                    .repeatForever()) <span class="comment">//一直执行，奔腾到老不停歇</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义一个JobDetail</span></span><br><span class="line">            JobDetail job = newJob(HelloQuartz.class) <span class="comment">//定义Job类为HelloQuartz类，这是真正的执行逻辑所在</span></span><br><span class="line">                .withIdentity(<span class="string">&quot;job1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//定义name/group</span></span><br><span class="line">                .usingJobData(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;quartz&quot;</span>) <span class="comment">//定义属性</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//加入这个调度</span></span><br><span class="line">            scheduler.scheduleJob(job, trigger);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//启动之</span></span><br><span class="line">            scheduler.start();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//运行一段时间后关闭</span></span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            scheduler.shutdown(<span class="keyword">true</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.quartz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.quartz.DisallowConcurrentExecution;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Job;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionContext;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloQuartz</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        JobDetail detail = context.getJobDetail();</span><br><span class="line">        String name = detail.getJobDataMap().getString(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;say hello to &quot;</span> + name + <span class="string">&quot; at &quot;</span> + <span class="keyword">new</span> Date());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="Quartz核心元素："><a href="#Quartz核心元素：" class="headerlink" title="Quartz核心元素："></a>Quartz核心元素：</h4><ul><li><p>Scheduler：调度器。<br>负责整个定时系统的调度，内部通过线程池进行调度。</p></li><li><p>Trigger： 定义触发的条件。<br>主要有四种类型：SimpleTrigger、CronTrigger、DataIntervalTrigger、NthIncludedTrigger，在项目中常用的为：SimpleTrigger和CronTrigger。。</p></li><li><p>JobDetail：定义任务数据。<br>记录Job的名字、组及任务执行的具体类和任务执行所需要的参数</p></li><li><p>Job： 真正的执行逻辑。  </p></li></ul><p>为什么设计成JobDetail + Job，不直接使用Job？<br>这是因为任务是有可能并发执行，如果Scheduler直接使用Job，就会存在对同一个Job实例并发访问的问题。<br>而JobDetail &amp; Job 方式，sheduler每次执行，都会根据JobDetail创建一个新的Job实例，这样就可以规避并发访问的问题。</p><h4 id="核心元素之间的关系"><a href="#核心元素之间的关系" class="headerlink" title="核心元素之间的关系"></a>核心元素之间的关系</h4><ul><li>先由SchedulerFactory创建Scheduler调度器</li><li>由调度器去调取即将执行的Trigger</li><li>执行时获取到对于的JobDetail信息</li><li>找到对应的Job类执行业务逻辑</li></ul><h3 id="Quartz-API"><a href="#Quartz-API" class="headerlink" title="Quartz API"></a>Quartz API</h3><p>Quartz的API的风格在2.x以后，采用的是DSL风格（通常意味着fluent interface风格），就是示例中newTrigger()那一段东西。它是通过Builder实现的，就是以下几个。（** 下面大部分代码都要引用这些Builder ** )</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//job相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.JobBuilder.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">//trigger相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.TriggerBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.SimpleScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.CronScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DailyTimeIntervalScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.CalendarIntervalScheduleBuilder.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">//日期相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DateBuilder.*;</span><br></pre></td></tr></table></figure><p>DSL风格写起来会更加连贯，畅快，而且由于不是使用setter的风格，语义上会更容易理解一些。对比一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JobDetail jobDetail=new JobDetailImpl(&quot;jobDetail1&quot;,&quot;group1&quot;,HelloQuartz.class);</span><br><span class="line">jobDetail.getJobDataMap().put(&quot;name&quot;, &quot;quartz&quot;);</span><br><span class="line"></span><br><span class="line">SimpleTriggerImpl trigger=new SimpleTriggerImpl(&quot;trigger1&quot;,&quot;group1&quot;);</span><br><span class="line">trigger.setStartTime(new Date());</span><br><span class="line">trigger.setRepeatInterval(1);</span><br><span class="line">trigger.setRepeatCount(-1);</span><br></pre></td></tr></table></figure><h3 id="关于name和group"><a href="#关于name和group" class="headerlink" title="关于name和group"></a>关于name和group</h3><p>JobDetail和Trigger都有name和group。</p><p>name是它们在这个sheduler里面的唯一标识。如果我们要更新一个JobDetail定义，只需要设置一个name相同的JobDetail实例即可。</p><p>group是一个组织单元，sheduler会提供一些对整组操作的API，比如 scheduler.resumeJobs()。</p><h3 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a>Trigger</h3><h4 id="StartTime-amp-EndTime"><a href="#StartTime-amp-EndTime" class="headerlink" title="StartTime &amp; EndTime"></a>StartTime &amp; EndTime</h4><p>startTime和endTime指定的Trigger会被触发的时间区间。在这个区间之外，Trigger是不会被触发的。</p><p>** 所有Trigger都会包含这两个属性 **</p><h4 id="优先级（Priority）"><a href="#优先级（Priority）" class="headerlink" title="优先级（Priority）"></a>优先级（Priority）</h4><p>当scheduler比较繁忙的时候，可能在同一个时刻，有多个Trigger被触发了，但资源不足（比如线程池不足）。那么这个时候比剪刀石头布更好的方式，就是设置优先级。优先级高的先执行。</p><p>需要注意的是，优先级只有在同一时刻执行的Trigger之间才会起作用，如果一个Trigger是9:00，另一个Trigger是9:30。那么无论后一个优先级多高，前一个都是先执行。</p><p>优先级的值默认是5，当为负数时使用默认值。最大值似乎没有指定，但建议遵循Java的标准，使用1-10，不然鬼才知道看到【优先级为10】是时，上头还有没有更大的值。</p><h4 id="Misfire-错失触发）策略"><a href="#Misfire-错失触发）策略" class="headerlink" title="Misfire(错失触发）策略"></a>Misfire(错失触发）策略</h4><p>类似的Scheduler资源不足的时候，或者机器崩溃重启等，有可能某一些Trigger在应该触发的时间点没有被触发，也就是Miss Fire了。这个时候Trigger需要一个策略来处理这种情况。每种Trigger可选的策略各不相同。</p><p>这里有两个点需要重点注意：</p><ul><li>MisFire的触发是有一个阀值，这个阀值是配置在JobStore的。比RAMJobStore是org.quartz.jobStore.misfireThreshold。只有超过这个阀值，才会算MisFire。小于这个阀值，Quartz是会全部重新触发。</li></ul><p>所有MisFire的策略实际上都是解答两个问题：</p><ul><li>已经MisFire的任务还要重新触发吗？</li><li>如果发生MisFire，要调整现有的调度时间吗？</li></ul><details><summary>比如SimpleTrigger的MisFire策略有</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>IGNORE<span class="emphasis">_MISFIRE_</span>POLICY</span><br><span class="line"></span><br><span class="line"><span class="code">    这个不是忽略已经错失的触发的意思，而是说忽略MisFire策略。它会在资源合适的时候，重新触发所有的MisFire任务，并且不会影响现有的调度时间。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    比如，SimpleTrigger每15秒执行一次，而中间有5分钟时间它都MisFire了，一共错失了20个，5分钟后，假设资源充足了，并且任务允许并发，它会被一次性触发。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    这个属性是所有Trigger都适用。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>FIRE<span class="emphasis">_NOW</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  忽略已经MisFire的任务，并且立即执行调度。这通常只适用于只执行一次的任务。</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">* MISFIRE_</span>INSTRUCTION<span class="emphasis">_RESCHEDULE_</span>NOW<span class="emphasis">_WITH_</span>EXISTING<span class="emphasis">_REPEAT_</span>COUNT</span><br><span class="line"></span><br><span class="line">  将startTime设置当前时间，立即重新调度任务，包括的MisFire的</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NOW_</span>WITH<span class="emphasis">_REMAINING_</span>REPEAT<span class="emphasis">_COUNT</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  类似MISFIRE_</span>INSTRUCTION<span class="emphasis">_RESCHEDULE_</span>NOW<span class="emphasis">_WITH_</span>EXISTING<span class="emphasis">_REPEAT_</span>COUNT，区别在于会忽略已经MisFire的任务</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_EXISTING_</span>COUNT</span><br><span class="line"></span><br><span class="line">  在下一次调度时间点，重新开始调度任务，包括的MisFire的</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_REMAINING_</span>COUNT</span><br><span class="line"></span><br><span class="line">  类似于MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_EXISTING_</span>COUNT，区别在于会忽略已经MisFire的任务。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>SMART<span class="emphasis">_POLICY</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  所有的Trigger的MisFire默认值都是这个，大致意思是“把处理逻辑交给聪明的Quartz去决定”。基本策略是，</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  * 如果是只执行一次的调度，使用MISFIRE_</span>INSTRUCTION<span class="emphasis">_FIRE_</span>NOW</span><br><span class="line"><span class="bullet">  *</span> 如果是无限次的调度(repeatCount是无限的)，使用MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_REMAINING_</span>COUNT</span><br><span class="line"><span class="bullet">  *</span> 否则，使用MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NOW_</span>WITH<span class="emphasis">_EXISTING_</span>REPEAT<span class="emphasis">_COUNT</span></span><br></pre></td></tr></table></figure></details><h4 id="Calendar"><a href="#Calendar" class="headerlink" title="Calendar"></a>Calendar</h4><p>这里的Calendar不是jdk的java.util.Calendar，不是为了计算日期的。它的作用是在于补充Trigger的时间。可以排除或加入某一些特定的时间点。</p><p>以”每月25日零点自动还卡债“为例，我们想排除掉每年的2月25号零点这个时间点（因为有2.14，所以2月一定会破产）。这个时间，就可以用Calendar来实现。</p><details><summary>例子</summary><pre><code>AnnualCalendar cal = new AnnualCalendar(); //定义一个每年执行Calendar，精度为天，即不能定义到2.25号下午2:00java.util.Calendar excludeDay = new GregorianCalendar();excludeDay.setTime(newDate().inMonthOnDay(2, 25).build());cal.setDayExcluded(excludeDay, true);  //设置排除2.25这个日期scheduler.addCalendar("FebCal", cal, false, false); //scheduler加入这个Calendar//定义一个TriggerTrigger trigger = newTrigger().withIdentity("trigger1", "group1").startNow()//一旦加入scheduler，立即生效.modifiedByCalendar("FebCal") //使用Calendar !!.withSchedule(simpleSchedule().withIntervalInSeconds(1).repeatForever()).build();</code></pre></details><p>Quartz体贴地为我们提供以下几种Calendar，注意，所有的Calendar既可以是排除，也可以是包含，取决于：</p><ul><li>HolidayCalendar。指定特定的日期，比如20140613。精度到天。</li><li>DailyCalendar。指定每天的时间段（rangeStartingTime, rangeEndingTime)，格式是HH:MM[:SS[:mmm]]。也就是最大精度可以到毫秒。</li><li>WeeklyCalendar。指定每星期的星期几，可选值比如为java.util.Calendar.SUNDAY。精度是天。</li><li>MonthlyCalendar。指定每月的几号。可选值为1-31。精度是天</li><li>AnnualCalendar。 指定每年的哪一天。使用方式如上例。精度是天。</li><li>CronCalendar。指定Cron表达式。精度取决于Cron表达式，也就是最大精度可以到秒。</li></ul><h4 id="其他属性"><a href="#其他属性" class="headerlink" title="其他属性"></a>其他属性</h4><ul><li><p>Durability(耐久性？)</p><p>如果一个任务不是durable，那么当没有Trigger关联它的时候，它就会被自动删除。</p></li><li><p>RequestsRecovery</p><p>如果一个任务是”requests recovery”，那么当任务运行过程非正常退出时（比如进程崩溃，机器断电，但不包括抛出异常这种情况），Quartz再次启动时，会重新运行一次这个任务实例。</p><p>可以通过JobExecutionContext.isRecovering()查询任务是否是被恢复的。</p></li></ul><h4 id="Trigger实现类"><a href="#Trigger实现类" class="headerlink" title="Trigger实现类"></a>Trigger实现类</h4><h5 id="SimpleTrigger"><a href="#SimpleTrigger" class="headerlink" title="SimpleTrigger"></a>SimpleTrigger</h5><p>指定从某一个时间开始，以一定的时间间隔（单位是毫秒）执行的任务。</p><p>它适合的任务类似于：9:00 开始，每隔1小时，执行一次。</p><p>它的属性有：</p><ul><li>repeatInterval 重复间隔</li><li>repeatCount 重复次数。实际执行次数是 repeatCount+1。因为在startTime的时候一定会执行一次。<strong>下面有关repeatCount 属性的都是同理</strong></li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">simpleSchedule()</span><br><span class="line">        .withIntervalInHours(1) //每小时执行一次</span><br><span class="line">        .repeatForever() //次数不限</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">simpleSchedule()</span><br><span class="line">    .withIntervalInMinutes(1) //每分钟执行一次</span><br><span class="line">    .withRepeatCount(10) //次数为10次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="CalendarIntervalTrigger"><a href="#CalendarIntervalTrigger" class="headerlink" title="CalendarIntervalTrigger"></a>CalendarIntervalTrigger</h5><p>类似于SimpleTrigger，指定从某一个时间开始，以一定的时间间隔执行的任务。<br>但是不同的是SimpleTrigger指定的时间间隔为毫秒，没办法指定每隔一个月执行一次（每月的时间间隔不是固定值），而CalendarIntervalTrigger支持的间隔单位有秒，分钟，小时，天，月，年，星期。</p><p>相较于SimpleTrigger有两个优势：1、更方便，比如每隔1小时执行，你不用自己去计算1小时等于多少毫秒。 2、支持不是固定长度的间隔，比如间隔为月和年。但劣势是精度只能到秒。</p><p>它适合的任务类似于：9:00 开始执行，并且以后每周 9:00 执行一次</p><p>它的属性有:</p><ul><li>interval 执行间隔</li><li>intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）</li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">calendarIntervalSchedule()</span><br><span class="line">    .withIntervalInDays(1) //每天执行一次</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">calendarIntervalSchedule()</span><br><span class="line">    .withIntervalInWeeks(1) //每周执行一次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="DailyTimeIntervalTrigger"><a href="#DailyTimeIntervalTrigger" class="headerlink" title="DailyTimeIntervalTrigger"></a>DailyTimeIntervalTrigger</h5><p>指定每天的某个时间段内，以一定的时间间隔执行任务。并且它可以支持指定星期。</p><p>它适合的任务类似于：指定每天9:00 至 18:00 ，每隔70秒执行一次，并且只要周一至周五执行。</p><p>它的属性有:</p><ul><li>startTimeOfDay 每天开始时间</li><li>endTimeOfDay 每天结束时间</li><li>daysOfWeek 需要执行的星期</li><li>interval 执行间隔</li><li>intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）</li><li>repeatCount 重复次数</li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dailyTimeIntervalSchedule()</span><br><span class="line">    .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始</span><br><span class="line">    .endingDailyAt(TimeOfDay.hourAndMinuteOfDay(16, 0)) //16：00 结束 </span><br><span class="line">    .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行</span><br><span class="line">    .withIntervalInHours(1) //每间隔1小时执行一次</span><br><span class="line">    .withRepeatCount(100) //最多重复100次（实际执行100+1次）</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">dailyTimeIntervalSchedule()</span><br><span class="line">    .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始</span><br><span class="line">    .endingDailyAfterCount(10) //每天执行10次，这个方法实际上根据 startTimeOfDay+interval*count 算出 endTimeOfDay</span><br><span class="line">    .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行</span><br><span class="line">    .withIntervalInHours(1) //每间隔1小时执行一次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="CronTrigger"><a href="#CronTrigger" class="headerlink" title="CronTrigger"></a>CronTrigger</h5><p>适合于更复杂的任务，它支持类型于Linux Cron的语法（并且更强大）。基本上它覆盖了以上三个Trigger的绝大部分能力（但不是全部）—— 当然，也更难理解。</p><p>它适合的任务类似于：每天0:00,9:00,18:00各执行一次。</p><p>它的属性只有:</p><p>Cron表达式。但这个表示式本身就够复杂了。</p><h3 id="JobDetail-amp-Job"><a href="#JobDetail-amp-Job" class="headerlink" title="JobDetail &amp; Job"></a>JobDetail &amp; Job</h3><p>JobDetail是任务的定义，而Job是任务的执行逻辑。在JobDetail里会引用一个Job Class定义。</p><details><summary>一个最简单的例子</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JobTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> SchedulerException, IOException </span>&#123;</span><br><span class="line">           JobDetail job=newJob()</span><br><span class="line">               .ofType(DoNothingJob.class) <span class="comment">//引用Job Class</span></span><br><span class="line">               .withIdentity(<span class="string">&quot;job1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//设置name/group</span></span><br><span class="line">               .withDescription(<span class="string">&quot;this is a test job&quot;</span>) <span class="comment">//设置描述</span></span><br><span class="line">               .usingJobData(<span class="string">&quot;age&quot;</span>, <span class="number">18</span>) <span class="comment">//加入属性到ageJobDataMap</span></span><br><span class="line">               .build();</span><br><span class="line"></span><br><span class="line">           job.getJobDataMap().put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;quertz&quot;</span>); <span class="comment">//加入属性name到JobDataMap</span></span><br><span class="line"></span><br><span class="line">           <span class="comment">//定义一个每秒执行一次的SimpleTrigger</span></span><br><span class="line">           Trigger trigger=newTrigger()</span><br><span class="line">                   .startNow()</span><br><span class="line">                   .withIdentity(<span class="string">&quot;trigger1&quot;</span>)</span><br><span class="line">                   .withSchedule(simpleSchedule()</span><br><span class="line">                       .withIntervalInSeconds(<span class="number">1</span>)</span><br><span class="line">                       .repeatForever())</span><br><span class="line">                   .build();</span><br><span class="line"></span><br><span class="line">           Scheduler sche=StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line">           sche.scheduleJob(job, trigger);</span><br><span class="line"></span><br><span class="line">           sche.start();</span><br><span class="line"></span><br><span class="line">           System.in.read();</span><br><span class="line"></span><br><span class="line">           sche.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DoNothingJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;do nothing&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>从上例我们可以看出，要定义一个任务，需要干几件事：</p><ul><li>创建一个org.quartz.Job的实现类，并实现实现自己的业务逻辑。比如上面的DoNothingJob。</li><li>定义一个JobDetail，引用这个实现类</li><li>加入scheduleJob</li></ul><p>Quartz调度一次任务，会干如下的事：</p><ul><li>JobClass jobClass=JobDetail.getJobClass()</li><li>Job jobInstance=jobClass.newInstance()。所以Job实现类，必须有一个public的无参构建方法。</li><li>jobInstance.execute(JobExecutionContext context)。JobExecutionContext是Job运行的上下文，可以获得Trigger、Scheduler、JobDetail的信息。</li></ul><p>也就是说，每次调度都会创建一个新的Job实例，这样的好处是有些任务并发执行的时候，不存在对临界资源的访问问题——当然，如果需要共享JobDataMap的时候，还是存在临界资源的并发访问的问题。</p><h4 id="JobDataMap"><a href="#JobDataMap" class="headerlink" title="JobDataMap"></a>JobDataMap</h4><p>每一个JobDetail都会有一个JobDataMap。JobDataMap本质就是一个Map的扩展类，只是提供了一些更便捷的方法，比如getString()之类的。</p><p>我们可以在定义JobDetail，加入属性值，方式有二：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">newJob().usingJobData(&quot;age&quot;, 18) //加入属性到ageJobDataMap</span><br><span class="line"></span><br><span class="line"> or</span><br><span class="line"></span><br><span class="line">job.getJobDataMap().put(&quot;name&quot;, &quot;quertz&quot;); //加入属性name到JobDataMap</span><br></pre></td></tr></table></figure><p>然后在Job中可以获取这个JobDataMap的值，方式同样有二：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloQuartz</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        JobDetail detail = context.getJobDetail();</span><br><span class="line">        JobDataMap map = detail.getJobDataMap(); <span class="comment">//方法一：获得JobDataMap</span></span><br><span class="line">        System.out.println(<span class="string">&quot;say hello to &quot;</span> + name + <span class="string">&quot;[&quot;</span> + map.getInt(<span class="string">&quot;age&quot;</span>) + <span class="string">&quot;]&quot;</span> + <span class="string">&quot; at &quot;</span></span><br><span class="line">                           + <span class="keyword">new</span> Date());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//方法二：属性的setter方法，会将JobDataMap的属性自动注入</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123; </span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于同一个JobDetail实例，执行的多个Job实例，是共享同样的JobDataMap，也就是说，如果你在任务里修改了里面的值，会对其他Job实例（并发的或者后续的）造成影响。</p><p>除了JobDetail，Trigger同样有一个JobDataMap，共享范围是所有使用这个Trigger的Job实例。</p><h4 id="Job并发"><a href="#Job并发" class="headerlink" title="Job并发"></a>Job并发</h4><p>Job是有可能并发执行的，比如一个任务要执行10秒中，而调度算法是每秒中触发1次，那么就有可能多个任务被并发执行。</p><p>有时候我们并不想任务并发执行，比如这个任务要去”获得数据库中所有未发送邮件的名单“，如果是并发执行，就需要一个数据库锁去避免一个数据被多次处理。这个时候一个@DisallowConcurrentExecution解决这个问题。</p><p>就是这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DoNothingJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="meta">@DisallowConcurrentExecution</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;do nothing&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，@DisallowConcurrentExecution是对JobDetail实例生效，也就是如果你定义两个JobDetail，引用同一个Job类，是可以并发执行的。</p><h4 id="JobExecutionException"><a href="#JobExecutionException" class="headerlink" title="JobExecutionException"></a>JobExecutionException</h4><p>Job.execute()方法是不允许抛出除JobExecutionException之外的所有异常的（包括RuntimeException)，所以编码的时候，最好是try-catch住所有的Throwable，小心处理。</p><h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>Scheduler就是Quartz的大脑，所有任务都是由它来设施。</p><p>Schduelr包含一个两个重要组件: JobStore和ThreadPool。</p><p>JobStore是会来存储运行时信息的，包括Trigger,Schduler,JobDetail，业务锁等。它有多种实现RAMJob(内存实现)，JobStoreTX(JDBC，事务由Quartz管理），JobStoreCMT(JDBC，使用容器事务)，ClusteredJobStore(集群实现)、TerracottaJobStore(什么是Terractta)。</p><p>ThreadPool就是线程池，Quartz有自己的线程池实现。所有任务的都会由线程池执行。</p><h4 id="SchedulerFactory"><a href="#SchedulerFactory" class="headerlink" title="SchedulerFactory"></a>SchedulerFactory</h4><p>SchdulerFactory，顾名思义就是来用创建Schduler了，有两个实现：DirectSchedulerFactory和 StdSchdulerFactory。前者可以用来在代码里定制你自己的Schduler参数。后者是直接读取classpath下的quartz.properties（不存在就都使用默认值）配置来实例化Schduler。通常来讲，我们使用StdSchdulerFactory也就足够了。</p><p>SchdulerFactory本身是支持创建RMI stub的，可以用来管理远程的Scheduler，功能与本地一样，可以远程提交个Job什么的。</p><p>DirectSchedulerFactory的创建接口</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Same as</span><br><span class="line">     * &#123;@link DirectSchedulerFactory#createScheduler(ThreadPool threadPool, JobStore jobStore)&#125;,</span><br><span class="line">     * with the addition of specifying the scheduler name and instance ID. This</span><br><span class="line">     * scheduler can only be retrieved via</span><br><span class="line">     * &#123;@link DirectSchedulerFactory#getScheduler(String)&#125;</span><br><span class="line">     *</span><br><span class="line">     * @param schedulerName</span><br><span class="line">     *          The name for the scheduler.</span><br><span class="line">     * @param schedulerInstanceId</span><br><span class="line">     *          The instance ID for the scheduler.</span><br><span class="line">     * @param threadPool</span><br><span class="line">     *          The thread pool for executing jobs</span><br><span class="line">     * @param jobStore</span><br><span class="line">     *          The type of job store</span><br><span class="line">     * @throws SchedulerException</span><br><span class="line">     *           if initialization failed</span><br><span class="line">     */</span><br><span class="line">    public void createScheduler(String schedulerName,</span><br><span class="line">            String schedulerInstanceId, ThreadPool threadPool, JobStore jobStore)</span><br><span class="line">        throws SchedulerException;</span><br></pre></td></tr></table></figure><p>StdSchdulerFactory的配置例子，更多配置，参考<a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/">Quartz配置指南</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">org.quartz.scheduler.instanceName = DefaultQuartzScheduler</span><br><span class="line">org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool</span><br><span class="line">org.quartz.threadPool.threadCount = 10 </span><br><span class="line">org.quartz.threadPool.threadPriority = 5</span><br><span class="line">org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true</span><br><span class="line">org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore</span><br></pre></td></tr></table></figure><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>JobStore <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-09">介绍</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/">配置</a></li></ul></li><li>集群: <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-11">介绍</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/ConfigJDBCJobStoreClustering">配置</a></li></ul></li><li>RMI</li><li>监听器 <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-07">TriggerListeners and JobListeners</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-08">SchedulerListeners</a></li></ul></li><li>插件</li></ul><p>主要的资料来自<a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/">官方文档</a>，这里有教程，例子，配置等，非常详细</p><h2 id="Quartz源码解析"><a href="#Quartz源码解析" class="headerlink" title="Quartz源码解析"></a>Quartz源码解析</h2><h3 id="Quartz启动流程"><a href="#Quartz启动流程" class="headerlink" title="Quartz启动流程"></a>Quartz启动流程</h3><p>当服务器启动时，Spring就加载相关的bean。<br>SchedulerFactoryBean实现了InitializingBean接口，因此在初始化bean的时候，会执行afterPropertiesSet方法，该方法将会调用SchedulerFactory(DirectSchedulerFactory 或者 StdSchedulerFactory，通常用StdSchedulerFactory)创建Scheduler。==<br>我们在SchedulerFactoryBean配置类中配了相关的配置及配置文件参数，所以会读取配置文件参数，初始化各个组件。  </p><p>关键组件如下：</p><ul><li><strong>ThreadPool</strong>：一般是使用SimpleThreadPool(线程数量固定的线程池),SimpleThreadPool创建了一定数量的WorkerThread实例来使得Job能够在线程中进行处理。WorkerThread是定义在SimpleThreadPool类中的内部类，它实质上就是一个线程。<br>在SimpleThreadPool中有三个list：workers-存放池中所有的线程引用，availWorkers-存放所有空闲的线程，busyWorkers-存放所有工作中的线程；配置如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool</span><br><span class="line">org.quartz.threadPool.threadCount=3</span><br><span class="line">org.quartz.threadPool.threadPriority=5</span><br></pre></td></tr></table></figure></li><li><strong>JobStore</strong>： 初始化定时任务的数据存储方式，分为两种：<ul><li>存储在内存的RAMJobStore<br>存取速度非常快，但是由于其在系统被停止后所有的数据都会丢失，所以在集群应用中，必须使用JobStoreSupport</li><li>存储在数据库的JobStoreSupport(包括JobStoreTX和JobStoreCMT两种实现，JobStoreCMT是依赖于容器来进行事务的管理，而JobStoreTX是自己管理事务） </li></ul></li><li><strong>QuartzSchedulerThread</strong>： 初始化调度线程，在初始化的时候paused=true,halted=false,虽然线程开始运行了，但是paused=true，线程会一直等待，直到start方法将paused置为false；SchedulerFactoryBean还实现了SmartLifeCycle接口，因此初始化完成后，会执行start()方法，该方法将主要会执行以下的几个动作：<ul><li>创建ClusterManager线程并启动线程:该线程用来进行集群故障检测和处理</li><li>创建MisfireHandler线程并启动线程:该线程用来进行misfire任务的处理</li><li>置QuartzSchedulerThread的paused=false，调度线程才真正开始调度</li></ul>整个启动流程图如下：<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img.png" alt="img.png"><br>流程图简要说明：<ol><li>先读取配置文件</li><li>初始化SchedulerFactoryBean</li><li>初始化SchedulerFactory</li><li>实例化执行线程池（TheadPool）</li><li>实例化数据存储</li><li>初始化QuartzScheduler(为Scheduler的简单实现，包括调度作业、注册JobListener实例等方法。)</li><li>new一个QuartzSchedulerThread调度线程（负责执行在QuartzScheduler中注册的触发触发器的线程。），并开始运行</li><li>调度开始，注册监听器，注册Job和Trigger</li><li>SchedulerFactoryBean初始化完成后执行start()方法</li><li>创建ClusterManager线程并启动线程</li><li>创建MisfireHandler线程并启动线程</li><li>置QuartzSchedulerThread的paused=false，调度线程真正开始调度，开始执行run方法</li></ol></li></ul><h3 id="Quartz-线程视图"><a href="#Quartz-线程视图" class="headerlink" title="Quartz 线程视图"></a>Quartz 线程视图</h3><p>在Quartz中，有两类线程，Scheduler调度线程和任务执行线程，其中任务执行线程通常使用一个线程池维护一组线程。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_3.png" alt="img.png"></p><p>Scheduler调度线程主要有两个：执行常规调度的线程，和执行misfiredtrigger的线程。  </p><ul><li>常规调度线程轮询存储的所有trigger，如果有需要触发的trigger，即到达了下一次触发的时间，则从任务执行线程池获取一个空闲线程，执行与该trigger关联的任务。<br>— Misfire线程是扫描所有的trigger，查看是否有misfiredtrigger，如果有的话根据misfire的策略分别处理(fire now OR wait for the next fire)。</li></ul><h3 id="QuartzSchedulerThread逻辑具体介绍"><a href="#QuartzSchedulerThread逻辑具体介绍" class="headerlink" title="QuartzSchedulerThread逻辑具体介绍"></a>QuartzSchedulerThread逻辑具体介绍</h3><p>类中主要的方法就是run方法，下面主要对run方法进行介绍：</p><details><summary>源码解析</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//只有当Quartzscheduler执行start方法时被调用</span><br><span class="line">void togglePause(boolean pause) &#123;</span><br><span class="line">    synchronized(this.sigLock) &#123;</span><br><span class="line">        this.paused = pause;</span><br><span class="line">        if (this.paused) &#123;</span><br><span class="line">          this.signalSchedulingChange(0L);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          this.sigLock.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">public void run() &#123;</span><br><span class="line">    boolean lastAcquireFailed = false;</span><br><span class="line">    label214:</span><br><span class="line">    //此处判断调度器是否终止</span><br><span class="line">    while(!this.halted.get()) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            synchronized(this.sigLock) &#123;</span><br><span class="line">                //此处判断调度器是否终止或是否暂停，由于我们在初始化的时候</span><br><span class="line">                //将paused=true，那么调度线程此时不会真正开始执行只会在不断循环阻塞</span><br><span class="line">                //只有当Quartzscheduler执行start方法时调用togglePause开始将</span><br><span class="line">                //paused置为false,run方法开始真正运行</span><br><span class="line">                while(this.paused &amp;&amp; !this.halted.get()) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        this.sigLock.wait(1000L);</span><br><span class="line">                    &#125; catch (InterruptedException var23) &#123;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                if (this.halted.get()) &#123;</span><br><span class="line">                    break;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            //取出执行线程池中空闲的线程数量</span><br><span class="line">            int availThreadCount = this.qsRsrcs.getThreadPool().blockForAvailableThreads();</span><br><span class="line">            if (availThreadCount &gt; 0) &#123;</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">            //如果可用线程数量足够那么查看30秒内需要触发的触发器。如果没有的</span><br><span class="line">            //话那么就是30后再次扫描，其中方法中三个参数idleWaitTime为如果</span><br><span class="line">            //没有的再次扫描的时间，第二个为最多取几个，最后一个参数</span><br><span class="line">            //batchTimeWindow，这个参数默认是0，同样是一个时间范围，如果</span><br><span class="line">            //有两个任务只差一两秒，而执行线程数量满足及batchTimeWindow时间</span><br><span class="line">            //也满足的情况下就会两个都取出来</span><br><span class="line"></span><br><span class="line">            triggers = this.qsRsrcs.getJobStore().acquireNextTriggers(now + this.idleWaitTime, Math.min(availThreadCount, this.qsRsrcs.getMaxBatchSize()), this.qsRsrcs.getBatchTimeWindow());</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">            //trigger列表是以下次执行时间排序查出来的</span><br><span class="line">            //在列表不为空的时候进行后续操作</span><br><span class="line">            if (triggers != null &amp;&amp; !triggers.isEmpty()) &#123;</span><br><span class="line">            now = System.currentTimeMillis();</span><br><span class="line">            //取出集合中最早执行的触发器</span><br><span class="line">            long triggerTime = ((OperableTrigger)triggers.get(0)).getNextFireTime().getTime();</span><br><span class="line">            //判断距离执行时间是否大于两毫秒</span><br><span class="line">            for(long timeUntilTrigger = triggerTime - now; timeUntilTrigger &gt; 2L; timeUntilTrigger = triggerTime - now) &#123;</span><br><span class="line">                synchronized(this.sigLock) &#123;</span><br><span class="line">                    if (this.halted.get()) &#123;</span><br><span class="line">                        break;</span><br><span class="line">                    &#125;</span><br><span class="line">                    //判断是否还有更早的trigger</span><br><span class="line">                    if (!this.isCandidateNewTimeEarlierWithinReason(triggerTime, false)) &#123;</span><br><span class="line">                    //没有的话进行简单的阻塞，到时候再执行</span><br><span class="line">                        try &#123;</span><br><span class="line">                            now = System.currentTimeMillis();</span><br><span class="line">                            timeUntilTrigger = triggerTime - now;</span><br><span class="line">                            if (timeUntilTrigger &gt;= 1L) &#123;</span><br><span class="line">                                this.sigLock.wait(timeUntilTrigger);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; catch (InterruptedException var22) &#123;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //开始根据需要执行的trigger从数据库中获取相应的JobDetail</span><br><span class="line">                 if (goAhead) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        List&lt;TriggerFiredResult&gt; res = this.qsRsrcs.getJobStore().triggersFired(triggers);</span><br><span class="line">                        if (res != null) &#123;</span><br><span class="line">                            bndles = res;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; catch (SchedulerException var24) &#123;</span><br><span class="line">                        this.qs.notifySchedulerListenersError(&quot;An error occurred while firing triggers &#x27;&quot; + triggers + &quot;&#x27;&quot;, var24);</span><br><span class="line">                        int i = 0;</span><br><span class="line"></span><br><span class="line">                        while(true) &#123;</span><br><span class="line">                            if (i &gt;= triggers.size()) &#123;</span><br><span class="line">                                continue label214;</span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                            ++i;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //将查询到的结果封装成为 TriggerFiredResult</span><br><span class="line">                 for(int i = 0; i &lt; ((List)bndles).size(); ++i) &#123;</span><br><span class="line">                    TriggerFiredResult result = (TriggerFiredResult)((List)bndles).get(i);</span><br><span class="line">                    TriggerFiredBundle bndle = result.getTriggerFiredBundle();</span><br><span class="line">                    Exception exception = result.getException();</span><br><span class="line">                    if (exception instanceof RuntimeException) &#123;</span><br><span class="line">                        this.getLog().error(&quot;RuntimeException while firing trigger &quot; + triggers.get(i), exception);</span><br><span class="line">                        this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                    &#125; else if (bndle == null) &#123;</span><br><span class="line">                        this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        JobRunShell shell = null;</span><br><span class="line"></span><br><span class="line">                        try &#123;</span><br><span class="line">                        //把任务封装成JobRunShell线程任务，然后放到线程池中跑动。</span><br><span class="line">                            shell = this.qsRsrcs.getJobRunShellFactory().createJobRunShell(bndle);</span><br><span class="line">                            shell.initialize(this.qs);</span><br><span class="line">                        &#125; catch (SchedulerException var27) &#123;</span><br><span class="line">                            this.qsRsrcs.getJobStore().triggeredJobComplete((OperableTrigger)triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR);</span><br><span class="line">                            continue;</span><br><span class="line">                        &#125;</span><br><span class="line">                        //runInThread方法加Job放入对应的工作线程进行执行Job</span><br><span class="line">                        if (!this.qsRsrcs.getThreadPool().runInThread(shell)) &#123;</span><br><span class="line">                            this.getLog().error(&quot;ThreadPool.runInThread() return false!&quot;);</span><br><span class="line">                            this.qsRsrcs.getJobStore().triggeredJobComplete((OperableTrigger)triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure></details><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_1.png" alt="img_1.png"></p><p>总结下来:</p><ol><li>先获取线程池中的可用线程数量（若没有可用的会阻塞，直到有可用的）；</li><li>获取30m内要执行的trigger(即acquireNextTriggers)获取trigger的锁，通过select …for update方式实现；获取30m内（可配置）要执行的triggers（需要保证集群节点的时间一致），若@ConcurrentExectionDisallowed且列表存在该条trigger则跳过，否则更新trigger状态为ACQUIRED(刚开始为WAITING)；插入firedTrigger表，状态为ACQUIRED;（注意：在RAMJobStore中，有个timeTriggers，排序方式是按触发时间nextFireTime排的；JobStoreSupport从数据库取出triggers时是按照nextFireTime排序）;</li><li>待直到获取的trigger中最先执行的trigger在2ms内；</li><li>triggersFired：<ol><li>更新firedTrigger的status=EXECUTING;</li><li>更新trigger下一次触发的时间; </li><li>更新trigger的状态：无状态的trigger-&gt;WAITING，有状态的trigger-&gt;BLOCKED，若nextFireTime==null -&gt;COMPLETE；</li><li>commit connection,释放锁；</li></ol></li><li>针对每个要执行的trigger，创建JobRunShell，并放入线程池执行：<ol><li>execute:执行job</li><li>获取TRIGGER_ACCESS锁</li><li>若是有状态的job：更新trigger状态：BLOCKED-&gt;WAITING,PAUSED_BLOCKED-&gt;BLOCKED</li><li>若@PersistJobDataAfterExecution，则updateJobData</li><li>删除firedTrigger</li><li>commit connection，释放锁</li></ol></li></ol><h3 id="misfireHandler线程"><a href="#misfireHandler线程" class="headerlink" title="misfireHandler线程"></a>misfireHandler线程</h3><p>下面这些原因可能造成 misfired job:</p><ol><li>系统因为某些原因被重启。在系统关闭到重新启动之间的一段时间里，可能有些任务会被 misfire；</li><li>Trigger 被暂停（suspend）的一段时间里，有些任务可能会被 misfire；</li><li>线程池中所有线程都被占用，导致任务无法被触发执行，造成 misfire；</li><li>有状态任务在下次触发时间到达时，上次执行还没有结束；为了处理 misfired job，Quartz 中为 trigger定义了处理策略，主要有下面两种：MISFIRE_INSTRUCTION_FIRE_ONCE_NOW：针对 misfired job马上执行一次；MISFIRE_INSTRUCTION_DO_NOTHING：忽略 misfired job，等待下次触发；默认是MISFIRE_INSTRUCTION_SMART_POLICY，该策略在CronTrigger中=MISFIRE_INSTRUCTION_FIRE_ONCE_NOW线程默认1分钟执行一次；在一个事务中，默认一次最多recovery 20个；</li></ol><p>执行流程：<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_2.png" alt="img_2.png"></p><ol><li>若配置(默认为true，可配置)成获取锁前先检查是否有需要recovery的trigger，先获取misfireCount；</li><li>获取TRIGGER_ACCESS锁；</li><li>hasMisfiredTriggersInState：获取misfired的trigger，默认一个事务里只能最大20个misfired trigger（可配置），misfired判断依据：status=waiting,next_fire_time &lt; current_time-misfirethreshold(可配置，默认1min)</li><li>notifyTriggerListenersMisfired</li><li>updateAfterMisfire:获取misfire策略(默认是MISFIRE_INSTRUCTION_SMART_POLICY，该策略在CronTrigger中=MISFIRE_INSTRUCTION_FIRE_ONCE_NOW)，根据策略更新nextFireTime；</li><li>将nextFireTime等更新到trigger表；</li><li>commit connection，释放锁8.如果还有更多的misfired，sleep短暂时间(为了集群负载均衡)，否则sleep misfirethreshold时间，后继续轮询；</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Quartz可以用来做什么？&quot;&gt;&lt;a href=&quot;#Quartz可以用来做什么？&quot; class=&quot;headerlink&quot; title=&quot;Quartz可以用来做什么？&quot;&gt;&lt;/a&gt;Quartz可以用来做什么？&lt;/h2&gt;&lt;p&gt;在某一个有规律的时间点干某件事。&lt;br&gt;并且</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
    <category term="Quartz" scheme="http://example.com/tags/Quartz/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之单机定时调度Linux定时任务cron</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/</id>
    <published>2021-07-14T01:07:05.000Z</published>
    <updated>2021-07-14T08:49:21.105Z</updated>
    
    <content type="html"><![CDATA[<p>实现linux定时任务有：cron、anacron、at,使用最多的是cron任务</p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul><li>cron–服务名；</li><li>crond–linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似；</li><li>crontab–是定制好的计划任务表，一个设置cron的工具</li></ul><h2 id="软件包安装"><a href="#软件包安装" class="headerlink" title="软件包安装"></a>软件包安装</h2><p>要使用cron服务，先要安装vixie-cron软件包和crontabs软件包，两个软件包作用如下：</p><ul><li>vixie-cron软件包是cron的主程序。<ul><li>查看是否安装了cron软件包: rpm -qa|grep vixie-cron</li></ul></li><li>crontabs软件包是用来安装、卸装、或列举用来驱动 cron 守护进程的表格的程序。<ul><li>查看是否安装了crontabs软件包:rpm -qa|grep crontabs</li></ul></li></ul><p>如果没有安装，则执行如下命令安装软件包(软件包必须存在)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh vixie-cron-4.1-54.FC5*</span><br><span class="line">rpm -ivh crontabs*</span><br></pre></td></tr></table></figure><p>如果本地没有安装包，在能够连网的情况下可以在线安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install vixie-cron</span><br><span class="line">yum install crontabs</span><br></pre></td></tr></table></figure><h3 id="查看crond服务是否运行"><a href="#查看crond服务是否运行" class="headerlink" title="查看crond服务是否运行"></a>查看crond服务是否运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pgrep crond 或 </span><br><span class="line">/sbin/service crond status 或 </span><br><span class="line">ps -elf|grep crond|grep -v &quot;grep&quot;</span><br></pre></td></tr></table></figure><h3 id="crond服务操作命令"><a href="#crond服务操作命令" class="headerlink" title="crond服务操作命令"></a>crond服务操作命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/sbin/service crond start //启动服务  </span><br><span class="line">/sbin/service crond stop //关闭服务  </span><br><span class="line">/sbin/service crond restart //重启服务  </span><br><span class="line">/sbin/service crond reload //重新载入配置</span><br></pre></td></tr></table></figure><h2 id="配置定时任务"><a href="#配置定时任务" class="headerlink" title="配置定时任务"></a>配置定时任务</h2><p>cron有两个配置文件，一个是一个全局配置文件（/etc/crontab），是针对系统任务的；一组是crontab命令生成的配置文件（/var/spool/cron下的文件），是针对某个用户的.定时任务配置到任意一个中都可以。</p><p>查看全局配置文件配置情况: <code>cat /etc/crontab</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">　---------------------------------------------</span><br><span class="line">　　SHELL=/bin/bash</span><br><span class="line">　　PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">　　MAILTO=root</span><br><span class="line">　　HOME=/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">　　#</span><span class="bash"> run-parts</span></span><br><span class="line">　　01 * * * * root run-parts /etc/cron.hourly</span><br><span class="line">　　02 4 * * * root run-parts /etc/cron.daily</span><br><span class="line">　　22 4 * * 0 root run-parts /etc/cron.weekly</span><br><span class="line">　　42 4 1 * * root run-parts /etc/cron.monthly</span><br><span class="line">　　----------------------------------------------</span><br></pre></td></tr></table></figure><p>查看用户下的定时任务:crontab -l或cat /var/spool/cron/用户名</p><h3 id="crontab任务配置基本格式"><a href="#crontab任务配置基本格式" class="headerlink" title="crontab任务配置基本格式"></a>crontab任务配置基本格式</h3><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img.png" alt="img.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-----------------------------------------------------------------------</span><br><span class="line">*   *　 *　 *　 *　　command</span><br><span class="line">分钟(0-59)　小时(0-23)　日期(1-31)　月份(1-12)　星期(0-6,0代表星期天)　 命令</span><br><span class="line">第1列表示分钟1～59 每分钟用*或者 */1表示</span><br><span class="line">第2列表示小时1～23（0表示0点）</span><br><span class="line">第3列表示日期1～31</span><br><span class="line">第4列表示月份1～12</span><br><span class="line">第5列标识号星期0～6（0表示星期天）</span><br><span class="line">第6列要运行的命令</span><br><span class="line"></span><br><span class="line">-----------------------------------------------------------------------</span><br><span class="line">在以上任何值中，星号（*）可以用来代表所有有效的值。譬如，月份值中的星号意味着在满足其它制约条件后每月都执行该命令。</span><br><span class="line">整数间的短线（-）指定一个整数范围。譬如，1-4 意味着整数 1、2、3、4。</span><br><span class="line">用逗号（,）隔开的一系列值指定一个列表。譬如，3, 4, 6, 8 标明这四个指定的整数。</span><br><span class="line">正斜线（/）可以用来指定间隔频率。在范围后加上 /&lt;integer&gt; 意味着在范围内可以跳过 integer。譬如，0-59/2 可以用来在分钟字段定义每两分钟。间隔频率值还可以和星号一起使用。例如，*/3 的值可以用在月份字段中表示每三个月运行一次任务。</span><br><span class="line">开头为井号（#）的行是注释，不会被处理</span><br><span class="line">-----------------------------------------------------------------------</span><br></pre></td></tr></table></figure><details><summary>使用实例</summary><pre><code>实例1：每1分钟执行一次command命令：* * * * * command<p>实例2：每小时的第3和第15分钟执行<br>命令：3,15 * * * * command</p><p>实例3：在上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 * * * command</p><p>实例4：每隔两天的上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 */2 * * command</p><p>实例5：每个星期一的上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 * * 1 command</p><p>实例6：每晚的21:30重启smb<br>命令：30 21 * * * /etc/init.d/smb restart</p><p>实例7：每月1、10、22日的4 : 45重启smb<br>命令：45 4 1,10,22 * * /etc/init.d/smb restart</p><p>实例8：每周六、周日的1 : 10重启smb<br>命令：10 1 * * 6,0 /etc/init.d/smb restart</p><p>实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb<br>命令：0,30 18-23 * * * /etc/init.d/smb restart</p><p>实例10：每星期六的晚上11 : 00 pm重启smb<br>命令：0 23 * * 6 /etc/init.d/smb restart</p><p>实例11：每一小时重启smb<br>命令：* */1 * * * /etc/init.d/smb restart</p><p>实例12：晚上11点到早上7点之间，每隔一小时重启smb<br>命令：* 23-7/1 * * * /etc/init.d/smb restart</p><p>实例13：每月的4号与每周一到周三的11点重启smb<br>命令：0 11 4 * mon-wed /etc/init.d/smb restart</p><p>实例14：一月一号的4点重启smb<br>命令：0 4 1 jan * /etc/init.d/smb restart</p><p>实例15：每小时执行/etc/cron.hourly目录内的脚本<br>命令：01   *   *   *   *     root run-parts /etc/cron.hourly<br>说明：<br>run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了</p></code></pre><p></p></details><h2 id="cron实现原理"><a href="#cron实现原理" class="headerlink" title="cron实现原理"></a>cron实现原理</h2><h3 id="基本原理图解"><a href="#基本原理图解" class="headerlink" title="基本原理图解"></a>基本原理图解</h3><p>fork 进程 + sleep 轮询<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img_1.png" alt="img_1.png"><br>Cron每分钟做一次检查，看看哪个命令可执行。</p><p>从上图可以看到，有4次fork，这4次fork分别是：</p><ul><li>第一个fork，让Cron自己成为Daemon进程，即成为守护进程；</li><li>第二个fork，当Cron检查到有命令需要执行时被创建，但注意它并不执行命令，执行命令由它的子进程来做；</li><li>第三个fork，有些版本调用的是vfork，但有些版本却是fork，它是负责执行Cron命令的进程，即会调用execle()的进程；</li><li>第四个fork不是必须的，只有为Cron命令配置了标准输入才会用：<br><code>*/1 * * * * /tmp/X/x%1234567890</code><br>像上面有个百分符“%”，后面跟一串，则会有第四个fork，它的作用是将“%”后面的内容作为标准输入传递给第三个fork出来的进程。</li></ul><p>注意fork出来的进程没有忽略(ignore)管道信号(SIGPIPE)，所以如果遇到SIGPIPE，则会导致进程无声无息的退出，比如标准输主输出重定向管道的读端被关闭了，写时就会触发SIGPIPE。</p><p>实践中，可能会遇到child_process()在做上述所说的第三个fork前因SIGPIPE信号退出，导致难以理解的问题。其中一个现象 是：Cron命令被执行了若干次，但之后再也不执行了，原因在于第二个fork出来的进程因SIGPIPE退出了，导致没有进行第三个fork，因此 Cron命令没有被调用(总是由execle()调用)。</p><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img_2.png" alt="img_2.png"></p><h3 id="一个诡异的问题"><a href="#一个诡异的问题" class="headerlink" title="一个诡异的问题"></a>一个诡异的问题</h3><p>你有可能遇到这样的情况，假设在cron中有如下一条配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo hello &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>观察到它正常运行几次后，就不再运行了，或者一次也不能，但确认无其它问题，因此十分诡异。</p><p>这个问题的原因，有可能是因为有共享库Hook了cron，共享库代码触发了SIGPIPE，导致了第二个fork出的进程退出，没来得及执行vfork。</p><p>fork出来的子进程，没有对SIGPIPE进行任何处理，默认行为是悄悄退出进程。通过修改/etc/ld.so.preload，可以将共享库注入到非关联的进程中，可通过ldd观察到这种依赖，使用LD_PRELOAD也可以达到同样的效果。</p><h3 id="crontab编辑后cron异常"><a href="#crontab编辑后cron异常" class="headerlink" title="crontab编辑后cron异常"></a>crontab编辑后cron异常</h3><p>使用crontab编辑后，cron卡住不动(不是指进程卡住了，而是指命令没有被调用)，原因可能是因为“tcb table full”，最简单的办法是重启cron。</p><p>建议避免写下面这样的嵌套命令语句，它有可能导致cron不能正常工作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo &quot;`date +%H:%M:%S` hello&quot; &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>“echo”中嵌套了“date”，可以改成脚本调用，或者不嵌套命令，如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo &quot;hello&quot; &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>一个现象是有一个cron子进程(如下述的14786)不退出了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ps -ef|grep cron</span></span><br><span class="line"></span><br><span class="line">root     10325     1  0 15:08 ?        00:00:00 /usr/sbin/cron</span><br><span class="line">root     14786 10325  0 15:13 ?        00:00:00 /usr/sbin/cron</span><br></pre></td></tr></table></figure><p>gdb看到的调用栈为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">0  0xffffe410 <span class="keyword">in</span> __kernel_vsyscall ()</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1  0xb7e88a63 <span class="keyword">in</span> __read_nocancel () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">2  0xb7e38e38 <span class="keyword">in</span> _IO_file_read_internal () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">3  0xb7e3a0bb <span class="keyword">in</span> _IO_new_file_underflow () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">4  0xb7e3a7fb <span class="keyword">in</span> _IO_default_uflow_internal () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">5  0xb7e3bb2d <span class="keyword">in</span> __uflow () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">6  0xb7e35b7b <span class="keyword">in</span> getc () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">7  0x80005d73 <span class="keyword">in</span> ?? () from /usr/sbin/cron</span></span><br></pre></td></tr></table></figure><p>strace看到如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> strace -f -p 14786</span></span><br><span class="line"></span><br><span class="line">Process 14786 attached</span><br><span class="line">read(7,</span><br></pre></td></tr></table></figure><p>借助lsof可以看到：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cron    14786 root    7r  FIFO        0,6         117960708 pipe</span><br></pre></td></tr></table></figure><p>为一个管道，read()挂住的原因可能是因为管道另一端所在进程调用_exit()退出而不是调用exit()退出。</p><p>这个时候只有人工kill这个挂起的cron子进程。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;实现linux定时任务有：cron、anacron、at,使用最多的是cron任务&lt;/p&gt;
&lt;h2 id=&quot;名词解释&quot;&gt;&lt;a href=&quot;#名词解释&quot; class=&quot;headerlink&quot; title=&quot;名词解释&quot;&gt;&lt;/a&gt;名词解释&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;cron–服务</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>JAVA线上故障排查全套路</title>
    <link href="http://example.com/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/"/>
    <id>http://example.com/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/</id>
    <published>2021-07-13T10:11:00.000Z</published>
    <updated>2021-07-14T09:01:26.746Z</updated>
    
    <content type="html"><![CDATA[<p>线上故障主要会包括cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。</p><p>同时例如jstack、jmap等工具也是不囿于一个方面的问题的，基本上出问题就是df、free、top 三连，然后依次jstack、jmap伺候，具体问题具体分析即可。</p><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><p>一般来讲我们首先会排查cpu方面的问题。cpu异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁gc以及上下文切换过多。而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用jstack来分析对应的堆栈情况。</p><h3 id="使用jstack分析cpu问题"><a href="#使用jstack分析cpu问题" class="headerlink" title="使用jstack分析cpu问题"></a>使用jstack分析cpu问题</h3><p>我们先用ps命令找到对应进程的pid(如果你有好几个目标进程，可以先用top看一下哪个占用比较高)。<br>接着用top -H -p pid来找到cpu使用率比较高的一些线程<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img.png" alt="img.png"><br>然后将占用最高的pid转换为16进制printf ‘%x\n’ pid得到nid<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_1.png" alt="img_1.png"><br>接着直接在jstack中找到相应的堆栈信息jstack pid |grep ‘nid’ -C5 –color<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_2.png" alt="img_2.png"><br>可以看到我们已经找到了nid为0x42的堆栈信息，接着只要仔细分析一番即可。</p><p>当然更常见的是我们对整个jstack文件进行分析，通常我们会比较关注WAITING和TIMED_WAITING的部分，BLOCKED就不用说了。我们可以使用命令cat jstack.log | grep “java.lang.Thread.State” | sort -nr | uniq -c来对jstack的状态有一个整体的把握，如果WAITING之类的特别多，那么多半是有问题啦。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_3.png" alt="img_3.png"></p><h3 id="频繁gc"><a href="#频繁gc" class="headerlink" title="频繁gc"></a>频繁gc</h3><p>当然我们还是会使用jstack来分析问题，但有时候我们可以先确定下gc是不是太频繁，使用<strong>jstat -gc pid 1000</strong>命令来对gc分代变化情况进行观察，</p><ul><li>1000表示采样间隔(ms)</li><li>S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU分别代表两个Survivor区、Eden区、老年代、元数据区的容量和使用量。</li><li>YGC/YGT、FGC/FGCT、GCT则代表YoungGc、FullGc的耗时和次数以及总耗时。</li></ul><p>如果看到gc比较频繁，再针对gc方面做进一步分析，具体可以参考一下gc章节的描述。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_4.png" alt="img_4.png"></p><h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>针对频繁上下文问题，我们可以使用vmstat命令来进行查看<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_5.png" alt="img_5.png"><br>cs(context switch)一列则代表了上下文切换的次数。<br>如果我们希望对特定的pid进行监控那么可以使用 pidstat -w pid命令，cswch和nvcswch表示自愿及非自愿切换。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_6.png" alt="img_6.png"></p><h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><p>磁盘问题和cpu一样是属于比较基础的。首先是磁盘空间方面，我们直接使用<strong>df -hl</strong>来查看文件系统状态<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_7.png" alt="img_7.png"><br>更多时候，磁盘问题还是性能上的问题。我们可以通过iostatiostat -d -k -x来进行分析<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_8.png" alt="img_8.png"><br>最后一列%util可以看到每块磁盘写入的程度，而rrqpm/s以及wrqm/s分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。</p><p>另外我们还需要知道是哪个进程在进行读写，一般来说开发自己心里有数，或者用iotop命令来进行定位文件读写的来源。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_9.png" alt="img_9.png"><br>不过这边拿到的是tid，我们要转换成pid，可以通过readlink来找到pidreadlink -f /proc/*/task/tid/../..。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_10.png" alt="img_10.png"><br>找到pid之后就可以看这个进程具体的读写情况cat /proc/pid/io<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_11.png" alt="img_11.png"><br>我们还可以通过lsof命令来确定具体的文件读写情况lsof -p pid<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_12.png" alt="img_12.png"></p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><p>内存问题排查起来相对比CPU麻烦一些，场景也比较多。主要包括OOM、GC问题和堆外内存。一般来讲，我们会先用free命令先来检查一发内存的各种情况。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_13.png" alt="img_13.png"></p><h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>内存问题大多还都是堆内内存问题。表象上主要分为OOM和StackOverflow。</p><h4 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h4><p><strong>Exception in thread “main” java.lang.OutOfMemoryError: unable to create new native thread</strong></p><p>这个意思是没有足够的内存空间给线程分配java栈，基本上还是线程池代码写的有问题，比如说忘记shutdown，所以说应该首先从代码层面来寻找问题，使用jstack或者jmap。如果一切都正常，JVM方面可以通过指定Xss来减少单个thread stack的大小。另外也可以在系统层面，可以通过修改/etc/security/limits.confnofile和nproc来增大os对线程的限制<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_14.png" alt="img_14.png"></p><p><strong>Exception in thread “main” java.lang.OutOfMemoryError: Java heap space</strong></p><p>这个意思是堆的内存占用已经达到-Xmx设置的最大值，应该是最常见的OOM错误了。解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过jstack和jmap去定位问题。如果说一切都正常，才需要通过调整Xmx的值来扩大内存。</p><p><strong>Caused by: java.lang.OutOfMemoryError: Meta space</strong></p><p>这个意思是元数据区的内存占用已经达到XX:MaxMetaspaceSize设置的最大值，排查思路和上面的一致，参数方面可以通过XX:MaxPermSize来进行调整(这里就不说1.8以前的永久代了)。</p><h4 id="Stack-Overflow"><a href="#Stack-Overflow" class="headerlink" title="Stack Overflow"></a>Stack Overflow</h4><p>栈内存溢出，这个大家见到也比较多。</p><p><strong>Exception in thread “main” java.lang.StackOverflowError</strong></p><p>表示线程栈需要的内存大于Xss值，同样也是先进行排查，参数方面通过Xss来调整，但调整的太大可能又会引起OOM。</p><h4 id="使用JMAP定位代码内存泄漏"><a href="#使用JMAP定位代码内存泄漏" class="headerlink" title="使用JMAP定位代码内存泄漏"></a>使用JMAP定位代码内存泄漏</h4><p>上述关于OOM和StackOverflow的代码排查方面，我们一般使用JMAPjmap -dump:format=b,file=filename pid来导出dump文件<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_15.png" alt="img_15.png"></p><p>通过mat(Eclipse Memory Analysis Tools)导入dump文件进行分析，内存泄漏问题一般我们直接选Leak Suspects即可，mat给出了内存泄漏的建议。另外也可以选择Top Consumers来查看最大对象报告。和线程相关的问题可以选择thread overview进行分析。除此之外就是选择Histogram类概览来自己慢慢分析，大家可以搜搜mat的相关教程。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_16.png" alt="img_16.png"></p><p>日常开发中，代码产生内存泄漏是比较常见的事，并且比较隐蔽，需要开发者更加关注细节。比如说每次请求都new对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发gc；ByteBuffer缓存分配不合理等都会造成代码OOM。</p><p>另一方面，我们可以在启动参数中指定-XX:+HeapDumpOnOutOfMemoryError来保存OOM时的dump文件。</p><h4 id="gc问题和线程"><a href="#gc问题和线程" class="headerlink" title="gc问题和线程"></a>gc问题和线程</h4><p>gc问题除了影响cpu也会影响内存，排查思路也是一致的。一般先使用jstat来查看分代变化情况，比如youngGC或者fullGC次数是不是太多呀；EU、OU等指标增长是不是异常呀等。</p><p>线程的话太多而且不被及时gc也会引发oom，大部分就是之前说的unable to create new native thread。除了jstack细细分析dump文件外，我们一般先会看下总体线程，通过pstreee -p pid |wc -l。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_17.png" alt="img_17.png"></p><p>或者直接通过查看/proc/pid/task的数量即为线程数量。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_18.png" alt="img_18.png"></p><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>如果碰到堆外内存溢出，那可真是太不幸了。首先堆外内存溢出表现就是物理常驻内存增长快，报错的话视使用方式都不确定，如果由于使用Netty导致的，那错误日志里可能会出现OutOfDirectMemoryError错误，如果直接是DirectByteBuffer，那会报OutOfMemoryError: Direct buffer memory。</p><p>堆外内存溢出往往是和NIO的使用相关，一般我们先通过pmap来查看下进程占用的内存情况pmap -x pid | sort -rn -k3 | head -30，这段意思是查看对应pid倒序前30大的内存段。这边可以再一段时间后再跑一次命令看看内存增长情况，或者和正常机器比较可疑的内存段在哪里。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_19.png" alt="img_19.png"></p><p>我们如果确定有可疑的内存端，需要通过gdb来分析gdb –batch –pid {pid} -ex “dump memory filename.dump {内存起始地址} {内存起始地址+内存块大小}”</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_20.png" alt="img_20.png"></p><p>获取dump文件后可用heaxdump进行查看hexdump -C filename | less，不过大多数看到的都是二进制乱码。</p><p>NMT是Java7U40引入的HotSpot新特性，配合jcmd命令我们就可以看到具体内存组成了。需要在启动参数中加入 -XX:NativeMemoryTracking=summary 或者 -XX:NativeMemoryTracking=detail，会有略微性能损耗。</p><p>一般对于堆外内存缓慢增长直到爆炸的情况来说，可以先设一个基线jcmd pid VM.native_memory baseline。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_21.png" alt="img_21.png"></p><p>然后等放一段时间后再去看看内存增长的情况，通过jcmd pid VM.native_memory detail.diff(summary.diff)做一下summary或者detail级别的diff。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_22.png" alt="img_22.png"><br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_23.png" alt="img_23.png"></p><p>可以看到jcmd分析出来的内存十分详细，包括堆内、线程以及gc(所以上述其他内存异常其实都可以用nmt来分析)，这边堆外内存我们重点关注Internal的内存增长，如果增长十分明显的话那就是有问题了。</p><p>detail级别的话还会有具体内存段的增长情况，如下图。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_24.png" alt="img_24.png"></p><p>此外在系统层面，我们还可以使用strace命令来监控内存分配 strace -f -e “brk,mmap,munmap” -p pid</p><p>这边内存分配信息主要包括了pid和内存地址。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_25.png" alt="img_25.png"><br>不过其实上面那些操作也很难定位到具体的问题点，关键还是要看错误日志栈，找到可疑的对象，搞清楚它的回收机制，然后去分析对应的对象。比如DirectByteBuffer分配内存的话，是需要full GC或者手动system.gc来进行回收的(所以最好不要使用-XX:+DisableExplicitGC)。那么其实我们可以跟踪一下DirectByteBuffer对象的内存情况，通过jmap -histo:live pid手动触发fullGC来看看堆外内存有没有被回收。如果被回收了，那么大概率是堆外内存本身分配的太小了，通过-XX:MaxDirectMemorySize进行调整。如果没有什么变化，那就要使用jmap去分析那些不能被gc的对象，以及和DirectByteBuffer之间的引用关系了。</p><h3 id="GC问题"><a href="#GC问题" class="headerlink" title="GC问题"></a>GC问题</h3><p>堆内内存泄漏总是和GC异常相伴。不过GC问题不只是和内存问题相关，还有可能引起CPU负载、网络问题等系列并发症，只是相对来说和内存联系紧密些，所以我们在此单独总结一下GC相关问题。</p><p>我们在cpu章介绍了使用jstat来获取当前GC分代变化信息。而更多时候，我们是通过GC日志来排查问题的，在启动参数中加上-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps来开启GC日志。</p><p>常见的Young GC、Full GC日志含义在此就不做赘述了。</p><p>针对gc日志，我们就能大致推断出youngGC与fullGC是否过于频繁或者耗时过长，从而对症下药。我们下面将对G1垃圾收集器来做分析，这边也建议大家使用G1-XX:+UseG1GC。</p><h4 id="youngGC过频繁"><a href="#youngGC过频繁" class="headerlink" title="youngGC过频繁"></a>youngGC过频繁</h4><p>youngGC频繁一般是短周期小对象较多，先考虑是不是Eden区/新生代设置的太小了，看能否通过调整-Xmn、-XX:SurvivorRatio等参数设置来解决问题。如果参数正常，但是young gc频率还是太高，就需要使用Jmap和MAT对dump文件进行进一步排查了</p><h4 id="youngGC耗时过长"><a href="#youngGC耗时过长" class="headerlink" title="youngGC耗时过长"></a>youngGC耗时过长</h4><p>耗时过长问题就要看GC日志里耗时耗在哪一块了。以G1日志为例，可以关注Root Scanning、Object Copy、Ref Proc等阶段。Ref Proc耗时长，就要注意引用相关的对象。Root Scanning耗时长，就要注意线程数、跨代引用。Object Copy则需要关注对象生存周期。而且耗时分析它需要横向比较，就是和其他项目或者正常时间段的耗时比较。比如说图中的Root Scanning和正常时间段比增长较多，那就是起的线程太多了。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_26.png" alt="img_26.png"></p><h4 id="触发fullGC"><a href="#触发fullGC" class="headerlink" title="触发fullGC"></a>触发fullGC</h4><p>G1中更多的还是mixedGC，但mixedGC可以和youngGC思路一样去排查。触发fullGC了一般都会有问题，G1会退化使用Serial收集器来完成垃圾的清理工作，暂停时长达到秒级别，可以说是半跪了。</p><p>fullGC的原因可能包括以下这些，以及参数调整方面的一些思路：</p><ul><li><p>并发阶段失败：在并发标记阶段，MixGC之前老年代就被填满了，那么这时候G1就会放弃标记周期。这种情况，可能就需要增加堆大小，或者调整并发标记线程数-XX:ConcGCThreads。</p></li><li><p>晋升失败：在GC的时候没有足够的内存供存活/晋升对象使用，所以触发了Full GC。这时候可以通过-XX:G1ReservePercent来增加预留内存百分比，减少-XX:InitiatingHeapOccupancyPercent来提前启动标记，-XX:ConcGCThreads来增加标记线程数也是可以的。</p></li><li><p>大对象分配失败：大对象找不到合适的region空间进行分配，就会进行fullGC，这种情况下可以增大内存或者增大-XX:G1HeapRegionSize。</p></li><li><p>程序主动执行System.gc()：不要随便写就对了。</p></li></ul><p>另外，我们可以在启动参数中配置-XX:HeapDumpPath=/xxx/dump.hprof来dump fullGC相关的文件，并通过jinfo来进行gc前后的dump</p><p>jinfo -flag +HeapDumpBeforeFullGC pid</p><p>jinfo -flag +HeapDumpAfterFullGC pid</p><p>这样得到2份dump文件，对比后主要关注被gc掉的问题对象来定位问题。</p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>涉及到网络层面的问题一般都比较复杂，场景多，定位难，成为了大多数开发的噩梦，应该是最复杂的了。这里会举一些例子，并从tcp层、应用层以及工具的使用等方面进行阐述。</p><h3 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h3><p>超时错误大部分处在应用层面，所以这块着重理解概念。超时大体可以分为连接超时和读写超时，某些使用连接池的客户端框架还会存在获取连接超时和空闲连接清理超时。</p><ul><li><p>读写超时。readTimeout/writeTimeout，有些框架叫做so_timeout或者socketTimeout，均指的是数据读写超时。注意这边的超时大部分是指逻辑上的超时。soa的超时指的也是读超时。读写超时一般都只针对客户端设置。</p></li><li><p>连接超时。connectionTimeout，客户端通常指与服务端建立连接的最大时间。服务端这边connectionTimeout就有些五花八门了，jetty中表示空闲连接清理时间，tomcat则表示连接维持的最大时间。</p></li><li><p>其他。包括连接获取超时connectionAcquireTimeout和空闲连接清理超时idleConnectionTimeout。多用于使用连接池或队列的客户端或服务端框架。</p></li></ul><p>我们在设置各种超时时间中，需要确认的是尽量保持客户端的超时小于服务端的超时，以保证连接正常结束。</p><p>在实际开发中，我们关心最多的应该是接口的读写超时了。</p><p>如何设置合理的接口超时是一个问题。如果接口超时设置的过长，那么有可能会过多地占用服务端的tcp连接。而如果接口设置的过短，那么接口超时就会非常频繁。</p><p>服务端接口明明rt降低，但客户端仍然一直超时又是另一个问题。这个问题其实很简单，客户端到服务端的链路包括网络传输、排队以及服务处理等，每一个环节都可能是耗时的原因。</p><h3 id="TCP队列溢出"><a href="#TCP队列溢出" class="headerlink" title="TCP队列溢出"></a>TCP队列溢出</h3><p>tcp队列溢出是个相对底层的错误，它可能会造成超时、rst等更表层的错误。因此错误也更隐蔽，所以我们单独说一说。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_27.png" alt="img_27.png"></p><p>如上图所示，这里有两个队列：syns queue(半连接队列）、accept queue（全连接队列）。三次握手，在server收到client的syn后，把消息放到syns queue，回复syn+ack给client，server收到client的ack，如果这时accept queue没满，那就从syns queue拿出暂存的信息放入accept queue中，否则按tcp_abort_on_overflow指示的执行。</p><p>tcp_abort_on_overflow 0表示如果三次握手第三步的时候accept queue满了那么server扔掉client发过来的ack。tcp_abort_on_overflow 1则表示第三步的时候如果全连接队列满了，server发送一个rst包给client，表示废掉这个握手过程和这个连接，意味着日志里可能会有很多connection reset / connection reset by peer。</p><p>那么在实际开发中，我们怎么能快速定位到tcp队列溢出呢？</p><p><strong>netstat命令，执行netstat -s | egrep “listen|LISTEN”</strong><br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_28.png" alt="img_28.png"><br>如上图所示，overflowed表示全连接队列溢出的次数，sockets dropped表示半连接队列溢出的次数。</p><p><strong>ss命令，执行ss -lnt=</strong><br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_29.png" alt="img_29.png"><br>上面看到Send-Q 表示第三列的listen端口上的全连接队列最大为5，第一列Recv-Q为全连接队列当前使用了多少。</p><p>接着我们看看怎么设置全连接、半连接队列大小吧：</p><p>全连接队列的大小取决于min(backlog, somaxconn)。backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数。而半连接队列的大小取决于max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog)。</p><p>在日常开发中，我们往往使用servlet容器作为服务端，所以我们有时候也需要关注容器的连接队列大小。在tomcat中backlog叫做acceptCount，在jetty里面则是acceptQueueSize。</p><h3 id="RST异常"><a href="#RST异常" class="headerlink" title="RST异常"></a>RST异常</h3><p>RST包表示连接重置，用于关闭一些无用的连接，通常表示异常关闭，区别于四次挥手。</p><p>在实际开发中，我们往往会看到connection reset / connection reset by peer错误，这种情况就是RST包导致的。</p><h3 id="端口不存在"><a href="#端口不存在" class="headerlink" title="端口不存在"></a>端口不存在</h3><p>如果像不存在的端口发出建立连接SYN请求，那么服务端发现自己并没有这个端口则会直接返回一个RST报文，用于中断连接。</p><h3 id="主动代替FIN终止连接"><a href="#主动代替FIN终止连接" class="headerlink" title="主动代替FIN终止连接"></a>主动代替FIN终止连接</h3><p>一般来说，正常的连接关闭都是需要通过FIN报文实现，然而我们也可以用RST报文来代替FIN，表示直接终止连接。实际开发中，可设置SO_LINGER数值来控制，这种往往是故意的，来跳过TIMED_WAIT，提供交互效率，不闲就慎用。</p><h3 id="客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接"><a href="#客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接" class="headerlink" title="客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接"></a>客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接</h3><p>我们上面讲的tcp队列溢出发送RST包其实也是属于这一种。这种往往是由于某些原因，一方无法再能正常处理请求连接了(比如程序崩了，队列满了)，从而告知另一方关闭连接。</p><p>接收到的TCP报文不在已知的TCP连接内</p><p>比如，一方机器由于网络实在太差TCP报文失踪了，另一方关闭了该连接，然后过了许久收到了之前失踪的TCP报文，但由于对应的TCP连接已不存在，那么会直接发一个RST包以便开启新的连接。</p><h3 id="一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文"><a href="#一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文" class="headerlink" title="一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文"></a>一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文</h3><p>这种大多也和网络环境相关了，网络环境差可能会导致更多的RST报文。</p><p>之前说过RST报文多会导致程序报错，在一个已关闭的连接上读操作会报connection reset，而在一个已关闭的连接上写操作则会报connection reset by peer。通常我们可能还会看到broken pipe错误，这是管道层面的错误，表示对已关闭的管道进行读写，往往是在收到RST，报出connection reset错后继续读写数据报的错，这个在glibc源码注释中也有介绍。</p><p>我们在排查故障时候怎么确定有RST包的存在呢？当然是使用tcpdump命令进行抓包，并使用wireshark进行简单分析了。tcpdump -i en0 tcp -w xxx.cap，en0表示监听的网卡。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_30.png" alt="img_30.png"></p><p>接下来我们通过wireshark打开抓到的包，可能就能看到如下图所示，红色的就表示RST包了。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_31.png" alt="img_31.png"></p><h3 id="TIME-WAIT和CLOSE-WAIT"><a href="#TIME-WAIT和CLOSE-WAIT" class="headerlink" title="TIME_WAIT和CLOSE_WAIT"></a>TIME_WAIT和CLOSE_WAIT</h3><p>TIME_WAIT和CLOSE_WAIT是啥意思相信大家都知道。<br>在线上时，我们可以直接用命令netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’来查看time-wait和close_wait的数量</p><p>用ss命令会更快ss -ant | awk ‘{++S[$1]} END {for(a in S) print a, S[a]}’</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_32.png" alt="img_32.png"></p><h3 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT"></a>TIME_WAIT</h3><p>time_wait的存在一是为了丢失的数据包被后面连接复用，二是为了在2MSL的时间范围内正常关闭连接。它的存在其实会大大减少RST包的出现。</p><p>过多的time_wait在短连接频繁的场景比较容易出现。这种情况可以在服务端做一些内核参数调优:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br></pre></td></tr></table></figure><p>当然我们不要忘记在NAT环境下因为时间戳错乱导致数据包被拒绝的坑了，另外的办法就是改小tcp_max_tw_buckets，超过这个数的time_wait都会被干掉，不过这也会导致报time wait bucket table overflow的错。</p><h3 id="CLOSE-WAIT"><a href="#CLOSE-WAIT" class="headerlink" title="CLOSE_WAIT"></a>CLOSE_WAIT</h3><p>close_wait往往都是因为应用程序写的有问题，没有在ACK后再次发起FIN报文。close_wait出现的概率甚至比time_wait要更高，后果也更严重。往往是由于某个地方阻塞住了，没有正常关闭连接，从而渐渐地消耗完所有的线程。</p><p>想要定位这类问题，最好是通过jstack来分析线程堆栈来排查问题，具体可参考上述章节。这里仅举一个例子。</p><p>开发同学说应用上线后CLOSE_WAIT就一直增多，直到挂掉为止，jstack后找到比较可疑的堆栈是大部分线程都卡在了countdownlatch.await方法，找开发同学了解后得知使用了多线程但是确没有catch异常，修改后发现异常仅仅是最简单的升级sdk后常出现的class not found。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;线上故障主要会包括cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。&lt;/p&gt;
&lt;p&gt;同时例如jstack、jmap等工具也是不囿于一个方面的问题的，基本上出问题就是df、free、top 三连，然后依次jst</summary>
      
    
    
    
    <category term="运维" scheme="http://example.com/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="线上问题" scheme="http://example.com/tags/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>代码规范之JAVA代码安全指南</title>
    <link href="http://example.com/2021/07/13/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://example.com/2021/07/13/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</id>
    <published>2021-07-13T09:37:37.000Z</published>
    <updated>2021-07-14T08:49:21.089Z</updated>
    
    <content type="html"><![CDATA[<h2 id="后台类"><a href="#后台类" class="headerlink" title="后台类"></a>后台类</h2><h3 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h3><h4 id="【必须】SQL语句默认使用预编译并绑定变量"><a href="#【必须】SQL语句默认使用预编译并绑定变量" class="headerlink" title="【必须】SQL语句默认使用预编译并绑定变量"></a>【必须】SQL语句默认使用预编译并绑定变量</h4><p>Web后台系统应默认使用预编译绑定变量的形式创建sql语句，保持查询语句和数据相分离。以从本质上避免SQL注入风险。</p><p>如使用Mybatis作为持久层框架，应通过#{}语法进行参数绑定，MyBatis 会创建 <code>PreparedStatement</code> 参数占位符，并通过占位符安全地设置参数。</p><p>示例：JDBC</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String custname=request.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        String query=<span class="string">&quot;SELECT * FROM user_data WHERE user_name = ? &quot;</span>;</span><br><span class="line">        PreparedStatement pstmt=connection.prepareStatement(query);</span><br><span class="line">        pstmt.setString(<span class="number">1</span>,custname);</span><br><span class="line">        ResultSet results=pstmt.executeQuery();</span><br></pre></td></tr></table></figure><p>Mybatis</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id=<span class="string">&quot;queryRuleIdByApplicationId&quot;</span>parameterType=<span class="string">&quot;java.lang.String&quot;</span>resultType=<span class="string">&quot;java.lang.String&quot;</span>&gt;</span><br><span class="line">        select rule_id from scan_rule_sqlmap_tab where application_id=#&#123;applicationId&#125;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure><p>应避免外部输入未经过滤直接拼接到SQL语句中，或者通过Mybatis中的${}传入SQL语句（即使使用PreparedStatement，SQL语句直接拼接外部输入也同样有风险。例如Mybatis中部分参数通过${}传入SQL语句后实际执行时调用的是PreparedStatement.execute()<br>，同样存在注入风险）。</p><h4 id="【必须】白名单过滤"><a href="#【必须】白名单过滤" class="headerlink" title="【必须】白名单过滤"></a>【必须】白名单过滤</h4><p>对于表名、列名等无法进行预编译的场景，比如外部数据拼接到order by, group<br>by语句中，需通过白名单的形式对数据进行校验，例如判断传入列名是否存在、升降序仅允许输入“ASC”和“DESC”、表名列名仅允许输入字符、数字、下划线等。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">someMethod</span><span class="params">(<span class="keyword">boolean</span> sortOrder)</span></span>&#123;</span><br><span class="line">        String SQLquery=<span class="string">&quot;some SQL ... order by Salary &quot;</span>+(sortOrder?<span class="string">&quot;ASC&quot;</span>:<span class="string">&quot;DESC&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><h4 id="【必须】文件类型限制"><a href="#【必须】文件类型限制" class="headerlink" title="【必须】文件类型限制"></a>【必须】文件类型限制</h4><p>须在服务器端采用白名单方式对上传或下载的文件类型、大小进行严格的限制。仅允许业务所需文件类型上传，避免上传.jsp、.jspx、.class、.java等可执行文件。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">String file_name=file.getOriginalFilename();</span><br><span class="line">String[]parts=file_name.split(<span class="string">&quot;\\.&quot;</span>);</span><br><span class="line">String suffix=parts[parts.length-<span class="number">1</span>];</span><br><span class="line"><span class="keyword">switch</span>(suffix)&#123;</span><br><span class="line">    <span class="keyword">case</span><span class="string">&quot;jpeg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpeg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;jpg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;bmp&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.bmp&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;png&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.png&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">//handle error</span></span><br><span class="line">        <span class="keyword">return</span><span class="string">&quot;error&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】禁止外部文件存储于可执行目录"><a href="#【必须】禁止外部文件存储于可执行目录" class="headerlink" title="【必须】禁止外部文件存储于可执行目录"></a>【必须】禁止外部文件存储于可执行目录</h4><p>禁止外部文件存储于WEB容器的可执行目录（appBase）。建议保存在专门的文件服务器中。</p><h4 id="【建议】避免路径拼接"><a href="#【建议】避免路径拼接" class="headerlink" title="【建议】避免路径拼接"></a>【建议】避免路径拼接</h4><p>文件目录避免外部参数拼接。保存文件目录建议后台写死并对文件名进行校验（字符类型、长度）。建议文件保存时，将文件名替换为随机字符串。</p><h4 id="【必须】避免路径穿越"><a href="#【必须】避免路径穿越" class="headerlink" title="【必须】避免路径穿越"></a>【必须】避免路径穿越</h4><p>如因业务需要不能满足避免路径拼接，文件路径、文件命中拼接了不可行数据，需判断请求文件名和文件路径参数中是否存在../或..\(仅windows)， 如存在应判定路径非法并拒绝请求。</p><h3 id="网络访问"><a href="#网络访问" class="headerlink" title="网络访问"></a>网络访问</h3><h4 id="【必须】避免直接访问不可信地址"><a href="#【必须】避免直接访问不可信地址" class="headerlink" title="【必须】避免直接访问不可信地址"></a>【必须】避免直接访问不可信地址</h4><p>服务器访问不可信地址时，禁止访问私有地址段及内网域名。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 以RFC定义的专有网络为例，如有自定义私有网段亦应加入禁止访问列表。</span><br><span class="line">10.0.0.0/8</span><br><span class="line">172.16.0.0/12</span><br><span class="line">192.168.0.0/16</span><br><span class="line">127.0.0.0/8</span><br></pre></td></tr></table></figure><p>建议通过URL解析函数进行解析，获取host或者domain后通过DNS获取其IP，然后和内网地址进行比较。</p><p>对已校验通过地址进行访问时，应关闭跟进跳转功能。</p><p>参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">httpConnection=(HttpURLConnection)Url.openConnection();</span><br><span class="line">httpConnection.setFollowRedirects(<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="XML读写"><a href="#XML读写" class="headerlink" title="XML读写"></a>XML读写</h3><h4 id="【必须】XML解析器关闭DTD解析"><a href="#【必须】XML解析器关闭DTD解析" class="headerlink" title="【必须】XML解析器关闭DTD解析"></a>【必须】XML解析器关闭DTD解析</h4><p>读取外部传入XML文件时，XML解析器初始化过程中设置关闭DTD解析。</p><p>参考示例：</p><p>javax.xml.parsers.DocumentBuilderFactory</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setXIncludeAware(<span class="keyword">false</span>);</span><br><span class="line">        dbf.setExpandEntityReferences(<span class="keyword">false</span>);</span><br><span class="line">        ……</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>org.dom4j.io.SAXReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">saxReader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><p>org.jdom2.input.SAXBuilder</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SAXBuilder builder=<span class="keyword">new</span> SAXBuilder();</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">Document doc=builder.build(<span class="keyword">new</span> File(fileName));</span><br></pre></td></tr></table></figure><p>org.xml.sax.XMLReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">XMLReader reader=XMLReaderFactory.createXMLReader();</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="响应输出"><a href="#响应输出" class="headerlink" title="响应输出"></a>响应输出</h3><h4 id="【必须】设置正确的HTTP响应包类型"><a href="#【必须】设置正确的HTTP响应包类型" class="headerlink" title="【必须】设置正确的HTTP响应包类型"></a>【必须】设置正确的HTTP响应包类型</h4><p>响应包的HTTP头“Content-Type”必须正确配置响应包的类型，禁止非HTML类型的响应包设置为“text/html”。此举会使浏览器在直接访问链接时，将非HTML格式的返回报文当做HTML解析，增加反射型XSS的触发几率。</p><h4 id="【建议】设置安全的HTTP响应头"><a href="#【建议】设置安全的HTTP响应头" class="headerlink" title="【建议】设置安全的HTTP响应头"></a>【建议】设置安全的HTTP响应头</h4><ul><li><p>X-Content-Type-Options：</p><p>建议添加“X-Content-Type-Options”响应头并将其值设置为“nosniff”，可避免部分浏览器根据其“Content-Sniff”特性，将一些非“text/html”类型的响应作为HTML解析，增加反射型XSS的触发几率。</p></li><li><p>HttpOnly：</p><p>控制用户登录鉴权的Cookie字段 应当设置HttpOnly属性以防止被XSS漏洞/JavaScript操纵泄漏。</p></li><li><p>X-Frame-Options：</p><p>设置X-Frame-Options响应头，并根据需求合理设置其允许范围。该头用于指示浏览器禁止当前页面在frame、iframe、embed等标签中展现。从而避免点击劫持问题。它有三个可选的值：<br>DENY： 浏览器会拒绝当前页面加载任何frame页面；<br>SAMEORIGIN：则frame页面的地址只能为同源域名下的页面<br>ALLOW-FROM origin：可以定义允许frame加载的页面地址。</p></li><li><p>Access-Control-Allow-Origin</p><p>当需要配置CORS跨域时，应对请求头的Origin值做严格过滤。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String currentOrigin = request.getHeader(<span class="string">&quot;Origin&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (currentOrigin.equals(<span class="string">&quot;https://domain.qq.com&quot;</span>)) &#123;</span><br><span class="line">       response.setHeader(<span class="string">&quot;Access-Control-Allow-Origin&quot;</span>, currentOrigin);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="【必须】外部输入拼接到response页面前进行编码处理"><a href="#【必须】外部输入拼接到response页面前进行编码处理" class="headerlink" title="【必须】外部输入拼接到response页面前进行编码处理"></a>【必须】外部输入拼接到response页面前进行编码处理</h4><p>当响应“content-type”为“html”类型时，外部输入拼接到响应包中，需根据输出位置进行编码处理。编码规则：</p><table><thead><tr><th>场景</th><th>编码规则</th></tr></thead><tbody><tr><td>输出点在HTML标签之间</td><td>需要对以下6个特殊字符进行HTML实体编码(&amp;, &lt;, &gt;, “, ‘,/)。<br>示例：<br>&amp; –&gt; &amp;amp;<br>&lt; –&gt; &amp;lt;<br>&gt;–&gt; &amp;gt;<br>“ –&gt; &amp;quot;<br>‘ –&gt; &amp;#x27;  <br>/ –&gt; &amp;#x2F;</td></tr><tr><td>输出点在HTML标签普通属性内（如href、src、style等，on事件除外）</td><td>要对数据进行HTML属性编码。<br>编码规则：除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为&#xHH;(以&amp;#x开头，HH则是指该字符对应的十六进制数字，分号作为结束符)</td></tr><tr><td>输出点在JS内的数据中</td><td>需要进行js编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \xHH （以 \x 开头，HH则是指该字符对应的十六进制数字）<br>Tips：这种场景仅限于外部数据拼接在js里被引号括起来的变量值中。除此之外禁止直接将代码拼接在js代码中。</td></tr><tr><td>输出点在CSS中（Style属性）</td><td>需要进行CSS编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \HH （以 \ 开头，HH则是指该字符对应的十六进制数字）</td></tr><tr><td>输出点在URL属性中</td><td>对这些数据进行URL编码<br>Tips：除此之外，所有链接类属性应该校验其协议。禁止JavaScript、data和Vb伪协议。</td></tr></tbody></table><p>以上编码规则相对较为繁琐，可参考或直接使用业界已有成熟第三方库如ESAPI.其提供以下函数对象上表中的编码规则:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ESAPI.encoder().encodeForHTML();</span><br><span class="line">        ESAPI.encoder().encodeForHTMLAttribute();</span><br><span class="line">        ESAPI.encoder().encodeForJavaScript();</span><br><span class="line">        ESAPI.encoder().encodeForCSS();</span><br><span class="line">        ESAPI.encoder().encodeForURL();</span><br></pre></td></tr></table></figure><h4 id="【必须】外部输入拼接到HTTP响应头中需进行过滤"><a href="#【必须】外部输入拼接到HTTP响应头中需进行过滤" class="headerlink" title="【必须】外部输入拼接到HTTP响应头中需进行过滤"></a>【必须】外部输入拼接到HTTP响应头中需进行过滤</h4><p>应尽量避免外部可控参数拼接到HTTP响应头中，如业务需要则需要过滤掉“\r”、”\n”等换行符，或者拒绝携带换行符号的外部输入。</p><h4 id="【必须】避免不可信域名的302跳转"><a href="#【必须】避免不可信域名的302跳转" class="headerlink" title="【必须】避免不可信域名的302跳转"></a>【必须】避免不可信域名的302跳转</h4><p>如果对外部传入域名进行302跳转，必须设置可信域名列表并对传入域名进行校验。</p><p>为避免校验被绕过，应避免直接对URL进行字符串匹配。应通过通过URL解析函数进行解析，获取host或者domain后和白名单进行比较。</p><p>需要注意的是，由于浏览器的容错机制，域名<code>https://www.qq.com\www.bbb.com</code>中的<code>\</code>会被替换成<code>/</code>，最终跳转到<code>www.qq.com</code><br>。而Java的域名解析函数则无此特性。为避免解析不一致导致绕过，建议对host中的<code>/</code>和<code>#</code>进行替换。</p><p>参考代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">String host=<span class="string">&quot;&quot;</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  url=url.replaceAll(<span class="string">&quot;[\\\\#]&quot;</span>,<span class="string">&quot;/&quot;</span>); <span class="comment">//替换掉反斜线和井号</span></span><br><span class="line">  host=<span class="keyword">new</span> URL(url).getHost();</span><br><span class="line">&#125; <span class="keyword">catch</span>(MalformedURLException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(host.endsWith(<span class="string">&quot;.qq.com&quot;</span>))&#123;</span><br><span class="line">    <span class="comment">//跳转操作</span></span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】避免通过Jsonp传输非公开敏感信息"><a href="#【必须】避免通过Jsonp传输非公开敏感信息" class="headerlink" title="【必须】避免通过Jsonp传输非公开敏感信息"></a>【必须】避免通过Jsonp传输非公开敏感信息</h4><p>jsonp请求再被CSRF攻击时，其响应包可被攻击方劫持导致信息泄露。应避免通过jsonp传输非公开的敏感信息，例如用户隐私信息、身份凭证等。</p><h4 id="【必须】限定JSONP接口的callback字符集范围"><a href="#【必须】限定JSONP接口的callback字符集范围" class="headerlink" title="【必须】限定JSONP接口的callback字符集范围"></a>【必须】限定JSONP接口的callback字符集范围</h4><p>JSONP接口的callback函数名为固定白名单。如callback函数名可用户自定义，应限制函数名仅包含 字母、数字和下划线。如：<code>[a-zA-Z0-9_-]+</code></p><h4 id="【必须】屏蔽异常栈"><a href="#【必须】屏蔽异常栈" class="headerlink" title="【必须】屏蔽异常栈"></a>【必须】屏蔽异常栈</h4><p>应用程序出现异常时，禁止将数据库版本、数据库结构、操作系统版本、堆栈跟踪、文件名和路径信息、SQL 查询字符串等对攻击者有用的信息返回给客户端。建议重定向到一个统一、默认的错误提示页面，进行信息过滤。</p><h4 id="【必须】模板-amp-表达式"><a href="#【必须】模板-amp-表达式" class="headerlink" title="【必须】模板&amp;表达式"></a>【必须】模板&amp;表达式</h4><p>web view层通常通过模板技术或者表达式引擎来实现界面与业务数据分离，比如jsp中的EL表达式。这些引擎通常可执行敏感操作，如果外部不可信数据未经过滤拼接到表达式中进行解析。则可能造成严重漏洞。</p><p>下列是基于EL表达式注入漏洞的演示demo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    <span class="meta">@RequestMapping(&quot;/ELdemo&quot;)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">ELdemo</span><span class="params">(RepeatDTO repeat)</span></span>&#123;</span><br><span class="line">    ExpressionFactory expressionFactory=<span class="keyword">new</span> ExpressionFactoryImpl();</span><br><span class="line">    SimpleContext simpleContext=<span class="keyword">new</span> SimpleContext();</span><br><span class="line">    String exp=<span class="string">&quot;$&#123;&quot;</span>+repeat.getel()+<span class="string">&quot;&#125;&quot;</span>;</span><br><span class="line">    ValueExpression valueExpression=expressionFactory.createValueExpression(simpleContext,exp,String.class);</span><br><span class="line">    <span class="keyword">return</span> valueExpression.getValue(simpleContext).toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>外部可通过el参数，将不可信输入拼接到EL表达式中并解析。</p><p>此时外部访问：x.x.x.x/ELdemo?el=”’’.getClass().forName(‘java.lang.Runtime’).getMethod(‘exec’,’’.getClass()).invoke(‘’<br>.getClass().forName(‘java.lang.Runtime’).getMethod(‘getRuntime’).invoke(null),’open /Applications/Calculator.app’)“<br>可执行操作系统命令调出计算器。</p><p>基于以上风险：</p><ul><li>应避免外部输入的内容拼接到EL表达式或其他表达式引起、模板引擎进行解析。</li><li>白名单过滤外部输入，仅允许字符、数字、下划线等。</li></ul><h3 id="OS命令执行"><a href="#OS命令执行" class="headerlink" title="OS命令执行"></a>OS命令执行</h3><h4 id="【建议】避免不可信数据拼接操作系统命令"><a href="#【建议】避免不可信数据拼接操作系统命令" class="headerlink" title="【建议】避免不可信数据拼接操作系统命令"></a>【建议】避免不可信数据拼接操作系统命令</h4><p>当不可信数据存在时，应尽量避免外部数据拼接到操作系统命令使用 <code>Runtime</code> 和 <code>ProcessBuilder</code> 来执行。优先使用其他同类操作进行代替，比如通过文件系统API进行文件操作而非直接调用操作系统命令。</p><h4 id="【必须】避免创建SHELL操作"><a href="#【必须】避免创建SHELL操作" class="headerlink" title="【必须】避免创建SHELL操作"></a>【必须】避免创建SHELL操作</h4><p>如无法避免直接访问操作系统命令，需要严格管理外部传入参数，使不可信数据仅作为执行命令的参数而非命令。</p><ul><li><p>禁止外部数据直接直接作为操作系统命令执行。</p></li><li><p>避免通过”cmd”、“bash”、“sh”等命令创建shell后拼接外部数据来执行操作系统命令。</p></li><li><p>对外部传入数据进行过滤。可通过白名单限制字符类型，仅允许字符、数字、下划线；或过滤转义以下符号：|;&amp;$&gt;&lt;`（反引号）!</p><p>白名单示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern FILTER_PATTERN = Pattern.compile(<span class="string">&quot;[0-9A-Za-z_]+&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (!FILTER_PATTERN.matcher(input).matches()) &#123;</span><br><span class="line">  <span class="comment">// 终止当前请求的处理</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="会话管理"><a href="#会话管理" class="headerlink" title="会话管理"></a>会话管理</h3><h4 id="【必须】非一次有效身份凭证禁止在URL中传输"><a href="#【必须】非一次有效身份凭证禁止在URL中传输" class="headerlink" title="【必须】非一次有效身份凭证禁止在URL中传输"></a>【必须】非一次有效身份凭证禁止在URL中传输</h4><p>身份凭证禁止在URL中传输，一次有效的身份凭证除外（如CAS中的st）。</p><h4 id="【必须】避免未经校验的数据直接给会话赋值"><a href="#【必须】避免未经校验的数据直接给会话赋值" class="headerlink" title="【必须】避免未经校验的数据直接给会话赋值"></a>【必须】避免未经校验的数据直接给会话赋值</h4><p>防止会话信息被篡改，如恶意用户通过URL篡改手机号码等。</p><h3 id="加解密"><a href="#加解密" class="headerlink" title="加解密"></a>加解密</h3><h4 id="【建议】对称加密"><a href="#【建议】对称加密" class="headerlink" title="【建议】对称加密"></a>【建议】对称加密</h4><p>建议使用AES，秘钥长度128位以上。禁止使用DES算法，由于秘钥太短，其为目前已知不安全加密算法。使用AES加密算法请参考以下注意事项：</p><ul><li>AES算法如果采用CBC模式：每次加密时IV必须采用密码学安全的伪随机发生器（如/dev/urandom）,禁止填充全0等固定值。</li><li>AES算法如采用GCM模式，nonce须采用密码学安全的伪随机数</li><li>AES算法避免使用ECB模式，推荐使用GCM模式。</li></ul><h4 id="【建议】非对称加密"><a href="#【建议】非对称加密" class="headerlink" title="【建议】非对称加密"></a>【建议】非对称加密</h4><p>建议使用RSA算法，秘钥2048及以上。</p><h4 id="【建议】哈希算法"><a href="#【建议】哈希算法" class="headerlink" title="【建议】哈希算法"></a>【建议】哈希算法</h4><p>哈希算法推荐使用SHA-2及以上。对于签名场景，应使用HMAC算法。如果采用字符串拼接盐值后哈希的方式，禁止将盐值置于字符串开头，以避免哈希长度拓展攻击。</p><h4 id="【建议】密码存储策略"><a href="#【建议】密码存储策略" class="headerlink" title="【建议】密码存储策略"></a>【建议】密码存储策略</h4><p>建议采用随机盐+明文密码进行多轮哈希后存储密码。</p><h3 id="查询业务"><a href="#查询业务" class="headerlink" title="查询业务"></a>查询业务</h3><h4 id="【必须】返回信息最小化"><a href="#【必须】返回信息最小化" class="headerlink" title="【必须】返回信息最小化"></a>【必须】返回信息最小化</h4><p>返回用户信息应遵循最小化原则，避免将业务需求之外的用户信息返回到前端。</p><h4 id="【必须】个人敏感信息脱敏展示"><a href="#【必须】个人敏感信息脱敏展示" class="headerlink" title="【必须】个人敏感信息脱敏展示"></a>【必须】个人敏感信息脱敏展示</h4><p>在满足业务需求的情况下，个人敏感信息需脱敏展示,如：</p><ul><li>鉴权信息（如口令、密保答案、生理标识等）不允许展示</li><li>身份证只显示第一位和最后一位字符，如3****************1。</li><li>移动电话号码隐藏中间6位字符，如134******48。</li><li>工作地址/家庭地址最多显示到“区”一级。</li><li>银行卡号仅显示最后4位字符，如************8639</li></ul><h4 id="【必须】数据权限校验"><a href="#【必须】数据权限校验" class="headerlink" title="【必须】数据权限校验"></a>【必须】数据权限校验</h4><p>查询个人非公开信息时，需要对当前访问账号进行数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>验当前用户是否具备访问数据的权限</li></ol><h3 id="操作业务"><a href="#操作业务" class="headerlink" title="操作业务"></a>操作业务</h3><h4 id="【必须】部署CSRF防御机制"><a href="#【必须】部署CSRF防御机制" class="headerlink" title="【必须】部署CSRF防御机制"></a>【必须】部署CSRF防御机制</h4><p>CSRF是指跨站请求伪造（Cross-site request forgery），是web常见的攻击之一。对于可重放的敏感操作请求，需部署CSRF防御机制。可参考以下两种常见的CSRF防御方式</p><ul><li><p>设置CSRF Token</p><p>服务端给合法的客户颁发CSRF<br>Token，客户端在发送请求时携带该token供服务端校验，服务端拒绝token验证不通过的请求。以此来防止第三方构造合法的恶意操作链接。Token的作用域可以是Request级或者Session级。下面以Session级CSRF<br>Token进行示例</p><ol><li><p>登录成功后颁发Token，并同时存储在服务端Session中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String uuidToken = UUID.randomUUID().toString();</span><br><span class="line">map.put(<span class="string">&quot;token&quot;</span>, uuidToken);</span><br><span class="line">request.getSession().setAttribute(<span class="string">&quot;token&quot;</span>,uuidToken );</span><br><span class="line"><span class="keyword">return</span> map;</span><br></pre></td></tr></table></figure></li></ol></li></ul><ol start="2"><li><p>创建Filter</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CsrfFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;  </span><br><span class="line">   HttpSession session = req.getSession();</span><br><span class="line">   Object token = session.getAttribute(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   String requestToken = req.getParameter(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span>(StringUtils.isBlank(requestToken) || !requestToken.equals(token))&#123;</span><br><span class="line">         AjaxResponseWriter.write(req, resp, ServiceStatusEnum.ILLEGAL_TOKEN, <span class="string">&quot;非法的token&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li></ol><p>CSRF Token应具备随机性，保证其不可预测和枚举。另外由于浏览器会自动对表单所访问的域名添加相应的cookie信息，所以CSRF Token不应该通过Cookie传输。</p><ul><li><p>校验Referer头</p><p>通过检查HTTP请求的Referer字段是否属于本站域名，非本站域名的请求进行拒绝。</p><p>这种校验方式需要注意两点：</p><ol><li>要需要处理Referer为空的情况，当Referer为空则拒绝请求</li><li>注意避免例如qq.com.evil.com 部分匹配的情况。</li></ol></li></ul><h4 id="【必须】权限校验"><a href="#【必须】权限校验" class="headerlink" title="【必须】权限校验"></a>【必须】权限校验</h4><p>对于非公共操作，应当校验当前访问账号进行操作权限（常见于CMS）和数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>校验当前用户是否具备该操作权限</li><li>校验当前用户是否具备所操作数据的权限。避免越权。</li></ol><h4 id="【建议】加锁操作"><a href="#【建议】加锁操作" class="headerlink" title="【建议】加锁操作"></a>【建议】加锁操作</h4><p>对于有次数限制的操作，比如抽奖。如果操作的过程中资源访问未正确加锁。在高并发的情况下可能造成条件竞争，导致实际操作成功次数多于用户实际操作资格次数。此类操作应加锁处理。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;后台类&quot;&gt;&lt;a href=&quot;#后台类&quot; class=&quot;headerlink&quot; title=&quot;后台类&quot;&gt;&lt;/a&gt;后台类&lt;/h2&gt;&lt;h3 id=&quot;数据持久化&quot;&gt;&lt;a href=&quot;#数据持久化&quot; class=&quot;headerlink&quot; title=&quot;数据持久化&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    <category term="代码规范" scheme="http://example.com/categories/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
    
    <category term="代码规范" scheme="http://example.com/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统04之分布式锁</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2021-07-09T10:35:00.000Z</published>
    <updated>2021-07-14T08:49:21.163Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁"></a>什么是分布式锁</h2><ul><li>分布式模型下，数据只有一份，需要锁技术控制某一时刻修改数据的进程数。 </li><li>不仅需要保证进程可见，还需要考虑进程与锁的网络问题 </li><li>可以将标记存在内存，但是内存不是进程分配而是公共内存（redis、zk）,保证标记互斥。</li></ul><h2 id="Java分布式锁需求"><a href="#Java分布式锁需求" class="headerlink" title="Java分布式锁需求"></a>Java分布式锁需求</h2><ul><li>同一个方法在同一时间只能被一台机器上一个线程执行。</li><li>可重入（避免死锁）</li><li>阻塞锁（业务需求） </li><li>公平锁（业务需求） </li><li>高可用、高性能获取/释放锁</li></ul><h2 id="Java分布式锁解决方案"><a href="#Java分布式锁解决方案" class="headerlink" title="Java分布式锁解决方案"></a>Java分布式锁解决方案</h2><h3 id="基于数据库"><a href="#基于数据库" class="headerlink" title="基于数据库"></a>基于数据库</h3><p>基于表主键唯一做分布式锁</p><h3 id="基于redis"><a href="#基于redis" class="headerlink" title="基于redis"></a>基于redis</h3><h4 id="基于-redis-的-SETNX-、EXPIRE-方法做分布式锁"><a href="#基于-redis-的-SETNX-、EXPIRE-方法做分布式锁" class="headerlink" title="基于 redis 的 SETNX()、EXPIRE() 方法做分布式锁"></a>基于 redis 的 SETNX()、EXPIRE() 方法做分布式锁</h4><p>使用步骤：</p><ul><li>setnx(lockkey, 1) 返回1，占位成功</li><li>expire()对lockkey设置超时时间，避免死锁</li><li>执行完业务后，delete命令删除key</li></ul><p>在 expire() 命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题。</p><h4 id="基于-redis-的-setnx-、get-和-getset-方法来实现分布式锁。"><a href="#基于-redis-的-setnx-、get-和-getset-方法来实现分布式锁。" class="headerlink" title="基于 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。"></a>基于 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。</h4><p>使用步骤</p><ul><li>setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。</li><li>get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。</li><li>计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。</li><li>判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</li><li>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</li></ul><h4 id="分布式锁Redlock"><a href="#分布式锁Redlock" class="headerlink" title="分布式锁Redlock"></a>分布式锁Redlock</h4><p>解决问题：<br>解决redis分布式锁的单点故障问题</p><p>使用步骤：</p><ul><li>获取当前时间（毫秒数）。</li><li>按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败，比如该Redis节点不可用，或者该Redis节点上的锁已经被其它客户端持有（注：Redlock原文中这里只提到了Redis节点不可用的情况，但也应该包含其它的失败情况）。</li><li>计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。</li><li>如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。</li><li>如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的Redis Lua脚本）。</li></ul><h4 id="基于-REDISSON-做分布式锁"><a href="#基于-REDISSON-做分布式锁" class="headerlink" title="基于 REDISSON 做分布式锁"></a>基于 REDISSON 做分布式锁</h4><p>redis 官方的分布式锁组件，解决超时时间设置不合理问题。每获得一个锁时，只设置一个很短的超时时间，同时起一个线程在每次快要到超时时间时去刷新锁的超时时间。在释放锁的同时结束这个线程。</p><h3 id="zookeeper实现分布式锁"><a href="#zookeeper实现分布式锁" class="headerlink" title="zookeeper实现分布式锁"></a>zookeeper实现分布式锁</h3><p>其实基于ZooKeeper，就是使用它的临时有序节点来实现的分布式锁。</p><p><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/img_1.png" alt="img.png"><br>当某客户端要进行逻辑的加锁时，就在zookeeper上的某个指定节点的目录下，去生成一个唯一的临时有序节点， 然后判断自己是否是这些有序节点中序号最小的一个。</p><ul><li>如果是，则算是获取了锁。</li><li>如果不是，则说明没有获取到锁，那么就需要在序列中找到比自己小的那个节点，并对其调用exist()方法，对其注册事件监听，当监听到这个节点被删除了，那就再去判断一次自己当初创建的节点是否变成了序列中最小的。<ul><li>如果是，则获取锁，如果不是，则重复上述步骤。</li></ul></li></ul><p>当释放锁的时候，只需将这个临时节点删除即可。</p><h2 id="redis分布式锁和zookeeper分布式锁的区别"><a href="#redis分布式锁和zookeeper分布式锁的区别" class="headerlink" title="redis分布式锁和zookeeper分布式锁的区别"></a>redis分布式锁和zookeeper分布式锁的区别</h2><h3 id="优缺点对比"><a href="#优缺点对比" class="headerlink" title="优缺点对比"></a>优缺点对比</h3><p>对于redis的分布式锁而言：</p><ul><li><p>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</p></li><li><p>redis的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮</p><ul><li>即便使用redlock算法来实现，在某些复杂场景下，也无法保证其实现100%没有问题，关于redlock的讨论可以看How to do distributed locking</li></ul></li></ul><p>但是另一方面使用redis实现分布式锁在很多企业中非常常见，而且大部分情况下都不会遇到所谓的“极端复杂场景”</p><p>所以使用redis作为分布式锁也不失为一种好的方案，最重要的一点是redis的性能很高，可以支撑高并发的获取、释放锁操作。</p><p>对于zk分布式锁而言:</p><ul><li><p>zookeeper天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</p></li><li><p>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</p></li></ul><p>但是zk也有其缺点：如果有较多的客户端频繁的申请加锁、释放锁，对于zk集群的压力会比较大。</p><h3 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h3><p>就个人而言的话，我<strong>比较推崇zk实现的锁</strong>：</p><p>因为redis是有可能存在隐患的，可能会导致数据不对的情况。但是，怎么选用要看具体在公司的场景了。</p><p>如果公司里面有zk集群条件，优先选用zk实现，但是如果说公司里面只有redis集群，没有条件搭建zk集群。</p><p>那么其实用redis来实现也可以，另外还可能是系统设计者考虑到了系统已经有redis，但是又不希望再次引入一些外部依赖的情况下，可以选用redis。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是分布式锁&quot;&gt;&lt;a href=&quot;#什么是分布式锁&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式锁&quot;&gt;&lt;/a&gt;什么是分布式锁&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;分布式模型下，数据只有一份，需要锁技术控制某一时刻修改数据的进程数。 &lt;/li&gt;
&lt;li</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="锁" scheme="http://example.com/tags/%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统03之分布式事务</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2021-07-09T10:34:43.000Z</published>
    <updated>2021-07-14T08:49:21.196Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是分布式事务"><a href="#什么是分布式事务" class="headerlink" title="什么是分布式事务"></a>什么是分布式事务</h2><p>分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。</p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。</p><h2 id="分布式系统一致性基础算法"><a href="#分布式系统一致性基础算法" class="headerlink" title="分布式系统一致性基础算法"></a>分布式系统一致性基础算法</h2><h3 id="Paxos算法"><a href="#Paxos算法" class="headerlink" title="Paxos算法"></a>Paxos算法</h3><p>Paxos 算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一，其解决的问题就是在分布式系统中如何就某个值（决议）达成一致 。</p><p>在 Paxos 中主要有三个角色，分别为 Proposer提案者、Acceptor表决者、Learner学习者。Paxos 算法和 2PC 一样，也有两个阶段，分别为 Prepare 和 accept 阶段。  </p><ul><li>prepare 阶段<ul><li>Proposer提案者：负责提出 proposal，每个提案者在提出提案时都会首先获取到一个 具有全局唯一性的、递增的提案编号N，即在整个集群中是唯一的编号 N，然后将该编号赋予其要提出的提案，在第一阶段是只将提案编号发送给所有的表决者。  </li><li>Acceptor表决者：每个表决者在 accept 某提案后，会将该提案编号N记录在本地，这样每个表决者中保存的已经被 accept 的提案中会存在一个编号最大的提案，其编号假设为 maxN。每个表决者仅会 accept 编号大于自己本地 maxN 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 Proposer。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_1.png"></li></ul></li><li>accept 阶段<br>当一个提案被 Proposer 提出后，如果 Proposer 收到了超过半数的 Acceptor 的批准（Proposer 本身同意），那么此时 Proposer 会给所有的 Acceptor 发送真正的提案（你可以理解为第一阶段为试探），这个时候 Proposer 就会发送提案的内容和提案编号。<br>表决者收到提案请求后会再次比较本身已经批准过的最大提案编号和该提案编号，如果该提案编号 大于等于 已经批准过的最大提案编号，那么就 accept 该提案（此时执行提案内容但不提交），随后将情况返回给 Proposer 。如果不满足则不回应或者返回 NO 。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_2.png"><br>当 Proposer 收到超过半数的 accept ，那么它这个时候会向所有的 acceptor 发送提案的提交请求。需要注意的是，因为上述仅仅是超过半数的 acceptor 批准执行了该提案内容，其他没有批准的并没有执行该提案内容，所以这个时候需要向未批准的 acceptor 发送提案内容和提案编号并让它无条件执行和提交，而对于前面已经批准过该提案的 acceptor 来说 仅仅需要发送该提案的编号 ，让 acceptor 执行提交就行了。<br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_3.png" alt="img.png"><br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。</li></ul><h4 id="Paxos算法的死循环问题"><a href="#Paxos算法的死循环问题" class="headerlink" title="Paxos算法的死循环问题"></a>Paxos算法的死循环问题</h4><p>其实就有点类似于两个人吵架，小明说我是对的，小红说我才是对的，两个人据理力争的谁也不让谁🤬🤬。<br>比如说，此时提案者 P1 提出一个方案 M1，完成了 Prepare 阶段的工作，这个时候 acceptor 则批准了 M1，但是此时提案者 P2 同时也提出了一个方案 M2，它也完成了 Prepare 阶段的工作。然后 P1 的方案已经不能在第二阶段被批准了（因为 acceptor 已经批准了比 M1 更大的 M2），所以 P1 自增方案变为 M3 重新进入 Prepare 阶段，然后 acceptor ，又批准了新的 M3 方案，它又不能批准 M2 了，这个时候 M2 又自增进入 Prepare 阶段。<br>就这样无休无止的永远提案下去，这就是 paxos 算法的死循环问题。<br>那么如何解决呢？很简单，人多了容易吵架，我现在 就允许一个能提案 就行了。</p><h3 id="Raft-算法"><a href="#Raft-算法" class="headerlink" title="Raft 算法"></a>Raft 算法</h3><h2 id="分布式事务解决方案"><a href="#分布式事务解决方案" class="headerlink" title="分布式事务解决方案"></a>分布式事务解决方案</h2><h3 id="XA规范-协议"><a href="#XA规范-协议" class="headerlink" title="XA规范/协议"></a>XA规范/协议</h3><p>X/Open组织（现在的Open Group）定义了一套DTP（Distributed Transaction Processing）分布式事务处理模型，主要包含以下四部分：</p><ul><li>AP（应用程序） </li><li>TM（事务管理器）：交易中间件</li><li>RM（资源管理器）：数据库</li><li>CRM（通信资源管理器）：消息中间件</li></ul><p><strong>XA规范</strong>则是DTP模型定义TM和RM之间通讯的接口规范。  </p><p>XA接口函数由数据库厂商提供。<br>TM用它来通知数据库事务的开始、结束、提交、回滚。<br>基于XA规范衍生出下面的二阶段提交（2PC）、三阶段提交（3PC）。  </p><p>XA规范包括两套函数，以xa_开头的及以ax_开头的。<br>以下的函数使事务管理器可以对资源管理器进行的操作：</p><ul><li>xa_open,xa_close：建立和关闭与资源管理器的连接。</li><li>xa_start,xa_end：开始和结束一个本地事务。</li><li>xa_prepare,xa_commit,xa_rollback：预提交、提交、回滚一个本地事务。</li><li>xa_recover：回滚一个已进行预提交的事务。</li><li>ax_开头的函数使资源管理器可以动态地在事务管理器中进行注册，并可以对XID(TRANSACTION IDS)进行操作。</li><li>ax_reg,ax_unreg；允许一个资源管理器在一个TMS(TRANSACTION MANAGER SERVER)中动态注册或撤消注册。<br>XA的一些问题：</li><li>性能（阻塞、响应时间增加、死锁）；</li><li>依赖于独立的J2EE中间件，Weblogic、Jboss，后期轻量级的Atomikos、Narayana、Bitronix；</li><li>不是所有资源(RM)都支持XA协议；</li></ul><h4 id="JTA（Java-Transaction-API）"><a href="#JTA（Java-Transaction-API）" class="headerlink" title="JTA（Java Transaction API）"></a>JTA（Java Transaction API）</h4><p>即Java的事务API，基于XA实现，也就是RM需要支持XA，所以也有JTA(XA)的说法，JTA仅定义了接口。主要包括javax.sql.XADataResource、javax.sql.XAConnection、javax.sql.XAException、javax.transaction.xa.XAResource、javax.transaction.Xid。 目下JTA的实现有几种形式：</p><ul><li>J2EE容器提供的JTA实现（Weblogic、JBoss ）；</li><li>JOTM（Java Open Transaction Manager）、Atomikos，可独立于J2EE容器的环境下实现JTA；</li></ul><h4 id="二阶段提交（2PC）"><a href="#二阶段提交（2PC）" class="headerlink" title="二阶段提交（2PC）"></a>二阶段提交（2PC）</h4><p>2PC就是分布式事务中将事务分为两步进行提交。基于数据库的XA协议完成事务本质上就是二阶段提交（XA、JTA/JTS）。</p><ul><li><p>协调者（Coordinater）：事务管理器（TM）</p></li><li><p>参与者（participants）：资源管理器（RM）<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_4.png"></p></li><li><p><strong>准备阶段</strong>：  </p><ul><li>协调者向参与者发送prepare信息，以询问参与者是否能够提交事务；</li><li>参与者在收到prepare信息后，进行本地事务的预处理，但不提交。并根据处理结果返回，失败not commit or 成功ready ；</li></ul></li><li><p><strong>提交阶段</strong>：  </p><ul><li>如协调者收到参与者的失败消息，则向每个参与者发送rollback消息进行回滚；</li><li>所有参与者都返回ready，则向每个参与者发送提交commit消息，通知参与者进行事务提交；</li></ul></li></ul><p>两阶段提交的一些问题:</p><ul><li>同步阻塞，事务执行过程中所有参与者都是阻塞型的，第三方参与者访问参与者占有的资源时会被阻塞；</li><li>单点故障，协调者一旦发生故障，参与者会被阻塞。尤其在提交阶段，所有参与者都处于锁定资源状态中，无法完成事务操作；（可以选择新的协调者，但无法解决参与者被阻塞的问题）；</li><li>数据不一致，提交阶段协调者向参与者发送commit信息，发生局部网络故障，会导致存在参与者未收到commit信息无法提交事务情况，导致出现数据不一致现象；</li></ul><h4 id="三阶段提交（3PC）"><a href="#三阶段提交（3PC）" class="headerlink" title="三阶段提交（3PC）"></a>三阶段提交（3PC）</h4><p>相比于2PC，3PC把2PC的准备阶段再次进行拆分，并且3PC引入了参与者超时机制。</p><ul><li>canCommit：协调者询问参与者，是否具备执行事务的条件，参与者进行自身事务必要条件的检查；</li><li>preCommit：协调者通知参与者进行事务的预提交；</li><li>doCommit：协调者根据preCommit阶段参与者的反馈结果通知参与者是否进行事务提交或是进行事务回滚。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_5.png"></li></ul><h4 id="TCC事务补偿方案"><a href="#TCC事务补偿方案" class="headerlink" title="TCC事务补偿方案"></a>TCC事务补偿方案</h4><p>TCC的核心思想就是校验、资源锁定、补偿，对每个操作（Try）都提供确认（Confirm）和取消（cancel）的操作，这样根据操作的结果，来确认是进行Confirm还是Cancel。<br>可以看出XA的两阶段提交是基于资源层面的，而TCC也是一种两阶段提交，但它是基于应用层面的。</p><ul><li>Try：主要负责对业务进行数据检查和资源预留，例如：对资金进行冻结；对状态更改为处理中；</li><li>Confirm：确认执行业务的操作，例如：进行实际资金扣除；更改状态为最终结果；</li><li>Cancel：取消执行业务的操作，例如：解冻资金；更改状态为未处理；</li></ul><p>TCC存在的一些问题：</p><ul><li>业务操作的是不同服务的Try来进行资源预留，每个Try都是独立完成本地事务，因此不会对资源一直加锁。</li><li>业务服务需要提供try、confirm、cancel，业务侵入性强，如不适用三方框架要做到对各阶段状态的感知，比较麻烦。</li><li>Confirm/Cancel要做幂等性设计。</li></ul><p>常用TCC框架：<br>tcc-transaction、ByteTCC、spring-cloud-rest-tcc、Himly</p><p>常见的微服务系统大部分接口调用是同步的，这时候使用TCC来保证一致性是比较合适的。</p><h4 id="SAGA"><a href="#SAGA" class="headerlink" title="SAGA"></a>SAGA</h4><p>Saga的核心是补偿，与TCC不同的是Saga不需要Try，而是直接进行confirm、cancel操作。  </p><ul><li>Confirm：依次按顺序依次执行资源操作，各个资源直接处理本地事务，如无问题，二阶段什么都不用做；</li><li>Cancel：异常情况下需要调用的补偿事务（逆操作）来保证数据的一致性。</li></ul><p>可以看出，Saga和TCC有些类似，都是补偿型事务</p><p>优势：</p><ul><li>一阶段提交本地事务，无锁，高性能；</li><li>事件驱动模式，参与者可异步执行，高吞吐；</li><li>应用成本低，补偿服务易于实现；</li></ul><p>劣势：</p><ul><li>无法保证隔离性（脏写）</li></ul><h4 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h4><p>有一些情况，服务间调用时异步的，服务A将消息发送到MQ，服务B进行消息的消费。这时我们就需要用到可靠消息最终一致性来解决分布式事务问题</p><ul><li>可靠消息：即这个消息一定是可靠的，并且最终一定需要被消费的。 </li><li>最终一致性：过程中数据存在一定时间内的不一致，但超过限定时间后，需要最终会保持一致。</li></ul><p>保证以上两点的情况下，可以通过消息中间件（RocketMQ）来完成分布式事务处理，因为RocketMQ支持事务消息，可以方便的让我们进行分布式事务控制。</p><p>RocketMQ的事务消息的原理：<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_6.png" alt="img.png"></p><p>half message：半消息，此时消息不能被consumer所发现和消费，需producer进行二次消息确认。</p><ul><li>producer发送half message给MQ Server；</li><li>producer根据MQ Server应答结果判断half message是否发送成功；</li><li>producer处理本地事务；</li><li>producer发送最终确认消息commit / rollback；</li><li>commit：consumer对消息可见并进行消费；</li><li>rollback：discard抛弃消息，consumer无法进行消息消费；</li></ul><p>如遇异常情况下step4最终确认消息为达到MQ Server，MQ Server会定期查询当前处于半消息状态下的消息，主动进行消息回查来询问producer该消息的最终状态；</p><ul><li>producer检查本地事务执行的最终结果；</li><li>producer根据检查到的结果，再次提交确认消息，MQ Server仍然按照step4进行后续操作。</li></ul><p>事务消息发送对应步骤1、2、3、4，事务消息回查对应步骤5、6、7。<br>由以上步骤可以看出通过事务性消息的两步操作，避免了消息直接投递所产生一些问题。最终投递到MQ Server的消息，是真实可靠且必须被消费的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="分布式事务设计权衡点"><a href="#分布式事务设计权衡点" class="headerlink" title="分布式事务设计权衡点"></a>分布式事务设计权衡点</h3><ul><li>实现复杂度：事务模式与当前业务结合，实施成本是否过高；</li><li>业务侵入性：基于注解、XML、补偿逻辑； </li><li>TC/TM部署：独立部署、与应用部署；</li><li>性能：回滚概率、回滚所付出的代价、响应时间、吞吐量；</li><li>高可用：数据库、注册中心、配置中心</li><li>持久化：文件、数据库；</li><li>同步/异步：分布式事务执行过程中是否阻塞，还是非阻塞；</li></ul><h3 id="分布式事务解决方案对比"><a href="#分布式事务解决方案对比" class="headerlink" title="分布式事务解决方案对比"></a>分布式事务解决方案对比</h3><p>分布式系统中，基于不同的一致性需求产生了不同的分布式事务解决方案，追求强一致的两阶段提交、追求最终一致性的柔性事务和事务消息等等。  </p><p>我们综合对比下几种分布式事务解决方案：  </p><ul><li>一致性保证：XA &gt; TCC = SAGA &gt; 事务消息  </li><li>业务友好性：XA &gt; 事务消息 &gt; SAGA &gt; TCC  </li><li>性 能 损 耗：XA &gt; TCC &gt; SAGA = 事务消息</li></ul><p>在柔性事务解决方案中，虽然SAGA和TCC看上去可以保证数据的最终一致性，但分布式系统的生产环境复杂多变，某些情况是可以导致柔性事务机制失效的，所以无论使用那种方案，都需要最终的兜底策略，人工校验，修复数据。</p><h3 id="分布式事务框架Seata"><a href="#分布式事务框架Seata" class="headerlink" title="分布式事务框架Seata"></a>分布式事务框架Seata</h3><p>阿里开源的Seata 是一款分布式事务解决方案，提供了 AT、TCC、SAGA 和 XA 事务模式。</p><p>Seata架构的亮点主要有几个:</p><ul><li>应用层基于SQL解析实现了自动补偿，从而最大程度的降低业务侵入性；</li><li>将分布式事务中TC（事务协调者）独立部署，负责事务的注册、回滚（支持多种注册中心形式以及本地文件形式）；</li><li>通过全局锁实现了写隔离与读隔离。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是分布式事务&quot;&gt;&lt;a href=&quot;#什么是分布式事务&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式事务&quot;&gt;&lt;/a&gt;什么是分布式事务&lt;/h2&gt;&lt;p&gt;分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="事务" scheme="http://example.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统02之分布式ID解决方案</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</id>
    <published>2021-07-09T10:32:44.000Z</published>
    <updated>2021-07-14T08:49:21.134Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么需要分布式ID"><a href="#为什么需要分布式ID" class="headerlink" title="为什么需要分布式ID"></a>为什么需要分布式ID</h2><p>在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如数据量太大之后，往往需要对进行对数据进行分库分表，分库分表后需要有一个唯一 ID 来标识一条数据或消息，数据库的自增 ID 显然不能满足需求。</p><h2 id="分布式ID生成方案"><a href="#分布式ID生成方案" class="headerlink" title="分布式ID生成方案"></a>分布式ID生成方案</h2><p><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/img_1.png"></p><h3 id="数据库自增ID"><a href="#数据库自增ID" class="headerlink" title="数据库自增ID"></a>数据库自增ID</h3><p>需要一个单独的Mysql实例，虽然可行，但是基于性能与可靠性来考虑的话都不够，业务系统每次需要一个ID时，都需要请求数据库获取，性能低，并且如果此数据库实例下线了，那么将影响所有的业务系统。</p><h3 id="数据库多主模式"><a href="#数据库多主模式" class="headerlink" title="数据库多主模式"></a>数据库多主模式</h3><p>多个数据库主节点实例，单独设置步长防止产生相同ID，或者使用号段模式每个节点生产部分号段的ID</p><h3 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h3><p>核心思想是：分布式ID固定是一个long型的数字，一个long型占8个字节，也就是64个bit，原始snowflake算法中对于bit的分配如下图：<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/img.png" alt="img.png"></p><ul><li>第一个bit位是标识部分，在java中由于long的最高位是符号位，正数是0，负数是1，一般生成的ID为正数，所以固定为0。</li><li>时间戳部分占41bit，这个是毫秒级的时间，一般实现上不会存储当前的时间戳，而是时间戳的差值（当前时间-固定的开始时间），这样可以使产生的ID从更小值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69年</li><li>工作机器id占10bit，这里比较灵活，比如，可以使用前5位作为数据中心机房标识，后5位作为单机房机器标识，可以部署1024个节点。</li><li>序列号部分占12bit，支持同一毫秒内同一个节点可以生成4096个ID</li><li>备注： 工作机器ID可以通过某种改造自动生成。</li></ul><h3 id="Redis自增ID"><a href="#Redis自增ID" class="headerlink" title="Redis自增ID"></a>Redis自增ID</h3><p>使用Redis来生成分布式ID，其实和利用Mysql自增ID类似，可以利用Redis中的incr命令来实现原子性的自增与返回，比如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set seq_id 1 // 初始化自增ID为1 OK </span><br><span class="line">127.0.0.1:6379&gt; incr seq_id // 增加1，并返回 (integer) 2 </span><br><span class="line">127.0.0.1:6379&gt; incr seq_id // 增加1，并返回</span><br><span class="line">备注：使用redis需要考虑持久化问题,RDB&amp;AOF。</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;为什么需要分布式ID&quot;&gt;&lt;a href=&quot;#为什么需要分布式ID&quot; class=&quot;headerlink&quot; title=&quot;为什么需要分布式ID&quot;&gt;&lt;/a&gt;为什么需要分布式ID&lt;/h2&gt;&lt;p&gt;在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如数据量太大之</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统01之分布式系统理论</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/</id>
    <published>2021-07-09T10:32:14.000Z</published>
    <updated>2021-07-14T08:49:21.149Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><h3 id="名词解析"><a href="#名词解析" class="headerlink" title="名词解析"></a>名词解析</h3><p>CAP理论作为分布式系统的基础理论,它描述的是一个分布式系统在以下三个特性中：</p><ul><li><strong>一致性（Consistency）</strong><ul><li>所有节点访问同一份最新的数据副本</li></ul></li><li><strong>可用性（Availability）</strong><ul><li>非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。</li></ul></li><li><strong>分区容错性（Partition tolerance）</strong><ul><li>分布式系统出现网络分区（多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域）的时候，仍然能够对外提供服务。<br>最多满足其中的两个特性。 </li></ul></li></ul><p>也就是下图所描述的。分布式系统要么满足CA,要么CP，要么AP。无法同时满足CAP。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/img.png"></p><h3 id="CAP三者不可兼得，该如何取舍："><a href="#CAP三者不可兼得，该如何取舍：" class="headerlink" title="CAP三者不可兼得，该如何取舍："></a>CAP三者不可兼得，该如何取舍：</h3><ul><li><strong>CA</strong>: 优先保证一致性和可用性，放弃分区容错。 这也意味着放弃系统的扩展性，系统不再是分布式的，有违设计的初衷。<ul><li>当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。</li><li><strong>因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。</strong></li></ul></li><li><strong>CP</strong>: 优先保证一致性和分区容错性，放弃可用性。 在<strong>数据一致性要求比较高的场合</strong>(譬如:zookeeper,Hbase) 是比较常见的做法，一旦发生网络故障或者消息丢失，就会牺牲用户体验，等恢复之后用户才逐渐能访问。</li><li><strong>AP</strong>: 优先保证可用性和分区容错性，放弃一致性。 NoSQL中的Cassandra 就是这种架构。跟CP一样，放弃一致性不是说一致性就不保证了，而是逐渐的变得一致。</li></ul><h3 id="实际应用案例–注册中心"><a href="#实际应用案例–注册中心" class="headerlink" title="实际应用案例–注册中心"></a>实际应用案例–注册中心</h3><p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos…。 </p><ul><li>ZooKeeper 保证的是 CP。<br>任何时刻对 ZooKeeper 的读请求都能得到一致性的结果。<br>但是， ZooKeeper 不保证每次请求的可用性，比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。</li><li>Eureka 保证的则是 AP。<br>Eureka 在设计的时候就是优先保证 A （可用性）。<br>在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。<br>因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。<br>Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。   </li><li>Nacos 不仅支持 CP 也支持 AP。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等。<br>如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”（网络连接通信正常）的话，我们要思考如何保证 CA。</p><h2 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h2><h3 id="BASE理论名词解析"><a href="#BASE理论名词解析" class="headerlink" title="BASE理论名词解析"></a>BASE理论名词解析</h3><ul><li><strong>基本可用（Basically Available）</strong><br>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。<br>什么叫允许损失部分可用性呢？ <ul><li>响应时间上的损失: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。 </li><li>系统功能上的损失：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。</li></ul></li><li><strong>软状态（Soft State）</strong><br>软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</li><li><strong>最终一致性（Eventually Consistent）</strong><br>虽然允许软状态，但是系统不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。<br>实际工程实践中，最终一致性分为5种：<ul><li>因果一致性（Causal consistency）<br>如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。</li><li>读己之所写（Read your writes）<br>节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。</li><li>会话一致性（Session consistency）<br>系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</li><li>单调读一致性（Monotonic read consistency）<br>如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。</li><li>单调写一致性（Monotonic write consistency）<br>一个系统要能够保证来自同一个节点的写操作被顺序的执行。</li></ul></li></ul><h3 id="系统一致性说明"><a href="#系统一致性说明" class="headerlink" title="系统一致性说明"></a>系统一致性说明</h3><ul><li><strong>强一致性</strong>：系统写入了什么，读出来的就是什么。 </li><li><strong>弱一致性</strong>：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</li><li><strong>最终一致性</strong>：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</li></ul><h3 id="BASE理论的核心思想"><a href="#BASE理论的核心思想" class="headerlink" title="BASE理论的核心思想"></a>BASE理论的核心思想</h3><p>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</span><br></pre></td></tr></table></figure><p>CAP的3选2实际是个伪命题，实际上，系统没有发生P(分区)的话，必须在C（一致性）和A（可用性）之间任选其一。<br>分区的情况很少出现，CAP在大多时间能够同时满足C和A。<br>对于分区存在或者探知其影响的情况下，需要提供一种预备策略做出处理：</p><ul><li>探知分区的发生；</li><li>进入显示的分区模式，限制某些操作；</li><li>启动恢复过程，恢复数据一致性，补偿分区发生期间的错误。</li></ul><p>因此，AP方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。<br>在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。</p><h2 id="ACID本地事务四大特性"><a href="#ACID本地事务四大特性" class="headerlink" title="ACID本地事务四大特性"></a>ACID本地事务四大特性</h2><ul><li><strong>原子性（atomicity）</strong><br>一个事务中的所有操作，不可分割，要么全部成功，要么全部失败；</li><li><strong>一致性（consistency）</strong><br>一个事务执行前与执行后数据的完整性必须保持一致；</li><li><strong>隔离性（isolation）</strong><br>一个事务的执行，不能被其他事务干扰，多并发时事务之间要相互隔离；</li><li><strong>持久性（durability）</strong><br>一个事务一旦被提交，它对数据库中数据的改变是永久性的。</li></ul><h2 id="幂等性设计"><a href="#幂等性设计" class="headerlink" title="幂等性设计"></a>幂等性设计</h2><p>幂等（Idempotent）是一个数学与计算机学中的概念。f(n) = 1^n // 无论n等于多少，f(n)永远值等于1；在程序中，使用相同参数执行同一个方法，每一次执行结果都是相同的，即具有幂等性。</p><h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><ul><li>ACID 是数据库事务完整性的理论，</li><li>CAP 是分布式系统设计理论，</li><li>BASE 是 CAP 理论中 AP 方案的延伸。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;CAP理论&quot;&gt;&lt;a href=&quot;#CAP理论&quot; class=&quot;headerlink&quot; title=&quot;CAP理论&quot;&gt;&lt;/a&gt;CAP理论&lt;/h2&gt;&lt;h3 id=&quot;名词解析&quot;&gt;&lt;a href=&quot;#名词解析&quot; class=&quot;headerlink&quot; title=&quot;名词解析&quot;</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="设计理念" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统00之什么是分布式系统</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</id>
    <published>2021-07-09T10:31:51.000Z</published>
    <updated>2021-07-14T09:06:24.911Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是分布式系统"><a href="#什么是分布式系统" class="headerlink" title="什么是分布式系统"></a>什么是分布式系统</h2><p>分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。</p><p>分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是<strong>利用更多的机器，处理更多的数据</strong>。</p><p>首先需要明确的是，只有</p><ul><li>单个节点的处理能力无法满足日益增长的计算、存储任务</li><li>且硬件的提升（加内存、加磁盘、使用更好的CPU）高昂到得不偿失</li><li>应用程序也不能进一步优化  </li></ul><p>我们才需要考虑分布式系统。</p><p>因为，分布式系统要解决的问题本身就是和单机系统一样的，而由于分布式系统多节点、通过网络通信的拓扑结构，会引入很多单机系统没有的问题，为了解决这些问题又会引入更多的机制、协议，带来更多的问题。</p><p>分布式系统怎么将任务分发到这些计算机节点呢，很简单的思想，分而治之，即分片（partition）。对于计算，那么就是对计算任务进行切换，每个节点算一些，最终汇总就行了，这就是MapReduce的思想；对于存储，更好理解一下，每个节点存一部分数据就行了。当数据规模变大的时候，Partition是唯一的选择，同时也会带来一些好处：</p><ul><li>提升性能和并发，操作被分发到不同的分片，相互独立</li><li>提升系统的可用性，即使部分分片不能用，其他分片不会受到影响</li></ul><p>理想的情况下，有分片就行了，但事实的情况却不大理想。</p><p>原因在于，分布式系统中有大量的节点，且通过网络通信。单个节点的故障（进程crash、断电、磁盘损坏）是个小概率事件，但整个系统的故障率会随节点的增加而指数级增加，网络通信也可能出现断网、高延迟的情况。在这种一定会出现的“异常”情况下，分布式系统还是需要继续稳定的对外提供服务，即需要较强的容错性。最简单的办法，就是冗余或者复制集（Replication），即多个节点负责同一个任务，最为常见的就是分布式存储中，多个节点复杂存储同一份数据，以此增强可用性与可靠性。同时，Replication也会带来性能的提升，比如数据的locality可以减少用户的等待时间。</p><p><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/img.png"></p><p>Partition和Replication是解决分布式系统问题的一记组合拳，很多具体的问题都可以用这个思路去解决。但这并不是银弹，往往是为了解决一个问题，会引入更多的问题，比如为了可用性与可靠性保证，引用了冗余（复制集）。有了冗余，各个副本间的一致性问题就变得很头疼，一致性在系统的角度和用户的角度又有不同的等级划分。如果要保证强一致性，那么会影响可用性与性能，在一些应用（比如电商、搜索）是难以接受的。如果是最终一致性，那么就需要处理数据冲突的情况。CAP、FLP这些理论告诉我们，在分布式系统中，没有最佳的选择，都是需要权衡，做出最合适的选择。</p><h2 id="分布式系统面临的挑战"><a href="#分布式系统面临的挑战" class="headerlink" title="分布式系统面临的挑战"></a>分布式系统面临的挑战</h2><ul><li><p>异构的机器与网络：</p><p>  分布式系统中的机器，配置不一样，其上运行的服务也可能由不同的语言、架构实现，因此处理能力也不一样；节点间通过网络连接，而不同网络运营商提供的网络的带宽、延时、丢包率又不一样。怎么保证大家齐头并进，共同完成目标，这四个不小的挑战。</p></li><li><p>普遍的节点故障：</p><p>  虽然单个节点的故障概率较低，但节点数目达到一定规模，出故障的概率就变高了。分布式系统需要保证故障发生的时候，系统仍然是可用的，这就需要监控节点的状态，在节点故障的情况下将该节点负责的计算、存储任务转移到其他节点</p></li><li><p>不可靠的网络：</p><p>  节点间通过网络通信，而网络是不可靠的。可能的网络问题包括：网络分割、延时、丢包、乱序。</p><p>  相比单机过程调用，网络通信最让人头疼的是超时：节点A向节点B发出请求，在约定的时间内没有收到节点B的响应，那么B是否处理了请求，这个是不确定的，这个不确定会带来诸多问题，最简单的，是否要重试请求，节点B会不会多次处理同一个请求。</p></li></ul><p>总而言之，分布式的挑战来自<strong>不确定性</strong>，不确定计算机什么时候crash、断电，不确定磁盘什么时候损坏，不确定每次网络通信要延迟多久，也不确定通信对端是否处理了发送的消息。而分布式的规模放大了这个不确定性，不确定性是令人讨厌的，所以有诸多的分布式理论、协议来保证在这种不确定性的情况下，系统还能继续正常工作。</p><h2 id="分布式系统特性与衡量标准"><a href="#分布式系统特性与衡量标准" class="headerlink" title="分布式系统特性与衡量标准"></a>分布式系统特性与衡量标准</h2><ul><li><p><strong>透明性</strong><br>使用分布式系统的用户并不关心系统是怎么实现的，也不关心读到的数据来自哪个节点，对用户而言，分布式系统的最高境界是用户根本感知不到这是一个分布式系统。</p></li><li><p><strong>可扩展性</strong><br>分布式系统的根本目标就是为了处理单个计算机无法处理的任务，当任务增加的时候，分布式系统的处理能力需要随之增加。简单来说，要比较方便的通过增加机器来应对数据量的增长，同时，当任务规模缩减的时候，可以撤掉一些多余的机器，达到动态伸缩的效果</p></li><li><p><strong>可用性与可靠性</strong><br>一般来说，分布式系统是需要长时间甚至7*24小时提供服务的。可用性是指系统在各种情况对外提供服务的能力，简单来说，可以通过不可用时间与正常服务时间的必知来衡量；而可靠性而是指计算结果正确、存储的数据不丢失。</p></li><li><p><strong>高性能</strong><br>不管是单机还是分布式系统，大家都非常关注性能。不同的系统对性能的衡量指标是不同的，最常见的：高并发，单位时间内处理的任务越多越好；低延迟：每个任务的平均时间越少越好。这个其实跟操作系统CPU的调度策略很像</p></li><li><p><strong>一致性</strong><br>分布式系统为了提高可用性可靠性，一般会引入冗余（复制集）。那么如何保证这些节点上的状态一致，这就是分布式系统不得不面对的一致性问题。一致性有很多等级，一致性越强，对用户越友好，但会制约系统的可用性；一致性等级越低，用户就需要兼容数据不一致的情况，但系统的可用性、并发性很高很多。</p></li></ul><h2 id="一个简化的架构图"><a href="#一个简化的架构图" class="headerlink" title="一个简化的架构图"></a>一个简化的架构图</h2><p><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/img_2.png" alt="img.png"></p><h3 id="概念及其实现"><a href="#概念及其实现" class="headerlink" title="概念及其实现"></a>概念及其实现</h3><p>负载均衡：<br>Nginx：高性能、高并发的web服务器；功能包括负载均衡、反向代理、静态内容缓存、访问控制；工作在应用层</p><p>LVS： Linux virtual server，基于集群技术和Linux操作系统实现一个高性能、高可用的服务器；工作在网络层</p><p>webserver：<br>Java：Tomcat，Apache，Jboss</p><p>Python：gunicorn、uwsgi、twisted、webpy、tornado</p><p>service：<br>SOA、微服务、spring boot，django</p><p>容器：<br>docker，kubernetes</p><p>cache：<br>memcache、redis等</p><p>协调中心：<br>zookeeper、etcd等</p><p>zookeeper使用了Paxos协议Paxos是强一致性，高可用的去中心化分布式。zookeeper的使用场景非常广泛，之后细讲。</p><p>rpc框架：<br>grpc、dubbo、brpc</p><p>dubbo是阿里开源的Java语言开发的高性能RPC框架，在阿里系的诸多架构中，都使用了dubbo + spring boot</p><p>消息队列：<br>kafka、rabbitMQ、rocketMQ、QSP</p><p>消息队列的应用场景：异步处理、应用解耦、流量削锋和消息通讯</p><p>实时数据平台：<br>storm、akka</p><p>离线数据平台：<br>hadoop、spark</p><p>PS: spark、akka、kafka都是scala语言写的，看到这个语言还是很牛逼的</p><p>dbproxy：<br>cobar也是阿里开源的，在阿里系中使用也非常广泛，是关系型数据库的sharding + replica 代理</p><p>db：<br>mysql、oracle、MongoDB、HBase</p><p>搜索：<br>elasticsearch、solr</p><p>日志：<br>rsyslog、elk、flume</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是分布式系统&quot;&gt;&lt;a href=&quot;#什么是分布式系统&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式系统&quot;&gt;&lt;/a&gt;什么是分布式系统&lt;/h2&gt;&lt;p&gt;分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。&lt;/</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="设计理念" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/"/>
    
  </entry>
  
</feed>
