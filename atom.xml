<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>沉默者</title>
  
  <subtitle>路漫漫其修远兮，吾将上下而求索</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-07-20T03:13:47.056Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>何鹏 [smile.hepeng@qq.com]</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>批处理框架之SpringBatch快速入门实践</title>
    <link href="http://example.com/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
    <id>http://example.com/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</id>
    <published>2021-07-19T08:47:31.000Z</published>
    <updated>2021-07-20T03:13:47.056Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是SpringBatch"><a href="#什么是SpringBatch" class="headerlink" title="什么是SpringBatch"></a>什么是SpringBatch</h3><p>一个轻量级，全面的<strong>批处理框架，不是一个 schuedling 的框架</strong>。</p><p>一个标准的批处理程序：</p><ul><li>通常会从数据库，文件或者队列中读取大量的数据和记录，</li><li>然后对获取的数据进行处理，</li><li>然后将修改后的格式写回到数据库中。</li></ul><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img.png"></p><p>通常 Spring Batch 在离线模式下进行工作，不需要用户干预就能自动进行基本的批处理迭代，进行类似事务方式的处理。批处理是大多数 IT 目的一个组成部分，而 Spring Batch<br>是唯一能够提供健壮的企业级扩展性的批处理开源框架。</p><h3 id="什么情况下需要用到SpringBatch"><a href="#什么情况下需要用到SpringBatch" class="headerlink" title="什么情况下需要用到SpringBatch"></a>什么情况下需要用到SpringBatch</h3><p>在大型企业中，由于业务复杂、数据量大、数据格式不同、数据交互格式繁杂，并非所有的操作都能通过交互界面进行处理。而有一些操作需要定期读取大批量的数据，然后进行一系列的后续处理。这样的过程就是“批处理”。</p><ul><li>数据量大，从数万到数百万甚至上亿不等；</li><li>整个过程全部自动化，并预留一定接口进行自定义配置；</li><li>这样的应用通常是周期性运行，比如按日、周、月运行；</li><li>对数据处理的准确性要求高，并且需要容错机制、回滚机制、完善的日志监控等。</li></ul><h3 id="SpringBatch提供了哪些功能"><a href="#SpringBatch提供了哪些功能" class="headerlink" title="SpringBatch提供了哪些功能"></a>SpringBatch提供了哪些功能</h3><ul><li>事务管理：全批次事务(因为可能有小数据量的批处理或存在存储过程/脚本中)</li><li>基于Web的管理员接口</li><li>分阶段的企业消息驱动处理</li><li>极高容量和高性能的基于块的处理过程(通过优化和分区技术)</li><li>按顺序处理任务依赖（使用工作流驱动的批处理插件）</li><li>声明式的输入/输出操作</li><li>启动、终止、（失败后的手动或定时）重启任务</li><li>重试/跳过任务，部分处理跳过记录（例如，回滚）<details><summary>具体使用场景</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在处理百万级的数据过程过程中难免会出现异常。如果一旦出现异常而导致整个批处理工作终止的话那么会导致后续的数据无法被处理。Spring Batch内置了Retry（重试）和Skip（跳过）机制帮助我们轻松处理各种异常。我 们需要将异常分为三种类型。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> 第一种是<span class="strong">**需要进行Retry的异常**</span>，它们的特点是该异常可能会随着时间推移而消失，比如数据库目前有锁无法写入、web服务当前不可用、web服务满载等。所以对它们适合配置Retry机制。</span><br><span class="line"><span class="bullet">*</span> 第二种是<span class="strong">**需要Skip的异常**</span>，比如解析文件的某条数据出现异常等，因为对这些异常即使执行Retry每次的结果也都是相同，但又不想由于某条数据出错而停止对后续数据的处理。</span><br><span class="line"><span class="bullet">*</span> 第三种异常是<span class="strong">**需要让整个Job立刻失败的异常**</span>，比如如果出现了OutOfMemory的异常，那么需要整个Job立刻终止运行。</span><br><span class="line"></span><br><span class="line">一般来说需要Retry的异常也要配置Skip选项，从而保证后续的数据能够被继续处理。我们也可以配置SkipLimit选项保证当Skip的数据条目达到一定数量后及时终止整个Job。</span><br></pre></td></tr></table></figure></details></li></ul><h3 id="SpringBatch整体架构"><a href="#SpringBatch整体架构" class="headerlink" title="SpringBatch整体架构"></a>SpringBatch整体架构</h3><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_1.png"></p><p>Spring batch框架有4个主要组件：JobLauncher、Job、Step和JobRepository。</p><ul><li>JobLauncher（任务启动器）：通过它启动任务，可以理解为程序的入口。</li><li>Job（任务）：一个具体的任务。<ul><li>由一个或多个step组成，</li><li>通过JobBuilderFactory实例创建Bean，</li><li>使用next指向下一个step,  可以按照指定的逻辑顺序组合 step,</li><li>提供了我们给所有 step 设置相同属性的方法（例如一些事件监听，跳过策略）;</li></ul></li><li>Step（步骤）：一个具体的执行步骤，一个Job中可以有多个Step。</li><li>JobRepository（任务仓库）：存储数据的仓库，在任务执行的时候，需要用它来记录任务状态信息，可以看做是一个数据库的接口。</li></ul><h4 id="JOB"><a href="#JOB" class="headerlink" title="JOB"></a>JOB</h4><p>Job 是一个封装整个批处理过程的一个概念。Job 在 spring batch 的体系当中只是一个最顶层的一个抽象概念，体现在代码当中则它只是一个最上层的接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Batch domain object representing a job. Job is an explicit abstraction</span></span><br><span class="line"><span class="comment"> * representing the configuration of a job specified by a developer. It should</span></span><br><span class="line"><span class="comment"> * be noted that restart policy is applied to the job as a whole and not to a</span></span><br><span class="line"><span class="comment"> * step.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"> <span class="function">String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">boolean</span> <span class="title">isRestartable</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function"><span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecution execution)</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersIncrementer <span class="title">getJobParametersIncrementer</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> <span class="function">JobParametersValidator <span class="title">getJobParametersValidator</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Job 这个接口当中定义了五个方法，它的实现类主要有两种类型的 job，一个是 simplejob，另一个是 flowjob。</p><p>Spring Batch 以 SimpleJob 类的形式提供了 Job 接口的默认简单实现，它在 Job 之上创建了一些标准功能。一个使用 java config 的例子代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job footballJob() &#123;</span><br><span class="line">    return this.jobBuilderFactory.get(&quot;footballJob&quot;)</span><br><span class="line">                     .start(playerLoad())</span><br><span class="line">                     .next(gameLoad())</span><br><span class="line">                     .next(playerSummarization())</span><br><span class="line">                     .end()</span><br><span class="line">                     .build();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="JobInstance"><a href="#JobInstance" class="headerlink" title="JobInstance"></a>JobInstance</h4><p>他是 Job 的更加底层的一个抽象，他的定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobInstance</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobInstance.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> instance id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getInstanceId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>他的方法很简单，一个是返回 Job 的 id，另一个是返回 Job 的名字。</p><p>JobInstance 指的是 job 运行当中，作业执行过程当中的概念。</p><p>比如说现在有一个批处理的 job，它的功能是在一天结束时执行行一次。我们假定这个批处理 job 的名字为’EndOfDay’。在这个情况下，那么每天就会有一个逻辑意义上的 JobInstance, 而我们必须记录 job 的每次运行的情况。</p><h4 id="JobParameters"><a href="#JobParameters" class="headerlink" title="JobParameters"></a>JobParameters</h4><p>JobParameters 对象包含一组用于启动批处理作业的参数，它可以在运行期间用于识别或甚至用作参考数据。</p><p>例如, 我们前面的’EndOfDay’的 job 现在已经有了两个实例，一个产生于 1 月 1 日，另一个产生于 1 月 2 日，那么我们就可以定义两个 JobParameter 对象：一个的参数是 01-01, 另一个的参数是 01-02。</p><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_2.png"></p><p>因此，我么可以通过 Jobparameter 来操作正确的 JobInstance</p><h4 id="JobExecution"><a href="#JobExecution" class="headerlink" title="JobExecution"></a>JobExecution</h4><p>JobExecution 指的是单次尝试运行一个我们定义好的 Job 的代码层面的概念。job 的一次执行可能以失败也可能成功。只有当执行成功完成时，给定的与执行相对应的 JobInstance 才也被视为完成。</p><p>还是以前面描述的 EndOfDay 的 job 作为示例，假设第一次运行 01-01-2019 的 JobInstance 结果是失败。那么此时如果使用与第一次运行相同的 Jobparameter 参数（即 01-01-2019）作业参数再次运行，那么就会创建一个对应于之前 jobInstance 的一个新的 JobExecution 实例, JobInstance 仍然只有一个。</p><p>JobExecution 的接口定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">JobExecution</span> </span>&#123;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get unique id for this JobExecution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> execution id</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getExecutionId</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job name.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> value of &#x27;id&#x27; attribute from &lt;job&gt;</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getJobName</span><span class="params">()</span></span>; </span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get batch status of this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> batch status value.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> BatchStatus <span class="title">getBatchStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered STARTED status. </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getStartTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution entered end status: COMPLETED, STOPPED, FAILED </span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getEndTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get execution exit status.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> exit status.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> String <span class="title">getExitStatus</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was created.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getCreateTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get time execution was last updated updated.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> date (time)</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Date <span class="title">getLastUpdatedTime</span><span class="params">()</span></span>;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Get job parameters for this execution.</span></span><br><span class="line"><span class="comment">  * <span class="doctag">@return</span> job parameters  </span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> Properties <span class="title">getJobParameters</span><span class="params">()</span></span>;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>JobExecution 当中提供了一个方法 getBatchStatus 用于获取一个 job 某一次特地执行的一个状态。BatchStatus 是一个代表 job 状态的枚举类，其定义如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">BatchStatus</span> </span>&#123;</span><br><span class="line">    STARTING, STARTED, STOPPING, STOPPED, FAILED, COMPLETED, ABANDONED</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h4><p>每一个 Step 对象都封装了批处理作业的一个独立的阶段。事实上，每一个 Job 本质上都是由一个或多个步骤组成。每一个 step 包含定义和控制实际批处理所需的所有信息。任何特定的内容都由编写 Job 的开发人员自行决定。</p><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_3.png"></p><p>StepExecution 表示一次执行 Step, 每次运行一个 Step 时都会创建一个新的 StepExecution，类似于 JobExecution。但是，某个步骤可能由于其之前的步骤失败而无法执行。且仅当 Step 实际启动时才会创建 StepExecution。</p><p>一次 step 执行的实例由 StepExecution 类的对象表示。每个 StepExecution 都包含对其相应步骤的引用以及 JobExecution 和事务相关的数据，例如提交和回滚计数以及开始和结束时间。</p><p>此外，每个步骤执行都包含一个 ExecutionContext，其中包含开发人员需要在批处理运行中保留的任何数据，例如重新启动所需的统计信息或状态信息。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public Job JobFlowDemo1()&#123;</span><br><span class="line">    return jobBuilderFactory.get(&quot;jobFlowDemo1&quot;)</span><br><span class="line">//                .start(step1())</span><br><span class="line">//                .next(step2())</span><br><span class="line">//                .next(step3())</span><br><span class="line">//                .build();</span><br><span class="line">                .start(step1())</span><br><span class="line">                .on(&quot;COMPLETED&quot;).to(step2())</span><br><span class="line">                .from(step2()).on(&quot;COMPLETED&quot;).to(step3())</span><br><span class="line">                .from(step3()).end()</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">当step1 成功执行完成后，返回COMPLETED， 才调用step2进行下一步处理。但是过多的step，不易于程序维护和复用</span><br></pre></td></tr></table></figure><h4 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h4><p><img src="/2021/07/19/%E6%89%B9%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E4%B9%8BSpringBatch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/img_4.png"></p><p>由于我们一次 batch 的任务可能会有很多的数据读写操作，因此一条一条的处理并向数据库提交的话效率不会很高，因此 spring batch 提供了 chunk 这个概念，我们可以设定一个 chunk size，spring batch 将一条一条处理数据，但不提交到数据库，只有当处理的数据数量达到 chunk size 设定的值得时候，才一起去 commit.</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Spring Batch为我们提供了非常实用的功能，对批处理场景进行了完善的抽象，它不仅能实现小数据的迁移，也能应对大企业的大数据实践应用。它让我们开发批处理应用可以事半功倍。  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;什么是SpringBatch&quot;&gt;&lt;a href=&quot;#什么是SpringBatch&quot; class=&quot;headerlink&quot; title=&quot;什么是SpringBatch&quot;&gt;&lt;/a&gt;什么是SpringBatch&lt;/h3&gt;&lt;p&gt;一个轻量级，全面的&lt;strong&gt;批处理框架</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="SpringBatch" scheme="http://example.com/tags/SpringBatch/"/>
    
    <category term="Spring生态" scheme="http://example.com/tags/Spring%E7%94%9F%E6%80%81/"/>
    
    <category term="批处理" scheme="http://example.com/tags/%E6%89%B9%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>状态机系列之SpringStatusMachine详解</title>
    <link href="http://example.com/2021/07/15/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2021/07/15/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/</id>
    <published>2021-07-15T01:48:09.000Z</published>
    <updated>2021-07-19T08:50:08.249Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是状态机"><a href="#什么是状态机" class="headerlink" title="什么是状态机"></a>什么是状态机</h2><p>有限状态机是一种用来进行对象行为建模的工具，其作用主要是描述对象在它的生命周期内所经历的状态序列，以及如何响应来自外界的各种事件。</p><p>在电商场景（订单、物流、售后）、社交（IM消息投递）、分布式集群管理（分布式计算平台任务编排）等场景都有大规模的使用。</p><h3 id="状态机的要素"><a href="#状态机的要素" class="headerlink" title="状态机的要素"></a>状态机的要素</h3><ul><li><strong>现态</strong>：指当前所处的状态</li><li><strong>条件</strong>：又称“事件”，当一个条件被满足，将会触发一个动作，或者执行一次状态的迁移</li><li><strong>动作</strong>：条件满足后执行的动作。动作执行完毕后，可以迁移到新的状态，也可以仍旧保持原状态。动作不是必须的，当条件满足后，也可以不执行任何动作，直接迁移到新的状态。<ul><li>进入动作：在进入状态时进行</li><li>退出动作：在退出状态时进行</li><li>输入动作：依赖于当前状态和输入条件进行</li><li>转移动作：在进行特定转移时进行</li></ul></li><li><strong>次态</strong>：条件满足后要迁往的新状态。“次态”是相对于“现态”而言的，“次态”一旦被激活，就转换成“现态”。</li></ul><h3 id="什么时候需要用到状态机"><a href="#什么时候需要用到状态机" class="headerlink" title="什么时候需要用到状态机"></a>什么时候需要用到状态机</h3><p>Spring文档指出，在以下情况下，项目很适合使用状态机：</p><ul><li>您可以将应用程序或其结构的一部分表示为状态。</li><li>您想将复杂的逻辑拆分为更小的可管理任务。</li><li>应用程序已经遇到了（例如）异步发生的并发问题。</li></ul><p>如果满足以下条件，您已经在尝试实现状态机 ：  </p><ul><li>使用布尔标志或枚举对情况进行建模。</li><li>具有仅对应用程序生命周期的一部分有意义的变量。</li><li>遍历if / else结构并检查是否设置了特定的标志或枚举，然后进一步对当标志和枚举的某些组合存在或不存在时的处理方式作进一步的例外。</li></ul><h4 id="使用状态机的优缺点"><a href="#使用状态机的优缺点" class="headerlink" title="使用状态机的优缺点"></a>使用状态机的优缺点</h4><p><strong>优点</strong></p><ul><li>状态及转换与业务解耦；</li><li>代码的可维护性增强；</li><li>对于流程复杂易变的业务场景能大减轻维护和测试的难度。</li></ul><p><strong>缺点</strong></p><ul><li>事务不好控制；</li><li>增加更多的类。<h3 id="状态机对比"><a href="#状态机对比" class="headerlink" title="状态机对比"></a>状态机对比</h3></li></ul><table><thead><tr><th>状态机</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>stateless4j</td><td>轻量级<br>支持基本事件迁移<br>二次开发难度低</td><td>不支持持久化和上下文传参</td></tr><tr><td>squirrel-foundation</td><td>功能齐全<br>StatueMachine精简版</td><td>—</td></tr><tr><td>Spring StatusMachine</td><td>功能齐全<br>&ensp; 状态：初始终止、历史状态、连接交并；<br>&ensp; 延迟事件;<br>&ensp; Guard;<br>&ensp; 持久化;<br>&ensp; JPA<br>使用方便<br>&ensp; 配置+注解，文档齐全</td><td>学习成本较高<br>状态机已捕获异常，需要手动编码处理异常，单个状态机可以被共享，需要builder多个实例<br>同时使用多个状态机事务需要手工控制</td></tr></tbody></table><h3 id="Spring-StatusMachine使用案例"><a href="#Spring-StatusMachine使用案例" class="headerlink" title="Spring StatusMachine使用案例"></a>Spring StatusMachine使用案例</h3><p>假设在一个业务系统中，有这样一个对象，它有三个状态：草稿、待发布、发布完成，针对这三个状态的业务动作也比较简单，分别是：上线、发布、回滚。该业务状态机如下图所示。<br><img src="/2021/07/15/%E7%8A%B6%E6%80%81%E6%9C%BA%E7%B3%BB%E5%88%97%E4%B9%8BSpringStatusMachine%E8%AF%A6%E8%A7%A3/img.png" alt="img.png"></p><p>创建一个基础的Spring Boot工程，在主pom文件中加入Spring StateMachine的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--加入spring statemachine的依赖--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.statemachine<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-statemachine-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.3.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>定义状态枚举和事件枚举，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 状态枚举</span></span><br><span class="line"><span class="comment">**/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">States</span> </span>&#123;</span><br><span class="line">    DRAFT,</span><br><span class="line">    PUBLISH_TODO,</span><br><span class="line">    PUBLISH_DONE,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 事件枚举</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Events</span> </span>&#123;</span><br><span class="line">  ONLINE,</span><br><span class="line">  PUBLISH,</span><br><span class="line">  ROLLBACK</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成状态机的配置，包括：（1）状态机的初始状态和所有状态；（2）状态之间的转移规则</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="comment">// @EnableStateMachine批注时，它将在应用程序启动时自动创建默认状态机。</span></span><br><span class="line"><span class="meta">@EnableStateMachine</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StateMachineConfig</span> <span class="keyword">extends</span> <span class="title">EnumStateMachineConfigurerAdapter</span>&lt;<span class="title">States</span>, <span class="title">Events</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(StateMachineStateConfigurer&lt;States, Events&gt; states)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        states.withStates().initial(States.DRAFT).states(EnumSet.allOf(States.class));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(StateMachineTransitionConfigurer&lt;States, Events&gt; transitions)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        transitions.withExternal()</span><br><span class="line">            .source(States.DRAFT).target(States.PUBLISH_TODO)</span><br><span class="line">            .event(Events.ONLINE)</span><br><span class="line">            .and()</span><br><span class="line">            .withExternal()</span><br><span class="line">            .source(States.PUBLISH_TODO).target(States.PUBLISH_DONE)</span><br><span class="line">            .event(Events.PUBLISH)</span><br><span class="line">            .and()</span><br><span class="line">            .withExternal()</span><br><span class="line">            .source(States.PUBLISH_DONE).target(States.DRAFT)</span><br><span class="line">            .event(Events.ROLLBACK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个测试业务对象，状态机的状态转移都会反映到该业务对象的状态变更上</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WithStateMachine</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BizBean</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@see</span> States</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> String status = States.DRAFT.name();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;PUBLISH_TODO&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">online</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作上线，待发布. target status:&#123;&#125;&quot;</span>, States.PUBLISH_TODO.name());</span><br><span class="line">        setStatus(States.PUBLISH_TODO.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;PUBLISH_DONE&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">publish</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作发布,发布完成. target status:&#123;&#125;&quot;</span>, States.PUBLISH_DONE.name());</span><br><span class="line">        setStatus(States.PUBLISH_DONE.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@OnTransition(target = &quot;DRAFT&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rollback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;操作回滚,回到草稿状态. target status:&#123;&#125;&quot;</span>, States.DRAFT.name());</span><br><span class="line">        setStatus(States.DRAFT.name());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编写测试用例，这里我们使用CommandLineRunner接口代替，定义了一个StartupRunner，在该类的run方法中启动状态机、发送不同的事件，通过日志验证状态机的流转过程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StartupRunner</span> <span class="keyword">implements</span> <span class="title">CommandLineRunner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    StateMachine&lt;States, Events&gt; stateMachine;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(String... args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        stateMachine.start();</span><br><span class="line">        stateMachine.sendEvent(Events.ONLINE);</span><br><span class="line">        stateMachine.sendEvent(Events.PUBLISH);</span><br><span class="line">        stateMachine.sendEvent(Events.ROLLBACK);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>使用步骤总结：</strong></p><ul><li>定义状态枚举和事件枚举</li><li>定义状态机的初始状态和所有状态</li><li>定义状态之间的转移规则</li><li>在业务对象中使用状态机，编写响应状态变化的监听器方法</li></ul><p>使用Spring StateMachine的好处在于自己无需关心状态机的实现细节，只需要关心业务有什么状态、它们之间的转移规则是什么、每个状态转移后真正要进行的业务操作。</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>Spring State Machine可以做的事情还很多。 </p><ul><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#statemachine-config-states">状态可以嵌套</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-security">可以配置为检查是否允许过渡的防护措施</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-extendedstate">允许定义选择状态，接合状态等的伪状态</a> </li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-triggers">事件可以由操作或在计时器上触发</a></li><li><a href="https://docs.spring.io/spring-statemachine/docs/current/reference/#sm-persist">状态机可以持久化以提高性能</a> </li></ul><p>要浏览所有内容，您需要研究 <a href="https://docs.spring.io/spring-statemachine/docs/current/reference/">Spring StateMachine文档</a> 并确定适合您的特定情况的文档。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是状态机&quot;&gt;&lt;a href=&quot;#什么是状态机&quot; class=&quot;headerlink&quot; title=&quot;什么是状态机&quot;&gt;&lt;/a&gt;什么是状态机&lt;/h2&gt;&lt;p&gt;有限状态机是一种用来进行对象行为建模的工具，其作用主要是描述对象在它的生命周期内所经历的状态序列，以及如何响</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Spring生态" scheme="http://example.com/tags/Spring%E7%94%9F%E6%80%81/"/>
    
    <category term="状态机" scheme="http://example.com/tags/%E7%8A%B6%E6%80%81%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之分布式定时调度Elastic-Job解析</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Elastic-Job%E8%A7%A3%E6%9E%90/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Elastic-Job%E8%A7%A3%E6%9E%90/</id>
    <published>2021-07-14T01:11:37.000Z</published>
    <updated>2021-07-14T08:49:21.120Z</updated>
    
    <content type="html"><![CDATA[<p>待完善，具体信息参考： </p><p><a href="http://www.iocoder.cn/categories/Elastic-Job-Lite/?vip&architect-awesome">Elastic-Job-Lite 源码解析</a></p><p><a href="http://www.iocoder.cn/categories/Elastic-Job-Cloud/?vip&architect-awesome">Elastic-Job-Cloud 源码解析</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;待完善，具体信息参考： &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.iocoder.cn/categories/Elastic-Job-Lite/?vip&amp;architect-awesome&quot;&gt;Elastic-Job-Lite 源码解析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之分布式定时调度Quartz集群基本实现原理</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</id>
    <published>2021-07-14T01:11:09.000Z</published>
    <updated>2021-07-14T08:49:21.156Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Quartz集群架构"><a href="#Quartz集群架构" class="headerlink" title="Quartz集群架构"></a>Quartz集群架构</h3><p>一个Quartz集群中的每个节点是一个独立的Quartz应用，它又管理着其他的节点。这就意味着你必须对每个节点分别启动或停止。Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的，如图2.1所示。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img.png" alt="img.png"></p><h3 id="Quartz集群相关数据库表"><a href="#Quartz集群相关数据库表" class="headerlink" title="Quartz集群相关数据库表"></a>Quartz集群相关数据库表</h3><p>因为Quartz集群依赖于数据库，所以必须首先创建Quartz数据库表，Quartz发布包中包括了所有被支持的数据库平台的SQL脚本。这些SQL脚本存放于<quartz_home>/docs/dbTables 目录下。</quartz_home></p><p>这里采用的Quartz 1.8.4版本，总共12张表，不同版本，表个数可能不同。数据库为mysql，用tables_mysql.sql创建数据库表。</p><p>Quartz 1.8.4在mysql数据库中生成的表：<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img_1.png" alt="img_1.png"></p><p>Quartz数据表简介：<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/img_2.png" alt="img_2.png"></p><h3 id="Quartz-Scheduler在集群中的启动流程"><a href="#Quartz-Scheduler在集群中的启动流程" class="headerlink" title="Quartz Scheduler在集群中的启动流程"></a>Quartz Scheduler在集群中的启动流程</h3><p>Quartz Scheduler自身是察觉不到被集群的，只有配置给Scheduler的JDBC JobStore才知道。<br>当Quartz Scheduler启动时，它调用JobStore的schedulerStarted()方法，它告诉JobStore Scheduler已经启动了。<br>schedulerStarted() 方法是在JobStoreSupport类中实现的。<br>JobStoreSupport类会根据<strong>quartz.properties</strong>文件中的设置来确定Scheduler实例是否参与到集群中。<br>假如配置了集群，一个新的ClusterManager类的实例就被创建、初始化并启动。<br>ClusterManager是在JobStoreSupport类中的一个内嵌类，继承了java.lang.Thread，它会定期运行，并对Scheduler实例执行检入的功能。<br>Scheduler也要查看是否有任何一个别的集群节点失败了。检入操作执行周期在quartz.properties中配置。</p><h4 id="侦测失败的Scheduler节点"><a href="#侦测失败的Scheduler节点" class="headerlink" title="侦测失败的Scheduler节点"></a>侦测失败的Scheduler节点</h4><p>当一个Scheduler实例执行检入时，它会查看是否有其他的Scheduler实例在到达他们所预期的时间还未检入。这是通过检查SCHEDULER_STATE表中Scheduler记录在LAST_CHEDK_TIME列的值是否早于org.quartz.jobStore.clusterCheckinInterval来确定的。如果一个或多个节点到了预定时间还没有检入，那么运行中的Scheduler就假定它(们) 失败了。</p><h4 id="从故障实例中恢复Job"><a href="#从故障实例中恢复Job" class="headerlink" title="从故障实例中恢复Job"></a>从故障实例中恢复Job</h4><p>当一个Sheduler实例在执行某个Job时失败了，有可能由另一正常工作的Scheduler实例接过这个Job重新运行。要实现这种行为，配置给JobDetail对象的Job可恢复属性必须设置为true（job.setRequestsRecovery(true)）。如果可恢复属性被设置为false(默认为false)，当某个Scheduler在运行该job失败时，它将不会重新运行；而是由另一个Scheduler实例在下一次触发时间触发。Scheduler实例出现故障后多快能被侦测到取决于每个Scheduler的检入间隔（即2.3中提到的org.quartz.jobStore.clusterCheckinInterval）。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><h4 id="时间同步问题"><a href="#时间同步问题" class="headerlink" title="时间同步问题"></a>时间同步问题</h4><p>Quartz实际并不关心你是在相同还是不同的机器上运行节点。当集群放置在不同的机器上时，称之为水平集群。节点跑在同一台机器上时，称之为垂直集群。对于垂直集群，存在着单点故障的问题。这对高可用性的应用来说是无法接受的，因为一旦机器崩溃了，所有的节点也就被终止了。对于水平集群，存在着时间同步问题。</p><p>节点用时间戳来通知其他实例它自己的最后检入时间。假如节点的时钟被设置为将来的时间，那么运行中的Scheduler将再也意识不到那个结点已经宕掉了。另一方面，如果某个节点的时钟被设置为过去的时间，也许另一节点就会认定那个节点已宕掉并试图接过它的Job重运行。最简单的同步计算机时钟的方式是使用某一个Internet时间服务器(Internet Time Server ITS)。</p><h4 id="节点争抢Job问题"><a href="#节点争抢Job问题" class="headerlink" title="节点争抢Job问题"></a>节点争抢Job问题</h4><p>因为Quartz使用了一个随机的负载均衡算法， Job以随机的方式由不同的实例执行。Quartz官网上提到当前，还不存在一个方法来指派(钉住) 一个 Job 到集群中特定的节点。</p><h4 id="从集群获取Job列表问题"><a href="#从集群获取Job列表问题" class="headerlink" title="从集群获取Job列表问题"></a>从集群获取Job列表问题</h4><p>当前，如果不直接进到数据库查询的话，还没有一个简单的方式来得到集群中所有正在执行的Job列表。请求一个Scheduler实例，将只能得到在那个实例上正运行Job的列表。Quartz官网建议可以通过写一些访问数据库JDBC代码来从相应的表中获取全部的Job信息。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Quartz集群架构&quot;&gt;&lt;a href=&quot;#Quartz集群架构&quot; class=&quot;headerlink&quot; title=&quot;Quartz集群架构&quot;&gt;&lt;/a&gt;Quartz集群架构&lt;/h3&gt;&lt;p&gt;一个Quartz集群中的每个节点是一个独立的Quartz应用，它又管理着其他</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
    <category term="Quartz" scheme="http://example.com/tags/Quartz/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之分布式定时调度优秀国产调度系统</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/</id>
    <published>2021-07-14T01:10:12.000Z</published>
    <updated>2021-07-14T08:49:21.111Z</updated>
    
    <content type="html"><![CDATA[<h3 id="opencron"><a href="#opencron" class="headerlink" title="opencron"></a>opencron</h3><p>opencron 是一个功能完善且通用的开源定时任务调度系统，拥有先进可靠的自动化任务管理调度功能，提供可操作的 web 图形化管理满足多种场景下各种复杂的定时任务调度，同时集成了 linux 实时监控、webssh 等功能特性。</p><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img.png" alt="img.png"></p><h3 id="LTS"><a href="#LTS" class="headerlink" title="LTS"></a>LTS</h3><p>LTS，light-task-scheduler，是一款分布式任务调度框架, 支持实时任务、定时任务和 Cron 任务。有较好的伸缩性和扩展性，提供对 Spring 的支持（包括 Xml 和注解），提供业务日志记录器。支持节点监控、任务执行监、JVM 监控，支持动态提交、更改、停止任务。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_1.png" alt="img_1.png"></p><h3 id="XXL-JOB"><a href="#XXL-JOB" class="headerlink" title="XXL-JOB"></a>XXL-JOB</h3><p>XXL-JOB 是一个轻量级分布式任务调度框架，支持通过 Web 页面对任务进行 CRUD 操作，支持动态修改任务状态、暂停/恢复任务，以及终止运行中任务，支持在线配置调度任务入参和在线查看调度结果。</p><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_2.png" alt="img_2.png"></p><h3 id="Elastic-Job"><a href="#Elastic-Job" class="headerlink" title="Elastic-Job"></a>Elastic-Job</h3><p>Elastic-Job 是一个分布式调度解决方案，由两个相互独立的子项目 Elastic-Job-Lite 和 Elastic-Job-Cloud 组成。定位为轻量级无中心化解决方案，使用 jar 包的形式提供分布式任务的协调服务。支持分布式调度协调、弹性扩容缩容、失效转移、错过执行作业重触发、并行调度、自诊断和修复等等功能特性。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_3.png" alt="img_3.png"></p><h3 id="Uncode-Schedule"><a href="#Uncode-Schedule" class="headerlink" title="Uncode-Schedule"></a>Uncode-Schedule</h3><p>Uncode-Schedule 是基于 ZooKeeper + Quartz / spring task 的分布式任务调度组件，确保每个任务在集群中不同节点上不重复的执行。支持动态添加和删除任务，支持添加 ip 黑名单，过滤不需要执行任务的节点。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_4.png" alt="img_4.png"></p><h3 id="Antares"><a href="#Antares" class="headerlink" title="Antares"></a>Antares</h3><p>Antares 是一款基于 Quartz 机制的分布式任务调度管理平台，内部重写执行逻辑，一个任务仅会被服务器集群中的某个节点调度。用户可通过对任务预分片，有效提升任务执行效率；也可通过控制台 antares-tower 对任务进行基本操作，如触发，暂停，监控等。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E4%BC%98%E7%A7%80%E5%9B%BD%E4%BA%A7%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F/img_5.png" alt="img_5.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;opencron&quot;&gt;&lt;a href=&quot;#opencron&quot; class=&quot;headerlink&quot; title=&quot;opencron&quot;&gt;&lt;/a&gt;opencron&lt;/h3&gt;&lt;p&gt;opencron 是一个功能完善且通用的开源定时任务调度系统，拥有先进可靠的自动化任务管理调</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之单机定时调度Quartz使用总结及原理解析</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</id>
    <published>2021-07-14T01:08:59.000Z</published>
    <updated>2021-07-14T08:49:21.074Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Quartz可以用来做什么？"><a href="#Quartz可以用来做什么？" class="headerlink" title="Quartz可以用来做什么？"></a>Quartz可以用来做什么？</h2><p>在某一个有规律的时间点干某件事。<br>并且时间的触发的条件可以非常复杂（比如每月最后一个工作日的17:50），复杂到需要一个专门的框架来干这个事。<br>Quartz就是来干这样的事，你给它一个触发条件的定义，它负责到了时间点，触发相应的Job起来干活。</p><h2 id="Quartz使用总结"><a href="#Quartz使用总结" class="headerlink" title="Quartz使用总结"></a>Quartz使用总结</h2><h3 id="从简单示例看Quartz核心设计"><a href="#从简单示例看Quartz核心设计" class="headerlink" title="从简单示例看Quartz核心设计"></a>从简单示例看Quartz核心设计</h3><h4 id="一个简单的Demo程序"><a href="#一个简单的Demo程序" class="headerlink" title="一个简单的Demo程序"></a>一个简单的Demo程序</h4><p>这里面的所有例子都是基于Quartz 2.2.1</p><details><summary>点击展开/收起</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.quartz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DateBuilder.newDate;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.JobBuilder.newJob;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.SimpleScheduleBuilder.simpleSchedule;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.TriggerBuilder.newTrigger;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.GregorianCalendar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Scheduler;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Trigger;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.StdSchedulerFactory;</span><br><span class="line"><span class="keyword">import</span> org.quartz.impl.calendar.AnnualCalendar;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuartzTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//创建scheduler</span></span><br><span class="line">            Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义一个Trigger</span></span><br><span class="line">            Trigger trigger = newTrigger().withIdentity(<span class="string">&quot;trigger1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//定义name/group</span></span><br><span class="line">                .startNow()<span class="comment">//一旦加入scheduler，立即生效</span></span><br><span class="line">                .withSchedule(simpleSchedule() <span class="comment">//使用SimpleTrigger</span></span><br><span class="line">                    .withIntervalInSeconds(<span class="number">1</span>) <span class="comment">//每隔一秒执行一次</span></span><br><span class="line">                    .repeatForever()) <span class="comment">//一直执行，奔腾到老不停歇</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//定义一个JobDetail</span></span><br><span class="line">            JobDetail job = newJob(HelloQuartz.class) <span class="comment">//定义Job类为HelloQuartz类，这是真正的执行逻辑所在</span></span><br><span class="line">                .withIdentity(<span class="string">&quot;job1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//定义name/group</span></span><br><span class="line">                .usingJobData(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;quartz&quot;</span>) <span class="comment">//定义属性</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//加入这个调度</span></span><br><span class="line">            scheduler.scheduleJob(job, trigger);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//启动之</span></span><br><span class="line">            scheduler.start();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//运行一段时间后关闭</span></span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            scheduler.shutdown(<span class="keyword">true</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.quartz;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.quartz.DisallowConcurrentExecution;</span><br><span class="line"><span class="keyword">import</span> org.quartz.Job;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobDetail;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionContext;</span><br><span class="line"><span class="keyword">import</span> org.quartz.JobExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloQuartz</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        JobDetail detail = context.getJobDetail();</span><br><span class="line">        String name = detail.getJobDataMap().getString(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;say hello to &quot;</span> + name + <span class="string">&quot; at &quot;</span> + <span class="keyword">new</span> Date());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><h4 id="Quartz核心元素："><a href="#Quartz核心元素：" class="headerlink" title="Quartz核心元素："></a>Quartz核心元素：</h4><ul><li><p>Scheduler：调度器。<br>负责整个定时系统的调度，内部通过线程池进行调度。</p></li><li><p>Trigger： 定义触发的条件。<br>主要有四种类型：SimpleTrigger、CronTrigger、DataIntervalTrigger、NthIncludedTrigger，在项目中常用的为：SimpleTrigger和CronTrigger。。</p></li><li><p>JobDetail：定义任务数据。<br>记录Job的名字、组及任务执行的具体类和任务执行所需要的参数</p></li><li><p>Job： 真正的执行逻辑。  </p></li></ul><p>为什么设计成JobDetail + Job，不直接使用Job？<br>这是因为任务是有可能并发执行，如果Scheduler直接使用Job，就会存在对同一个Job实例并发访问的问题。<br>而JobDetail &amp; Job 方式，sheduler每次执行，都会根据JobDetail创建一个新的Job实例，这样就可以规避并发访问的问题。</p><h4 id="核心元素之间的关系"><a href="#核心元素之间的关系" class="headerlink" title="核心元素之间的关系"></a>核心元素之间的关系</h4><ul><li>先由SchedulerFactory创建Scheduler调度器</li><li>由调度器去调取即将执行的Trigger</li><li>执行时获取到对于的JobDetail信息</li><li>找到对应的Job类执行业务逻辑</li></ul><h3 id="Quartz-API"><a href="#Quartz-API" class="headerlink" title="Quartz API"></a>Quartz API</h3><p>Quartz的API的风格在2.x以后，采用的是DSL风格（通常意味着fluent interface风格），就是示例中newTrigger()那一段东西。它是通过Builder实现的，就是以下几个。（** 下面大部分代码都要引用这些Builder ** )</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//job相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.JobBuilder.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">//trigger相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.TriggerBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.SimpleScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.CronScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DailyTimeIntervalScheduleBuilder.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.CalendarIntervalScheduleBuilder.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">//日期相关的builder</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.quartz.DateBuilder.*;</span><br></pre></td></tr></table></figure><p>DSL风格写起来会更加连贯，畅快，而且由于不是使用setter的风格，语义上会更容易理解一些。对比一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JobDetail jobDetail=new JobDetailImpl(&quot;jobDetail1&quot;,&quot;group1&quot;,HelloQuartz.class);</span><br><span class="line">jobDetail.getJobDataMap().put(&quot;name&quot;, &quot;quartz&quot;);</span><br><span class="line"></span><br><span class="line">SimpleTriggerImpl trigger=new SimpleTriggerImpl(&quot;trigger1&quot;,&quot;group1&quot;);</span><br><span class="line">trigger.setStartTime(new Date());</span><br><span class="line">trigger.setRepeatInterval(1);</span><br><span class="line">trigger.setRepeatCount(-1);</span><br></pre></td></tr></table></figure><h3 id="关于name和group"><a href="#关于name和group" class="headerlink" title="关于name和group"></a>关于name和group</h3><p>JobDetail和Trigger都有name和group。</p><p>name是它们在这个sheduler里面的唯一标识。如果我们要更新一个JobDetail定义，只需要设置一个name相同的JobDetail实例即可。</p><p>group是一个组织单元，sheduler会提供一些对整组操作的API，比如 scheduler.resumeJobs()。</p><h3 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a>Trigger</h3><h4 id="StartTime-amp-EndTime"><a href="#StartTime-amp-EndTime" class="headerlink" title="StartTime &amp; EndTime"></a>StartTime &amp; EndTime</h4><p>startTime和endTime指定的Trigger会被触发的时间区间。在这个区间之外，Trigger是不会被触发的。</p><p>** 所有Trigger都会包含这两个属性 **</p><h4 id="优先级（Priority）"><a href="#优先级（Priority）" class="headerlink" title="优先级（Priority）"></a>优先级（Priority）</h4><p>当scheduler比较繁忙的时候，可能在同一个时刻，有多个Trigger被触发了，但资源不足（比如线程池不足）。那么这个时候比剪刀石头布更好的方式，就是设置优先级。优先级高的先执行。</p><p>需要注意的是，优先级只有在同一时刻执行的Trigger之间才会起作用，如果一个Trigger是9:00，另一个Trigger是9:30。那么无论后一个优先级多高，前一个都是先执行。</p><p>优先级的值默认是5，当为负数时使用默认值。最大值似乎没有指定，但建议遵循Java的标准，使用1-10，不然鬼才知道看到【优先级为10】是时，上头还有没有更大的值。</p><h4 id="Misfire-错失触发）策略"><a href="#Misfire-错失触发）策略" class="headerlink" title="Misfire(错失触发）策略"></a>Misfire(错失触发）策略</h4><p>类似的Scheduler资源不足的时候，或者机器崩溃重启等，有可能某一些Trigger在应该触发的时间点没有被触发，也就是Miss Fire了。这个时候Trigger需要一个策略来处理这种情况。每种Trigger可选的策略各不相同。</p><p>这里有两个点需要重点注意：</p><ul><li>MisFire的触发是有一个阀值，这个阀值是配置在JobStore的。比RAMJobStore是org.quartz.jobStore.misfireThreshold。只有超过这个阀值，才会算MisFire。小于这个阀值，Quartz是会全部重新触发。</li></ul><p>所有MisFire的策略实际上都是解答两个问题：</p><ul><li>已经MisFire的任务还要重新触发吗？</li><li>如果发生MisFire，要调整现有的调度时间吗？</li></ul><details><summary>比如SimpleTrigger的MisFire策略有</summary><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>IGNORE<span class="emphasis">_MISFIRE_</span>POLICY</span><br><span class="line"></span><br><span class="line"><span class="code">    这个不是忽略已经错失的触发的意思，而是说忽略MisFire策略。它会在资源合适的时候，重新触发所有的MisFire任务，并且不会影响现有的调度时间。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    比如，SimpleTrigger每15秒执行一次，而中间有5分钟时间它都MisFire了，一共错失了20个，5分钟后，假设资源充足了，并且任务允许并发，它会被一次性触发。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    这个属性是所有Trigger都适用。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>FIRE<span class="emphasis">_NOW</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  忽略已经MisFire的任务，并且立即执行调度。这通常只适用于只执行一次的任务。</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">* MISFIRE_</span>INSTRUCTION<span class="emphasis">_RESCHEDULE_</span>NOW<span class="emphasis">_WITH_</span>EXISTING<span class="emphasis">_REPEAT_</span>COUNT</span><br><span class="line"></span><br><span class="line">  将startTime设置当前时间，立即重新调度任务，包括的MisFire的</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NOW_</span>WITH<span class="emphasis">_REMAINING_</span>REPEAT<span class="emphasis">_COUNT</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  类似MISFIRE_</span>INSTRUCTION<span class="emphasis">_RESCHEDULE_</span>NOW<span class="emphasis">_WITH_</span>EXISTING<span class="emphasis">_REPEAT_</span>COUNT，区别在于会忽略已经MisFire的任务</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_EXISTING_</span>COUNT</span><br><span class="line"></span><br><span class="line">  在下一次调度时间点，重新开始调度任务，包括的MisFire的</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_REMAINING_</span>COUNT</span><br><span class="line"></span><br><span class="line">  类似于MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_EXISTING_</span>COUNT，区别在于会忽略已经MisFire的任务。</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> MISFIRE<span class="emphasis">_INSTRUCTION_</span>SMART<span class="emphasis">_POLICY</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  所有的Trigger的MisFire默认值都是这个，大致意思是“把处理逻辑交给聪明的Quartz去决定”。基本策略是，</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  * 如果是只执行一次的调度，使用MISFIRE_</span>INSTRUCTION<span class="emphasis">_FIRE_</span>NOW</span><br><span class="line"><span class="bullet">  *</span> 如果是无限次的调度(repeatCount是无限的)，使用MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NEXT_</span>WITH<span class="emphasis">_REMAINING_</span>COUNT</span><br><span class="line"><span class="bullet">  *</span> 否则，使用MISFIRE<span class="emphasis">_INSTRUCTION_</span>RESCHEDULE<span class="emphasis">_NOW_</span>WITH<span class="emphasis">_EXISTING_</span>REPEAT<span class="emphasis">_COUNT</span></span><br></pre></td></tr></table></figure></details><h4 id="Calendar"><a href="#Calendar" class="headerlink" title="Calendar"></a>Calendar</h4><p>这里的Calendar不是jdk的java.util.Calendar，不是为了计算日期的。它的作用是在于补充Trigger的时间。可以排除或加入某一些特定的时间点。</p><p>以”每月25日零点自动还卡债“为例，我们想排除掉每年的2月25号零点这个时间点（因为有2.14，所以2月一定会破产）。这个时间，就可以用Calendar来实现。</p><details><summary>例子</summary><pre><code>AnnualCalendar cal = new AnnualCalendar(); //定义一个每年执行Calendar，精度为天，即不能定义到2.25号下午2:00java.util.Calendar excludeDay = new GregorianCalendar();excludeDay.setTime(newDate().inMonthOnDay(2, 25).build());cal.setDayExcluded(excludeDay, true);  //设置排除2.25这个日期scheduler.addCalendar("FebCal", cal, false, false); //scheduler加入这个Calendar//定义一个TriggerTrigger trigger = newTrigger().withIdentity("trigger1", "group1").startNow()//一旦加入scheduler，立即生效.modifiedByCalendar("FebCal") //使用Calendar !!.withSchedule(simpleSchedule().withIntervalInSeconds(1).repeatForever()).build();</code></pre></details><p>Quartz体贴地为我们提供以下几种Calendar，注意，所有的Calendar既可以是排除，也可以是包含，取决于：</p><ul><li>HolidayCalendar。指定特定的日期，比如20140613。精度到天。</li><li>DailyCalendar。指定每天的时间段（rangeStartingTime, rangeEndingTime)，格式是HH:MM[:SS[:mmm]]。也就是最大精度可以到毫秒。</li><li>WeeklyCalendar。指定每星期的星期几，可选值比如为java.util.Calendar.SUNDAY。精度是天。</li><li>MonthlyCalendar。指定每月的几号。可选值为1-31。精度是天</li><li>AnnualCalendar。 指定每年的哪一天。使用方式如上例。精度是天。</li><li>CronCalendar。指定Cron表达式。精度取决于Cron表达式，也就是最大精度可以到秒。</li></ul><h4 id="其他属性"><a href="#其他属性" class="headerlink" title="其他属性"></a>其他属性</h4><ul><li><p>Durability(耐久性？)</p><p>如果一个任务不是durable，那么当没有Trigger关联它的时候，它就会被自动删除。</p></li><li><p>RequestsRecovery</p><p>如果一个任务是”requests recovery”，那么当任务运行过程非正常退出时（比如进程崩溃，机器断电，但不包括抛出异常这种情况），Quartz再次启动时，会重新运行一次这个任务实例。</p><p>可以通过JobExecutionContext.isRecovering()查询任务是否是被恢复的。</p></li></ul><h4 id="Trigger实现类"><a href="#Trigger实现类" class="headerlink" title="Trigger实现类"></a>Trigger实现类</h4><h5 id="SimpleTrigger"><a href="#SimpleTrigger" class="headerlink" title="SimpleTrigger"></a>SimpleTrigger</h5><p>指定从某一个时间开始，以一定的时间间隔（单位是毫秒）执行的任务。</p><p>它适合的任务类似于：9:00 开始，每隔1小时，执行一次。</p><p>它的属性有：</p><ul><li>repeatInterval 重复间隔</li><li>repeatCount 重复次数。实际执行次数是 repeatCount+1。因为在startTime的时候一定会执行一次。<strong>下面有关repeatCount 属性的都是同理</strong></li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">simpleSchedule()</span><br><span class="line">        .withIntervalInHours(1) //每小时执行一次</span><br><span class="line">        .repeatForever() //次数不限</span><br><span class="line">        .build();</span><br><span class="line"></span><br><span class="line">simpleSchedule()</span><br><span class="line">    .withIntervalInMinutes(1) //每分钟执行一次</span><br><span class="line">    .withRepeatCount(10) //次数为10次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="CalendarIntervalTrigger"><a href="#CalendarIntervalTrigger" class="headerlink" title="CalendarIntervalTrigger"></a>CalendarIntervalTrigger</h5><p>类似于SimpleTrigger，指定从某一个时间开始，以一定的时间间隔执行的任务。<br>但是不同的是SimpleTrigger指定的时间间隔为毫秒，没办法指定每隔一个月执行一次（每月的时间间隔不是固定值），而CalendarIntervalTrigger支持的间隔单位有秒，分钟，小时，天，月，年，星期。</p><p>相较于SimpleTrigger有两个优势：1、更方便，比如每隔1小时执行，你不用自己去计算1小时等于多少毫秒。 2、支持不是固定长度的间隔，比如间隔为月和年。但劣势是精度只能到秒。</p><p>它适合的任务类似于：9:00 开始执行，并且以后每周 9:00 执行一次</p><p>它的属性有:</p><ul><li>interval 执行间隔</li><li>intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）</li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">calendarIntervalSchedule()</span><br><span class="line">    .withIntervalInDays(1) //每天执行一次</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">calendarIntervalSchedule()</span><br><span class="line">    .withIntervalInWeeks(1) //每周执行一次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="DailyTimeIntervalTrigger"><a href="#DailyTimeIntervalTrigger" class="headerlink" title="DailyTimeIntervalTrigger"></a>DailyTimeIntervalTrigger</h5><p>指定每天的某个时间段内，以一定的时间间隔执行任务。并且它可以支持指定星期。</p><p>它适合的任务类似于：指定每天9:00 至 18:00 ，每隔70秒执行一次，并且只要周一至周五执行。</p><p>它的属性有:</p><ul><li>startTimeOfDay 每天开始时间</li><li>endTimeOfDay 每天结束时间</li><li>daysOfWeek 需要执行的星期</li><li>interval 执行间隔</li><li>intervalUnit 执行间隔的单位（秒，分钟，小时，天，月，年，星期）</li><li>repeatCount 重复次数</li></ul><details><summary>例子</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dailyTimeIntervalSchedule()</span><br><span class="line">    .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始</span><br><span class="line">    .endingDailyAt(TimeOfDay.hourAndMinuteOfDay(16, 0)) //16：00 结束 </span><br><span class="line">    .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行</span><br><span class="line">    .withIntervalInHours(1) //每间隔1小时执行一次</span><br><span class="line">    .withRepeatCount(100) //最多重复100次（实际执行100+1次）</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">dailyTimeIntervalSchedule()</span><br><span class="line">    .startingDailyAt(TimeOfDay.hourAndMinuteOfDay(9, 0)) //第天9：00开始</span><br><span class="line">    .endingDailyAfterCount(10) //每天执行10次，这个方法实际上根据 startTimeOfDay+interval*count 算出 endTimeOfDay</span><br><span class="line">    .onDaysOfTheWeek(MONDAY,TUESDAY,WEDNESDAY,THURSDAY,FRIDAY) //周一至周五执行</span><br><span class="line">    .withIntervalInHours(1) //每间隔1小时执行一次</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></details><h5 id="CronTrigger"><a href="#CronTrigger" class="headerlink" title="CronTrigger"></a>CronTrigger</h5><p>适合于更复杂的任务，它支持类型于Linux Cron的语法（并且更强大）。基本上它覆盖了以上三个Trigger的绝大部分能力（但不是全部）—— 当然，也更难理解。</p><p>它适合的任务类似于：每天0:00,9:00,18:00各执行一次。</p><p>它的属性只有:</p><p>Cron表达式。但这个表示式本身就够复杂了。</p><h3 id="JobDetail-amp-Job"><a href="#JobDetail-amp-Job" class="headerlink" title="JobDetail &amp; Job"></a>JobDetail &amp; Job</h3><p>JobDetail是任务的定义，而Job是任务的执行逻辑。在JobDetail里会引用一个Job Class定义。</p><details><summary>一个最简单的例子</summary><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JobTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> SchedulerException, IOException </span>&#123;</span><br><span class="line">           JobDetail job=newJob()</span><br><span class="line">               .ofType(DoNothingJob.class) <span class="comment">//引用Job Class</span></span><br><span class="line">               .withIdentity(<span class="string">&quot;job1&quot;</span>, <span class="string">&quot;group1&quot;</span>) <span class="comment">//设置name/group</span></span><br><span class="line">               .withDescription(<span class="string">&quot;this is a test job&quot;</span>) <span class="comment">//设置描述</span></span><br><span class="line">               .usingJobData(<span class="string">&quot;age&quot;</span>, <span class="number">18</span>) <span class="comment">//加入属性到ageJobDataMap</span></span><br><span class="line">               .build();</span><br><span class="line"></span><br><span class="line">           job.getJobDataMap().put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;quertz&quot;</span>); <span class="comment">//加入属性name到JobDataMap</span></span><br><span class="line"></span><br><span class="line">           <span class="comment">//定义一个每秒执行一次的SimpleTrigger</span></span><br><span class="line">           Trigger trigger=newTrigger()</span><br><span class="line">                   .startNow()</span><br><span class="line">                   .withIdentity(<span class="string">&quot;trigger1&quot;</span>)</span><br><span class="line">                   .withSchedule(simpleSchedule()</span><br><span class="line">                       .withIntervalInSeconds(<span class="number">1</span>)</span><br><span class="line">                       .repeatForever())</span><br><span class="line">                   .build();</span><br><span class="line"></span><br><span class="line">           Scheduler sche=StdSchedulerFactory.getDefaultScheduler();</span><br><span class="line">           sche.scheduleJob(job, trigger);</span><br><span class="line"></span><br><span class="line">           sche.start();</span><br><span class="line"></span><br><span class="line">           System.in.read();</span><br><span class="line"></span><br><span class="line">           sche.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DoNothingJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;do nothing&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></details><p>从上例我们可以看出，要定义一个任务，需要干几件事：</p><ul><li>创建一个org.quartz.Job的实现类，并实现实现自己的业务逻辑。比如上面的DoNothingJob。</li><li>定义一个JobDetail，引用这个实现类</li><li>加入scheduleJob</li></ul><p>Quartz调度一次任务，会干如下的事：</p><ul><li>JobClass jobClass=JobDetail.getJobClass()</li><li>Job jobInstance=jobClass.newInstance()。所以Job实现类，必须有一个public的无参构建方法。</li><li>jobInstance.execute(JobExecutionContext context)。JobExecutionContext是Job运行的上下文，可以获得Trigger、Scheduler、JobDetail的信息。</li></ul><p>也就是说，每次调度都会创建一个新的Job实例，这样的好处是有些任务并发执行的时候，不存在对临界资源的访问问题——当然，如果需要共享JobDataMap的时候，还是存在临界资源的并发访问的问题。</p><h4 id="JobDataMap"><a href="#JobDataMap" class="headerlink" title="JobDataMap"></a>JobDataMap</h4><p>每一个JobDetail都会有一个JobDataMap。JobDataMap本质就是一个Map的扩展类，只是提供了一些更便捷的方法，比如getString()之类的。</p><p>我们可以在定义JobDetail，加入属性值，方式有二：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">newJob().usingJobData(&quot;age&quot;, 18) //加入属性到ageJobDataMap</span><br><span class="line"></span><br><span class="line"> or</span><br><span class="line"></span><br><span class="line">job.getJobDataMap().put(&quot;name&quot;, &quot;quertz&quot;); //加入属性name到JobDataMap</span><br></pre></td></tr></table></figure><p>然后在Job中可以获取这个JobDataMap的值，方式同样有二：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloQuartz</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        JobDetail detail = context.getJobDetail();</span><br><span class="line">        JobDataMap map = detail.getJobDataMap(); <span class="comment">//方法一：获得JobDataMap</span></span><br><span class="line">        System.out.println(<span class="string">&quot;say hello to &quot;</span> + name + <span class="string">&quot;[&quot;</span> + map.getInt(<span class="string">&quot;age&quot;</span>) + <span class="string">&quot;]&quot;</span> + <span class="string">&quot; at &quot;</span></span><br><span class="line">                           + <span class="keyword">new</span> Date());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//方法二：属性的setter方法，会将JobDataMap的属性自动注入</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123; </span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于同一个JobDetail实例，执行的多个Job实例，是共享同样的JobDataMap，也就是说，如果你在任务里修改了里面的值，会对其他Job实例（并发的或者后续的）造成影响。</p><p>除了JobDetail，Trigger同样有一个JobDataMap，共享范围是所有使用这个Trigger的Job实例。</p><h4 id="Job并发"><a href="#Job并发" class="headerlink" title="Job并发"></a>Job并发</h4><p>Job是有可能并发执行的，比如一个任务要执行10秒中，而调度算法是每秒中触发1次，那么就有可能多个任务被并发执行。</p><p>有时候我们并不想任务并发执行，比如这个任务要去”获得数据库中所有未发送邮件的名单“，如果是并发执行，就需要一个数据库锁去避免一个数据被多次处理。这个时候一个@DisallowConcurrentExecution解决这个问题。</p><p>就是这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DoNothingJob</span> <span class="keyword">implements</span> <span class="title">Job</span> </span>&#123;</span><br><span class="line">    <span class="meta">@DisallowConcurrentExecution</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(JobExecutionContext context)</span> <span class="keyword">throws</span> JobExecutionException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;do nothing&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，@DisallowConcurrentExecution是对JobDetail实例生效，也就是如果你定义两个JobDetail，引用同一个Job类，是可以并发执行的。</p><h4 id="JobExecutionException"><a href="#JobExecutionException" class="headerlink" title="JobExecutionException"></a>JobExecutionException</h4><p>Job.execute()方法是不允许抛出除JobExecutionException之外的所有异常的（包括RuntimeException)，所以编码的时候，最好是try-catch住所有的Throwable，小心处理。</p><h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>Scheduler就是Quartz的大脑，所有任务都是由它来设施。</p><p>Schduelr包含一个两个重要组件: JobStore和ThreadPool。</p><p>JobStore是会来存储运行时信息的，包括Trigger,Schduler,JobDetail，业务锁等。它有多种实现RAMJob(内存实现)，JobStoreTX(JDBC，事务由Quartz管理），JobStoreCMT(JDBC，使用容器事务)，ClusteredJobStore(集群实现)、TerracottaJobStore(什么是Terractta)。</p><p>ThreadPool就是线程池，Quartz有自己的线程池实现。所有任务的都会由线程池执行。</p><h4 id="SchedulerFactory"><a href="#SchedulerFactory" class="headerlink" title="SchedulerFactory"></a>SchedulerFactory</h4><p>SchdulerFactory，顾名思义就是来用创建Schduler了，有两个实现：DirectSchedulerFactory和 StdSchdulerFactory。前者可以用来在代码里定制你自己的Schduler参数。后者是直接读取classpath下的quartz.properties（不存在就都使用默认值）配置来实例化Schduler。通常来讲，我们使用StdSchdulerFactory也就足够了。</p><p>SchdulerFactory本身是支持创建RMI stub的，可以用来管理远程的Scheduler，功能与本地一样，可以远程提交个Job什么的。</p><p>DirectSchedulerFactory的创建接口</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">     * Same as</span><br><span class="line">     * &#123;@link DirectSchedulerFactory#createScheduler(ThreadPool threadPool, JobStore jobStore)&#125;,</span><br><span class="line">     * with the addition of specifying the scheduler name and instance ID. This</span><br><span class="line">     * scheduler can only be retrieved via</span><br><span class="line">     * &#123;@link DirectSchedulerFactory#getScheduler(String)&#125;</span><br><span class="line">     *</span><br><span class="line">     * @param schedulerName</span><br><span class="line">     *          The name for the scheduler.</span><br><span class="line">     * @param schedulerInstanceId</span><br><span class="line">     *          The instance ID for the scheduler.</span><br><span class="line">     * @param threadPool</span><br><span class="line">     *          The thread pool for executing jobs</span><br><span class="line">     * @param jobStore</span><br><span class="line">     *          The type of job store</span><br><span class="line">     * @throws SchedulerException</span><br><span class="line">     *           if initialization failed</span><br><span class="line">     */</span><br><span class="line">    public void createScheduler(String schedulerName,</span><br><span class="line">            String schedulerInstanceId, ThreadPool threadPool, JobStore jobStore)</span><br><span class="line">        throws SchedulerException;</span><br></pre></td></tr></table></figure><p>StdSchdulerFactory的配置例子，更多配置，参考<a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/">Quartz配置指南</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">org.quartz.scheduler.instanceName = DefaultQuartzScheduler</span><br><span class="line">org.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool</span><br><span class="line">org.quartz.threadPool.threadCount = 10 </span><br><span class="line">org.quartz.threadPool.threadPriority = 5</span><br><span class="line">org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true</span><br><span class="line">org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore</span><br></pre></td></tr></table></figure><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>JobStore <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-09">介绍</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/">配置</a></li></ul></li><li>集群: <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-11">介绍</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/configuration/ConfigJDBCJobStoreClustering">配置</a></li></ul></li><li>RMI</li><li>监听器 <ul><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-07">TriggerListeners and JobListeners</a></li><li><a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-08">SchedulerListeners</a></li></ul></li><li>插件</li></ul><p>主要的资料来自<a href="http://quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/">官方文档</a>，这里有教程，例子，配置等，非常详细</p><h2 id="Quartz源码解析"><a href="#Quartz源码解析" class="headerlink" title="Quartz源码解析"></a>Quartz源码解析</h2><h3 id="Quartz启动流程"><a href="#Quartz启动流程" class="headerlink" title="Quartz启动流程"></a>Quartz启动流程</h3><p>当服务器启动时，Spring就加载相关的bean。<br>SchedulerFactoryBean实现了InitializingBean接口，因此在初始化bean的时候，会执行afterPropertiesSet方法，该方法将会调用SchedulerFactory(DirectSchedulerFactory 或者 StdSchedulerFactory，通常用StdSchedulerFactory)创建Scheduler。==<br>我们在SchedulerFactoryBean配置类中配了相关的配置及配置文件参数，所以会读取配置文件参数，初始化各个组件。  </p><p>关键组件如下：</p><ul><li><strong>ThreadPool</strong>：一般是使用SimpleThreadPool(线程数量固定的线程池),SimpleThreadPool创建了一定数量的WorkerThread实例来使得Job能够在线程中进行处理。WorkerThread是定义在SimpleThreadPool类中的内部类，它实质上就是一个线程。<br>在SimpleThreadPool中有三个list：workers-存放池中所有的线程引用，availWorkers-存放所有空闲的线程，busyWorkers-存放所有工作中的线程；配置如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool</span><br><span class="line">org.quartz.threadPool.threadCount=3</span><br><span class="line">org.quartz.threadPool.threadPriority=5</span><br></pre></td></tr></table></figure></li><li><strong>JobStore</strong>： 初始化定时任务的数据存储方式，分为两种：<ul><li>存储在内存的RAMJobStore<br>存取速度非常快，但是由于其在系统被停止后所有的数据都会丢失，所以在集群应用中，必须使用JobStoreSupport</li><li>存储在数据库的JobStoreSupport(包括JobStoreTX和JobStoreCMT两种实现，JobStoreCMT是依赖于容器来进行事务的管理，而JobStoreTX是自己管理事务） </li></ul></li><li><strong>QuartzSchedulerThread</strong>： 初始化调度线程，在初始化的时候paused=true,halted=false,虽然线程开始运行了，但是paused=true，线程会一直等待，直到start方法将paused置为false；SchedulerFactoryBean还实现了SmartLifeCycle接口，因此初始化完成后，会执行start()方法，该方法将主要会执行以下的几个动作：<ul><li>创建ClusterManager线程并启动线程:该线程用来进行集群故障检测和处理</li><li>创建MisfireHandler线程并启动线程:该线程用来进行misfire任务的处理</li><li>置QuartzSchedulerThread的paused=false，调度线程才真正开始调度</li></ul>整个启动流程图如下：<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img.png" alt="img.png"><br>流程图简要说明：<ol><li>先读取配置文件</li><li>初始化SchedulerFactoryBean</li><li>初始化SchedulerFactory</li><li>实例化执行线程池（TheadPool）</li><li>实例化数据存储</li><li>初始化QuartzScheduler(为Scheduler的简单实现，包括调度作业、注册JobListener实例等方法。)</li><li>new一个QuartzSchedulerThread调度线程（负责执行在QuartzScheduler中注册的触发触发器的线程。），并开始运行</li><li>调度开始，注册监听器，注册Job和Trigger</li><li>SchedulerFactoryBean初始化完成后执行start()方法</li><li>创建ClusterManager线程并启动线程</li><li>创建MisfireHandler线程并启动线程</li><li>置QuartzSchedulerThread的paused=false，调度线程真正开始调度，开始执行run方法</li></ol></li></ul><h3 id="Quartz-线程视图"><a href="#Quartz-线程视图" class="headerlink" title="Quartz 线程视图"></a>Quartz 线程视图</h3><p>在Quartz中，有两类线程，Scheduler调度线程和任务执行线程，其中任务执行线程通常使用一个线程池维护一组线程。<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_3.png" alt="img.png"></p><p>Scheduler调度线程主要有两个：执行常规调度的线程，和执行misfiredtrigger的线程。  </p><ul><li>常规调度线程轮询存储的所有trigger，如果有需要触发的trigger，即到达了下一次触发的时间，则从任务执行线程池获取一个空闲线程，执行与该trigger关联的任务。<br>— Misfire线程是扫描所有的trigger，查看是否有misfiredtrigger，如果有的话根据misfire的策略分别处理(fire now OR wait for the next fire)。</li></ul><h3 id="QuartzSchedulerThread逻辑具体介绍"><a href="#QuartzSchedulerThread逻辑具体介绍" class="headerlink" title="QuartzSchedulerThread逻辑具体介绍"></a>QuartzSchedulerThread逻辑具体介绍</h3><p>类中主要的方法就是run方法，下面主要对run方法进行介绍：</p><details><summary>源码解析</summary><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//只有当Quartzscheduler执行start方法时被调用</span><br><span class="line">void togglePause(boolean pause) &#123;</span><br><span class="line">    synchronized(this.sigLock) &#123;</span><br><span class="line">        this.paused = pause;</span><br><span class="line">        if (this.paused) &#123;</span><br><span class="line">          this.signalSchedulingChange(0L);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">          this.sigLock.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">public void run() &#123;</span><br><span class="line">    boolean lastAcquireFailed = false;</span><br><span class="line">    label214:</span><br><span class="line">    //此处判断调度器是否终止</span><br><span class="line">    while(!this.halted.get()) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            synchronized(this.sigLock) &#123;</span><br><span class="line">                //此处判断调度器是否终止或是否暂停，由于我们在初始化的时候</span><br><span class="line">                //将paused=true，那么调度线程此时不会真正开始执行只会在不断循环阻塞</span><br><span class="line">                //只有当Quartzscheduler执行start方法时调用togglePause开始将</span><br><span class="line">                //paused置为false,run方法开始真正运行</span><br><span class="line">                while(this.paused &amp;&amp; !this.halted.get()) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        this.sigLock.wait(1000L);</span><br><span class="line">                    &#125; catch (InterruptedException var23) &#123;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                if (this.halted.get()) &#123;</span><br><span class="line">                    break;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            //取出执行线程池中空闲的线程数量</span><br><span class="line">            int availThreadCount = this.qsRsrcs.getThreadPool().blockForAvailableThreads();</span><br><span class="line">            if (availThreadCount &gt; 0) &#123;</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">            //如果可用线程数量足够那么查看30秒内需要触发的触发器。如果没有的</span><br><span class="line">            //话那么就是30后再次扫描，其中方法中三个参数idleWaitTime为如果</span><br><span class="line">            //没有的再次扫描的时间，第二个为最多取几个，最后一个参数</span><br><span class="line">            //batchTimeWindow，这个参数默认是0，同样是一个时间范围，如果</span><br><span class="line">            //有两个任务只差一两秒，而执行线程数量满足及batchTimeWindow时间</span><br><span class="line">            //也满足的情况下就会两个都取出来</span><br><span class="line"></span><br><span class="line">            triggers = this.qsRsrcs.getJobStore().acquireNextTriggers(now + this.idleWaitTime, Math.min(availThreadCount, this.qsRsrcs.getMaxBatchSize()), this.qsRsrcs.getBatchTimeWindow());</span><br><span class="line">            ...</span><br><span class="line">            ...</span><br><span class="line">            //trigger列表是以下次执行时间排序查出来的</span><br><span class="line">            //在列表不为空的时候进行后续操作</span><br><span class="line">            if (triggers != null &amp;&amp; !triggers.isEmpty()) &#123;</span><br><span class="line">            now = System.currentTimeMillis();</span><br><span class="line">            //取出集合中最早执行的触发器</span><br><span class="line">            long triggerTime = ((OperableTrigger)triggers.get(0)).getNextFireTime().getTime();</span><br><span class="line">            //判断距离执行时间是否大于两毫秒</span><br><span class="line">            for(long timeUntilTrigger = triggerTime - now; timeUntilTrigger &gt; 2L; timeUntilTrigger = triggerTime - now) &#123;</span><br><span class="line">                synchronized(this.sigLock) &#123;</span><br><span class="line">                    if (this.halted.get()) &#123;</span><br><span class="line">                        break;</span><br><span class="line">                    &#125;</span><br><span class="line">                    //判断是否还有更早的trigger</span><br><span class="line">                    if (!this.isCandidateNewTimeEarlierWithinReason(triggerTime, false)) &#123;</span><br><span class="line">                    //没有的话进行简单的阻塞，到时候再执行</span><br><span class="line">                        try &#123;</span><br><span class="line">                            now = System.currentTimeMillis();</span><br><span class="line">                            timeUntilTrigger = triggerTime - now;</span><br><span class="line">                            if (timeUntilTrigger &gt;= 1L) &#123;</span><br><span class="line">                                this.sigLock.wait(timeUntilTrigger);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; catch (InterruptedException var22) &#123;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //开始根据需要执行的trigger从数据库中获取相应的JobDetail</span><br><span class="line">                 if (goAhead) &#123;</span><br><span class="line">                    try &#123;</span><br><span class="line">                        List&lt;TriggerFiredResult&gt; res = this.qsRsrcs.getJobStore().triggersFired(triggers);</span><br><span class="line">                        if (res != null) &#123;</span><br><span class="line">                            bndles = res;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; catch (SchedulerException var24) &#123;</span><br><span class="line">                        this.qs.notifySchedulerListenersError(&quot;An error occurred while firing triggers &#x27;&quot; + triggers + &quot;&#x27;&quot;, var24);</span><br><span class="line">                        int i = 0;</span><br><span class="line"></span><br><span class="line">                        while(true) &#123;</span><br><span class="line">                            if (i &gt;= triggers.size()) &#123;</span><br><span class="line">                                continue label214;</span><br><span class="line">                            &#125;</span><br><span class="line"></span><br><span class="line">                            this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                            ++i;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                //将查询到的结果封装成为 TriggerFiredResult</span><br><span class="line">                 for(int i = 0; i &lt; ((List)bndles).size(); ++i) &#123;</span><br><span class="line">                    TriggerFiredResult result = (TriggerFiredResult)((List)bndles).get(i);</span><br><span class="line">                    TriggerFiredBundle bndle = result.getTriggerFiredBundle();</span><br><span class="line">                    Exception exception = result.getException();</span><br><span class="line">                    if (exception instanceof RuntimeException) &#123;</span><br><span class="line">                        this.getLog().error(&quot;RuntimeException while firing trigger &quot; + triggers.get(i), exception);</span><br><span class="line">                        this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                    &#125; else if (bndle == null) &#123;</span><br><span class="line">                        this.qsRsrcs.getJobStore().releaseAcquiredTrigger((OperableTrigger)triggers.get(i));</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        JobRunShell shell = null;</span><br><span class="line"></span><br><span class="line">                        try &#123;</span><br><span class="line">                        //把任务封装成JobRunShell线程任务，然后放到线程池中跑动。</span><br><span class="line">                            shell = this.qsRsrcs.getJobRunShellFactory().createJobRunShell(bndle);</span><br><span class="line">                            shell.initialize(this.qs);</span><br><span class="line">                        &#125; catch (SchedulerException var27) &#123;</span><br><span class="line">                            this.qsRsrcs.getJobStore().triggeredJobComplete((OperableTrigger)triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR);</span><br><span class="line">                            continue;</span><br><span class="line">                        &#125;</span><br><span class="line">                        //runInThread方法加Job放入对应的工作线程进行执行Job</span><br><span class="line">                        if (!this.qsRsrcs.getThreadPool().runInThread(shell)) &#123;</span><br><span class="line">                            this.getLog().error(&quot;ThreadPool.runInThread() return false!&quot;);</span><br><span class="line">                            this.qsRsrcs.getJobStore().triggeredJobComplete((OperableTrigger)triggers.get(i), bndle.getJobDetail(), CompletedExecutionInstruction.SET_ALL_JOB_TRIGGERS_ERROR);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure></details><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_1.png" alt="img_1.png"></p><p>总结下来:</p><ol><li>先获取线程池中的可用线程数量（若没有可用的会阻塞，直到有可用的）；</li><li>获取30m内要执行的trigger(即acquireNextTriggers)获取trigger的锁，通过select …for update方式实现；获取30m内（可配置）要执行的triggers（需要保证集群节点的时间一致），若@ConcurrentExectionDisallowed且列表存在该条trigger则跳过，否则更新trigger状态为ACQUIRED(刚开始为WAITING)；插入firedTrigger表，状态为ACQUIRED;（注意：在RAMJobStore中，有个timeTriggers，排序方式是按触发时间nextFireTime排的；JobStoreSupport从数据库取出triggers时是按照nextFireTime排序）;</li><li>待直到获取的trigger中最先执行的trigger在2ms内；</li><li>triggersFired：<ol><li>更新firedTrigger的status=EXECUTING;</li><li>更新trigger下一次触发的时间; </li><li>更新trigger的状态：无状态的trigger-&gt;WAITING，有状态的trigger-&gt;BLOCKED，若nextFireTime==null -&gt;COMPLETE；</li><li>commit connection,释放锁；</li></ol></li><li>针对每个要执行的trigger，创建JobRunShell，并放入线程池执行：<ol><li>execute:执行job</li><li>获取TRIGGER_ACCESS锁</li><li>若是有状态的job：更新trigger状态：BLOCKED-&gt;WAITING,PAUSED_BLOCKED-&gt;BLOCKED</li><li>若@PersistJobDataAfterExecution，则updateJobData</li><li>删除firedTrigger</li><li>commit connection，释放锁</li></ol></li></ol><h3 id="misfireHandler线程"><a href="#misfireHandler线程" class="headerlink" title="misfireHandler线程"></a>misfireHandler线程</h3><p>下面这些原因可能造成 misfired job:</p><ol><li>系统因为某些原因被重启。在系统关闭到重新启动之间的一段时间里，可能有些任务会被 misfire；</li><li>Trigger 被暂停（suspend）的一段时间里，有些任务可能会被 misfire；</li><li>线程池中所有线程都被占用，导致任务无法被触发执行，造成 misfire；</li><li>有状态任务在下次触发时间到达时，上次执行还没有结束；为了处理 misfired job，Quartz 中为 trigger定义了处理策略，主要有下面两种：MISFIRE_INSTRUCTION_FIRE_ONCE_NOW：针对 misfired job马上执行一次；MISFIRE_INSTRUCTION_DO_NOTHING：忽略 misfired job，等待下次触发；默认是MISFIRE_INSTRUCTION_SMART_POLICY，该策略在CronTrigger中=MISFIRE_INSTRUCTION_FIRE_ONCE_NOW线程默认1分钟执行一次；在一个事务中，默认一次最多recovery 20个；</li></ol><p>执行流程：<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Quartz%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%E5%8F%8A%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/img_2.png" alt="img_2.png"></p><ol><li>若配置(默认为true，可配置)成获取锁前先检查是否有需要recovery的trigger，先获取misfireCount；</li><li>获取TRIGGER_ACCESS锁；</li><li>hasMisfiredTriggersInState：获取misfired的trigger，默认一个事务里只能最大20个misfired trigger（可配置），misfired判断依据：status=waiting,next_fire_time &lt; current_time-misfirethreshold(可配置，默认1min)</li><li>notifyTriggerListenersMisfired</li><li>updateAfterMisfire:获取misfire策略(默认是MISFIRE_INSTRUCTION_SMART_POLICY，该策略在CronTrigger中=MISFIRE_INSTRUCTION_FIRE_ONCE_NOW)，根据策略更新nextFireTime；</li><li>将nextFireTime等更新到trigger表；</li><li>commit connection，释放锁8.如果还有更多的misfired，sleep短暂时间(为了集群负载均衡)，否则sleep misfirethreshold时间，后继续轮询；</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Quartz可以用来做什么？&quot;&gt;&lt;a href=&quot;#Quartz可以用来做什么？&quot; class=&quot;headerlink&quot; title=&quot;Quartz可以用来做什么？&quot;&gt;&lt;/a&gt;Quartz可以用来做什么？&lt;/h2&gt;&lt;p&gt;在某一个有规律的时间点干某件事。&lt;br&gt;并且</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
    <category term="Quartz" scheme="http://example.com/tags/Quartz/"/>
    
  </entry>
  
  <entry>
    <title>定时调度系列之单机定时调度Linux定时任务cron</title>
    <link href="http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/"/>
    <id>http://example.com/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/</id>
    <published>2021-07-14T01:07:05.000Z</published>
    <updated>2021-07-14T08:49:21.105Z</updated>
    
    <content type="html"><![CDATA[<p>实现linux定时任务有：cron、anacron、at,使用最多的是cron任务</p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul><li>cron–服务名；</li><li>crond–linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似；</li><li>crontab–是定制好的计划任务表，一个设置cron的工具</li></ul><h2 id="软件包安装"><a href="#软件包安装" class="headerlink" title="软件包安装"></a>软件包安装</h2><p>要使用cron服务，先要安装vixie-cron软件包和crontabs软件包，两个软件包作用如下：</p><ul><li>vixie-cron软件包是cron的主程序。<ul><li>查看是否安装了cron软件包: rpm -qa|grep vixie-cron</li></ul></li><li>crontabs软件包是用来安装、卸装、或列举用来驱动 cron 守护进程的表格的程序。<ul><li>查看是否安装了crontabs软件包:rpm -qa|grep crontabs</li></ul></li></ul><p>如果没有安装，则执行如下命令安装软件包(软件包必须存在)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh vixie-cron-4.1-54.FC5*</span><br><span class="line">rpm -ivh crontabs*</span><br></pre></td></tr></table></figure><p>如果本地没有安装包，在能够连网的情况下可以在线安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install vixie-cron</span><br><span class="line">yum install crontabs</span><br></pre></td></tr></table></figure><h3 id="查看crond服务是否运行"><a href="#查看crond服务是否运行" class="headerlink" title="查看crond服务是否运行"></a>查看crond服务是否运行</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pgrep crond 或 </span><br><span class="line">/sbin/service crond status 或 </span><br><span class="line">ps -elf|grep crond|grep -v &quot;grep&quot;</span><br></pre></td></tr></table></figure><h3 id="crond服务操作命令"><a href="#crond服务操作命令" class="headerlink" title="crond服务操作命令"></a>crond服务操作命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/sbin/service crond start //启动服务  </span><br><span class="line">/sbin/service crond stop //关闭服务  </span><br><span class="line">/sbin/service crond restart //重启服务  </span><br><span class="line">/sbin/service crond reload //重新载入配置</span><br></pre></td></tr></table></figure><h2 id="配置定时任务"><a href="#配置定时任务" class="headerlink" title="配置定时任务"></a>配置定时任务</h2><p>cron有两个配置文件，一个是一个全局配置文件（/etc/crontab），是针对系统任务的；一组是crontab命令生成的配置文件（/var/spool/cron下的文件），是针对某个用户的.定时任务配置到任意一个中都可以。</p><p>查看全局配置文件配置情况: <code>cat /etc/crontab</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">　---------------------------------------------</span><br><span class="line">　　SHELL=/bin/bash</span><br><span class="line">　　PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">　　MAILTO=root</span><br><span class="line">　　HOME=/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">　　#</span><span class="bash"> run-parts</span></span><br><span class="line">　　01 * * * * root run-parts /etc/cron.hourly</span><br><span class="line">　　02 4 * * * root run-parts /etc/cron.daily</span><br><span class="line">　　22 4 * * 0 root run-parts /etc/cron.weekly</span><br><span class="line">　　42 4 1 * * root run-parts /etc/cron.monthly</span><br><span class="line">　　----------------------------------------------</span><br></pre></td></tr></table></figure><p>查看用户下的定时任务:crontab -l或cat /var/spool/cron/用户名</p><h3 id="crontab任务配置基本格式"><a href="#crontab任务配置基本格式" class="headerlink" title="crontab任务配置基本格式"></a>crontab任务配置基本格式</h3><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img.png" alt="img.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-----------------------------------------------------------------------</span><br><span class="line">*   *　 *　 *　 *　　command</span><br><span class="line">分钟(0-59)　小时(0-23)　日期(1-31)　月份(1-12)　星期(0-6,0代表星期天)　 命令</span><br><span class="line">第1列表示分钟1～59 每分钟用*或者 */1表示</span><br><span class="line">第2列表示小时1～23（0表示0点）</span><br><span class="line">第3列表示日期1～31</span><br><span class="line">第4列表示月份1～12</span><br><span class="line">第5列标识号星期0～6（0表示星期天）</span><br><span class="line">第6列要运行的命令</span><br><span class="line"></span><br><span class="line">-----------------------------------------------------------------------</span><br><span class="line">在以上任何值中，星号（*）可以用来代表所有有效的值。譬如，月份值中的星号意味着在满足其它制约条件后每月都执行该命令。</span><br><span class="line">整数间的短线（-）指定一个整数范围。譬如，1-4 意味着整数 1、2、3、4。</span><br><span class="line">用逗号（,）隔开的一系列值指定一个列表。譬如，3, 4, 6, 8 标明这四个指定的整数。</span><br><span class="line">正斜线（/）可以用来指定间隔频率。在范围后加上 /&lt;integer&gt; 意味着在范围内可以跳过 integer。譬如，0-59/2 可以用来在分钟字段定义每两分钟。间隔频率值还可以和星号一起使用。例如，*/3 的值可以用在月份字段中表示每三个月运行一次任务。</span><br><span class="line">开头为井号（#）的行是注释，不会被处理</span><br><span class="line">-----------------------------------------------------------------------</span><br></pre></td></tr></table></figure><details><summary>使用实例</summary><pre><code>实例1：每1分钟执行一次command命令：* * * * * command<p>实例2：每小时的第3和第15分钟执行<br>命令：3,15 * * * * command</p><p>实例3：在上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 * * * command</p><p>实例4：每隔两天的上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 */2 * * command</p><p>实例5：每个星期一的上午8点到11点的第3和第15分钟执行<br>命令：3,15 8-11 * * 1 command</p><p>实例6：每晚的21:30重启smb<br>命令：30 21 * * * /etc/init.d/smb restart</p><p>实例7：每月1、10、22日的4 : 45重启smb<br>命令：45 4 1,10,22 * * /etc/init.d/smb restart</p><p>实例8：每周六、周日的1 : 10重启smb<br>命令：10 1 * * 6,0 /etc/init.d/smb restart</p><p>实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb<br>命令：0,30 18-23 * * * /etc/init.d/smb restart</p><p>实例10：每星期六的晚上11 : 00 pm重启smb<br>命令：0 23 * * 6 /etc/init.d/smb restart</p><p>实例11：每一小时重启smb<br>命令：* */1 * * * /etc/init.d/smb restart</p><p>实例12：晚上11点到早上7点之间，每隔一小时重启smb<br>命令：* 23-7/1 * * * /etc/init.d/smb restart</p><p>实例13：每月的4号与每周一到周三的11点重启smb<br>命令：0 11 4 * mon-wed /etc/init.d/smb restart</p><p>实例14：一月一号的4点重启smb<br>命令：0 4 1 jan * /etc/init.d/smb restart</p><p>实例15：每小时执行/etc/cron.hourly目录内的脚本<br>命令：01   *   *   *   *     root run-parts /etc/cron.hourly<br>说明：<br>run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了</p></code></pre><p></p></details><h2 id="cron实现原理"><a href="#cron实现原理" class="headerlink" title="cron实现原理"></a>cron实现原理</h2><h3 id="基本原理图解"><a href="#基本原理图解" class="headerlink" title="基本原理图解"></a>基本原理图解</h3><p>fork 进程 + sleep 轮询<br><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img_1.png" alt="img_1.png"><br>Cron每分钟做一次检查，看看哪个命令可执行。</p><p>从上图可以看到，有4次fork，这4次fork分别是：</p><ul><li>第一个fork，让Cron自己成为Daemon进程，即成为守护进程；</li><li>第二个fork，当Cron检查到有命令需要执行时被创建，但注意它并不执行命令，执行命令由它的子进程来做；</li><li>第三个fork，有些版本调用的是vfork，但有些版本却是fork，它是负责执行Cron命令的进程，即会调用execle()的进程；</li><li>第四个fork不是必须的，只有为Cron命令配置了标准输入才会用：<br><code>*/1 * * * * /tmp/X/x%1234567890</code><br>像上面有个百分符“%”，后面跟一串，则会有第四个fork，它的作用是将“%”后面的内容作为标准输入传递给第三个fork出来的进程。</li></ul><p>注意fork出来的进程没有忽略(ignore)管道信号(SIGPIPE)，所以如果遇到SIGPIPE，则会导致进程无声无息的退出，比如标准输主输出重定向管道的读端被关闭了，写时就会触发SIGPIPE。</p><p>实践中，可能会遇到child_process()在做上述所说的第三个fork前因SIGPIPE信号退出，导致难以理解的问题。其中一个现象 是：Cron命令被执行了若干次，但之后再也不执行了，原因在于第二个fork出来的进程因SIGPIPE退出了，导致没有进行第三个fork，因此 Cron命令没有被调用(总是由execle()调用)。</p><p><img src="/2021/07/14/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8D%95%E6%9C%BA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6Linux%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1cron/img_2.png" alt="img_2.png"></p><h3 id="一个诡异的问题"><a href="#一个诡异的问题" class="headerlink" title="一个诡异的问题"></a>一个诡异的问题</h3><p>你有可能遇到这样的情况，假设在cron中有如下一条配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo hello &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>观察到它正常运行几次后，就不再运行了，或者一次也不能，但确认无其它问题，因此十分诡异。</p><p>这个问题的原因，有可能是因为有共享库Hook了cron，共享库代码触发了SIGPIPE，导致了第二个fork出的进程退出，没来得及执行vfork。</p><p>fork出来的子进程，没有对SIGPIPE进行任何处理，默认行为是悄悄退出进程。通过修改/etc/ld.so.preload，可以将共享库注入到非关联的进程中，可通过ldd观察到这种依赖，使用LD_PRELOAD也可以达到同样的效果。</p><h3 id="crontab编辑后cron异常"><a href="#crontab编辑后cron异常" class="headerlink" title="crontab编辑后cron异常"></a>crontab编辑后cron异常</h3><p>使用crontab编辑后，cron卡住不动(不是指进程卡住了，而是指命令没有被调用)，原因可能是因为“tcb table full”，最简单的办法是重启cron。</p><p>建议避免写下面这样的嵌套命令语句，它有可能导致cron不能正常工作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo &quot;`date +%H:%M:%S` hello&quot; &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>“echo”中嵌套了“date”，可以改成脚本调用，或者不嵌套命令，如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * echo &quot;hello&quot; &gt;&gt; /tmp/hello.txt</span><br></pre></td></tr></table></figure><p>一个现象是有一个cron子进程(如下述的14786)不退出了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ps -ef|grep cron</span></span><br><span class="line"></span><br><span class="line">root     10325     1  0 15:08 ?        00:00:00 /usr/sbin/cron</span><br><span class="line">root     14786 10325  0 15:13 ?        00:00:00 /usr/sbin/cron</span><br></pre></td></tr></table></figure><p>gdb看到的调用栈为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">0  0xffffe410 <span class="keyword">in</span> __kernel_vsyscall ()</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1  0xb7e88a63 <span class="keyword">in</span> __read_nocancel () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">2  0xb7e38e38 <span class="keyword">in</span> _IO_file_read_internal () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">3  0xb7e3a0bb <span class="keyword">in</span> _IO_new_file_underflow () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">4  0xb7e3a7fb <span class="keyword">in</span> _IO_default_uflow_internal () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">5  0xb7e3bb2d <span class="keyword">in</span> __uflow () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">6  0xb7e35b7b <span class="keyword">in</span> getc () from /lib/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">7  0x80005d73 <span class="keyword">in</span> ?? () from /usr/sbin/cron</span></span><br></pre></td></tr></table></figure><p>strace看到如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> strace -f -p 14786</span></span><br><span class="line"></span><br><span class="line">Process 14786 attached</span><br><span class="line">read(7,</span><br></pre></td></tr></table></figure><p>借助lsof可以看到：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cron    14786 root    7r  FIFO        0,6         117960708 pipe</span><br></pre></td></tr></table></figure><p>为一个管道，read()挂住的原因可能是因为管道另一端所在进程调用_exit()退出而不是调用exit()退出。</p><p>这个时候只有人工kill这个挂起的cron子进程。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;实现linux定时任务有：cron、anacron、at,使用最多的是cron任务&lt;/p&gt;
&lt;h2 id=&quot;名词解释&quot;&gt;&lt;a href=&quot;#名词解释&quot; class=&quot;headerlink&quot; title=&quot;名词解释&quot;&gt;&lt;/a&gt;名词解释&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;cron–服务</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="定时调度" scheme="http://example.com/tags/%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>JAVA线上故障排查全套路</title>
    <link href="http://example.com/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/"/>
    <id>http://example.com/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/</id>
    <published>2021-07-13T10:11:00.000Z</published>
    <updated>2021-07-14T09:01:26.746Z</updated>
    
    <content type="html"><![CDATA[<p>线上故障主要会包括cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。</p><p>同时例如jstack、jmap等工具也是不囿于一个方面的问题的，基本上出问题就是df、free、top 三连，然后依次jstack、jmap伺候，具体问题具体分析即可。</p><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><p>一般来讲我们首先会排查cpu方面的问题。cpu异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁gc以及上下文切换过多。而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用jstack来分析对应的堆栈情况。</p><h3 id="使用jstack分析cpu问题"><a href="#使用jstack分析cpu问题" class="headerlink" title="使用jstack分析cpu问题"></a>使用jstack分析cpu问题</h3><p>我们先用ps命令找到对应进程的pid(如果你有好几个目标进程，可以先用top看一下哪个占用比较高)。<br>接着用top -H -p pid来找到cpu使用率比较高的一些线程<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img.png" alt="img.png"><br>然后将占用最高的pid转换为16进制printf ‘%x\n’ pid得到nid<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_1.png" alt="img_1.png"><br>接着直接在jstack中找到相应的堆栈信息jstack pid |grep ‘nid’ -C5 –color<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_2.png" alt="img_2.png"><br>可以看到我们已经找到了nid为0x42的堆栈信息，接着只要仔细分析一番即可。</p><p>当然更常见的是我们对整个jstack文件进行分析，通常我们会比较关注WAITING和TIMED_WAITING的部分，BLOCKED就不用说了。我们可以使用命令cat jstack.log | grep “java.lang.Thread.State” | sort -nr | uniq -c来对jstack的状态有一个整体的把握，如果WAITING之类的特别多，那么多半是有问题啦。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_3.png" alt="img_3.png"></p><h3 id="频繁gc"><a href="#频繁gc" class="headerlink" title="频繁gc"></a>频繁gc</h3><p>当然我们还是会使用jstack来分析问题，但有时候我们可以先确定下gc是不是太频繁，使用<strong>jstat -gc pid 1000</strong>命令来对gc分代变化情况进行观察，</p><ul><li>1000表示采样间隔(ms)</li><li>S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU分别代表两个Survivor区、Eden区、老年代、元数据区的容量和使用量。</li><li>YGC/YGT、FGC/FGCT、GCT则代表YoungGc、FullGc的耗时和次数以及总耗时。</li></ul><p>如果看到gc比较频繁，再针对gc方面做进一步分析，具体可以参考一下gc章节的描述。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_4.png" alt="img_4.png"></p><h3 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>针对频繁上下文问题，我们可以使用vmstat命令来进行查看<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_5.png" alt="img_5.png"><br>cs(context switch)一列则代表了上下文切换的次数。<br>如果我们希望对特定的pid进行监控那么可以使用 pidstat -w pid命令，cswch和nvcswch表示自愿及非自愿切换。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_6.png" alt="img_6.png"></p><h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><p>磁盘问题和cpu一样是属于比较基础的。首先是磁盘空间方面，我们直接使用<strong>df -hl</strong>来查看文件系统状态<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_7.png" alt="img_7.png"><br>更多时候，磁盘问题还是性能上的问题。我们可以通过iostatiostat -d -k -x来进行分析<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_8.png" alt="img_8.png"><br>最后一列%util可以看到每块磁盘写入的程度，而rrqpm/s以及wrqm/s分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。</p><p>另外我们还需要知道是哪个进程在进行读写，一般来说开发自己心里有数，或者用iotop命令来进行定位文件读写的来源。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_9.png" alt="img_9.png"><br>不过这边拿到的是tid，我们要转换成pid，可以通过readlink来找到pidreadlink -f /proc/*/task/tid/../..。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_10.png" alt="img_10.png"><br>找到pid之后就可以看这个进程具体的读写情况cat /proc/pid/io<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_11.png" alt="img_11.png"><br>我们还可以通过lsof命令来确定具体的文件读写情况lsof -p pid<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_12.png" alt="img_12.png"></p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><p>内存问题排查起来相对比CPU麻烦一些，场景也比较多。主要包括OOM、GC问题和堆外内存。一般来讲，我们会先用free命令先来检查一发内存的各种情况。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_13.png" alt="img_13.png"></p><h3 id="堆内内存"><a href="#堆内内存" class="headerlink" title="堆内内存"></a>堆内内存</h3><p>内存问题大多还都是堆内内存问题。表象上主要分为OOM和StackOverflow。</p><h4 id="OOM"><a href="#OOM" class="headerlink" title="OOM"></a>OOM</h4><p><strong>Exception in thread “main” java.lang.OutOfMemoryError: unable to create new native thread</strong></p><p>这个意思是没有足够的内存空间给线程分配java栈，基本上还是线程池代码写的有问题，比如说忘记shutdown，所以说应该首先从代码层面来寻找问题，使用jstack或者jmap。如果一切都正常，JVM方面可以通过指定Xss来减少单个thread stack的大小。另外也可以在系统层面，可以通过修改/etc/security/limits.confnofile和nproc来增大os对线程的限制<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_14.png" alt="img_14.png"></p><p><strong>Exception in thread “main” java.lang.OutOfMemoryError: Java heap space</strong></p><p>这个意思是堆的内存占用已经达到-Xmx设置的最大值，应该是最常见的OOM错误了。解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过jstack和jmap去定位问题。如果说一切都正常，才需要通过调整Xmx的值来扩大内存。</p><p><strong>Caused by: java.lang.OutOfMemoryError: Meta space</strong></p><p>这个意思是元数据区的内存占用已经达到XX:MaxMetaspaceSize设置的最大值，排查思路和上面的一致，参数方面可以通过XX:MaxPermSize来进行调整(这里就不说1.8以前的永久代了)。</p><h4 id="Stack-Overflow"><a href="#Stack-Overflow" class="headerlink" title="Stack Overflow"></a>Stack Overflow</h4><p>栈内存溢出，这个大家见到也比较多。</p><p><strong>Exception in thread “main” java.lang.StackOverflowError</strong></p><p>表示线程栈需要的内存大于Xss值，同样也是先进行排查，参数方面通过Xss来调整，但调整的太大可能又会引起OOM。</p><h4 id="使用JMAP定位代码内存泄漏"><a href="#使用JMAP定位代码内存泄漏" class="headerlink" title="使用JMAP定位代码内存泄漏"></a>使用JMAP定位代码内存泄漏</h4><p>上述关于OOM和StackOverflow的代码排查方面，我们一般使用JMAPjmap -dump:format=b,file=filename pid来导出dump文件<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_15.png" alt="img_15.png"></p><p>通过mat(Eclipse Memory Analysis Tools)导入dump文件进行分析，内存泄漏问题一般我们直接选Leak Suspects即可，mat给出了内存泄漏的建议。另外也可以选择Top Consumers来查看最大对象报告。和线程相关的问题可以选择thread overview进行分析。除此之外就是选择Histogram类概览来自己慢慢分析，大家可以搜搜mat的相关教程。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_16.png" alt="img_16.png"></p><p>日常开发中，代码产生内存泄漏是比较常见的事，并且比较隐蔽，需要开发者更加关注细节。比如说每次请求都new对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发gc；ByteBuffer缓存分配不合理等都会造成代码OOM。</p><p>另一方面，我们可以在启动参数中指定-XX:+HeapDumpOnOutOfMemoryError来保存OOM时的dump文件。</p><h4 id="gc问题和线程"><a href="#gc问题和线程" class="headerlink" title="gc问题和线程"></a>gc问题和线程</h4><p>gc问题除了影响cpu也会影响内存，排查思路也是一致的。一般先使用jstat来查看分代变化情况，比如youngGC或者fullGC次数是不是太多呀；EU、OU等指标增长是不是异常呀等。</p><p>线程的话太多而且不被及时gc也会引发oom，大部分就是之前说的unable to create new native thread。除了jstack细细分析dump文件外，我们一般先会看下总体线程，通过pstreee -p pid |wc -l。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_17.png" alt="img_17.png"></p><p>或者直接通过查看/proc/pid/task的数量即为线程数量。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_18.png" alt="img_18.png"></p><h3 id="堆外内存"><a href="#堆外内存" class="headerlink" title="堆外内存"></a>堆外内存</h3><p>如果碰到堆外内存溢出，那可真是太不幸了。首先堆外内存溢出表现就是物理常驻内存增长快，报错的话视使用方式都不确定，如果由于使用Netty导致的，那错误日志里可能会出现OutOfDirectMemoryError错误，如果直接是DirectByteBuffer，那会报OutOfMemoryError: Direct buffer memory。</p><p>堆外内存溢出往往是和NIO的使用相关，一般我们先通过pmap来查看下进程占用的内存情况pmap -x pid | sort -rn -k3 | head -30，这段意思是查看对应pid倒序前30大的内存段。这边可以再一段时间后再跑一次命令看看内存增长情况，或者和正常机器比较可疑的内存段在哪里。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_19.png" alt="img_19.png"></p><p>我们如果确定有可疑的内存端，需要通过gdb来分析gdb –batch –pid {pid} -ex “dump memory filename.dump {内存起始地址} {内存起始地址+内存块大小}”</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_20.png" alt="img_20.png"></p><p>获取dump文件后可用heaxdump进行查看hexdump -C filename | less，不过大多数看到的都是二进制乱码。</p><p>NMT是Java7U40引入的HotSpot新特性，配合jcmd命令我们就可以看到具体内存组成了。需要在启动参数中加入 -XX:NativeMemoryTracking=summary 或者 -XX:NativeMemoryTracking=detail，会有略微性能损耗。</p><p>一般对于堆外内存缓慢增长直到爆炸的情况来说，可以先设一个基线jcmd pid VM.native_memory baseline。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_21.png" alt="img_21.png"></p><p>然后等放一段时间后再去看看内存增长的情况，通过jcmd pid VM.native_memory detail.diff(summary.diff)做一下summary或者detail级别的diff。</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_22.png" alt="img_22.png"><br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_23.png" alt="img_23.png"></p><p>可以看到jcmd分析出来的内存十分详细，包括堆内、线程以及gc(所以上述其他内存异常其实都可以用nmt来分析)，这边堆外内存我们重点关注Internal的内存增长，如果增长十分明显的话那就是有问题了。</p><p>detail级别的话还会有具体内存段的增长情况，如下图。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_24.png" alt="img_24.png"></p><p>此外在系统层面，我们还可以使用strace命令来监控内存分配 strace -f -e “brk,mmap,munmap” -p pid</p><p>这边内存分配信息主要包括了pid和内存地址。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_25.png" alt="img_25.png"><br>不过其实上面那些操作也很难定位到具体的问题点，关键还是要看错误日志栈，找到可疑的对象，搞清楚它的回收机制，然后去分析对应的对象。比如DirectByteBuffer分配内存的话，是需要full GC或者手动system.gc来进行回收的(所以最好不要使用-XX:+DisableExplicitGC)。那么其实我们可以跟踪一下DirectByteBuffer对象的内存情况，通过jmap -histo:live pid手动触发fullGC来看看堆外内存有没有被回收。如果被回收了，那么大概率是堆外内存本身分配的太小了，通过-XX:MaxDirectMemorySize进行调整。如果没有什么变化，那就要使用jmap去分析那些不能被gc的对象，以及和DirectByteBuffer之间的引用关系了。</p><h3 id="GC问题"><a href="#GC问题" class="headerlink" title="GC问题"></a>GC问题</h3><p>堆内内存泄漏总是和GC异常相伴。不过GC问题不只是和内存问题相关，还有可能引起CPU负载、网络问题等系列并发症，只是相对来说和内存联系紧密些，所以我们在此单独总结一下GC相关问题。</p><p>我们在cpu章介绍了使用jstat来获取当前GC分代变化信息。而更多时候，我们是通过GC日志来排查问题的，在启动参数中加上-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps来开启GC日志。</p><p>常见的Young GC、Full GC日志含义在此就不做赘述了。</p><p>针对gc日志，我们就能大致推断出youngGC与fullGC是否过于频繁或者耗时过长，从而对症下药。我们下面将对G1垃圾收集器来做分析，这边也建议大家使用G1-XX:+UseG1GC。</p><h4 id="youngGC过频繁"><a href="#youngGC过频繁" class="headerlink" title="youngGC过频繁"></a>youngGC过频繁</h4><p>youngGC频繁一般是短周期小对象较多，先考虑是不是Eden区/新生代设置的太小了，看能否通过调整-Xmn、-XX:SurvivorRatio等参数设置来解决问题。如果参数正常，但是young gc频率还是太高，就需要使用Jmap和MAT对dump文件进行进一步排查了</p><h4 id="youngGC耗时过长"><a href="#youngGC耗时过长" class="headerlink" title="youngGC耗时过长"></a>youngGC耗时过长</h4><p>耗时过长问题就要看GC日志里耗时耗在哪一块了。以G1日志为例，可以关注Root Scanning、Object Copy、Ref Proc等阶段。Ref Proc耗时长，就要注意引用相关的对象。Root Scanning耗时长，就要注意线程数、跨代引用。Object Copy则需要关注对象生存周期。而且耗时分析它需要横向比较，就是和其他项目或者正常时间段的耗时比较。比如说图中的Root Scanning和正常时间段比增长较多，那就是起的线程太多了。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_26.png" alt="img_26.png"></p><h4 id="触发fullGC"><a href="#触发fullGC" class="headerlink" title="触发fullGC"></a>触发fullGC</h4><p>G1中更多的还是mixedGC，但mixedGC可以和youngGC思路一样去排查。触发fullGC了一般都会有问题，G1会退化使用Serial收集器来完成垃圾的清理工作，暂停时长达到秒级别，可以说是半跪了。</p><p>fullGC的原因可能包括以下这些，以及参数调整方面的一些思路：</p><ul><li><p>并发阶段失败：在并发标记阶段，MixGC之前老年代就被填满了，那么这时候G1就会放弃标记周期。这种情况，可能就需要增加堆大小，或者调整并发标记线程数-XX:ConcGCThreads。</p></li><li><p>晋升失败：在GC的时候没有足够的内存供存活/晋升对象使用，所以触发了Full GC。这时候可以通过-XX:G1ReservePercent来增加预留内存百分比，减少-XX:InitiatingHeapOccupancyPercent来提前启动标记，-XX:ConcGCThreads来增加标记线程数也是可以的。</p></li><li><p>大对象分配失败：大对象找不到合适的region空间进行分配，就会进行fullGC，这种情况下可以增大内存或者增大-XX:G1HeapRegionSize。</p></li><li><p>程序主动执行System.gc()：不要随便写就对了。</p></li></ul><p>另外，我们可以在启动参数中配置-XX:HeapDumpPath=/xxx/dump.hprof来dump fullGC相关的文件，并通过jinfo来进行gc前后的dump</p><p>jinfo -flag +HeapDumpBeforeFullGC pid</p><p>jinfo -flag +HeapDumpAfterFullGC pid</p><p>这样得到2份dump文件，对比后主要关注被gc掉的问题对象来定位问题。</p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>涉及到网络层面的问题一般都比较复杂，场景多，定位难，成为了大多数开发的噩梦，应该是最复杂的了。这里会举一些例子，并从tcp层、应用层以及工具的使用等方面进行阐述。</p><h3 id="超时"><a href="#超时" class="headerlink" title="超时"></a>超时</h3><p>超时错误大部分处在应用层面，所以这块着重理解概念。超时大体可以分为连接超时和读写超时，某些使用连接池的客户端框架还会存在获取连接超时和空闲连接清理超时。</p><ul><li><p>读写超时。readTimeout/writeTimeout，有些框架叫做so_timeout或者socketTimeout，均指的是数据读写超时。注意这边的超时大部分是指逻辑上的超时。soa的超时指的也是读超时。读写超时一般都只针对客户端设置。</p></li><li><p>连接超时。connectionTimeout，客户端通常指与服务端建立连接的最大时间。服务端这边connectionTimeout就有些五花八门了，jetty中表示空闲连接清理时间，tomcat则表示连接维持的最大时间。</p></li><li><p>其他。包括连接获取超时connectionAcquireTimeout和空闲连接清理超时idleConnectionTimeout。多用于使用连接池或队列的客户端或服务端框架。</p></li></ul><p>我们在设置各种超时时间中，需要确认的是尽量保持客户端的超时小于服务端的超时，以保证连接正常结束。</p><p>在实际开发中，我们关心最多的应该是接口的读写超时了。</p><p>如何设置合理的接口超时是一个问题。如果接口超时设置的过长，那么有可能会过多地占用服务端的tcp连接。而如果接口设置的过短，那么接口超时就会非常频繁。</p><p>服务端接口明明rt降低，但客户端仍然一直超时又是另一个问题。这个问题其实很简单，客户端到服务端的链路包括网络传输、排队以及服务处理等，每一个环节都可能是耗时的原因。</p><h3 id="TCP队列溢出"><a href="#TCP队列溢出" class="headerlink" title="TCP队列溢出"></a>TCP队列溢出</h3><p>tcp队列溢出是个相对底层的错误，它可能会造成超时、rst等更表层的错误。因此错误也更隐蔽，所以我们单独说一说。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_27.png" alt="img_27.png"></p><p>如上图所示，这里有两个队列：syns queue(半连接队列）、accept queue（全连接队列）。三次握手，在server收到client的syn后，把消息放到syns queue，回复syn+ack给client，server收到client的ack，如果这时accept queue没满，那就从syns queue拿出暂存的信息放入accept queue中，否则按tcp_abort_on_overflow指示的执行。</p><p>tcp_abort_on_overflow 0表示如果三次握手第三步的时候accept queue满了那么server扔掉client发过来的ack。tcp_abort_on_overflow 1则表示第三步的时候如果全连接队列满了，server发送一个rst包给client，表示废掉这个握手过程和这个连接，意味着日志里可能会有很多connection reset / connection reset by peer。</p><p>那么在实际开发中，我们怎么能快速定位到tcp队列溢出呢？</p><p><strong>netstat命令，执行netstat -s | egrep “listen|LISTEN”</strong><br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_28.png" alt="img_28.png"><br>如上图所示，overflowed表示全连接队列溢出的次数，sockets dropped表示半连接队列溢出的次数。</p><p><strong>ss命令，执行ss -lnt=</strong><br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_29.png" alt="img_29.png"><br>上面看到Send-Q 表示第三列的listen端口上的全连接队列最大为5，第一列Recv-Q为全连接队列当前使用了多少。</p><p>接着我们看看怎么设置全连接、半连接队列大小吧：</p><p>全连接队列的大小取决于min(backlog, somaxconn)。backlog是在socket创建的时候传入的，somaxconn是一个os级别的系统参数。而半连接队列的大小取决于max(64, /proc/sys/net/ipv4/tcp_max_syn_backlog)。</p><p>在日常开发中，我们往往使用servlet容器作为服务端，所以我们有时候也需要关注容器的连接队列大小。在tomcat中backlog叫做acceptCount，在jetty里面则是acceptQueueSize。</p><h3 id="RST异常"><a href="#RST异常" class="headerlink" title="RST异常"></a>RST异常</h3><p>RST包表示连接重置，用于关闭一些无用的连接，通常表示异常关闭，区别于四次挥手。</p><p>在实际开发中，我们往往会看到connection reset / connection reset by peer错误，这种情况就是RST包导致的。</p><h3 id="端口不存在"><a href="#端口不存在" class="headerlink" title="端口不存在"></a>端口不存在</h3><p>如果像不存在的端口发出建立连接SYN请求，那么服务端发现自己并没有这个端口则会直接返回一个RST报文，用于中断连接。</p><h3 id="主动代替FIN终止连接"><a href="#主动代替FIN终止连接" class="headerlink" title="主动代替FIN终止连接"></a>主动代替FIN终止连接</h3><p>一般来说，正常的连接关闭都是需要通过FIN报文实现，然而我们也可以用RST报文来代替FIN，表示直接终止连接。实际开发中，可设置SO_LINGER数值来控制，这种往往是故意的，来跳过TIMED_WAIT，提供交互效率，不闲就慎用。</p><h3 id="客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接"><a href="#客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接" class="headerlink" title="客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接"></a>客户端或服务端有一边发生了异常，该方向对端发送RST以告知关闭连接</h3><p>我们上面讲的tcp队列溢出发送RST包其实也是属于这一种。这种往往是由于某些原因，一方无法再能正常处理请求连接了(比如程序崩了，队列满了)，从而告知另一方关闭连接。</p><p>接收到的TCP报文不在已知的TCP连接内</p><p>比如，一方机器由于网络实在太差TCP报文失踪了，另一方关闭了该连接，然后过了许久收到了之前失踪的TCP报文，但由于对应的TCP连接已不存在，那么会直接发一个RST包以便开启新的连接。</p><h3 id="一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文"><a href="#一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文" class="headerlink" title="一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文"></a>一方长期未收到另一方的确认报文，在一定时间或重传次数后发出RST报文</h3><p>这种大多也和网络环境相关了，网络环境差可能会导致更多的RST报文。</p><p>之前说过RST报文多会导致程序报错，在一个已关闭的连接上读操作会报connection reset，而在一个已关闭的连接上写操作则会报connection reset by peer。通常我们可能还会看到broken pipe错误，这是管道层面的错误，表示对已关闭的管道进行读写，往往是在收到RST，报出connection reset错后继续读写数据报的错，这个在glibc源码注释中也有介绍。</p><p>我们在排查故障时候怎么确定有RST包的存在呢？当然是使用tcpdump命令进行抓包，并使用wireshark进行简单分析了。tcpdump -i en0 tcp -w xxx.cap，en0表示监听的网卡。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_30.png" alt="img_30.png"></p><p>接下来我们通过wireshark打开抓到的包，可能就能看到如下图所示，红色的就表示RST包了。<br><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_31.png" alt="img_31.png"></p><h3 id="TIME-WAIT和CLOSE-WAIT"><a href="#TIME-WAIT和CLOSE-WAIT" class="headerlink" title="TIME_WAIT和CLOSE_WAIT"></a>TIME_WAIT和CLOSE_WAIT</h3><p>TIME_WAIT和CLOSE_WAIT是啥意思相信大家都知道。<br>在线上时，我们可以直接用命令netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’来查看time-wait和close_wait的数量</p><p>用ss命令会更快ss -ant | awk ‘{++S[$1]} END {for(a in S) print a, S[a]}’</p><p><img src="/2021/07/13/JAVA%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%85%A8%E5%A5%97%E8%B7%AF/img_32.png" alt="img_32.png"></p><h3 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT"></a>TIME_WAIT</h3><p>time_wait的存在一是为了丢失的数据包被后面连接复用，二是为了在2MSL的时间范围内正常关闭连接。它的存在其实会大大减少RST包的出现。</p><p>过多的time_wait在短连接频繁的场景比较容易出现。这种情况可以在服务端做一些内核参数调优:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br></pre></td></tr></table></figure><p>当然我们不要忘记在NAT环境下因为时间戳错乱导致数据包被拒绝的坑了，另外的办法就是改小tcp_max_tw_buckets，超过这个数的time_wait都会被干掉，不过这也会导致报time wait bucket table overflow的错。</p><h3 id="CLOSE-WAIT"><a href="#CLOSE-WAIT" class="headerlink" title="CLOSE_WAIT"></a>CLOSE_WAIT</h3><p>close_wait往往都是因为应用程序写的有问题，没有在ACK后再次发起FIN报文。close_wait出现的概率甚至比time_wait要更高，后果也更严重。往往是由于某个地方阻塞住了，没有正常关闭连接，从而渐渐地消耗完所有的线程。</p><p>想要定位这类问题，最好是通过jstack来分析线程堆栈来排查问题，具体可参考上述章节。这里仅举一个例子。</p><p>开发同学说应用上线后CLOSE_WAIT就一直增多，直到挂掉为止，jstack后找到比较可疑的堆栈是大部分线程都卡在了countdownlatch.await方法，找开发同学了解后得知使用了多线程但是确没有catch异常，修改后发现异常仅仅是最简单的升级sdk后常出现的class not found。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;线上故障主要会包括cpu、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。&lt;/p&gt;
&lt;p&gt;同时例如jstack、jmap等工具也是不囿于一个方面的问题的，基本上出问题就是df、free、top 三连，然后依次jst</summary>
      
    
    
    
    <category term="运维" scheme="http://example.com/categories/%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="线上问题" scheme="http://example.com/tags/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>代码规范之JAVA代码安全指南</title>
    <link href="http://example.com/2021/07/13/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/"/>
    <id>http://example.com/2021/07/13/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E4%B9%8BJAVA%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</id>
    <published>2021-07-13T09:37:37.000Z</published>
    <updated>2021-07-14T08:49:21.089Z</updated>
    
    <content type="html"><![CDATA[<h2 id="后台类"><a href="#后台类" class="headerlink" title="后台类"></a>后台类</h2><h3 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h3><h4 id="【必须】SQL语句默认使用预编译并绑定变量"><a href="#【必须】SQL语句默认使用预编译并绑定变量" class="headerlink" title="【必须】SQL语句默认使用预编译并绑定变量"></a>【必须】SQL语句默认使用预编译并绑定变量</h4><p>Web后台系统应默认使用预编译绑定变量的形式创建sql语句，保持查询语句和数据相分离。以从本质上避免SQL注入风险。</p><p>如使用Mybatis作为持久层框架，应通过#{}语法进行参数绑定，MyBatis 会创建 <code>PreparedStatement</code> 参数占位符，并通过占位符安全地设置参数。</p><p>示例：JDBC</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String custname=request.getParameter(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        String query=<span class="string">&quot;SELECT * FROM user_data WHERE user_name = ? &quot;</span>;</span><br><span class="line">        PreparedStatement pstmt=connection.prepareStatement(query);</span><br><span class="line">        pstmt.setString(<span class="number">1</span>,custname);</span><br><span class="line">        ResultSet results=pstmt.executeQuery();</span><br></pre></td></tr></table></figure><p>Mybatis</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;select id=<span class="string">&quot;queryRuleIdByApplicationId&quot;</span>parameterType=<span class="string">&quot;java.lang.String&quot;</span>resultType=<span class="string">&quot;java.lang.String&quot;</span>&gt;</span><br><span class="line">        select rule_id from scan_rule_sqlmap_tab where application_id=#&#123;applicationId&#125;</span><br><span class="line">&lt;/select&gt;</span><br></pre></td></tr></table></figure><p>应避免外部输入未经过滤直接拼接到SQL语句中，或者通过Mybatis中的${}传入SQL语句（即使使用PreparedStatement，SQL语句直接拼接外部输入也同样有风险。例如Mybatis中部分参数通过${}传入SQL语句后实际执行时调用的是PreparedStatement.execute()<br>，同样存在注入风险）。</p><h4 id="【必须】白名单过滤"><a href="#【必须】白名单过滤" class="headerlink" title="【必须】白名单过滤"></a>【必须】白名单过滤</h4><p>对于表名、列名等无法进行预编译的场景，比如外部数据拼接到order by, group<br>by语句中，需通过白名单的形式对数据进行校验，例如判断传入列名是否存在、升降序仅允许输入“ASC”和“DESC”、表名列名仅允许输入字符、数字、下划线等。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">someMethod</span><span class="params">(<span class="keyword">boolean</span> sortOrder)</span></span>&#123;</span><br><span class="line">        String SQLquery=<span class="string">&quot;some SQL ... order by Salary &quot;</span>+(sortOrder?<span class="string">&quot;ASC&quot;</span>:<span class="string">&quot;DESC&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><h4 id="【必须】文件类型限制"><a href="#【必须】文件类型限制" class="headerlink" title="【必须】文件类型限制"></a>【必须】文件类型限制</h4><p>须在服务器端采用白名单方式对上传或下载的文件类型、大小进行严格的限制。仅允许业务所需文件类型上传，避免上传.jsp、.jspx、.class、.java等可执行文件。参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">String file_name=file.getOriginalFilename();</span><br><span class="line">String[]parts=file_name.split(<span class="string">&quot;\\.&quot;</span>);</span><br><span class="line">String suffix=parts[parts.length-<span class="number">1</span>];</span><br><span class="line"><span class="keyword">switch</span>(suffix)&#123;</span><br><span class="line">    <span class="keyword">case</span><span class="string">&quot;jpeg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpeg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;jpg&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.jpg&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;bmp&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.bmp&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span><span class="string">&quot;png&quot;</span>:</span><br><span class="line">        suffix=<span class="string">&quot;.png&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">//handle error</span></span><br><span class="line">        <span class="keyword">return</span><span class="string">&quot;error&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】禁止外部文件存储于可执行目录"><a href="#【必须】禁止外部文件存储于可执行目录" class="headerlink" title="【必须】禁止外部文件存储于可执行目录"></a>【必须】禁止外部文件存储于可执行目录</h4><p>禁止外部文件存储于WEB容器的可执行目录（appBase）。建议保存在专门的文件服务器中。</p><h4 id="【建议】避免路径拼接"><a href="#【建议】避免路径拼接" class="headerlink" title="【建议】避免路径拼接"></a>【建议】避免路径拼接</h4><p>文件目录避免外部参数拼接。保存文件目录建议后台写死并对文件名进行校验（字符类型、长度）。建议文件保存时，将文件名替换为随机字符串。</p><h4 id="【必须】避免路径穿越"><a href="#【必须】避免路径穿越" class="headerlink" title="【必须】避免路径穿越"></a>【必须】避免路径穿越</h4><p>如因业务需要不能满足避免路径拼接，文件路径、文件命中拼接了不可行数据，需判断请求文件名和文件路径参数中是否存在../或..\(仅windows)， 如存在应判定路径非法并拒绝请求。</p><h3 id="网络访问"><a href="#网络访问" class="headerlink" title="网络访问"></a>网络访问</h3><h4 id="【必须】避免直接访问不可信地址"><a href="#【必须】避免直接访问不可信地址" class="headerlink" title="【必须】避免直接访问不可信地址"></a>【必须】避免直接访问不可信地址</h4><p>服务器访问不可信地址时，禁止访问私有地址段及内网域名。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 以RFC定义的专有网络为例，如有自定义私有网段亦应加入禁止访问列表。</span><br><span class="line">10.0.0.0/8</span><br><span class="line">172.16.0.0/12</span><br><span class="line">192.168.0.0/16</span><br><span class="line">127.0.0.0/8</span><br></pre></td></tr></table></figure><p>建议通过URL解析函数进行解析，获取host或者domain后通过DNS获取其IP，然后和内网地址进行比较。</p><p>对已校验通过地址进行访问时，应关闭跟进跳转功能。</p><p>参考示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">httpConnection=(HttpURLConnection)Url.openConnection();</span><br><span class="line">httpConnection.setFollowRedirects(<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="XML读写"><a href="#XML读写" class="headerlink" title="XML读写"></a>XML读写</h3><h4 id="【必须】XML解析器关闭DTD解析"><a href="#【必须】XML解析器关闭DTD解析" class="headerlink" title="【必须】XML解析器关闭DTD解析"></a>【必须】XML解析器关闭DTD解析</h4><p>读取外部传入XML文件时，XML解析器初始化过程中设置关闭DTD解析。</p><p>参考示例：</p><p>javax.xml.parsers.DocumentBuilderFactory</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">        dbf.setXIncludeAware(<span class="keyword">false</span>);</span><br><span class="line">        dbf.setExpandEntityReferences(<span class="keyword">false</span>);</span><br><span class="line">        ……</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>org.dom4j.io.SAXReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">saxReader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">saxReader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><p>org.jdom2.input.SAXBuilder</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SAXBuilder builder=<span class="keyword">new</span> SAXBuilder();</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">builder.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">Document doc=builder.build(<span class="keyword">new</span> File(fileName));</span><br></pre></td></tr></table></figure><p>org.xml.sax.XMLReader</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">XMLReader reader=XMLReaderFactory.createXMLReader();</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/disallow-doctype-decl&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://apache.org/xml/features/nonvalidating/load-external-dtd&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-general-entities&quot;</span>,<span class="keyword">false</span>);</span><br><span class="line">reader.setFeature(<span class="string">&quot;http://xml.org/sax/features/external-parameter-entities&quot;</span>,<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h3 id="响应输出"><a href="#响应输出" class="headerlink" title="响应输出"></a>响应输出</h3><h4 id="【必须】设置正确的HTTP响应包类型"><a href="#【必须】设置正确的HTTP响应包类型" class="headerlink" title="【必须】设置正确的HTTP响应包类型"></a>【必须】设置正确的HTTP响应包类型</h4><p>响应包的HTTP头“Content-Type”必须正确配置响应包的类型，禁止非HTML类型的响应包设置为“text/html”。此举会使浏览器在直接访问链接时，将非HTML格式的返回报文当做HTML解析，增加反射型XSS的触发几率。</p><h4 id="【建议】设置安全的HTTP响应头"><a href="#【建议】设置安全的HTTP响应头" class="headerlink" title="【建议】设置安全的HTTP响应头"></a>【建议】设置安全的HTTP响应头</h4><ul><li><p>X-Content-Type-Options：</p><p>建议添加“X-Content-Type-Options”响应头并将其值设置为“nosniff”，可避免部分浏览器根据其“Content-Sniff”特性，将一些非“text/html”类型的响应作为HTML解析，增加反射型XSS的触发几率。</p></li><li><p>HttpOnly：</p><p>控制用户登录鉴权的Cookie字段 应当设置HttpOnly属性以防止被XSS漏洞/JavaScript操纵泄漏。</p></li><li><p>X-Frame-Options：</p><p>设置X-Frame-Options响应头，并根据需求合理设置其允许范围。该头用于指示浏览器禁止当前页面在frame、iframe、embed等标签中展现。从而避免点击劫持问题。它有三个可选的值：<br>DENY： 浏览器会拒绝当前页面加载任何frame页面；<br>SAMEORIGIN：则frame页面的地址只能为同源域名下的页面<br>ALLOW-FROM origin：可以定义允许frame加载的页面地址。</p></li><li><p>Access-Control-Allow-Origin</p><p>当需要配置CORS跨域时，应对请求头的Origin值做严格过滤。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String currentOrigin = request.getHeader(<span class="string">&quot;Origin&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (currentOrigin.equals(<span class="string">&quot;https://domain.qq.com&quot;</span>)) &#123;</span><br><span class="line">       response.setHeader(<span class="string">&quot;Access-Control-Allow-Origin&quot;</span>, currentOrigin);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="【必须】外部输入拼接到response页面前进行编码处理"><a href="#【必须】外部输入拼接到response页面前进行编码处理" class="headerlink" title="【必须】外部输入拼接到response页面前进行编码处理"></a>【必须】外部输入拼接到response页面前进行编码处理</h4><p>当响应“content-type”为“html”类型时，外部输入拼接到响应包中，需根据输出位置进行编码处理。编码规则：</p><table><thead><tr><th>场景</th><th>编码规则</th></tr></thead><tbody><tr><td>输出点在HTML标签之间</td><td>需要对以下6个特殊字符进行HTML实体编码(&amp;, &lt;, &gt;, “, ‘,/)。<br>示例：<br>&amp; –&gt; &amp;amp;<br>&lt; –&gt; &amp;lt;<br>&gt;–&gt; &amp;gt;<br>“ –&gt; &amp;quot;<br>‘ –&gt; &amp;#x27;  <br>/ –&gt; &amp;#x2F;</td></tr><tr><td>输出点在HTML标签普通属性内（如href、src、style等，on事件除外）</td><td>要对数据进行HTML属性编码。<br>编码规则：除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为&#xHH;(以&amp;#x开头，HH则是指该字符对应的十六进制数字，分号作为结束符)</td></tr><tr><td>输出点在JS内的数据中</td><td>需要进行js编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \xHH （以 \x 开头，HH则是指该字符对应的十六进制数字）<br>Tips：这种场景仅限于外部数据拼接在js里被引号括起来的变量值中。除此之外禁止直接将代码拼接在js代码中。</td></tr><tr><td>输出点在CSS中（Style属性）</td><td>需要进行CSS编码<br>编码规则：<br>除了阿拉伯数字和字母，对其他所有的字符进行编码，只要该字符的ASCII码小于256。编码后输出的格式为 \HH （以 \ 开头，HH则是指该字符对应的十六进制数字）</td></tr><tr><td>输出点在URL属性中</td><td>对这些数据进行URL编码<br>Tips：除此之外，所有链接类属性应该校验其协议。禁止JavaScript、data和Vb伪协议。</td></tr></tbody></table><p>以上编码规则相对较为繁琐，可参考或直接使用业界已有成熟第三方库如ESAPI.其提供以下函数对象上表中的编码规则:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ESAPI.encoder().encodeForHTML();</span><br><span class="line">        ESAPI.encoder().encodeForHTMLAttribute();</span><br><span class="line">        ESAPI.encoder().encodeForJavaScript();</span><br><span class="line">        ESAPI.encoder().encodeForCSS();</span><br><span class="line">        ESAPI.encoder().encodeForURL();</span><br></pre></td></tr></table></figure><h4 id="【必须】外部输入拼接到HTTP响应头中需进行过滤"><a href="#【必须】外部输入拼接到HTTP响应头中需进行过滤" class="headerlink" title="【必须】外部输入拼接到HTTP响应头中需进行过滤"></a>【必须】外部输入拼接到HTTP响应头中需进行过滤</h4><p>应尽量避免外部可控参数拼接到HTTP响应头中，如业务需要则需要过滤掉“\r”、”\n”等换行符，或者拒绝携带换行符号的外部输入。</p><h4 id="【必须】避免不可信域名的302跳转"><a href="#【必须】避免不可信域名的302跳转" class="headerlink" title="【必须】避免不可信域名的302跳转"></a>【必须】避免不可信域名的302跳转</h4><p>如果对外部传入域名进行302跳转，必须设置可信域名列表并对传入域名进行校验。</p><p>为避免校验被绕过，应避免直接对URL进行字符串匹配。应通过通过URL解析函数进行解析，获取host或者domain后和白名单进行比较。</p><p>需要注意的是，由于浏览器的容错机制，域名<code>https://www.qq.com\www.bbb.com</code>中的<code>\</code>会被替换成<code>/</code>，最终跳转到<code>www.qq.com</code><br>。而Java的域名解析函数则无此特性。为避免解析不一致导致绕过，建议对host中的<code>/</code>和<code>#</code>进行替换。</p><p>参考代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">String host=<span class="string">&quot;&quot;</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  url=url.replaceAll(<span class="string">&quot;[\\\\#]&quot;</span>,<span class="string">&quot;/&quot;</span>); <span class="comment">//替换掉反斜线和井号</span></span><br><span class="line">  host=<span class="keyword">new</span> URL(url).getHost();</span><br><span class="line">&#125; <span class="keyword">catch</span>(MalformedURLException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(host.endsWith(<span class="string">&quot;.qq.com&quot;</span>))&#123;</span><br><span class="line">    <span class="comment">//跳转操作</span></span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="【必须】避免通过Jsonp传输非公开敏感信息"><a href="#【必须】避免通过Jsonp传输非公开敏感信息" class="headerlink" title="【必须】避免通过Jsonp传输非公开敏感信息"></a>【必须】避免通过Jsonp传输非公开敏感信息</h4><p>jsonp请求再被CSRF攻击时，其响应包可被攻击方劫持导致信息泄露。应避免通过jsonp传输非公开的敏感信息，例如用户隐私信息、身份凭证等。</p><h4 id="【必须】限定JSONP接口的callback字符集范围"><a href="#【必须】限定JSONP接口的callback字符集范围" class="headerlink" title="【必须】限定JSONP接口的callback字符集范围"></a>【必须】限定JSONP接口的callback字符集范围</h4><p>JSONP接口的callback函数名为固定白名单。如callback函数名可用户自定义，应限制函数名仅包含 字母、数字和下划线。如：<code>[a-zA-Z0-9_-]+</code></p><h4 id="【必须】屏蔽异常栈"><a href="#【必须】屏蔽异常栈" class="headerlink" title="【必须】屏蔽异常栈"></a>【必须】屏蔽异常栈</h4><p>应用程序出现异常时，禁止将数据库版本、数据库结构、操作系统版本、堆栈跟踪、文件名和路径信息、SQL 查询字符串等对攻击者有用的信息返回给客户端。建议重定向到一个统一、默认的错误提示页面，进行信息过滤。</p><h4 id="【必须】模板-amp-表达式"><a href="#【必须】模板-amp-表达式" class="headerlink" title="【必须】模板&amp;表达式"></a>【必须】模板&amp;表达式</h4><p>web view层通常通过模板技术或者表达式引擎来实现界面与业务数据分离，比如jsp中的EL表达式。这些引擎通常可执行敏感操作，如果外部不可信数据未经过滤拼接到表达式中进行解析。则可能造成严重漏洞。</p><p>下列是基于EL表达式注入漏洞的演示demo：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    <span class="meta">@RequestMapping(&quot;/ELdemo&quot;)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">ELdemo</span><span class="params">(RepeatDTO repeat)</span></span>&#123;</span><br><span class="line">    ExpressionFactory expressionFactory=<span class="keyword">new</span> ExpressionFactoryImpl();</span><br><span class="line">    SimpleContext simpleContext=<span class="keyword">new</span> SimpleContext();</span><br><span class="line">    String exp=<span class="string">&quot;$&#123;&quot;</span>+repeat.getel()+<span class="string">&quot;&#125;&quot;</span>;</span><br><span class="line">    ValueExpression valueExpression=expressionFactory.createValueExpression(simpleContext,exp,String.class);</span><br><span class="line">    <span class="keyword">return</span> valueExpression.getValue(simpleContext).toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>外部可通过el参数，将不可信输入拼接到EL表达式中并解析。</p><p>此时外部访问：x.x.x.x/ELdemo?el=”’’.getClass().forName(‘java.lang.Runtime’).getMethod(‘exec’,’’.getClass()).invoke(‘’<br>.getClass().forName(‘java.lang.Runtime’).getMethod(‘getRuntime’).invoke(null),’open /Applications/Calculator.app’)“<br>可执行操作系统命令调出计算器。</p><p>基于以上风险：</p><ul><li>应避免外部输入的内容拼接到EL表达式或其他表达式引起、模板引擎进行解析。</li><li>白名单过滤外部输入，仅允许字符、数字、下划线等。</li></ul><h3 id="OS命令执行"><a href="#OS命令执行" class="headerlink" title="OS命令执行"></a>OS命令执行</h3><h4 id="【建议】避免不可信数据拼接操作系统命令"><a href="#【建议】避免不可信数据拼接操作系统命令" class="headerlink" title="【建议】避免不可信数据拼接操作系统命令"></a>【建议】避免不可信数据拼接操作系统命令</h4><p>当不可信数据存在时，应尽量避免外部数据拼接到操作系统命令使用 <code>Runtime</code> 和 <code>ProcessBuilder</code> 来执行。优先使用其他同类操作进行代替，比如通过文件系统API进行文件操作而非直接调用操作系统命令。</p><h4 id="【必须】避免创建SHELL操作"><a href="#【必须】避免创建SHELL操作" class="headerlink" title="【必须】避免创建SHELL操作"></a>【必须】避免创建SHELL操作</h4><p>如无法避免直接访问操作系统命令，需要严格管理外部传入参数，使不可信数据仅作为执行命令的参数而非命令。</p><ul><li><p>禁止外部数据直接直接作为操作系统命令执行。</p></li><li><p>避免通过”cmd”、“bash”、“sh”等命令创建shell后拼接外部数据来执行操作系统命令。</p></li><li><p>对外部传入数据进行过滤。可通过白名单限制字符类型，仅允许字符、数字、下划线；或过滤转义以下符号：|;&amp;$&gt;&lt;`（反引号）!</p><p>白名单示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Pattern FILTER_PATTERN = Pattern.compile(<span class="string">&quot;[0-9A-Za-z_]+&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (!FILTER_PATTERN.matcher(input).matches()) &#123;</span><br><span class="line">  <span class="comment">// 终止当前请求的处理</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="会话管理"><a href="#会话管理" class="headerlink" title="会话管理"></a>会话管理</h3><h4 id="【必须】非一次有效身份凭证禁止在URL中传输"><a href="#【必须】非一次有效身份凭证禁止在URL中传输" class="headerlink" title="【必须】非一次有效身份凭证禁止在URL中传输"></a>【必须】非一次有效身份凭证禁止在URL中传输</h4><p>身份凭证禁止在URL中传输，一次有效的身份凭证除外（如CAS中的st）。</p><h4 id="【必须】避免未经校验的数据直接给会话赋值"><a href="#【必须】避免未经校验的数据直接给会话赋值" class="headerlink" title="【必须】避免未经校验的数据直接给会话赋值"></a>【必须】避免未经校验的数据直接给会话赋值</h4><p>防止会话信息被篡改，如恶意用户通过URL篡改手机号码等。</p><h3 id="加解密"><a href="#加解密" class="headerlink" title="加解密"></a>加解密</h3><h4 id="【建议】对称加密"><a href="#【建议】对称加密" class="headerlink" title="【建议】对称加密"></a>【建议】对称加密</h4><p>建议使用AES，秘钥长度128位以上。禁止使用DES算法，由于秘钥太短，其为目前已知不安全加密算法。使用AES加密算法请参考以下注意事项：</p><ul><li>AES算法如果采用CBC模式：每次加密时IV必须采用密码学安全的伪随机发生器（如/dev/urandom）,禁止填充全0等固定值。</li><li>AES算法如采用GCM模式，nonce须采用密码学安全的伪随机数</li><li>AES算法避免使用ECB模式，推荐使用GCM模式。</li></ul><h4 id="【建议】非对称加密"><a href="#【建议】非对称加密" class="headerlink" title="【建议】非对称加密"></a>【建议】非对称加密</h4><p>建议使用RSA算法，秘钥2048及以上。</p><h4 id="【建议】哈希算法"><a href="#【建议】哈希算法" class="headerlink" title="【建议】哈希算法"></a>【建议】哈希算法</h4><p>哈希算法推荐使用SHA-2及以上。对于签名场景，应使用HMAC算法。如果采用字符串拼接盐值后哈希的方式，禁止将盐值置于字符串开头，以避免哈希长度拓展攻击。</p><h4 id="【建议】密码存储策略"><a href="#【建议】密码存储策略" class="headerlink" title="【建议】密码存储策略"></a>【建议】密码存储策略</h4><p>建议采用随机盐+明文密码进行多轮哈希后存储密码。</p><h3 id="查询业务"><a href="#查询业务" class="headerlink" title="查询业务"></a>查询业务</h3><h4 id="【必须】返回信息最小化"><a href="#【必须】返回信息最小化" class="headerlink" title="【必须】返回信息最小化"></a>【必须】返回信息最小化</h4><p>返回用户信息应遵循最小化原则，避免将业务需求之外的用户信息返回到前端。</p><h4 id="【必须】个人敏感信息脱敏展示"><a href="#【必须】个人敏感信息脱敏展示" class="headerlink" title="【必须】个人敏感信息脱敏展示"></a>【必须】个人敏感信息脱敏展示</h4><p>在满足业务需求的情况下，个人敏感信息需脱敏展示,如：</p><ul><li>鉴权信息（如口令、密保答案、生理标识等）不允许展示</li><li>身份证只显示第一位和最后一位字符，如3****************1。</li><li>移动电话号码隐藏中间6位字符，如134******48。</li><li>工作地址/家庭地址最多显示到“区”一级。</li><li>银行卡号仅显示最后4位字符，如************8639</li></ul><h4 id="【必须】数据权限校验"><a href="#【必须】数据权限校验" class="headerlink" title="【必须】数据权限校验"></a>【必须】数据权限校验</h4><p>查询个人非公开信息时，需要对当前访问账号进行数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>验当前用户是否具备访问数据的权限</li></ol><h3 id="操作业务"><a href="#操作业务" class="headerlink" title="操作业务"></a>操作业务</h3><h4 id="【必须】部署CSRF防御机制"><a href="#【必须】部署CSRF防御机制" class="headerlink" title="【必须】部署CSRF防御机制"></a>【必须】部署CSRF防御机制</h4><p>CSRF是指跨站请求伪造（Cross-site request forgery），是web常见的攻击之一。对于可重放的敏感操作请求，需部署CSRF防御机制。可参考以下两种常见的CSRF防御方式</p><ul><li><p>设置CSRF Token</p><p>服务端给合法的客户颁发CSRF<br>Token，客户端在发送请求时携带该token供服务端校验，服务端拒绝token验证不通过的请求。以此来防止第三方构造合法的恶意操作链接。Token的作用域可以是Request级或者Session级。下面以Session级CSRF<br>Token进行示例</p><ol><li><p>登录成功后颁发Token，并同时存储在服务端Session中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String uuidToken = UUID.randomUUID().toString();</span><br><span class="line">map.put(<span class="string">&quot;token&quot;</span>, uuidToken);</span><br><span class="line">request.getSession().setAttribute(<span class="string">&quot;token&quot;</span>,uuidToken );</span><br><span class="line"><span class="keyword">return</span> map;</span><br></pre></td></tr></table></figure></li></ol></li></ul><ol start="2"><li><p>创建Filter</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CsrfFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;  </span><br><span class="line">   HttpSession session = req.getSession();</span><br><span class="line">   Object token = session.getAttribute(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   String requestToken = req.getParameter(<span class="string">&quot;token&quot;</span>);</span><br><span class="line">   <span class="keyword">if</span>(StringUtils.isBlank(requestToken) || !requestToken.equals(token))&#123;</span><br><span class="line">         AjaxResponseWriter.write(req, resp, ServiceStatusEnum.ILLEGAL_TOKEN, <span class="string">&quot;非法的token&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></li></ol><p>CSRF Token应具备随机性，保证其不可预测和枚举。另外由于浏览器会自动对表单所访问的域名添加相应的cookie信息，所以CSRF Token不应该通过Cookie传输。</p><ul><li><p>校验Referer头</p><p>通过检查HTTP请求的Referer字段是否属于本站域名，非本站域名的请求进行拒绝。</p><p>这种校验方式需要注意两点：</p><ol><li>要需要处理Referer为空的情况，当Referer为空则拒绝请求</li><li>注意避免例如qq.com.evil.com 部分匹配的情况。</li></ol></li></ul><h4 id="【必须】权限校验"><a href="#【必须】权限校验" class="headerlink" title="【必须】权限校验"></a>【必须】权限校验</h4><p>对于非公共操作，应当校验当前访问账号进行操作权限（常见于CMS）和数据权限校验。</p><ol><li>验证当前用户的登录态</li><li>从可信结构中获取经过校验的当前请求账号的身份信息（如：session）。禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询。</li><li>校验当前用户是否具备该操作权限</li><li>校验当前用户是否具备所操作数据的权限。避免越权。</li></ol><h4 id="【建议】加锁操作"><a href="#【建议】加锁操作" class="headerlink" title="【建议】加锁操作"></a>【建议】加锁操作</h4><p>对于有次数限制的操作，比如抽奖。如果操作的过程中资源访问未正确加锁。在高并发的情况下可能造成条件竞争，导致实际操作成功次数多于用户实际操作资格次数。此类操作应加锁处理。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;后台类&quot;&gt;&lt;a href=&quot;#后台类&quot; class=&quot;headerlink&quot; title=&quot;后台类&quot;&gt;&lt;/a&gt;后台类&lt;/h2&gt;&lt;h3 id=&quot;数据持久化&quot;&gt;&lt;a href=&quot;#数据持久化&quot; class=&quot;headerlink&quot; title=&quot;数据持久化&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    <category term="代码规范" scheme="http://example.com/categories/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
    
    <category term="代码规范" scheme="http://example.com/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统04之分布式锁</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2021-07-09T10:35:00.000Z</published>
    <updated>2021-07-14T08:49:21.163Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁"></a>什么是分布式锁</h2><ul><li>分布式模型下，数据只有一份，需要锁技术控制某一时刻修改数据的进程数。 </li><li>不仅需要保证进程可见，还需要考虑进程与锁的网络问题 </li><li>可以将标记存在内存，但是内存不是进程分配而是公共内存（redis、zk）,保证标记互斥。</li></ul><h2 id="Java分布式锁需求"><a href="#Java分布式锁需求" class="headerlink" title="Java分布式锁需求"></a>Java分布式锁需求</h2><ul><li>同一个方法在同一时间只能被一台机器上一个线程执行。</li><li>可重入（避免死锁）</li><li>阻塞锁（业务需求） </li><li>公平锁（业务需求） </li><li>高可用、高性能获取/释放锁</li></ul><h2 id="Java分布式锁解决方案"><a href="#Java分布式锁解决方案" class="headerlink" title="Java分布式锁解决方案"></a>Java分布式锁解决方案</h2><h3 id="基于数据库"><a href="#基于数据库" class="headerlink" title="基于数据库"></a>基于数据库</h3><p>基于表主键唯一做分布式锁</p><h3 id="基于redis"><a href="#基于redis" class="headerlink" title="基于redis"></a>基于redis</h3><h4 id="基于-redis-的-SETNX-、EXPIRE-方法做分布式锁"><a href="#基于-redis-的-SETNX-、EXPIRE-方法做分布式锁" class="headerlink" title="基于 redis 的 SETNX()、EXPIRE() 方法做分布式锁"></a>基于 redis 的 SETNX()、EXPIRE() 方法做分布式锁</h4><p>使用步骤：</p><ul><li>setnx(lockkey, 1) 返回1，占位成功</li><li>expire()对lockkey设置超时时间，避免死锁</li><li>执行完业务后，delete命令删除key</li></ul><p>在 expire() 命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题。</p><h4 id="基于-redis-的-setnx-、get-和-getset-方法来实现分布式锁。"><a href="#基于-redis-的-setnx-、get-和-getset-方法来实现分布式锁。" class="headerlink" title="基于 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。"></a>基于 redis 的 setnx()、get() 和 getset() 方法来实现分布式锁。</h4><p>使用步骤</p><ul><li>setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。</li><li>get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。</li><li>计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。</li><li>判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。</li><li>在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。</li></ul><h4 id="分布式锁Redlock"><a href="#分布式锁Redlock" class="headerlink" title="分布式锁Redlock"></a>分布式锁Redlock</h4><p>解决问题：<br>解决redis分布式锁的单点故障问题</p><p>使用步骤：</p><ul><li>获取当前时间（毫秒数）。</li><li>按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。这里的失败，应该包含任何类型的失败，比如该Redis节点不可用，或者该Redis节点上的锁已经被其它客户端持有（注：Redlock原文中这里只提到了Redis节点不可用的情况，但也应该包含其它的失败情况）。</li><li>计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。</li><li>如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。</li><li>如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的Redis Lua脚本）。</li></ul><h4 id="基于-REDISSON-做分布式锁"><a href="#基于-REDISSON-做分布式锁" class="headerlink" title="基于 REDISSON 做分布式锁"></a>基于 REDISSON 做分布式锁</h4><p>redis 官方的分布式锁组件，解决超时时间设置不合理问题。每获得一个锁时，只设置一个很短的超时时间，同时起一个线程在每次快要到超时时间时去刷新锁的超时时间。在释放锁的同时结束这个线程。</p><h3 id="zookeeper实现分布式锁"><a href="#zookeeper实现分布式锁" class="headerlink" title="zookeeper实现分布式锁"></a>zookeeper实现分布式锁</h3><p>其实基于ZooKeeper，就是使用它的临时有序节点来实现的分布式锁。</p><p><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F04%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/img_1.png" alt="img.png"><br>当某客户端要进行逻辑的加锁时，就在zookeeper上的某个指定节点的目录下，去生成一个唯一的临时有序节点， 然后判断自己是否是这些有序节点中序号最小的一个。</p><ul><li>如果是，则算是获取了锁。</li><li>如果不是，则说明没有获取到锁，那么就需要在序列中找到比自己小的那个节点，并对其调用exist()方法，对其注册事件监听，当监听到这个节点被删除了，那就再去判断一次自己当初创建的节点是否变成了序列中最小的。<ul><li>如果是，则获取锁，如果不是，则重复上述步骤。</li></ul></li></ul><p>当释放锁的时候，只需将这个临时节点删除即可。</p><h2 id="redis分布式锁和zookeeper分布式锁的区别"><a href="#redis分布式锁和zookeeper分布式锁的区别" class="headerlink" title="redis分布式锁和zookeeper分布式锁的区别"></a>redis分布式锁和zookeeper分布式锁的区别</h2><h3 id="优缺点对比"><a href="#优缺点对比" class="headerlink" title="优缺点对比"></a>优缺点对比</h3><p>对于redis的分布式锁而言：</p><ul><li><p>它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。</p></li><li><p>redis的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题。锁的模型不够健壮</p><ul><li>即便使用redlock算法来实现，在某些复杂场景下，也无法保证其实现100%没有问题，关于redlock的讨论可以看How to do distributed locking</li></ul></li></ul><p>但是另一方面使用redis实现分布式锁在很多企业中非常常见，而且大部分情况下都不会遇到所谓的“极端复杂场景”</p><p>所以使用redis作为分布式锁也不失为一种好的方案，最重要的一点是redis的性能很高，可以支撑高并发的获取、释放锁操作。</p><p>对于zk分布式锁而言:</p><ul><li><p>zookeeper天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。</p></li><li><p>如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。</p></li></ul><p>但是zk也有其缺点：如果有较多的客户端频繁的申请加锁、释放锁，对于zk集群的压力会比较大。</p><h3 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h3><p>就个人而言的话，我<strong>比较推崇zk实现的锁</strong>：</p><p>因为redis是有可能存在隐患的，可能会导致数据不对的情况。但是，怎么选用要看具体在公司的场景了。</p><p>如果公司里面有zk集群条件，优先选用zk实现，但是如果说公司里面只有redis集群，没有条件搭建zk集群。</p><p>那么其实用redis来实现也可以，另外还可能是系统设计者考虑到了系统已经有redis，但是又不希望再次引入一些外部依赖的情况下，可以选用redis。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是分布式锁&quot;&gt;&lt;a href=&quot;#什么是分布式锁&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式锁&quot;&gt;&lt;/a&gt;什么是分布式锁&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;分布式模型下，数据只有一份，需要锁技术控制某一时刻修改数据的进程数。 &lt;/li&gt;
&lt;li</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="锁" scheme="http://example.com/tags/%E9%94%81/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统03之分布式事务</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2021-07-09T10:34:43.000Z</published>
    <updated>2021-07-14T08:49:21.196Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是分布式事务"><a href="#什么是分布式事务" class="headerlink" title="什么是分布式事务"></a>什么是分布式事务</h2><p>分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。</p><h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。</p><h2 id="分布式系统一致性基础算法"><a href="#分布式系统一致性基础算法" class="headerlink" title="分布式系统一致性基础算法"></a>分布式系统一致性基础算法</h2><h3 id="Paxos算法"><a href="#Paxos算法" class="headerlink" title="Paxos算法"></a>Paxos算法</h3><p>Paxos 算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一，其解决的问题就是在分布式系统中如何就某个值（决议）达成一致 。</p><p>在 Paxos 中主要有三个角色，分别为 Proposer提案者、Acceptor表决者、Learner学习者。Paxos 算法和 2PC 一样，也有两个阶段，分别为 Prepare 和 accept 阶段。  </p><ul><li>prepare 阶段<ul><li>Proposer提案者：负责提出 proposal，每个提案者在提出提案时都会首先获取到一个 具有全局唯一性的、递增的提案编号N，即在整个集群中是唯一的编号 N，然后将该编号赋予其要提出的提案，在第一阶段是只将提案编号发送给所有的表决者。  </li><li>Acceptor表决者：每个表决者在 accept 某提案后，会将该提案编号N记录在本地，这样每个表决者中保存的已经被 accept 的提案中会存在一个编号最大的提案，其编号假设为 maxN。每个表决者仅会 accept 编号大于自己本地 maxN 的提案，在批准提案时表决者会将以前接受过的最大编号的提案作为响应反馈给 Proposer。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_1.png"></li></ul></li><li>accept 阶段<br>当一个提案被 Proposer 提出后，如果 Proposer 收到了超过半数的 Acceptor 的批准（Proposer 本身同意），那么此时 Proposer 会给所有的 Acceptor 发送真正的提案（你可以理解为第一阶段为试探），这个时候 Proposer 就会发送提案的内容和提案编号。<br>表决者收到提案请求后会再次比较本身已经批准过的最大提案编号和该提案编号，如果该提案编号 大于等于 已经批准过的最大提案编号，那么就 accept 该提案（此时执行提案内容但不提交），随后将情况返回给 Proposer 。如果不满足则不回应或者返回 NO 。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_2.png"><br>当 Proposer 收到超过半数的 accept ，那么它这个时候会向所有的 acceptor 发送提案的提交请求。需要注意的是，因为上述仅仅是超过半数的 acceptor 批准执行了该提案内容，其他没有批准的并没有执行该提案内容，所以这个时候需要向未批准的 acceptor 发送提案内容和提案编号并让它无条件执行和提交，而对于前面已经批准过该提案的 acceptor 来说 仅仅需要发送该提案的编号 ，让 acceptor 执行提交就行了。<br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_3.png" alt="img.png"><br>而如果 Proposer 如果没有收到超过半数的 accept 那么它将会将 递增 该 Proposal 的编号，然后 重新进入 Prepare 阶段 。</li></ul><h4 id="Paxos算法的死循环问题"><a href="#Paxos算法的死循环问题" class="headerlink" title="Paxos算法的死循环问题"></a>Paxos算法的死循环问题</h4><p>其实就有点类似于两个人吵架，小明说我是对的，小红说我才是对的，两个人据理力争的谁也不让谁🤬🤬。<br>比如说，此时提案者 P1 提出一个方案 M1，完成了 Prepare 阶段的工作，这个时候 acceptor 则批准了 M1，但是此时提案者 P2 同时也提出了一个方案 M2，它也完成了 Prepare 阶段的工作。然后 P1 的方案已经不能在第二阶段被批准了（因为 acceptor 已经批准了比 M1 更大的 M2），所以 P1 自增方案变为 M3 重新进入 Prepare 阶段，然后 acceptor ，又批准了新的 M3 方案，它又不能批准 M2 了，这个时候 M2 又自增进入 Prepare 阶段。<br>就这样无休无止的永远提案下去，这就是 paxos 算法的死循环问题。<br>那么如何解决呢？很简单，人多了容易吵架，我现在 就允许一个能提案 就行了。</p><h3 id="Raft-算法"><a href="#Raft-算法" class="headerlink" title="Raft 算法"></a>Raft 算法</h3><h2 id="分布式事务解决方案"><a href="#分布式事务解决方案" class="headerlink" title="分布式事务解决方案"></a>分布式事务解决方案</h2><h3 id="XA规范-协议"><a href="#XA规范-协议" class="headerlink" title="XA规范/协议"></a>XA规范/协议</h3><p>X/Open组织（现在的Open Group）定义了一套DTP（Distributed Transaction Processing）分布式事务处理模型，主要包含以下四部分：</p><ul><li>AP（应用程序） </li><li>TM（事务管理器）：交易中间件</li><li>RM（资源管理器）：数据库</li><li>CRM（通信资源管理器）：消息中间件</li></ul><p><strong>XA规范</strong>则是DTP模型定义TM和RM之间通讯的接口规范。  </p><p>XA接口函数由数据库厂商提供。<br>TM用它来通知数据库事务的开始、结束、提交、回滚。<br>基于XA规范衍生出下面的二阶段提交（2PC）、三阶段提交（3PC）。  </p><p>XA规范包括两套函数，以xa_开头的及以ax_开头的。<br>以下的函数使事务管理器可以对资源管理器进行的操作：</p><ul><li>xa_open,xa_close：建立和关闭与资源管理器的连接。</li><li>xa_start,xa_end：开始和结束一个本地事务。</li><li>xa_prepare,xa_commit,xa_rollback：预提交、提交、回滚一个本地事务。</li><li>xa_recover：回滚一个已进行预提交的事务。</li><li>ax_开头的函数使资源管理器可以动态地在事务管理器中进行注册，并可以对XID(TRANSACTION IDS)进行操作。</li><li>ax_reg,ax_unreg；允许一个资源管理器在一个TMS(TRANSACTION MANAGER SERVER)中动态注册或撤消注册。<br>XA的一些问题：</li><li>性能（阻塞、响应时间增加、死锁）；</li><li>依赖于独立的J2EE中间件，Weblogic、Jboss，后期轻量级的Atomikos、Narayana、Bitronix；</li><li>不是所有资源(RM)都支持XA协议；</li></ul><h4 id="JTA（Java-Transaction-API）"><a href="#JTA（Java-Transaction-API）" class="headerlink" title="JTA（Java Transaction API）"></a>JTA（Java Transaction API）</h4><p>即Java的事务API，基于XA实现，也就是RM需要支持XA，所以也有JTA(XA)的说法，JTA仅定义了接口。主要包括javax.sql.XADataResource、javax.sql.XAConnection、javax.sql.XAException、javax.transaction.xa.XAResource、javax.transaction.Xid。 目下JTA的实现有几种形式：</p><ul><li>J2EE容器提供的JTA实现（Weblogic、JBoss ）；</li><li>JOTM（Java Open Transaction Manager）、Atomikos，可独立于J2EE容器的环境下实现JTA；</li></ul><h4 id="二阶段提交（2PC）"><a href="#二阶段提交（2PC）" class="headerlink" title="二阶段提交（2PC）"></a>二阶段提交（2PC）</h4><p>2PC就是分布式事务中将事务分为两步进行提交。基于数据库的XA协议完成事务本质上就是二阶段提交（XA、JTA/JTS）。</p><ul><li><p>协调者（Coordinater）：事务管理器（TM）</p></li><li><p>参与者（participants）：资源管理器（RM）<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_4.png"></p></li><li><p><strong>准备阶段</strong>：  </p><ul><li>协调者向参与者发送prepare信息，以询问参与者是否能够提交事务；</li><li>参与者在收到prepare信息后，进行本地事务的预处理，但不提交。并根据处理结果返回，失败not commit or 成功ready ；</li></ul></li><li><p><strong>提交阶段</strong>：  </p><ul><li>如协调者收到参与者的失败消息，则向每个参与者发送rollback消息进行回滚；</li><li>所有参与者都返回ready，则向每个参与者发送提交commit消息，通知参与者进行事务提交；</li></ul></li></ul><p>两阶段提交的一些问题:</p><ul><li>同步阻塞，事务执行过程中所有参与者都是阻塞型的，第三方参与者访问参与者占有的资源时会被阻塞；</li><li>单点故障，协调者一旦发生故障，参与者会被阻塞。尤其在提交阶段，所有参与者都处于锁定资源状态中，无法完成事务操作；（可以选择新的协调者，但无法解决参与者被阻塞的问题）；</li><li>数据不一致，提交阶段协调者向参与者发送commit信息，发生局部网络故障，会导致存在参与者未收到commit信息无法提交事务情况，导致出现数据不一致现象；</li></ul><h4 id="三阶段提交（3PC）"><a href="#三阶段提交（3PC）" class="headerlink" title="三阶段提交（3PC）"></a>三阶段提交（3PC）</h4><p>相比于2PC，3PC把2PC的准备阶段再次进行拆分，并且3PC引入了参与者超时机制。</p><ul><li>canCommit：协调者询问参与者，是否具备执行事务的条件，参与者进行自身事务必要条件的检查；</li><li>preCommit：协调者通知参与者进行事务的预提交；</li><li>doCommit：协调者根据preCommit阶段参与者的反馈结果通知参与者是否进行事务提交或是进行事务回滚。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_5.png"></li></ul><h4 id="TCC事务补偿方案"><a href="#TCC事务补偿方案" class="headerlink" title="TCC事务补偿方案"></a>TCC事务补偿方案</h4><p>TCC的核心思想就是校验、资源锁定、补偿，对每个操作（Try）都提供确认（Confirm）和取消（cancel）的操作，这样根据操作的结果，来确认是进行Confirm还是Cancel。<br>可以看出XA的两阶段提交是基于资源层面的，而TCC也是一种两阶段提交，但它是基于应用层面的。</p><ul><li>Try：主要负责对业务进行数据检查和资源预留，例如：对资金进行冻结；对状态更改为处理中；</li><li>Confirm：确认执行业务的操作，例如：进行实际资金扣除；更改状态为最终结果；</li><li>Cancel：取消执行业务的操作，例如：解冻资金；更改状态为未处理；</li></ul><p>TCC存在的一些问题：</p><ul><li>业务操作的是不同服务的Try来进行资源预留，每个Try都是独立完成本地事务，因此不会对资源一直加锁。</li><li>业务服务需要提供try、confirm、cancel，业务侵入性强，如不适用三方框架要做到对各阶段状态的感知，比较麻烦。</li><li>Confirm/Cancel要做幂等性设计。</li></ul><p>常用TCC框架：<br>tcc-transaction、ByteTCC、spring-cloud-rest-tcc、Himly</p><p>常见的微服务系统大部分接口调用是同步的，这时候使用TCC来保证一致性是比较合适的。</p><h4 id="SAGA"><a href="#SAGA" class="headerlink" title="SAGA"></a>SAGA</h4><p>Saga的核心是补偿，与TCC不同的是Saga不需要Try，而是直接进行confirm、cancel操作。  </p><ul><li>Confirm：依次按顺序依次执行资源操作，各个资源直接处理本地事务，如无问题，二阶段什么都不用做；</li><li>Cancel：异常情况下需要调用的补偿事务（逆操作）来保证数据的一致性。</li></ul><p>可以看出，Saga和TCC有些类似，都是补偿型事务</p><p>优势：</p><ul><li>一阶段提交本地事务，无锁，高性能；</li><li>事件驱动模式，参与者可异步执行，高吞吐；</li><li>应用成本低，补偿服务易于实现；</li></ul><p>劣势：</p><ul><li>无法保证隔离性（脏写）</li></ul><h4 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h4><p>有一些情况，服务间调用时异步的，服务A将消息发送到MQ，服务B进行消息的消费。这时我们就需要用到可靠消息最终一致性来解决分布式事务问题</p><ul><li>可靠消息：即这个消息一定是可靠的，并且最终一定需要被消费的。 </li><li>最终一致性：过程中数据存在一定时间内的不一致，但超过限定时间后，需要最终会保持一致。</li></ul><p>保证以上两点的情况下，可以通过消息中间件（RocketMQ）来完成分布式事务处理，因为RocketMQ支持事务消息，可以方便的让我们进行分布式事务控制。</p><p>RocketMQ的事务消息的原理：<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/img_6.png" alt="img.png"></p><p>half message：半消息，此时消息不能被consumer所发现和消费，需producer进行二次消息确认。</p><ul><li>producer发送half message给MQ Server；</li><li>producer根据MQ Server应答结果判断half message是否发送成功；</li><li>producer处理本地事务；</li><li>producer发送最终确认消息commit / rollback；</li><li>commit：consumer对消息可见并进行消费；</li><li>rollback：discard抛弃消息，consumer无法进行消息消费；</li></ul><p>如遇异常情况下step4最终确认消息为达到MQ Server，MQ Server会定期查询当前处于半消息状态下的消息，主动进行消息回查来询问producer该消息的最终状态；</p><ul><li>producer检查本地事务执行的最终结果；</li><li>producer根据检查到的结果，再次提交确认消息，MQ Server仍然按照step4进行后续操作。</li></ul><p>事务消息发送对应步骤1、2、3、4，事务消息回查对应步骤5、6、7。<br>由以上步骤可以看出通过事务性消息的两步操作，避免了消息直接投递所产生一些问题。最终投递到MQ Server的消息，是真实可靠且必须被消费的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="分布式事务设计权衡点"><a href="#分布式事务设计权衡点" class="headerlink" title="分布式事务设计权衡点"></a>分布式事务设计权衡点</h3><ul><li>实现复杂度：事务模式与当前业务结合，实施成本是否过高；</li><li>业务侵入性：基于注解、XML、补偿逻辑； </li><li>TC/TM部署：独立部署、与应用部署；</li><li>性能：回滚概率、回滚所付出的代价、响应时间、吞吐量；</li><li>高可用：数据库、注册中心、配置中心</li><li>持久化：文件、数据库；</li><li>同步/异步：分布式事务执行过程中是否阻塞，还是非阻塞；</li></ul><h3 id="分布式事务解决方案对比"><a href="#分布式事务解决方案对比" class="headerlink" title="分布式事务解决方案对比"></a>分布式事务解决方案对比</h3><p>分布式系统中，基于不同的一致性需求产生了不同的分布式事务解决方案，追求强一致的两阶段提交、追求最终一致性的柔性事务和事务消息等等。  </p><p>我们综合对比下几种分布式事务解决方案：  </p><ul><li>一致性保证：XA &gt; TCC = SAGA &gt; 事务消息  </li><li>业务友好性：XA &gt; 事务消息 &gt; SAGA &gt; TCC  </li><li>性 能 损 耗：XA &gt; TCC &gt; SAGA = 事务消息</li></ul><p>在柔性事务解决方案中，虽然SAGA和TCC看上去可以保证数据的最终一致性，但分布式系统的生产环境复杂多变，某些情况是可以导致柔性事务机制失效的，所以无论使用那种方案，都需要最终的兜底策略，人工校验，修复数据。</p><h3 id="分布式事务框架Seata"><a href="#分布式事务框架Seata" class="headerlink" title="分布式事务框架Seata"></a>分布式事务框架Seata</h3><p>阿里开源的Seata 是一款分布式事务解决方案，提供了 AT、TCC、SAGA 和 XA 事务模式。</p><p>Seata架构的亮点主要有几个:</p><ul><li>应用层基于SQL解析实现了自动补偿，从而最大程度的降低业务侵入性；</li><li>将分布式事务中TC（事务协调者）独立部署，负责事务的注册、回滚（支持多种注册中心形式以及本地文件形式）；</li><li>通过全局锁实现了写隔离与读隔离。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是分布式事务&quot;&gt;&lt;a href=&quot;#什么是分布式事务&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式事务&quot;&gt;&lt;/a&gt;什么是分布式事务&lt;/h2&gt;&lt;p&gt;分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="事务" scheme="http://example.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统02之分布式ID解决方案</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</id>
    <published>2021-07-09T10:32:44.000Z</published>
    <updated>2021-07-14T08:49:21.134Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么需要分布式ID"><a href="#为什么需要分布式ID" class="headerlink" title="为什么需要分布式ID"></a>为什么需要分布式ID</h2><p>在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如数据量太大之后，往往需要对进行对数据进行分库分表，分库分表后需要有一个唯一 ID 来标识一条数据或消息，数据库的自增 ID 显然不能满足需求。</p><h2 id="分布式ID生成方案"><a href="#分布式ID生成方案" class="headerlink" title="分布式ID生成方案"></a>分布式ID生成方案</h2><p><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/img_1.png"></p><h3 id="数据库自增ID"><a href="#数据库自增ID" class="headerlink" title="数据库自增ID"></a>数据库自增ID</h3><p>需要一个单独的Mysql实例，虽然可行，但是基于性能与可靠性来考虑的话都不够，业务系统每次需要一个ID时，都需要请求数据库获取，性能低，并且如果此数据库实例下线了，那么将影响所有的业务系统。</p><h3 id="数据库多主模式"><a href="#数据库多主模式" class="headerlink" title="数据库多主模式"></a>数据库多主模式</h3><p>多个数据库主节点实例，单独设置步长防止产生相同ID，或者使用号段模式每个节点生产部分号段的ID</p><h3 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h3><p>核心思想是：分布式ID固定是一个long型的数字，一个long型占8个字节，也就是64个bit，原始snowflake算法中对于bit的分配如下图：<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8FID%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/img.png" alt="img.png"></p><ul><li>第一个bit位是标识部分，在java中由于long的最高位是符号位，正数是0，负数是1，一般生成的ID为正数，所以固定为0。</li><li>时间戳部分占41bit，这个是毫秒级的时间，一般实现上不会存储当前的时间戳，而是时间戳的差值（当前时间-固定的开始时间），这样可以使产生的ID从更小值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69年</li><li>工作机器id占10bit，这里比较灵活，比如，可以使用前5位作为数据中心机房标识，后5位作为单机房机器标识，可以部署1024个节点。</li><li>序列号部分占12bit，支持同一毫秒内同一个节点可以生成4096个ID</li><li>备注： 工作机器ID可以通过某种改造自动生成。</li></ul><h3 id="Redis自增ID"><a href="#Redis自增ID" class="headerlink" title="Redis自增ID"></a>Redis自增ID</h3><p>使用Redis来生成分布式ID，其实和利用Mysql自增ID类似，可以利用Redis中的incr命令来实现原子性的自增与返回，比如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set seq_id 1 // 初始化自增ID为1 OK </span><br><span class="line">127.0.0.1:6379&gt; incr seq_id // 增加1，并返回 (integer) 2 </span><br><span class="line">127.0.0.1:6379&gt; incr seq_id // 增加1，并返回</span><br><span class="line">备注：使用redis需要考虑持久化问题,RDB&amp;AOF。</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;为什么需要分布式ID&quot;&gt;&lt;a href=&quot;#为什么需要分布式ID&quot; class=&quot;headerlink&quot; title=&quot;为什么需要分布式ID&quot;&gt;&lt;/a&gt;为什么需要分布式ID&lt;/h2&gt;&lt;p&gt;在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。比如数据量太大之</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统01之分布式系统理论</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/</id>
    <published>2021-07-09T10:32:14.000Z</published>
    <updated>2021-07-14T08:49:21.149Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><h3 id="名词解析"><a href="#名词解析" class="headerlink" title="名词解析"></a>名词解析</h3><p>CAP理论作为分布式系统的基础理论,它描述的是一个分布式系统在以下三个特性中：</p><ul><li><strong>一致性（Consistency）</strong><ul><li>所有节点访问同一份最新的数据副本</li></ul></li><li><strong>可用性（Availability）</strong><ul><li>非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。</li></ul></li><li><strong>分区容错性（Partition tolerance）</strong><ul><li>分布式系统出现网络分区（多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域）的时候，仍然能够对外提供服务。<br>最多满足其中的两个特性。 </li></ul></li></ul><p>也就是下图所描述的。分布式系统要么满足CA,要么CP，要么AP。无法同时满足CAP。<br><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/img.png"></p><h3 id="CAP三者不可兼得，该如何取舍："><a href="#CAP三者不可兼得，该如何取舍：" class="headerlink" title="CAP三者不可兼得，该如何取舍："></a>CAP三者不可兼得，该如何取舍：</h3><ul><li><strong>CA</strong>: 优先保证一致性和可用性，放弃分区容错。 这也意味着放弃系统的扩展性，系统不再是分布式的，有违设计的初衷。<ul><li>当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。</li><li><strong>因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。</strong></li></ul></li><li><strong>CP</strong>: 优先保证一致性和分区容错性，放弃可用性。 在<strong>数据一致性要求比较高的场合</strong>(譬如:zookeeper,Hbase) 是比较常见的做法，一旦发生网络故障或者消息丢失，就会牺牲用户体验，等恢复之后用户才逐渐能访问。</li><li><strong>AP</strong>: 优先保证可用性和分区容错性，放弃一致性。 NoSQL中的Cassandra 就是这种架构。跟CP一样，放弃一致性不是说一致性就不保证了，而是逐渐的变得一致。</li></ul><h3 id="实际应用案例–注册中心"><a href="#实际应用案例–注册中心" class="headerlink" title="实际应用案例–注册中心"></a>实际应用案例–注册中心</h3><p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos…。 </p><ul><li>ZooKeeper 保证的是 CP。<br>任何时刻对 ZooKeeper 的读请求都能得到一致性的结果。<br>但是， ZooKeeper 不保证每次请求的可用性，比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。</li><li>Eureka 保证的则是 AP。<br>Eureka 在设计的时候就是优先保证 A （可用性）。<br>在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。<br>因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。<br>Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。   </li><li>Nacos 不仅支持 CP 也支持 AP。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等。<br>如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”（网络连接通信正常）的话，我们要思考如何保证 CA。</p><h2 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h2><h3 id="BASE理论名词解析"><a href="#BASE理论名词解析" class="headerlink" title="BASE理论名词解析"></a>BASE理论名词解析</h3><ul><li><strong>基本可用（Basically Available）</strong><br>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。<br>什么叫允许损失部分可用性呢？ <ul><li>响应时间上的损失: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。 </li><li>系统功能上的损失：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。</li></ul></li><li><strong>软状态（Soft State）</strong><br>软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</li><li><strong>最终一致性（Eventually Consistent）</strong><br>虽然允许软状态，但是系统不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。<br>实际工程实践中，最终一致性分为5种：<ul><li>因果一致性（Causal consistency）<br>如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。</li><li>读己之所写（Read your writes）<br>节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。</li><li>会话一致性（Session consistency）<br>系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</li><li>单调读一致性（Monotonic read consistency）<br>如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。</li><li>单调写一致性（Monotonic write consistency）<br>一个系统要能够保证来自同一个节点的写操作被顺序的执行。</li></ul></li></ul><h3 id="系统一致性说明"><a href="#系统一致性说明" class="headerlink" title="系统一致性说明"></a>系统一致性说明</h3><ul><li><strong>强一致性</strong>：系统写入了什么，读出来的就是什么。 </li><li><strong>弱一致性</strong>：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</li><li><strong>最终一致性</strong>：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</li></ul><h3 id="BASE理论的核心思想"><a href="#BASE理论的核心思想" class="headerlink" title="BASE理论的核心思想"></a>BASE理论的核心思想</h3><p>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</span><br></pre></td></tr></table></figure><p>CAP的3选2实际是个伪命题，实际上，系统没有发生P(分区)的话，必须在C（一致性）和A（可用性）之间任选其一。<br>分区的情况很少出现，CAP在大多时间能够同时满足C和A。<br>对于分区存在或者探知其影响的情况下，需要提供一种预备策略做出处理：</p><ul><li>探知分区的发生；</li><li>进入显示的分区模式，限制某些操作；</li><li>启动恢复过程，恢复数据一致性，补偿分区发生期间的错误。</li></ul><p>因此，AP方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。<br>在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。</p><h2 id="ACID本地事务四大特性"><a href="#ACID本地事务四大特性" class="headerlink" title="ACID本地事务四大特性"></a>ACID本地事务四大特性</h2><ul><li><strong>原子性（atomicity）</strong><br>一个事务中的所有操作，不可分割，要么全部成功，要么全部失败；</li><li><strong>一致性（consistency）</strong><br>一个事务执行前与执行后数据的完整性必须保持一致；</li><li><strong>隔离性（isolation）</strong><br>一个事务的执行，不能被其他事务干扰，多并发时事务之间要相互隔离；</li><li><strong>持久性（durability）</strong><br>一个事务一旦被提交，它对数据库中数据的改变是永久性的。</li></ul><h2 id="幂等性设计"><a href="#幂等性设计" class="headerlink" title="幂等性设计"></a>幂等性设计</h2><p>幂等（Idempotent）是一个数学与计算机学中的概念。f(n) = 1^n // 无论n等于多少，f(n)永远值等于1；在程序中，使用相同参数执行同一个方法，每一次执行结果都是相同的，即具有幂等性。</p><h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><ul><li>ACID 是数据库事务完整性的理论，</li><li>CAP 是分布式系统设计理论，</li><li>BASE 是 CAP 理论中 AP 方案的延伸。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;CAP理论&quot;&gt;&lt;a href=&quot;#CAP理论&quot; class=&quot;headerlink&quot; title=&quot;CAP理论&quot;&gt;&lt;/a&gt;CAP理论&lt;/h2&gt;&lt;h3 id=&quot;名词解析&quot;&gt;&lt;a href=&quot;#名词解析&quot; class=&quot;headerlink&quot; title=&quot;名词解析&quot;</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="设计理念" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统00之什么是分布式系统</title>
    <link href="http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</id>
    <published>2021-07-09T10:31:51.000Z</published>
    <updated>2021-07-14T09:06:24.911Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是分布式系统"><a href="#什么是分布式系统" class="headerlink" title="什么是分布式系统"></a>什么是分布式系统</h2><p>分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。</p><p>分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是<strong>利用更多的机器，处理更多的数据</strong>。</p><p>首先需要明确的是，只有</p><ul><li>单个节点的处理能力无法满足日益增长的计算、存储任务</li><li>且硬件的提升（加内存、加磁盘、使用更好的CPU）高昂到得不偿失</li><li>应用程序也不能进一步优化  </li></ul><p>我们才需要考虑分布式系统。</p><p>因为，分布式系统要解决的问题本身就是和单机系统一样的，而由于分布式系统多节点、通过网络通信的拓扑结构，会引入很多单机系统没有的问题，为了解决这些问题又会引入更多的机制、协议，带来更多的问题。</p><p>分布式系统怎么将任务分发到这些计算机节点呢，很简单的思想，分而治之，即分片（partition）。对于计算，那么就是对计算任务进行切换，每个节点算一些，最终汇总就行了，这就是MapReduce的思想；对于存储，更好理解一下，每个节点存一部分数据就行了。当数据规模变大的时候，Partition是唯一的选择，同时也会带来一些好处：</p><ul><li>提升性能和并发，操作被分发到不同的分片，相互独立</li><li>提升系统的可用性，即使部分分片不能用，其他分片不会受到影响</li></ul><p>理想的情况下，有分片就行了，但事实的情况却不大理想。</p><p>原因在于，分布式系统中有大量的节点，且通过网络通信。单个节点的故障（进程crash、断电、磁盘损坏）是个小概率事件，但整个系统的故障率会随节点的增加而指数级增加，网络通信也可能出现断网、高延迟的情况。在这种一定会出现的“异常”情况下，分布式系统还是需要继续稳定的对外提供服务，即需要较强的容错性。最简单的办法，就是冗余或者复制集（Replication），即多个节点负责同一个任务，最为常见的就是分布式存储中，多个节点复杂存储同一份数据，以此增强可用性与可靠性。同时，Replication也会带来性能的提升，比如数据的locality可以减少用户的等待时间。</p><p><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/img.png"></p><p>Partition和Replication是解决分布式系统问题的一记组合拳，很多具体的问题都可以用这个思路去解决。但这并不是银弹，往往是为了解决一个问题，会引入更多的问题，比如为了可用性与可靠性保证，引用了冗余（复制集）。有了冗余，各个副本间的一致性问题就变得很头疼，一致性在系统的角度和用户的角度又有不同的等级划分。如果要保证强一致性，那么会影响可用性与性能，在一些应用（比如电商、搜索）是难以接受的。如果是最终一致性，那么就需要处理数据冲突的情况。CAP、FLP这些理论告诉我们，在分布式系统中，没有最佳的选择，都是需要权衡，做出最合适的选择。</p><h2 id="分布式系统面临的挑战"><a href="#分布式系统面临的挑战" class="headerlink" title="分布式系统面临的挑战"></a>分布式系统面临的挑战</h2><ul><li><p>异构的机器与网络：</p><p>  分布式系统中的机器，配置不一样，其上运行的服务也可能由不同的语言、架构实现，因此处理能力也不一样；节点间通过网络连接，而不同网络运营商提供的网络的带宽、延时、丢包率又不一样。怎么保证大家齐头并进，共同完成目标，这四个不小的挑战。</p></li><li><p>普遍的节点故障：</p><p>  虽然单个节点的故障概率较低，但节点数目达到一定规模，出故障的概率就变高了。分布式系统需要保证故障发生的时候，系统仍然是可用的，这就需要监控节点的状态，在节点故障的情况下将该节点负责的计算、存储任务转移到其他节点</p></li><li><p>不可靠的网络：</p><p>  节点间通过网络通信，而网络是不可靠的。可能的网络问题包括：网络分割、延时、丢包、乱序。</p><p>  相比单机过程调用，网络通信最让人头疼的是超时：节点A向节点B发出请求，在约定的时间内没有收到节点B的响应，那么B是否处理了请求，这个是不确定的，这个不确定会带来诸多问题，最简单的，是否要重试请求，节点B会不会多次处理同一个请求。</p></li></ul><p>总而言之，分布式的挑战来自<strong>不确定性</strong>，不确定计算机什么时候crash、断电，不确定磁盘什么时候损坏，不确定每次网络通信要延迟多久，也不确定通信对端是否处理了发送的消息。而分布式的规模放大了这个不确定性，不确定性是令人讨厌的，所以有诸多的分布式理论、协议来保证在这种不确定性的情况下，系统还能继续正常工作。</p><h2 id="分布式系统特性与衡量标准"><a href="#分布式系统特性与衡量标准" class="headerlink" title="分布式系统特性与衡量标准"></a>分布式系统特性与衡量标准</h2><ul><li><p><strong>透明性</strong><br>使用分布式系统的用户并不关心系统是怎么实现的，也不关心读到的数据来自哪个节点，对用户而言，分布式系统的最高境界是用户根本感知不到这是一个分布式系统。</p></li><li><p><strong>可扩展性</strong><br>分布式系统的根本目标就是为了处理单个计算机无法处理的任务，当任务增加的时候，分布式系统的处理能力需要随之增加。简单来说，要比较方便的通过增加机器来应对数据量的增长，同时，当任务规模缩减的时候，可以撤掉一些多余的机器，达到动态伸缩的效果</p></li><li><p><strong>可用性与可靠性</strong><br>一般来说，分布式系统是需要长时间甚至7*24小时提供服务的。可用性是指系统在各种情况对外提供服务的能力，简单来说，可以通过不可用时间与正常服务时间的必知来衡量；而可靠性而是指计算结果正确、存储的数据不丢失。</p></li><li><p><strong>高性能</strong><br>不管是单机还是分布式系统，大家都非常关注性能。不同的系统对性能的衡量指标是不同的，最常见的：高并发，单位时间内处理的任务越多越好；低延迟：每个任务的平均时间越少越好。这个其实跟操作系统CPU的调度策略很像</p></li><li><p><strong>一致性</strong><br>分布式系统为了提高可用性可靠性，一般会引入冗余（复制集）。那么如何保证这些节点上的状态一致，这就是分布式系统不得不面对的一致性问题。一致性有很多等级，一致性越强，对用户越友好，但会制约系统的可用性；一致性等级越低，用户就需要兼容数据不一致的情况，但系统的可用性、并发性很高很多。</p></li></ul><h2 id="一个简化的架构图"><a href="#一个简化的架构图" class="headerlink" title="一个简化的架构图"></a>一个简化的架构图</h2><p><img src="/2021/07/09/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/img_2.png" alt="img.png"></p><h3 id="概念及其实现"><a href="#概念及其实现" class="headerlink" title="概念及其实现"></a>概念及其实现</h3><p>负载均衡：<br>Nginx：高性能、高并发的web服务器；功能包括负载均衡、反向代理、静态内容缓存、访问控制；工作在应用层</p><p>LVS： Linux virtual server，基于集群技术和Linux操作系统实现一个高性能、高可用的服务器；工作在网络层</p><p>webserver：<br>Java：Tomcat，Apache，Jboss</p><p>Python：gunicorn、uwsgi、twisted、webpy、tornado</p><p>service：<br>SOA、微服务、spring boot，django</p><p>容器：<br>docker，kubernetes</p><p>cache：<br>memcache、redis等</p><p>协调中心：<br>zookeeper、etcd等</p><p>zookeeper使用了Paxos协议Paxos是强一致性，高可用的去中心化分布式。zookeeper的使用场景非常广泛，之后细讲。</p><p>rpc框架：<br>grpc、dubbo、brpc</p><p>dubbo是阿里开源的Java语言开发的高性能RPC框架，在阿里系的诸多架构中，都使用了dubbo + spring boot</p><p>消息队列：<br>kafka、rabbitMQ、rocketMQ、QSP</p><p>消息队列的应用场景：异步处理、应用解耦、流量削锋和消息通讯</p><p>实时数据平台：<br>storm、akka</p><p>离线数据平台：<br>hadoop、spark</p><p>PS: spark、akka、kafka都是scala语言写的，看到这个语言还是很牛逼的</p><p>dbproxy：<br>cobar也是阿里开源的，在阿里系中使用也非常广泛，是关系型数据库的sharding + replica 代理</p><p>db：<br>mysql、oracle、MongoDB、HBase</p><p>搜索：<br>elasticsearch、solr</p><p>日志：<br>rsyslog、elk、flume</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是分布式系统&quot;&gt;&lt;a href=&quot;#什么是分布式系统&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式系统&quot;&gt;&lt;/a&gt;什么是分布式系统&lt;/h2&gt;&lt;p&gt;分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。&lt;/</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="设计理念" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>高并发系统03之高并发三大利器之降级</title>
    <link href="http://example.com/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%8D%E7%BA%A7/"/>
    <id>http://example.com/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F03%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%8D%E7%BA%A7/</id>
    <published>2021-07-09T08:28:03.000Z</published>
    <updated>2021-07-14T08:49:21.170Z</updated>
    
    <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h3 id="什么是服务降级"><a href="#什么是服务降级" class="headerlink" title="什么是服务降级"></a>什么是服务降级</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。</span><br></pre></td></tr></table></figure><p>服务降级主要用于当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，将一些 不重要 或 不紧急 的服务或任务进行服务的 <strong>延迟使用</strong> 或 <strong>暂停使用</strong>。</p><p>降级就是为了解决资源不足和访问量增加的矛盾。</p><h3 id="服务降级方式"><a href="#服务降级方式" class="headerlink" title="服务降级方式"></a>服务降级方式</h3><ul><li><strong>延迟服务</strong>：定时任务处理、或者mq延时处理。比如新用户注册送多少优惠券可以提示用户优惠券会24小时到达用户账号中，我们可以选择再凌晨流量较小的时候，批量去执行送券</li><li><strong>页面降级</strong>：页面点击按钮全部置灰，或者页面调整成为一个静态页面显示“系统正在维护中，。。。。”。</li><li><strong>关闭非核心服务</strong>：比如电商关闭推荐服务、关闭运费险、退货退款等。保证主流程的核心服务下单付款就好。</li><li><strong>写降级</strong>：比如秒杀抢购，我们可以只进行Cache的更新返回，然后通过mq异步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。</li><li><strong>读降级</strong>：比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景。</li></ul><h3 id="服务熔断"><a href="#服务熔断" class="headerlink" title="服务熔断"></a>服务熔断</h3><h4 id="服务雪崩"><a href="#服务雪崩" class="headerlink" title="服务雪崩"></a>服务雪崩</h4><p>多个微服务之间调用的时候，比如A服务调用了B服务，B服务调用了C服务，然后C服务由于机器宕机或者网略故障， 然后就会导致B服务调用C服务的时候超时，然后A服务调用B服务也会超时，最终整个链路都不可用了，导致整个系统不可用就跟雪蹦一样。</p><h4 id="雪崩效应产生的几种场景"><a href="#雪崩效应产生的几种场景" class="headerlink" title="雪崩效应产生的几种场景"></a>雪崩效应产生的几种场景</h4><p><strong>突增流量</strong>：比如一大波爬虫，或者黑客攻击等。<br><strong>程序bug</strong>：代码死循环，或者资源未释放等。<br><strong>硬件原因</strong>：机器宕机、机房断电、光纤被挖断等。  </p><h4 id="服务熔断-1"><a href="#服务熔断-1" class="headerlink" title="服务熔断"></a>服务熔断</h4><p>熔断机制是应对雪崩效应的一种微服务链路保护机制，在互联网系统中当下游的服务因为某种原因突然变得不可用或响应过慢，上游服务为了保证自己整体服务的可用性，暂时不再继续调用目标服务，直接快速返回，快速释放资源。如果目标服务情况好转则恢复调用。</p><h3 id="熔断和降级的比较"><a href="#熔断和降级的比较" class="headerlink" title="熔断和降级的比较"></a>熔断和降级的比较</h3><h4 id="共性"><a href="#共性" class="headerlink" title="共性"></a>共性</h4><ul><li>目的很一致：都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段，都是为了保证系统的稳定。</li><li>最终表现类似:对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用；</li><li>粒度一般都是服务级别:当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）；</li><li>自治性要求很高: 熔断模式一般都是服务基于策略的自动触发，比如</li><li>降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段；</li></ul><h4 id="差异性"><a href="#差异性" class="headerlink" title="差异性"></a>差异性</h4><ul><li>触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；</li><li>管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）熔断是降级方式的一种体现。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;高并发三大利器&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹&lt;/li&gt;
&lt;li&gt;降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="高并发" scheme="http://example.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
    <category term="降级" scheme="http://example.com/tags/%E9%99%8D%E7%BA%A7/"/>
    
  </entry>
  
  <entry>
    <title>高并发系统02之高并发三大利器之缓存</title>
    <link href="http://example.com/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/"/>
    <id>http://example.com/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/</id>
    <published>2021-07-09T08:27:12.000Z</published>
    <updated>2021-07-14T08:49:21.143Z</updated>
    
    <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h2 id="缓存分类"><a href="#缓存分类" class="headerlink" title="缓存分类"></a>缓存分类</h2><ul><li>分布式缓存： 如redis、memcached等</li><li>本地（进程内）缓存： 如ehcache、GuavaCache、Caffeine等</li></ul><h2 id="缓存特性"><a href="#缓存特性" class="headerlink" title="缓存特性"></a>缓存特性</h2><h3 id="命中率"><a href="#命中率" class="headerlink" title="命中率"></a>命中率</h3><p>命中率=命中数/（命中数+没有命中数）当某个请求能够通过访问缓存而得到响应时，称为缓存命中。缓存命中率越高，缓存的利用率也就越高。</p><h3 id="最大空间"><a href="#最大空间" class="headerlink" title="最大空间"></a>最大空间</h3><p>缓存中可以容纳最大元素的数量。当缓存存放的数据超过最大空间时，就需要根据淘汰算法来淘汰部分数据存放新到达的数据。</p><h3 id="淘汰算法"><a href="#淘汰算法" class="headerlink" title="淘汰算法"></a>淘汰算法</h3><p>缓存的存储空间有限制，当缓存空间被用满时，如何保证在稳定服务的同时有效提升命中率？这就由缓存淘汰算法来处理，设计适合自身数据特征的淘汰算法能够有效提升缓存命中率。<br>常见的淘汰算法有：</p><ul><li><p>FIFO(first in first out)「先进先出」<br>最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。「适用于保证高频数据有效性场景，优先保障最新数据可用」。</p></li><li><p>LFU(less frequently used)「最少使用」<br>无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。「适用于保证高频数据有效性场景」。</p></li><li><p>LRU(least recently used)「最近最少使用」<br>无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。「比较适用于热点数据场景，优先保证热点数据的有效性。」</p></li></ul><h2 id="本地缓存"><a href="#本地缓存" class="headerlink" title="本地缓存"></a>本地缓存</h2><p>常见本地缓存有以下几种实现方式：</p><p><img src="/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F02%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E7%BC%93%E5%AD%98/img.png"></p><p>其中性能最佳的是Caffeine，了解更详细信息参考： <a href="https://mp.weixin.qq.com/s?__biz=MzIyMjQwMTgyNA==&mid=2247483811&idx=1&sn=9d0b207044b5fe447169d630a7f77aab&scene=21#wechat_redirect">本地缓存性能之王</a></p><h2 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h2><p>分布式缓存详细信息参考redis系列文章</p><h2 id="缓存更新方案"><a href="#缓存更新方案" class="headerlink" title="缓存更新方案"></a>缓存更新方案</h2><p>我们一般的缓存更新主要有以下几种更新策略：</p><ul><li>先更新缓存，再更新数据库</li><li>先更新数据库，再更新缓存</li><li>先删除缓存，再更新数据库</li><li>先更新数据源库，再删除缓存</li></ul><p>至于选择哪种更新策略的话，没有绝对的选择，可以根据自己的业务情况来选择适合自己的。<br>不过一般推荐的话是选择 「<strong>先更新数据源库，再删除缓存</strong>」。</p><h2 id="缓存常见问题"><a href="#缓存常见问题" class="headerlink" title="缓存常见问题"></a>缓存常见问题</h2><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>大量查询数据库不存在数据，缓存无数据，大量无效请求落库。</p><p>解决方案</p><ul><li>数据库不存在数据写空值入缓存</li></ul><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>大规模缓存崩溃，大量请求落库。</p><p>解决方案</p><ul><li>事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。</li><li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li><li>事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>热点key失效瞬间大量请求落库。</p><p>解决方案</p><ul><li>基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>更新不频繁且更新时间段，加互斥锁保证少量请求重建缓存。</li><li>数据更新频繁或更新时间长，定时线程主动重建缓存。</li></ul><h3 id="缓存双写一致性"><a href="#缓存双写一致性" class="headerlink" title="缓存双写一致性"></a>缓存双写一致性</h3><p>缓存使用方法：<br>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。<br>更新的时候，先更新数据库，然后再删除缓存。</p><p>不一致解决方案</p><ul><li>初级：先删除缓存，再更新数据库。</li><li>高并发：使用队列做轻异步，多个并发更新请求阻塞过滤。（必须压测防止长时间阻塞积压）</li></ul><h3 id="redis并发竞争"><a href="#redis并发竞争" class="headerlink" title="redis并发竞争"></a>redis并发竞争</h3><p>多客户端同时并发写key，后来的数据先改。</p><p>解决方案：</p><ul><li>Redis存在CAS方案</li><li>实现分布式锁</li><li>写前判断版本号</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;高并发三大利器&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹&lt;/li&gt;
&lt;li&gt;降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="高并发" scheme="http://example.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
    <category term="缓存" scheme="http://example.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>高并发系统01之高并发三大利器之限流</title>
    <link href="http://example.com/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/"/>
    <id>http://example.com/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/</id>
    <published>2021-07-09T07:54:02.000Z</published>
    <updated>2021-07-14T08:49:21.177Z</updated>
    
    <content type="html"><![CDATA[<p><strong>高并发三大利器</strong></p><ul><li>缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹</li><li>降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开</li><li>限流  –  通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）、特权处理(优先处理需要高保障的用户群体)</li></ul><h2 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h2><h3 id="快速失败-–-滑动时间窗口"><a href="#快速失败-–-滑动时间窗口" class="headerlink" title="快速失败 – 滑动时间窗口"></a>快速失败 – 滑动时间窗口</h3><p>滑动窗口算法是将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期<br><img src="/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/%E6%BB%91%E5%8A%A8%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3.png"></p><h3 id="排队等待-漏桶算法"><a href="#排队等待-漏桶算法" class="headerlink" title="排队等待 - 漏桶算法"></a>排队等待 - 漏桶算法</h3><p>漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。<br><img src="/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/%E6%BC%8F%E6%A1%B6%E7%AE%97%E6%B3%95.png" alt="漏桶算法"></p><p>首先，我们有一个固定容量的桶，有水流进来，也有水流出去。对于流进来的水来说，我们无法预计一共有多少水会流进来，也无法预计水流的速度。但是对于流出去的水来说，这个桶可以固定水流出的速率。而且，当桶满了之后，多余的水将会溢出。</p><p>我们将算法中的水换成实际应用中的请求，我们可以看到漏桶算法天生就限制了请求的速度。当使用了漏桶算法，我们可以保证接口会以一个常速速率来处理请求。所以漏桶算法天生不会出现临界问题。<br>漏桶算法可以粗略的认为就是注水漏水过程，往桶中<strong>以一定速率流出水，以任意速率流入水</strong>，当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。</p><h3 id="Warm-Up-令牌桶算法"><a href="#Warm-Up-令牌桶算法" class="headerlink" title="Warm Up - 令牌桶算法"></a>Warm Up - 令牌桶算法</h3><p>首先，我们有一个固定容量的桶，桶里存放着令牌（token）。<br>桶一开始是空的，token以 一个固定的速率r往桶里填充，直到达到桶的容量，多余的令牌将会被丢弃。<br>每当一个请求过来时，就会尝试从桶里移除一个令牌，如果没有令牌的话，请求无法通过。</p><p><img src="/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/aegar-6o1hz.png"></p><h4 id="解决问题："><a href="#解决问题：" class="headerlink" title="解决问题："></a>解决问题：</h4><ul><li>Warm Up（冷启动/预热）：通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。</li></ul><h3 id="各算法适用场景"><a href="#各算法适用场景" class="headerlink" title="各算法适用场景"></a>各算法适用场景</h3><ul><li>计数法用于简单粗暴的连接池数量等。</li><li>令牌桶可以用来保护自己，主要用来对调用者频率进行限流，为的是让自己不被打垮。所以如果自己本身有处理能力的时候，如果流量突发（实际消费能力强于配置的流量限制），那么实际处理速率可以超过配置的限制。</li><li>漏桶算法，这是用来保护他人，也就是保护他所调用的系统。主要场景是，当调用的第三方系统本身没有保护机制，或者有流量限制的时候，我们的调用速度不能超过他的限制，由于我们不能更改第三方系统，所以只有在主调方控制。这个时候，即使流量突发，也必须舍弃。因为消费能力是第三方决定的。</li></ul><p>** 简单粗暴场景用计数法。如果要让自己的系统不被打垮，用令牌桶。如果保证别人的系统不被打垮，用漏桶。**</p><h2 id="流量控制组件对比"><a href="#流量控制组件对比" class="headerlink" title="流量控制组件对比"></a>流量控制组件对比</h2><p><img src="/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F01%E4%B9%8B%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%89%E5%A4%A7%E5%88%A9%E5%99%A8%E4%B9%8B%E9%99%90%E6%B5%81/aegar-6o1hz.png"></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.cnblogs.com/xuwc/p/9123078.html">高并发系统限流-漏桶算法和令牌桶算法</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;高并发三大利器&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存  –  缓存目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹&lt;/li&gt;
&lt;li&gt;降级  –  当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="高并发" scheme="http://example.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
    <category term="限流" scheme="http://example.com/tags/%E9%99%90%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>高并发系统00之如何设计一个高并发系统</title>
    <link href="http://example.com/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/</id>
    <published>2021-07-09T07:08:32.000Z</published>
    <updated>2021-07-14T08:49:21.128Z</updated>
    
    <content type="html"><![CDATA[<p>为啥会有高并发？为啥高并发就很牛逼？</p><p>很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。<br>所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。</p><p>设计一个高并发系统可以简单分为以下 6 点：</p><ul><li>系统拆分</li><li>缓存</li><li>MQ</li><li>分库分表</li><li>读写分离</li><li>ElasticSearch</li></ul><p><img src="/2021/07/09/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F00%E4%B9%8B%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/img_1.png" alt="img.png"></p><h3 id="系统拆分"><a href="#系统拆分" class="headerlink" title="系统拆分"></a>系统拆分</h3><p>将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存，必须得用缓存。大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。</p><h3 id="MQ"><a href="#MQ" class="headerlink" title="MQ"></a>MQ</h3><p>MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。</p><h3 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h3><p>分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 sql 跑的性能。</p><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。</p><h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><p>Elasticsearch，简称 ES。</p><p>ES 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;为啥会有高并发？为啥高并发就很牛逼？&lt;/p&gt;
&lt;p&gt;很简单，就是因为刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。&lt;br&gt;所以才有说，很多公司，刚开始干的时候，技术比较 low，结果业务发展太快，有的时候系统扛不住压力就挂了。&lt;/p&gt;</summary>
      
    
    
    
    <category term="JAVA开发" scheme="http://example.com/categories/JAVA%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="设计理念" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/"/>
    
    <category term="高并发" scheme="http://example.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>消息中间件Kafka系列01之Kafka为什么这么快</title>
    <link href="http://example.com/2021/07/09/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/"/>
    <id>http://example.com/2021/07/09/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/</id>
    <published>2021-07-09T06:12:42.000Z</published>
    <updated>2021-07-14T08:49:21.097Z</updated>
    
    <content type="html"><![CDATA[<ul><li>partition 并行处理</li><li>顺序写磁盘，充分利用磁盘特性</li><li>利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率</li><li>采用了零拷贝技术</li><li>Producer 生产的数据持久化到 broker，采用 mmap 文件映射，实现顺序的快速写入</li><li>Customer 从 broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer进行网络发送，减少 CPU 消耗</li></ul><h2 id="详细解读"><a href="#详细解读" class="headerlink" title="详细解读"></a>详细解读</h2><p>无论 kafka 作为 MQ 也好，作为存储层也罢，无非就是两个功能（好简单的样子），一是 Producer 生产的数据存到 broker，二是 Consumer 从 broker 读取数据。那 Kafka 的快也就体现在读写两个方面了，下面我们就聊聊 Kafka 快的原因。</p><h3 id="利用-Partition-实现并行处理"><a href="#利用-Partition-实现并行处理" class="headerlink" title="利用 Partition 实现并行处理"></a>利用 Partition 实现并行处理</h3><p>我们都知道 Kafka 是一个 Pub-Sub 的消息系统，无论是发布还是订阅，都要指定 Topic。</p><p>Topic 只是一个逻辑的概念。每个 Topic 都包含一个或多个 Partition，不同 Partition 可位于不同节点。</p><p>一方面，由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。</p><p>能并行处理，速度肯定会有提升，多个工人肯定比一个工人干的快。</p><h3 id="顺序写磁盘"><a href="#顺序写磁盘" class="headerlink" title="顺序写磁盘"></a>顺序写磁盘</h3><p><img src="/2021/07/09/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img.png"><br>Kafka 中每个分区是一个有序的，不可变的消息序列，新的消息不断追加到 partition 的末尾，这个就是顺序写。</p><p>由于磁盘有限，不可能保存所有数据，实际上作为消息系统 Kafka 也没必要保存所有数据，需要删除旧的数据。</p><p>又由于顺序写入的原因，所以 Kafka 采用各种删除策略删除数据的时候，并非通过使用“读 - 写”模式去修改文件，而是将 Partition 分为多个 Segment，每个 Segment 对应一个物理文件，通过删除整个文件的方式去删除 Partition 内的数据。这种方式清除旧数据的方式，也避免了对文件的随机写操作。</p><h4 id="简单扯扯磁盘-IO-的那些事"><a href="#简单扯扯磁盘-IO-的那些事" class="headerlink" title="简单扯扯磁盘/IO 的那些事"></a>简单扯扯磁盘/IO 的那些事</h4><p>硬盘性能的制约因素是什么？如何根据磁盘I/O特性来进行系统设计？<br>硬盘内部主要部件为磁盘盘片、传动手臂、读写磁头和主轴马达。<br>实际数据都是写在盘片上，读写主要是通过传动手臂上的读写磁头来完成。实际运行时，主轴让磁盘盘片转动，然后传动手臂可伸展让读取头在盘片上进行读写操作。磁盘物理结构如下图所示：</p><p><img src="/2021/07/09/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img2.png"></p><p>由于单一盘片容量有限，一般硬盘都有两张以上的盘片，每个盘片有两面，都可记录信息，所以一张盘片对应着两个磁头。盘片被分为许多扇形的区域，每个区域叫一个扇区。盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用。磁盘盘片垂直视角如下图所示：</p><p><img src="/2021/07/09/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img1.png"></p><p>影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由寻道时间、旋转延迟和数据传输时间三部分构成。<br>机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是IOPS和吞吐量。<br>在许多的开源框架如 Kafka、HBase 中，都通过追加写的方式来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。  </p><p>感兴趣的同学可以看看 <a href="https://link.zhihu.com/?target=https://tech.meituan.com/2017/05/19/about-desk-io.html">磁盘I/O那些事</a></p><p>磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。</p><h3 id="充分利用-Page-Cache"><a href="#充分利用-Page-Cache" class="headerlink" title="充分利用 Page Cache"></a>充分利用 Page Cache</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache。</span><br><span class="line">  每一个 Page Cache 包含若干 Buffer Cache。</span><br><span class="line">* Page Cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read/write 操作的时候。</span><br><span class="line">* Buffer Cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。</span><br></pre></td></tr></table></figure><p>使用 Page Cache 的好处：</p><ul><li>I/O Scheduler 会将连续的小块写组装成大块的物理写从而提高性能</li><li>I/O Scheduler 会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</li><li>充分利用所有空闲内存（非 JVM 内存）。如果使用应用层 Cache（即 JVM 堆内存），会增加 GC 负担</li><li>读操作可直接在 Page Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 Page Cache）交换数据</li><li>如果进程重启，JVM 内的 Cache 会失效，但 Page Cache 仍然可用</li></ul><p>Broker 收到数据后，写磁盘时只是将数据写入 Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache 内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由 Kafka 层面的 Replication 机制去解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。也正因如此，Kafka 虽然提供了 flush.messages 和 flush.ms 两个参数将 Page Cache 中的数据强制 Flush 到磁盘，但是 Kafka 并不建议使用。</p><h3 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h3><p>Kafka 中存在大量的网络数据持久化到磁盘（Producer 到 Broker）和磁盘文件通过网络发送（Broker 到 Consumer）的过程。这一过程的性能直接影响 Kafka 的整体吞吐量。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的权限。</span><br><span class="line">为了避免用户进程直接操作内核，保证内核安全，操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space），一部分是用户空间（User-space）。</span><br></pre></td></tr></table></figure><p>传统的 Linux 系统中，标准的 I/O 接口（例如read，write）都是基于数据拷贝操作的，即 I/O 操作会导致数据在内核地址空间的缓冲区和用户地址空间的缓冲区之间进行拷贝，所以标准 I/O 也被称作缓存 I/O。这样做的好处是，如果所请求的数据已经存放在内核的高速缓冲存储器中，那么就可以减少实际的 I/O 操作，但坏处就是数据拷贝的过程，会导致 CPU 开销。</p><p>我们把 Kafka 的生产和消费简化成如下两个过程来看：</p><ul><li>网络数据持久化到磁盘 (Producer 到 Broker)</li><li>磁盘文件通过网络发送（Broker 到 Consumer）</li></ul><h4 id="1-网络数据持久化到磁盘-Producer-到-Broker"><a href="#1-网络数据持久化到磁盘-Producer-到-Broker" class="headerlink" title="1) 网络数据持久化到磁盘 (Producer 到 Broker)"></a>1) 网络数据持久化到磁盘 (Producer 到 Broker)</h4><p>传统模式下，数据从网络传输到文件需要 4 次数据拷贝、4 次上下文切换和两次系统调用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = socket.read()// 读取网络数据 </span><br><span class="line">File file = new File() </span><br><span class="line">file.write(data)// 持久化到磁盘 </span><br><span class="line">file.flush()</span><br></pre></td></tr></table></figure><p>这一过程实际上发生了四次数据拷贝：</p><ul><li>首先通过 DMA copy 将网络数据拷贝到内核态 Socket Buffer</li><li>然后应用程序将内核态 Buffer 数据读入用户态（CPU copy）</li><li>接着用户程序将用户态 Buffer 再拷贝到内核态（CPU copy）</li><li>最后通过 DMA copy 将数据拷贝到磁盘文件</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DMA（Direct Memory Access）：直接存储器访问。DMA 是一种无需 CPU 的参与，让外设和系统内存之间进行双向数据传输的硬件机制。使用 DMA 可以使系统 CPU 从实际的 I/O 数据传输过程中摆脱出来，从而大大提高系统的吞吐率。</span><br></pre></td></tr></table></figure><p>其中伴随着四次上下文切换，如图所示</p><p><img src="/2021/07/09/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img3.png"></p><p>数据落盘通常都是非实时的，kafka 生产者数据持久化也是如此。Kafka 的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高 I/O 效率，就是上一节提到的 Page Cache。</p><p>对于 kafka 来说，Producer 生产的数据存到 broker，这个过程读取到 socket buffer 的网络数据，其实可以直接在内核空间完成落盘。并没有必要将 socket buffer 的网络数据，读取到应用进程缓冲区；在这里应用进程缓冲区其实就是 broker，broker 收到生产者的数据，就是为了持久化。</p><p><strong>在此特殊场景下</strong>：接收来自 socket buffer 的网络数据，应用进程不需要中间处理、直接进行持久化时。可以使用 <strong>mmpp</strong> 内存文件映射。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Memory Mapped Files：简称 mmap，也有叫 MMFile 的，使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射。从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程。它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。</span><br><span class="line">使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销。</span><br><span class="line">mmap 也有一个很明显的缺陷——不可靠，写到 mmap 中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。Kafka 提供了一个参数——producer.type 来控制是不是主动flush；如果 Kafka 写入到 mmap 之后就立即 flush 然后再返回 Producer 叫同步(sync)；写入 mmap 之后立即返回 Producer 不调用 flush 就叫异步(async)，默认是 sync。</span><br></pre></td></tr></table></figure><p><img src="/2021/07/09/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img4.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。</span><br><span class="line">它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。</span><br><span class="line">目前零拷贝技术主要有三种类型：</span><br><span class="line">直接I/O：</span><br><span class="line">        数据直接跨过内核，在用户地址空间与I/O设备之间传递，内核只是进行必要的虚拟存储配置等辅助工作；</span><br><span class="line">避免内核和用户空间之间的数据拷贝：</span><br><span class="line">        当应用程序不需要对数据进行访问时，则可以避免将数据从内核空间拷贝到用户空间</span><br><span class="line">        * mmap</span><br><span class="line">        * sendfile</span><br><span class="line">        * splice &amp;&amp; tee</span><br><span class="line">        * sockmap</span><br><span class="line">copy on write：</span><br><span class="line">        写时拷贝技术，数据不需要提前拷贝，而是当需要修改的时候再进行部分拷贝。</span><br></pre></td></tr></table></figure><h4 id="2-磁盘文件通过网络发送（Broker-到-Consumer）"><a href="#2-磁盘文件通过网络发送（Broker-到-Consumer）" class="headerlink" title="2) 磁盘文件通过网络发送（Broker 到 Consumer）"></a>2) 磁盘文件通过网络发送（Broker 到 Consumer）</h4><p>传统方式实现：先读取磁盘、再用 socket 发送，实际也是进过四次 copy</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buffer = File.read</span><br><span class="line">Socket.send(buffer)</span><br></pre></td></tr></table></figure><p>这一过程可以类比上边的生产消息：</p><ul><li>首先通过系统调用将文件数据读入到内核态 Buffer（DMA 拷贝）</li><li>然后应用程序将内存态 Buffer 数据读入到用户态 Buffer（CPU 拷贝）</li><li>接着用户程序通过 Socket 发送数据时将用户态 Buffer 数据拷贝到内核态 Buffer（CPU 拷贝）</li><li>最后通过 DMA 拷贝将数据拷贝到 NIC Buffer </li></ul><p>Linux 2.4+ 内核通过 sendfile 系统调用，提供了零拷贝。数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer，无需 CPU 拷贝。这也是零拷贝这一说法的来源。除了减少数据拷贝外，因为整个读文件 - 网络发送由一个 sendfile 调用完成，整个过程只有两次上下文切换，因此大大提高了性能。</p><p><img src="/2021/07/09/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6Kafka%E7%B3%BB%E5%88%9701%E4%B9%8BKafka%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/img5.png"></p><p>Kafka 在这里采用的方案是通过 NIO 的 transferTo/transferFrom 调用操作系统的 sendfile 实现零拷贝。总共发生 2 次内核数据拷贝、2 次上下文切换和一次系统调用，消除了 CPU 数据拷贝</p><h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>在很多情况下，系统的瓶颈不是 CPU 或磁盘，而是网络IO。</p><p>因此，除了操作系统提供的低级批处理之外，Kafka 的客户端和 broker 还会在通过网络发送数据之前，在一个批处理中累积多条记录 (包括读和写)。记录的批处理分摊了网络往返的开销，使用了更大的数据包从而提高了带宽利用率。</p><h3 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h3><p>Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;partition 并行处理&lt;/li&gt;
&lt;li&gt;顺序写磁盘，充分利用磁盘特性&lt;/li&gt;
&lt;li&gt;利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率&lt;/li&gt;
&lt;li&gt;采用了零拷贝技术&lt;/li&gt;
&lt;li&gt;Producer 生产的数据持久</summary>
      
    
    
    
    <category term="中间件" scheme="http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="消息中间件" scheme="http://example.com/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    <category term="MQ" scheme="http://example.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>数据库MySQL系列01之死锁原理及其解决方案研究</title>
    <link href="http://example.com/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/"/>
    <id>http://example.com/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/</id>
    <published>2021-07-09T05:36:08.000Z</published>
    <updated>2021-07-14T08:49:21.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是死锁"><a href="#什么是死锁" class="headerlink" title="什么是死锁"></a>什么是死锁</h1><p>死锁是并发系统中常见的问题，同样也会出现在数据库MySQL的并发读写请求场景中。<br>当两个及以上的事务，双方都在等待对方释放已经持有的锁或因为加锁顺序不一致造成循环等待锁资源，就会出现“死锁”。<br>常见的报错信息为 Deadlock found when trying to get lock…<br>举例来说 A 事务持有 X1 锁 ，申请 X2 锁，B事务持有 X2 锁，申请 X1 锁。A 和 B 事务持有锁并且申请对方持有的锁进入循环等待，就造成了死锁。</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img.png" alt="死锁示例图"></p><p>如上图，是右侧的四辆汽车资源请求产生了回路现象，即死循环，导致了死锁。</p><h1 id="死锁出现要素"><a href="#死锁出现要素" class="headerlink" title="死锁出现要素"></a>死锁出现要素</h1><ul><li>两个或者两个以上事务</li><li>每个事务都已经持有锁并且申请新的锁</li><li>锁资源同时只能被同一个事务持有或者不兼容</li><li>事务之间因为持有锁和申请锁导致彼此循环等待</li></ul><h1 id="经典案例"><a href="#经典案例" class="headerlink" title="经典案例"></a>经典案例</h1><h2 id="案例一-事务并发-insert-唯一键冲突"><a href="#案例一-事务并发-insert-唯一键冲突" class="headerlink" title="案例一:事务并发 insert 唯一键冲突"></a>案例一:事务并发 insert 唯一键冲突</h2><p>表结构如下所示:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_1.png" alt="事务并发insert表结构"></p><p>测试用例如下:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_2.png" alt="事务并发insert测试用例"></p><p>日志分析如下:</p><ul><li><p>事务 T2 insert into t7(id,a) values (26,10) 语句 insert 成功，持有 a=10 的 排他行锁( Xlocks rec but no gap )</p></li><li><p>事务 T1 insert into t7(id,a) values (30,10), 因为T2的第一条 insert 已经插入 a=10 的记录,事务 T1 insert a=10 则发生唯一键冲突,需要申请对冲突的唯一索引加上S Next-key Lock( 即 lock mode S waiting ) 这是一个间隙锁会申请锁住(,10],(10,20]之间的 gap 区域。</p></li><li><p>事务 T2 insert into t7(id,a) values (40，9)该语句插入的 a=9 的值在事务 T1 申请的 gap 锁4-10之间， 故需事务 T2 的第二条 insert 语句要等待事务 T1 的 S-Next-key Lock 锁释放,在日志中显示 lock_mode X locks gap before rec insert intention waiting 。</p></li></ul><h2 id="案例二-先-update-再-insert-的并发死锁问题"><a href="#案例二-先-update-再-insert-的并发死锁问题" class="headerlink" title="案例二:先 update 再 insert 的并发死锁问题"></a>案例二:先 update 再 insert 的并发死锁问题</h2><p>表结构如下，无数据:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_3.png" alt="先update再insert表结构"></p><p>测试用例如下:</p><p><img src="/2021/07/09/%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%B3%BB%E5%88%9701%E4%B9%8B%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E7%A0%94%E7%A9%B6/img_4.png" alt="先update再insert测试用例"></p><p>死锁分析:<br>可以看到两个事务 update 不存在的记录，先后获得间隙锁( gap 锁)，gap 锁之间是兼容的所以在update环节不会阻塞。</p><p>两者都持有 gap 锁，然后去竞争插入意向锁。当存在其他会话持有 gap 锁的时候，当前会话申请不了插入意向锁，导致死锁。</p><h1 id="如何尽可能避免死锁"><a href="#如何尽可能避免死锁" class="headerlink" title="如何尽可能避免死锁"></a>如何尽可能避免死锁</h1><ul><li><p>合理的设计索引，区分度高的列放到组合索引前面，使业务 SQL 尽可能通过索引定位更少的行，减少锁竞争。</p></li><li><p>调整业务逻辑 SQL 执行顺序， 避免 update/delete 长时间持有锁的 SQL 在事务前面。</p></li><li><p>避免大事务，尽量将大事务拆成多个小事务来处理，小事务发生锁冲突的几率也更小。</p></li><li><p>以固定的顺序访问表和行。比如两个更新数据的事务，事务 A 更新数据的顺序为 1，2;事务 B 更新数据的顺序为 2，1。这样更可能会造成死锁。</p></li><li><p>在并发比较高的系统中，不要显式加锁，特别是是在事务里显式加锁。如 select … for update 语句，如果是在事务里（运行了 start transaction 或设置了autocommit 等于0）,那么就会锁定所查找到的记录。</p></li><li><p>尽量按主键/索引去查找记录，范围查找增加了锁冲突的可能性，也不要利用数据库做一些额外额度计算工作。比如有的程序会用到 “select … where … order by rand();”这样的语句，由于类似这样的语句用不到索引，因此将导致整个表的数据都被锁住。</p></li><li><p>优化 SQL 和表设计，减少同时占用太多资源的情况。比如说，减少连接的表，将复杂 SQL 分解为多个简单的 SQL。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;什么是死锁&quot;&gt;&lt;a href=&quot;#什么是死锁&quot; class=&quot;headerlink&quot; title=&quot;什么是死锁&quot;&gt;&lt;/a&gt;什么是死锁&lt;/h1&gt;&lt;p&gt;死锁是并发系统中常见的问题，同样也会出现在数据库MySQL的并发读写请求场景中。&lt;br&gt;当两个及以上的事务，双方都在</summary>
      
    
    
    
    <category term="数据库" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="数据库" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="死锁" scheme="http://example.com/tags/%E6%AD%BB%E9%94%81/"/>
    
  </entry>
  
</feed>
